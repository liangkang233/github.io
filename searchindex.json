{"categories":[{"title":"Core","uri":"https://liangkang233.github.io/categories/core/"},{"title":"学习","uri":"https://liangkang233.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"title":"工具","uri":"https://liangkang233.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"title":"杂谈","uri":"https://liangkang233.github.io/categories/%E6%9D%82%E8%B0%88/"},{"title":"编程","uri":"https://liangkang233.github.io/categories/%E7%BC%96%E7%A8%8B/"},{"title":"记录","uri":"https://liangkang233.github.io/categories/%E8%AE%B0%E5%BD%95/"}],"posts":[{"content":"背景 最近刷B站 看到有人分享了个桌面摆件，看了下制作过程，原件不多 焊接也算简单。\n想到之前买的 GC9A01 也没用上，正好自己复刻一个桌面摆件吧。\n说干就干，打开 立创商城开始打板。\n硬件打板及焊接 Bom 表 ID Name Designator Footprint Quantity BOM_Manufacturer Part BOM_Manufacturer BOM_Supplier Part 1 100nF C1,C4,C5,C7 C0603 4 CL21B104KBCNNNC SAMSUNG C1711 2 10uf C2,C3 C0603 2 CL21B104KBCNNNC SAMSUNG C1711 3 ORH-G35A LED2,LED3 LED0603-R-RD_BLUE 2 ORH-G35A Orient C205442 4 470 R1,R3 R0603 2 MFR0W4F4701A50 UniOhm C57204 5 12K R5 R0603 1 MFR0W4F4701A50 UniOhm C57204 6 TS-1086E-AC03526 SW1,SW2 SW-SMD_TS-1086E-AC03526 2 TS-1086E-AC03526 XUNPU C720473 7 GC9A01 TFT1 GC9A01_B 1 FPC_LH128RIG01 Limito NULL 8 KH-TYPE-C-16P TYPE-C1 USB-C-SMD_KH-TYPE-C-16P 1 KH-TYPE-C-16P Shenzhen Kinghelm Elec C709357 9 RT9013-33GB U2 SOT-23-5_L3.0-W1.7-P0.95-LS2.8-BR 1 RT9013-33GB RICHTEK C47773 10 ESP32-S-P U11 WIRELM-SMD_ESP32-S 1 ESP32-S-P null C2764350 11 CH340N U3 SOP-8_L5.0-W4.0-P1.27-LS6.0-BL 1 CH340N WCH(Jiangsu Qin Heng) C506813 这里的 BOM 表在如果在导入到立创商城时 不知到为啥封装会变成 0805 的，还好下单前注意了下，应该是 0603的封装。\n开源板子链接\npcb设计基本可以不变，我为了它的保证它不要过厚就没改(懒得改)。可以直接用这个在线EDA操作并打板下单，不用装AD改板子还挺方便的。\n注意的是 这个走线是没有涉及到 圆屏的 LEDA 脚接到 默认接高 所以后面的代码是控制不了亮度的。。。\n在实验室翻了半天才找到了烙铁，省的买 等了好几天，器件 锡膏 Esp32模块 和 焊贴片用的简易加热板也到了，准备焊接。\n这个板子设计的 正面没有器件最后焊接上屏幕就行了，贴器件 加热焊锡膏还是很方便的。\n注意 发光二极管 在pcb丝印上 矩形的是正极，六边形的是负极，不要像我第一块板子一样焊反了。\n上次焊板子还是本科的时候，也算是好久没闻锡丝的臭味了🤣\n手生了，焊的很烂 第一个块板子 typec母座没焊好烧入不进去固件，第二块焊的不错 接屏幕时不小心连锡太多，也失败了。最后第三块总算焊接成功, 连锡处直接拖焊搞定。\n环境搭建 Esp32 有很多实用的 arduino 库，开发起来挺方便的，所以我选择 vscode 集成 的 PLatformIO 来开发工程，把B站老哥的代码和库拿来用下创个工程。由于初始化创建工程很慢，可以直接下载 离线包\n相关教程: PlatformIO+VScode+ESP32开发环境搭建教程\n相关模块库也可以 直接 下载，如下所示\n添加了按键模块，对下载按键添加切换功能。 像写 C++ 程序一样给 button 类 添加对应 单击 双击 的回调函数， 相关教程。芯片的模组IO编号和代码里设置的gpio编号不同，最好设置前查下。例如 此处按键的IO\nPlarformIO 包含了编译 下载 串口调试等功能。 点击 -\u0026gt; 按钮编译并下载后，程序显示烧录长按下载按钮即可下载固件。\n注意 这里的串口助手 第一次进入 需要下载插件可能会比较慢，进入后 输入 ctrl t + ctrl h 打印帮助信息。例如修改 连接波特率 使用命令 ctrl t + b。其命令的回显 修改默认 rts 为 0 不同步串口等此操作，可以放在配置文件 platformio.ini 中，以免每次进入需要修改。\n官方串口设置文档\n这里我就是没设置 rts = 0 导致进入串口 程序就卡住同步不再执行了。\n其次是 烧录问题 默认flash过小 编译会报错，修改下分区表即可：\nplatformio.ini 添加如下参数 board_build.partitions = partition.csv partition.csv 内容 # Name, Type, SubType, Offset, Size, Flags nvs, data, nvs, 0x9000, 0x5000, otadata, data, ota, 0xe000, 0x2000, app0, app, ota_0, 0x10000, 0x300000, spiffs, data, spiffs, 0x310000,0xF0000, 软件搬运 将原来的代码封装了下, Arduino ide中 的工程文件 ino 转为 cpp\n主函数如下所示:\n#include \u0026lt;Arduino.h\u0026gt; #include \u0026quot;mytools.h\u0026quot; //---------------初始wifi配置信息-------------------- const char ssid[] = \u0026quot;Xbox_Home\u0026quot;; // WIFI名称 const char pass[] = \u0026quot;liangkang233\u0026quot;; // WIFI密码 int LCD_BL_PWM = 200; // 屏幕亮度0-255 //---------------------------------------------------- static int last = -1; void setup() { Serial.begin(115200); key_setup(); tft_setup(); Smart_Config(ssid, pass); Serial.println(\u0026quot;Power your dreams!\u0026quot;); } void loop() { unsigned int now = get_flag(); if(last != now) { // 切换模式需要启动 清理函数 和 初始化函数 fun_clear(last); fun_setup(now); } fun_loop(now); last = now; } Arduino 代码 分为两部分，启动的初始化 以及 while 循环执行 loop\n剩下的 主要分为四部分\nsrc\\mytools.cpp 集成显示驱动 wifi微信配网 按键等功能模块。\nsrc\\getload.cpp 建立Http服务器，监听上位机发送的get请求 以解析并展示当前状态信息。\nsrc\\myclock.cpp 使用 udp 套接字和 http请求 获取ntp服务器时间天气等信息 显示时钟。上位机程序\nsrc\\remote_display.cpp 使用 tcp (建议后续改进为udp) 传输jpg图片流并刷新展示。上位机程序\n常用工具 也分享下：\ngif 转编码数组\njpg 转 16进制编码数组\n展示及总结 tft驱动库 和 其他 相关代码已经打包好了 托管到github上了\n时钟功能 无线投屏 显示pc主机性能占用 可惜的是 模组待机就发热严重，更别说跑上代码后了。只能放在桌上当摆件不太好把玩了。\n有机会的话会继续改良，设计个壳子 整漂亮点。\n","id":0,"section":"posts","summary":"背景 最近刷B站 看到有人分享了个桌面摆件，看了下制作过程，原件不多 焊接也算简单。 想到之前买的 GC9A01 也没用上，正好自己复刻一个桌面摆件吧。 说干就干，","tags":["C/C++","开发"],"title":"迷你桌面摆件","uri":"https://liangkang233.github.io/2022/08/%E6%A1%8C%E9%9D%A2%E6%91%86%E4%BB%B6/","year":"2022"},{"content":"最近在学习SRv6相关的知识, 实践方面参考这篇 使用 mininet的 博客。我这里使用 core 平台 搭建了个简易场景 体会 SRv6 整个数据的ip包的包装解析。二者都是使用轻量 lxc容器 模拟 SRv6路由器节点，使用quagga构建路由器间的路由表。在实践前 先学习相关理论知识。\nSRv6背景 在网络发展初期，ip网络的无连接尽力而为的设计理念战胜了类如采用固定长度信元交换的ATM等面向连接的设计理念的传输技术。随着后续的网络发展，为了满足IP网络QoS能力，开发了LANE，IPoA等，完成的比较好的是 MPLS (Multiprotocol Label Switching)。可以支撑TE (Traffic Engineering)、VPN和FRR等技术，其虚拟标签的的设计为无连接的IP网络保障QoS能力，还具备IP路由的灵活性。\n但是随着网络发展 IPv4地址耗尽需要扩展至IPv6，MPLS无法基于全局视角做出全局最优网络决策，数据面与控制面的紧密耦合等问题，逐渐有了SDN即为网络提供可编程能力的想法。\nSR技术是SDN竞争压力下的产物，其核心思想是将报文转发路径切割为不同的分段，并在路径起始点往报文中插入分段信息，中间节点只需要按照报文里携带的分段信息转发即可。这样的路径分段，称之为 “Segment” ，并通过SID（Segment Identifier，段标识）来标识。报文在SR技术的转发过程也是类似的。由上可知，SR技术关键在于两点：对路径进行分段 (Segment) 以及在起始节点对路径进行排序成表 (Segment List) ，确定出行路径。\n在SR技术中，将代表不同功能的Segment进行组合，可以实现对路径的编程，满足不同路径服务质量的需求。SR技术支持MPLS和IPv6两种转发平面，基于MPLS转发平面的SR称为 SR-MPLS（Segment Routing MPLS），其SID为MPLS标签（Label）；基于IPv6转发平面的SR称为 SRv6 ，其SID为IPv6地址。\nSRv6 技术使命 SRv6兼容IPv6的路由转发，基于IP可达性更加容易实现不同网络互联，不需要像MPLS那样使用额外信令，也不需要全网升级。 SRv6基于SRH ( Segment Routing Header, 段路由扩展报文头)能够支持更多种类的封装，可以很好地满足新业务的多样化需求。 SRv6对于IPv6的亲和性使得它能够将IP承载网与支持IPv6的应用无缝融合在一起，通过网络感知应用，使运营商可以提供更多可能的增值业务。 SRv6的设计 SRv6将网络比作计算机，类比计算机编程，将网络承载的业务翻译成发给沿途网络设备的一系列转发指令，从而实现网络编程，满足业务的定制化需求。\nSRH设计\n为基于IPv6转发平面实现SR技术，在IPv6路由扩展头新增SRH（Segment Routing Header）扩展头，该扩展头指定一个IPv6的显式路径，存储IPv6的Segment List信息。Segment List即对段和网络节点进行有序排列得到的一条转发路径。报文转发时，依靠 Segments Left 和 Segment List 字段共同决定IPv6目的地址（IPv6 DA）信息，从而指导报文的转发路径和行为。\n字段名 长度 含义 Next Header 8 bit 标识紧跟在SRH之后的报文头的类型。常见的几种类型如下。4: IPv4封装。41: IPv6封装。43: IPv6 Routing Header.58: ICMPv6 (Internet Control Message Protocol version6)59: Next Header为空 Hdr Ext Len 8 bit SRH的长度，指不包括前64 bit (前64 bit为固定长度)的SRH的长度 Routing Type 8 bit 标识路由扩展报文头类型，标记SRH的值为4 Segments Left 8 bit 剩余的Segment数目，简称SL Last Entry 8 bit segment List 的最后一个元素的索引 Flags 8 bit 预留的标志位，用于特殊的处理，比如OAM Tag 16 bit 标识同组报文 Segment List[n] 128 * n bit Segment List 中的第n个Segment, Segment 的值是IPv6地址的形式 Optional TLV 可变 可选TLV (Type Length Value,类型长度值)部分，例如PaddingTLV和HMAC (Hash-based Message Authentication Code,散列消息认证码) TLV Segment List。如前所述，可以将多个Segment组合起来，形成SRv6路径，即路径可编辑。对SRv6 SID 128bit的运用。\nSRv6 Segment定义了SRv6网络编程中的网络指令，指示要去哪，怎么去。标识SRv6 Segment的ID被称为SRv6 SID。SRv6 SID是一个128bit的值，为IPv6地址形式，由Locator、Function和Arguments三部分组成。下图为SID构成\nLocator：具有定位功能。提供IPv6的路由能力，报文通过该字段实现寻址转发。此外，Locator对应的路由也是可聚合的。\nFunction：用来表达该设备指令要执行的转发动作，不同的转发行为由不同的Function来表达。\nArguments：可选字段，是对Function的补充，是指令在执行时对应的参数，这些参数可能包含流、服务或任何其他相关的信息。 SRv6的每个Segment是128bit，可以灵活分为多段，每段功能和长度可以自定义，由此具备灵活编程能力，即业务可编辑。\nSRv6 工作流程 SRv6 网络种节点角色基本可以分为三类:\nSRv6 源节点：生成SRv6报文的源节点，如果list只包含单个SID，无需再报文中添加SRH，只要 中转节点：中转节点是SRv6报文转发路径上不参与SRv6报文处理的节点。可以是普通的IPv6节点也可以是支持SRv6节点。 SRv6 段端点节点：在SRv6报文转发过程种，如果节点接收的IPv6地址是目的地址配置的SID，则命中本地SID处理表，进行EndPoint处理。 SRv6 源节点指令介绍:\n源节点行为 功能简述 H.Insert 为接收到的IP报文插入SRH,并查表转发 H.Insert.Red 为接收到的IP报文插入Reduced SRH,并查表转发 H.Encaps 为接收到的IP报文封装外层IPv6报文头与SRH,并查表转发 H.Encaps.Red 为接收到的IP报文封装外层IPv6报文头与Reduced SRH,并查表转发 H Encaps.L2 为接收到的二层报文封装外层IPv6报文头与SRH,并查表转发 H.Encaps.L2.Red 为接收到的二层报文封装外层IPv6报文头与Reduced SRH,并查表转发 SRv6 段端点指令介绍:\n指令 功能简述 应用场景 End 把下一个SID复制到IPv6目的地址，进行查表转发 指定节点转发，相当于SR-MPLS的节点标签 End.X 根据指定出接口转发报文 指定出接口转发，相当于SR-MPLS的邻接标签 End.T 在指定的IPv6转发表中进行查表并转发报文 用于多转发表转发场景 End.DX6 解封装报文，向指定的IPv6三层邻接转发 L3VPNv6场景，通过指定的IPv6邻接转发到CE (Customer Edge, 用户网络边缘设备) End.DX4 解封装报文，向指定的IPv4三层邻接转发 L3VPNv4场景，通过指定的IPv4邻接转发到CE End.DT6 解封装报文， 在指定的IPv6转发表中进行查表转发 L3VPNv6场景 End.DT4 解封装报文，在指定的IPv4转发表中进行查表转发 L3VPNv4 场景 End.DT46 解封装报文，在指定的IPv4或IPv6转发表种进行查表转发 L3VPNv4/L3VPNv6场景 End.DX2 解封装报文，从指定的二层出接口转发 EVPN VPWS (Virtual Private Wire Service, 虚拟专用线路业务)场景 EndDX2V 解封装报文，在指定的二层表中用内层VLAN信息进行查表转发 EVPN VPLS (Virtual Private LAN Service, 虚拟专用局域网业务)场景 EndDT2U 解封装报文，在指定的二层表中学习内层源MAC地址，用内层目的MAC地址进行查表转发 EVPN VPLS的单播场景 End.DT2M 解封装报文，在指定的二层表中学习内层源MAC地址，排除指定的接口后向其他二层接口转发 EVPN VPLS的组播场景 End.B6.Insert 插入 SRH,应用指定的SRv6 Policy Insert 模式下引流入SRv6 Policy,隧道拼接、SD-WAN 选路等 End.B6.Insert.Red 插入 Reduced SRH,应用指定的 SRv6 Poliey Insert\u0026amp;Reduce 模式下引流入SRv6 Policy,隧道拼接、SD-WAN 选路等 End.B6.Encaps 封装外层IPv6报文头和SRH,应用指定的用指定的SRv6 Policy Encaps 模式下引流入SRv6 Poliey, 隧道隧道拼接、SD-WAN选路等 End.B6.Encaps.Red 封装外层IPv6报文头和Reduced SRH,应用指定的 SRv6 Policy Enaps\u0026amp;Rcuce模式下引流入SRv6 Pliy,隧道拼接、SD-WAN选路等 End.BM 插入MPLS标签栈，应用指定的SR-MPLS Policy SRv6 与SR-MPLS互通场景，引流入SR-MPLS Policy 如图所示，假设有报文需要从主机1转发到主机2，主机1将报文发送给节点A处理。节点A、B、D、E均支持SRv6，节点C不支持SRv6，只支持IPv6。我们在源节点A上进行网络编程，希望报文经过B-C、C-D链路，送达节点E，由E节点送达主机2。\n报文转发流程分为以下几步：\n源节点A将SRv6路径信息封装在SRH中，指定B-C，C-D链路的SID，另外封装E点发布的SID A5::10（此SID对应于节点E的一个IPv4 VPN），共3个SID，按照逆序形式压入SID序列。此时SL（Segment Left）=2，将Segment List[2]值复制到目的地址DA字段，按照最长匹配原则查找IPv6路由表，将其转发到节点B。 报文到达节点B，B节点查找本地SID表（存储本节点生成的SRv6 SID信息）,命中自身的SID（End.X SID），执行SID对应的指令动作。SL值减1，并将Segment List[1]值复制到DA字段，同时将报文从SID绑定的链路（B-C）发送出去。 报文到达节点C，C无SRv6能力，无法识别SRH，按照正常IPv6报文处理流程，按照最长匹配原则查找IPv6路由表，将其转发到当前目的地址所代表的节点D。 节点D收报文后根据目的地址A4::45查找本地SID表，命中自身的SID（End.X SID）。同节点B，SL值减1，将A5::10作为DA，并将报文发送出去。 节点E收到报文后根据A5::10查找本地SID表，命中自身SID（End.DT4 SID），执行对应的指令动作，解封装报文，去除IPv6报文头，并将内层IPv4报文在SID绑定的VPN实例的IPv4路由表中进程查表转发，最终将报文发送给主机2。 SRv6 TE 工作模式 SRv6 TE Policy 利用Segment Routing 的源路由机制，通过在头节点封装一个有序的指令列表来指导报文穿越网络。\nSRv6 TE Policy的工作流程主要也可以概括为5个步骤:\n转发器将网络拓扑信息通过 BGP LS. 上报给网络控制器。拓扑信息包括节点(类比交叉路口)、链路信息(类比道路)，以及链路的开销(类比流速)、带宽(类比车道)和时延(类比信号灯)等TE属性。 控制器基 于收集到的拓扑信息，按照业务需求计算路径，符合业务的SLA。 控制器通过 BGP SR-Policy扩展将路径信息下发给网络的头节点，头节点生成SRv6 TE Policy。 生成的SRv6 TE Policy 包括头端地址、目的地址和Color等关 键信息。 网络的头节 点为业务选择合适的 SRv6TE Policy 指导转发。 数据转发时， 转发器需要执行自己发布的SID的指令。 SRv6 BE 工作模式 传统MPLS有LDP和RSVP-TE两种控制协议，其中LDP方式不支持流量工程能力，LDP利用IGP算路结果，建立LDP LSP指导转发。在SRv6里，也有类似的方式，只不过SRv6仅使用一个业务SID来指引报文在IP 网络里进行尽力而为( Best Effort，BE) 的转发，这种方式就是SRv6 BE。下面以 EVPN L3VPNv4 over SRv6 BE介绍。\n在VPN概念中，把整个网络中的路由器如下三类：\nP(Provider，运营商骨干路由器) PE(Provider Edge、运营商边缘路由器) CE(Customer Edge、客户侧边缘路由器)\n在路由发布阶段:\nPE2 .上配置Locator,然后PE2通过IGP协议将SRv6 SID对应的 Locator 网段路由2001:DB8:3:/64发布给PE1。PE1安装路由到自己的IPv6路由表。 PE2 在Locator范围内配置VPN实例的End.DT4 SID 2001:DB8:3::C100， 生成本地SID表。 PE2收到CE2发布的私网IPv4路由后，PE2将私网IPv4路由转换成IP Prefix Route形式的EVPN路由，通过BGP EVPN邻居关系发布给PE1 。此路由携带 SRv6 VPN SID属性，也就是VPN实例的End.DT4 SID 2001:DB8::C100。 PE1 接收到EVPN路由后，将其交叉到对应的VPN实例IPv4路由表，然后转换成普通IPv4路由，对CE1发布。 在数据转发阶段:\nCE1 向PE1发送一个普通IPv4报文。 PE1 从绑定了VPN实例的接口.上收到私网报文以后，查找对应VPN实例的IPv4路由转发表，匹配目的IPv4前缀，查找到关联的SRv6 VPN SID 以及下一跳信息。然后直接使用SRv6 VPN SID 2001:DB8:3::C100 作为目的地址封装成IPv6报文。 PE1然后按照最长匹配原则，匹配到路由2001:DB8::/64, 按最短路径转发到P设备。 P 设备按照最长匹配原则，匹配到路由2001:DB8:3:/64， 按最短路径转发到PE2。 PE2 使用2001:DB8::C100查找本地SID表，匹配到End.DT4 SID对应的转发动作，将IPv6报文头去除，然后根据End.DT4 SID匹配VPN实例，查找VPN 实例IPv4路由表进行转发。 实践演示 指令介绍 由于 该实验环境使用 iproute2 包实现，不包含全部上述理论介绍SRv6指令，这里按照 iproute2 包的实现来进行介绍，使用 man ip route 可以看到\nip route replace encap ENCAPTYPE ENCAPHDR attach tunnel encapsulation attributes to this route. seg6 mode inline - Directly insert Segment Routing Header after IPv6 header mode encap - Encapsulate packet in an outer IPv6 header with SRH mode l2encap - Encapsulate ingress L2 frame within an outer IPv6 header and SRH SEGMENTS - List of comma-separated IPv6 addresses KEYID - Numerical value in decimal representation. See ip-sr(8). seg6local SEG6_ACTION [ SEG6_ACTION_PARAM ] - Operation to perform on match‐ ing packets. The following actions are currently supported (Linux 4.14+ only). SEG6_ACTION [ SEG6_ACTION_PARAM ] - Operation to perform on match‐ ing packets. The following actions are currently supported (Linux 4.14+ only). End - Regular SRv6 processing as intermediate segment endpoint. This action only accepts packets with a non-zero Segments Left value. Other matching packets are dropped. End.X nh6 NEXTHOP - Regular SRv6 processing as intermediate seg‐ ment endpoint. Additionally, forward processed packets to given next-hop. This action only accepts packets with a non-zero Seg‐ ments Left value. Other matching packets are dropped. End.DX6 nh6 NEXTHOP - Decapsulate inner IPv6 packet and forward it to the specified next-hop. If the argument is set to ::, then the next-hop is selected according to the local selection rules. This action only accepts packets with either a zero Segments Left value or no SRH at all, and an inner IPv6 packet. Other matching packets are dropped. End.B6 srh segs SEGMENTS [ hmac KEYID ] - Insert the specified SRH immediately after the IPv6 header, update the DA with the first segment of the newly inserted SRH, then forward the re‐ sulting packet. The original SRH is not modified. This action only accepts packets with a non-zero Segments Left value. Other matching packets are dropped. End.B6.Encaps srh segs SEGMENTS [ hmac KEYID ] - Regular SRv6 processing as intermediate segment endpoint. Additionally, en‐ capsulate the matching packet within an outer IPv6 header fol‐ lowed by the specified SRH. The destination address of the outer IPv6 header is set to the first segment of the new SRH. The source address is set as described in ip-sr(8). 本地SID表在 主机环境种可以使用路由表查看，即为 ip 6 route show 或 ip -6 route show 当然也可以使用其他第三方工具。\n场景环境配置 Ubuntu18.04 内核版本 4.14及以上 iproute2 版本4.9.0 及以上 core 版本7.5.1 及以上 Quagga 版本1.2.4 及以上 参考这篇博客，设计了一个 IPv4 使用 IPv6 通道的流量工程拓扑。每台路由器都开启 IPforword 和 quagga。\nsysctl -w net.ipv4.conf.all.forwarding=1 sysctl -w net.ipv4.conf.default.forwarding=1 sysctl -w net.ipv6.conf.all.forwarding=1 sysctl -w net.ipv6.conf.default.forwarding=1 从主机n1发出的IPv4数据包，到达支持SRv6的路由器 n4 ， n4 会根据所配置的操作对数据包进行封装，在外层加上IPv6以及SRH的报头，并进行正常的IPv6转发。在仅支持IPv6的路由器 n5，n5根据IPv6报头基于目的IPv6地址进行转发。在n6，n6路由器根据Segment执行End操作，将Segment Left减1，并根据Segment列表更新IPv6的目的地址，将数据包转发至下一跳n7。在支持SRv6的路由器n7，n7根据Segment执行End.DX4操作，剥掉外层的IPv6报头，将内含的IPv4数据包发给主机n3，完成转发流程。 之后的返回包流程就是 直接从n7 指向 n4。\n这里一开始做对 SRv6 理解不够透彻认为 SID 就是单纯的IPv6地址，按照原图的配置 发现居然所有节点的路由 是按照 fc00:4::bb 网段操作，可是原场景没有这些IP地址，这让我非常疑惑。一切如上图配置完毕后，发现从n4开始就没有发出 SRv6 的路由包。也没有报错提示，最后瞎试发现，是中转的例如 fc00:4:bb 没有这个路由系统内核直接处理为不可达，也就没有做 SRv6 转发操作。\n一顿折腾后，每一跳都配置好路由后觉得不太对，这每一跳都要设置路由也太蠢了，一定是我配置的问题。\n后来在github找到个 onos 做SDN控制器、 mininet做仿真环境的一个开源项目，里面的 issue 作者提到尽量把 sid 与物理接口隔离开，这时我才突然明白，sid 设计的巧妙之处：\nsid 长度为128bit，与IPv6地址相同能够在不具备SRv6的节点上作为普通ip地址使用，即将 locator作为路由器网段内前缀，function 字段设计并标识为不同的流量，相应的节点对该sid地址做不同的处理，后面的长度也足够长可以设计同一fuction下的不同Arguments。这就是 路由 + MPLS 的融合的设计思路，设计的SID前缀与主机网络前缀相同使用同一个 locator，之后再加上 定义的 funtion arguments字段，sid 又能做ip地址又能直接对网络进行编程。\n这里使用一个新的场景举例说明，对出发流量 fuction 设定为 a，返回的流量 fuction 设定 为 b，arguments 都是233 此处不做处理。其间绿色路由器为普通 IPv6 路由器仅支持igp协议，此处使用的是 quagga 实现的 OSPFv3。\n由于网段全部为 64位，fuction设定占用16位，sid 设计为 2001:X:0:0:$fuction:0:0:0:0/80 后面的arguments设定位固定的 233。\n不过需要注意，使用SRv6路由定义时不要与原有内核 或 zebra 生成的路由冲突，SRv6的优先级不够高可能永远也无法触发相应end操作，导致节点使用NDP协议去寻找对应物理意义不存在的IPv6地址。\n具体配置信息：\n开启了IPforword 无所谓指定的dev，不影响最后的结果\n# n1配置 ip route add 10.0.6.0/24 encap seg6 mode encap segs 2001:2:0:0:a::233,2001:6:0:0:a::233 dev eth0 ip -6 route add 2001:0:0:0:b::233/80 encap seg6local action End.DX4 nh4 10.0.0.20 dev eth1 # n2配置 ip -6 route add 2001:1:0:0:b::233/80 encap seg6local action End dev eth1 ip -6 route add 2001:2:0:0:a::233/80 encap seg6local action End.X nh6 2001:2::2 dev eth1# end操作后 按照指定下一跳接口转发ip 不指定会按照路由最短路径走 # n6配置 ip -6 route add 2001:6:0:0:a::233/80 encap seg6local action End.DX4 nh4 10.0.6.20 dev eth1 ip route add 10.0.0.0/24 encap seg6 mode encap segs 2001:1:0:0:b::233,2001:0:0:0:b::233 dev eth0 抓包分析 主机n7 ping n8 在n4 n9使用tcpdump可以看到SRv6数据包，出发的路径 segment list是逆序的，指令指定的是正序。为2001:2:0:0:a::233,2001:6:0:0:a::233\n路由信息走到节点n2命中本地SID表后执行 END.X 不仅将 segment left - 1 修改目的地址，还转发至指定下一跳2001:2::2。之后到达n3后 由于不存在 SRv6 处理能力，单纯按照网段最长前缀匹配路由。最后转发到n6后执行解包操作拆分出原始的 IPv4 报文。返回数据包的操作类似，不过是走路由的最短路经过上面的路由器转发SRv6数据。\n在无 SRv6 路由器上的转发。在n2使用wireshark具体分析包结构\n这里给出我搭建的场景链接，新版的core需要使用 legacy ui 打开。仿真一开始可能ping不通，需要等待中间绿色节点的ospf路由生成。\n扩展场景 该场景链接\n场景如上所示，主机n1到主机n2的流量，在n4上添加SRH要求经由n6进行转发，因此原流量路径如图黑色路径所示。 在n6路由器上，修改End操作为End.B6.Encaps操作，将流量先引导到 IDS n8进行处理，再回到n6进行正常转发流程。对应的新的流量路径如图绿色路径所示。最后通过绿色路径返回n1。\nEnd.B6.Encaps就是在在现有IPv6数据包上再封装一个新的IPv6的报头，并添加新的SRH报头；而End.B6操作则不会添加新的IPv6报头，而是直接插入新的SRH报头到现有的IPv6报头当中。这两种操作本质上都相当于是Binding-SID。\n这些 sid 设计如上面场景一样。 即为2001:X:0:0:$fuction:0:0:0:0/80 。locator 为路由器网段前缀，fuction 对应 a, aa, b 三种操作。\n具体配置如下所示。\n# n4配置 ip route add 10.0.2.0/24 encap seg6 mode encap segs 2001:8:0:0:a::233,2001:6:0:0:a::233 dev eth0 ip -6 route add 2001:0:0:0:b::233/80 encap seg6local action End.DX4 nh4 10.0.1.20 dev eth1 # n7配置 ip -6 route add 2001:6:0:0:a::233/80 encap seg6local action End.DX4 nh4 10.0.2.20 dev eth1 ip route add 10.0.1.0/24 encap seg6 mode encap segs 2001:0:0:0:b::233 dev eth1 # n8配置 ip route add fc:4:0:0:aa::aa via 2001:8::1 ip -6 route add fc:8:0:0:aa::aa encap seg6local action End dev eth0 # n6配置 ip -6 route add fc:8:0:0:aa::aa/80 via 2001:8::2 #由于该节点相邻 需要使用特殊网段 防止优先匹配了2001:8网段导致无法转发 ip -6 route add 2001:8:0:0:a::233/80 encap seg6local action End.B6.Encaps srh segs fc:8:0:0:aa::aa,fc:4:0:0:aa::aa dev eth1 ip -6 route add fc:4:0:0:aa::aa/80 encap seg6local action End.DX6 nh6 :: dev eth1 还可以修改优先级 做处理 使得先进行SRv6 sid 的处理 避免链路路由处理 使用ntp寻找不存在的ip。n6 n8 配置的修改如下所示。\n# n6配置 ip -6 route add 2001:8:0:0:aa::aa via 2001:8::2 metric 255 ip -6 route add 2001:8:0:0:a::233/80 encap seg6local action End.B6.Encaps srh segs 2001:8:0:0:aa::aa,2001:4:0:0:aa::aa dev eth1 ip -6 route add 2001:4:0:0:aa::aa/80 encap seg6local action End.DX6 nh6 :: dev eth1 # n8配置 ip route add 2001:4:0:0:aa::aa via 2001:8::1 metric 255 ip -6 route add 2001:8:0:0:aa::aa encap seg6local action End dev eth0 抓包数据大都相同，这里分别抓取 n5 n8 n9 的数据包:\n","id":1,"section":"posts","summary":"最近在学习SRv6相关的知识, 实践方面参考这篇 使用 mininet的 博客。我这里使用 core 平台 搭建了个简易场景 体会 SRv6 整个数据的ip包的包装解析。二","tags":["linux","network","sdn"],"title":"SRv6学习","uri":"https://liangkang233.github.io/2022/07/srv6%E5%AD%A6%E4%B9%A0/","year":"2022"},{"content":"之前安装docker时候惊讶其居然有windows版本的安装包，心想 docker 不是靠linux内核实现的资源控制空间隔离么，怎么会有windows版本，看了下安装方法才了解到 微软内置了linux内核的子系统，即 wsl (Windows Subsystem for Linux)。\n可以在win系统上不用虚拟机的方式原生执行 linux ，没有虚拟机那些其他开销，这也太牛了直接开整，试试wsl好不好用，也玩下windows版的docker。\n配置 wsl 在 powershell 下:\nwsl --install # 配置环境 wsl --list --online # 只有内核 还需要在该列表中选择镜像启动 wsl --install -d \u0026lt;DistroName\u0026gt; WSL 2 使用最新、最强大的虚拟化技术在轻量级实用工具虚拟机 (VM) 中运行 Linux 内核。 所以先升级对应wsl内核版本（docker只能运行在wsl2上）适用于 x64 计算机的 WSL2 Linux 内核更新包\nwsl # 开启并进入默认系统 后加命令会在分发系统内执行该命令 wsl -d Ubuntu -u root # 进入指定版本 指定用户 wsl --export \u0026lt;Distribution Name\u0026gt; \u0026lt;FileName\u0026gt; # 系统导出 wsl --import \u0026lt;Distribution Name\u0026gt; \u0026lt;InstallLocation\u0026gt; \u0026lt;FileName\u0026gt; # 系统导入 wsl --unregister \u0026lt;DistributionName\u0026gt; # 卸载系统 wsl -l -v # 查看全部系统的wsl版本 和状态 wsl --terminate, -t \u0026lt;distro name\u0026gt; # 关闭该系统 --shutdown 关闭全部系统 wsl --set-default-version \u0026lt;Version\u0026gt; # 设置默认 WSL 版本 wsl --distribution \u0026lt;Distribution Name\u0026gt; --user \u0026lt;User Name\u0026gt; # 以特定用户 运行 linux发行版 导入系统的发行包没法像 ubuntu2004.exe config --default-user new_user_name 配置默认登录用户，进入发行系统，添加或修改 /etc/wsl.conf 停止wsl系统重新进入即可生效。\nYourUserName=lk233 sudo echo -e \u0026quot;[user] \\ndefault = $YourUserName\u0026quot; \u0026gt; /etc/wsl.conf 若是不对wsl资源进行限制，其vmmem进程会逐渐吃光物理机内存，参考该WSL 中的高级设置配置 | Microsoft Docs 进行限定wsl系统性能。 Linux内核中有一个参数/proc/sys/vm/drop_caches，是可以用来手动释放Linux中的cache缓存，如果发现wsl2的cache过大影响到宿主机正常运行了，可以手动执行以下命令来释放cache：\necho 3 \u0026gt; /proc/sys/vm/drop_caches\n开发环境 配置用户后 拿来跑数据库 docker Linux gui应用(需要win11) 前端框架 甚至机器学习 的python 项目都可以。设置 WSL 开发环境 | Microsoft Docs\n使用windows的资源管理器查看wsl系统，路径为 \\\\wsl$\\系统名 其默认的真实路径为 C:\\Users\\LAB\\AppData\\Local\\Packages\\Project$ 路径后缀肯定是不同机器不一样的我这里Project$ = CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgsc。在linux内该路径为 /mnt/c 对应 windows中的c盘，使用 explorer.exe . 来在资源管理器中查看。像docker这类应用考虑到io性能，最好使用 linux内的路径例如 ~/my-project 而不是 /mnt/c/users 这样的挂载路径。\n原生的 powersehll 不太好用，也懒得整个windows终端。接下来使用vscode来优雅的体验wsl吧。wsl分发系统 通过虚拟网卡vEthernet (WSL) 与物理主机连接，就像远程登录其它linux主机一样，wsl作为服务器主机，vscode作为客户端显示。所以当本地vscode 升级时，远端 / wsl 的 code server 也会升级。\n把 集成wsl2 的 docker 装起来，WSL 上的 Docker 容器入门 | Microsoft Docs 配置好后wsl就可以使用 docker了。\n由于win系统都是通过调用linux内核实现docker功能，整个 docker daemon 还是由docker-desktop控制的，所以只在本地主机上的 vscode 配置 docker 和 remote-docker 插件进行全局管理即可。可以看到 wsl 多了 两个发行版 docker-desktop-data docker-desktop 对应路径为 C:\\Users\\user\\AppData\\Local\\Docker\\wsl。后面C盘占用太高可以尝试迁移: WSL2 迁移 Docker 镜像存储位置\n项目执行 一切就绪，试试跑这个 爬虫监视项目。其他 mangodb grafana influxdb 等环境 跑个docker容器即可。该项目使用selenium 爬取豆瓣关键词相关电影信息存入 mongodb中，使用 时序数据库 InfluxDB 来记录将数据抓取的变化情况，使用 Grafana 展示。\n注意 redis 配置文件不要开 daemonize yes，类似的 monggo也不要开 fork之类的后台执行。\n使用 docker-compose 部署数据库容器: docker-compose up -d 不使用 -f 指定默认使用当前目录的docker-compose.yml\ndocker-compose # Use root/example as user/password credentials version: '3.1' services: mongo: image: mongo restart: always container_name: some-mongo ports: - 27017:27017 environment: MONGO_INITDB_ROOT_USERNAME: root MONGO_INITDB_ROOT_PASSWORD: example volumes: - ~/MyCustom/mongo/daemon_config:/etc/mongo - ~/MyCustom/mongo/mong_data_conf:/data/configdb - mong_data:/data/db command: --config /etc/mongo/mongod.conf mongo-express: image: mongo-express container_name: mongo-express depends_on: - mongo restart: always ports: - 8081:8081 environment: ME_CONFIG_MONGODB_AUTH_USERNAME: root ME_CONFIG_MONGODB_AUTH_PASSWORD: example ME_CONFIG_BASICAUTH_USERNAME: root # 管理界面 express 的账号 密码 ME_CONFIG_BASICAUTH_PASSWORD: lk233pass ME_CONFIG_MONGODB_URL: mongodb://root:example@mongo:27017/ VCAP_APP_HOST: 0.0.0.0 VCAP_APP_PORT: 8081 # 配置参数 https://grafana.com/docs/grafana/latest/administration/configure-docker/ 默认账户密码 admin@admin grafana: image: grafana/grafana container_name: grafana ports: - 3000:3000 environment: GF_DEFAULT_INSTANCE_NAME: my-instance GF_SECURITY_ADMIN_USER: root GF_AUTH_GOOGLE_CLIENT_SECRET: example GF_PLUGIN_GRAFANA_IMAGE_RENDERER_RENDERING_IGNORE_HTTPS_ERRORS: true # influxdb docker 配置 https://hub.docker.com/_/influxdb influxdb: image: influxdb container_name: influxdb ports: - 8086:8086 volumes: - influxdb_data:/var/lib/influxdb2 - ~/MyCustom/influx_db/config:/data/db environment: # DOCKER_INFLUXDB_INIT_MODE: setup upgrade DOCKER_INFLUXDB_INIT_USERNAME: root DOCKER_INFLUXDB_INIT_PASSWORD: example DOCKER_INFLUXDB_INIT_ORG: my_org DOCKER_INFLUXDB_INIT_BUCKET: my_bucket volumes: mong_data: redis_data: influxdb_data: mong_data_conf: 由于wsl里没有浏览器，所以这个抓取的脚本改为用 edge 的在windows上执行。然后脚本有些函数被弃用了，修改后的版本。如果 msedgedriver 不在path环境下，需要设定 路径。\n爬虫代码 # -*- coding:utf-8 -*- import time from selenium.webdriver.common.by import By from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC import re from selenium.common.exceptions import TimeoutException from msedge.selenium_tools import Edge, EdgeOptions from lxml import etree import pymongo import datetime MONGO_URL = 'mongodb://root:example@172.18.96.216:27017/' MONGO_DB = 'douband_movices' client = pymongo.MongoClient(MONGO_URL) db = client[MONGO_DB] MONGO_TABLE = \u0026quot;movie_info\u0026quot; key_word = input(\u0026quot;请输入需要爬取的关键词: \u0026quot;) edge_options = EdgeOptions() edge_options.use_chromium = True edge_options.add_argument(\u0026quot;inprivate\u0026quot;) browser = Edge(executable_path = \u0026quot;E:\\\\Github_code\\\\Tools\\\\spider_douban_selenium_mongodb\\\\msedgedriver.exe\u0026quot;, options=edge_options) wait = WebDriverWait(browser,10) browser.get('https://movie.douban.com/') def search(): try: input = wait.until( EC.presence_of_element_located((By.CSS_SELECTOR,'#inp-query')) ) submit = wait.until( EC.element_to_be_clickable((By.CSS_SELECTOR,'#db-nav-movie \u0026gt; div.nav-wrap \u0026gt; div \u0026gt; div.nav-search \u0026gt; form \u0026gt; fieldset \u0026gt; div.inp-btn \u0026gt; input[type=\u0026quot;submit\u0026quot;]')) ) input.send_keys('{}'.format(key_word)) submit.click() print('正在加载') active = wait.until( EC.presence_of_element_located((By.CSS_SELECTOR,'a.num.activate.thispage')) ) print('加载第【{}】页成功'.format(active.text)) get_movies() except TimeoutException: print('等待超时，重新搜索...') return search() def next_page(): try: next_page_submit = wait.until( EC.element_to_be_clickable((By.CSS_SELECTOR,'a.next')) ) next_page_submit.click() wait.until( EC.presence_of_element_located((By.CSS_SELECTOR,'a.num.activate.thispage')) ) print('成功加载该页数据...') get_movies() print('--------------加载完成，并打印成功，开始加载下一页------------') time.sleep(3) next_page() except TimeoutException: print('加载超时，重新加载...') return next_page() def get_movies(): try: print('正在解析...') page = browser.page_source.encode('utf-8') selector = etree.HTML(page) print('开始打印输出电影信息...') items = selector.xpath('//*[@id=\u0026quot;root\u0026quot;]/div/div[2]/div[1]/div[1]') for item in items: names = item.xpath('div/div/div/div[1]/a/text()') urls = item.xpath('div/div/div/div[1]/a/@href') ratings = item.xpath('div/div/div/div[2]/span[2]/text()') durations = re.findall(r'\\d\\d+',str(item.xpath('div/div/div/div[3]/text()'))) actors = item.xpath('div/div/div/div[4]/text()') for name,url,rating,duration,actor in zip(names,urls,ratings,durations,actors): # 打包为元组的列表 movie_info = {} movie_info['name'] = name movie_info['url'] = url if rating == '(尚未上映)' or '(暂无评分)': movie_info['rating'] = None else: movie_info['rating'] = float(rating) movie_info['duration'] = int(duration) movie_info['actors'] = actor movie_info['key_word'] = key_word print(movie_info) save_to_mongo(movie_info) except Exception as e: print(e) time.sleep(3) return get_movies() def save_to_mongo(result): try: # if db[MONGO_TABLE].insert_one(result): if db.get_collection(MONGO_TABLE).insert_one(result): # get 函数没有该表便会创建一个 print('成功存储到MONGODB') except Exception as e: raise e def main(): start_time = datetime.datetime.now() # global MONGO_TABLE # 定义写入的表为时间戳 # MONGO_TABLE = start_time.strftime(\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot;) try: db_list = client.list_database_names() # db.list_collection_names() 是该数据库的全部数据集 print(f\u0026quot;全部数据库为: {db_list}\u0026quot;) if MONGO_DB in db_list : print(\u0026quot;数据库存在\u0026quot;) search() next_page() else: print(f\u0026quot;{MONGO_DB} 不存在, 连接不可用\u0026quot;) except Exception as e: raise e finally: browser.close() end_time = datetime.datetime.now() print('*'*100) print('共计用时：', end_time - start_time) total_nums = db[MONGO_TABLE].count_documents({}) print('共计获取数据：',total_nums,' 条') print('*'*100) if __name__ == '__main__': main() 验证 mongodb 的数据可以使用 mongo-express 直接访问 wsl_ip:8081 例如 172.18.96.216:8081 即可图形化界面查看筛选数据库内容。\ninfluxdb采集脚本 InfluxDB 的版本变化，原文章的脚本不在适用，启用influx容器后 访问 8086 端口，进入后查看 data 页 的Client L ibraries 查看编写例程。\n改写后：\nfrom datetime import datetime from influxdb_client import InfluxDBClient, Point, WritePrecision from influxdb_client.client.write_api import SYNCHRONOUS import pymongo, time # You can generate an API token from the \u0026quot;API Tokens Tab\u0026quot; in the UI token = \u0026quot;UNX9i2BpV_VTWyccXomQ6F026rg6j_nUeXtheR4THu8WoWmky09Fgw2WBJAltHL0sQadeDaSb2OGE-J0B7-2vg==\u0026quot; org = \u0026quot;CQUPT\u0026quot; bucket = \u0026quot;douban\u0026quot; MONGO_URL = 'mongodb://root:example@172.18.96.216:27017/' MONGO_DB = 'douband_movices' mongodb = pymongo.MongoClient(MONGO_URL).get_database(MONGO_DB) # 连接 MongoDB 数据库 client = InfluxDBClient(url=\u0026quot;http://172.18.96.216:8086\u0026quot;, token=token, org=org) # 连接 influxDB 数据库 write_api = client.write_api(write_options=SYNCHRONOUS) interval = 8 def main() : last_size, last_count = {}, {} for dbname in mongodb.list_collection_names(): last_size[dbname], last_count[dbname] = 0.0, 0 while True: for dbname in mongodb.list_collection_names(): # db = mongodb.get_collection(dbname) dbstat = mongodb.command(\u0026quot;collstats\u0026quot;, dbname) now_size = round(float(dbstat[\u0026quot;size\u0026quot;] / 1024 / 1024), 2) now_count = dbstat[\u0026quot;count\u0026quot;] # 得到数据 增长量 increase_amount = now_size - last_size[dbname] increase_collection_size = now_count - last_count[dbname] point = Point(\u0026quot;crawler\u0026quot;) \\ .tag(\u0026quot;db_name\u0026quot;, dbname) \\ .field(\u0026quot;count\u0026quot;, now_count) \\ .field(\u0026quot;increase_count\u0026quot;, increase_amount) \\ .field(\u0026quot;size\u0026quot;, now_size) \\ .field(\u0026quot;increase_size\u0026quot;, increase_collection_size) \\ .time(datetime.utcnow(), WritePrecision.NS) write_api.write(bucket, org, point) print('成功写入influxdb 数据: ', point) last_size[dbname], last_count[dbname] = now_size, now_count time.sleep(interval) if __name__ == '__main__': main() 先试试 能够否 如图 将 Buckets 的数据争取抓出来，筛选好信息 submit 看见有数据导入即可验证 influx 脚本正常\nGrafans 配置 最后配置 Grafans，进入 3000 端口 admin账号 密码admin 创建初始账号。新版的 Grafans 已经有直接支持 mongodb 了，绝了 绕一大圈😫。还是先像文章一样配置数据库吧。\n介绍下怎么装插件：\n# 进入容器终端 docker exec -it grafana bash grafana-cli plugins list-remote grafana-cli plugins install grafana-mongodb-datasource # 之后重启容器即可生效 docker container restart grafana 图形界面 Server Admin 的 plugins 选项下装插件更方便，而且很奇怪无法在 Configuration / Data sources 下 使用 Add data source 按钮添加该数据库，只能在 Configuration 的 plugins 或 Server Admin 的 plugins 下添加。\n配置好后 弹窗 Enterprise License Error 发现是 需要企业版才能用。放弃！\n老老实实配 influx 吧，2.0以上版本 Query Language 使用 Flux，这里的ip要注意，我之前搭建的环境都是通过 wsl 的ip 172.18.96.216 来进行通信的，而此处是 grafana 容器访问 influx 容器，所以跨网段会找不到路由，排错了半天在 日志里才发现端倪，进 ifluxdb 容器 内执行 ip link addr show 获取ip为 172.18.0.4，连接配置 url 设置为其网关或网卡ip，InfluxDB Details 里的 token 为 上述代码用到的 api token。\n最后在 dashboard 添加一个新的 panel， query 里选择 influxDB 使用 sample Query 快速填入一些简单的案例。或者直接在 ifluxdb的界面 Data Explorer中进行元素筛选，然后点击 Scipt Editor 复制其查询语句 Grafans 到 panel。设定完成后 Query inspector 生成对应图像示例。\n然后 开始爬数据 看看渲染效果\n可以看看其他写的比较好的 Grafana 教程 数据导出的插件也有很多方便的实现，例如 Prometheus 搭配各类 Exporter 统计数据，Prometheus 的显示可以使用 Grafana 现有的仪表盘导入prometheus的数据能做到许多监控效果例如mysql 主机运行状态等监控参数。(在Prometheus的架构设计中，Prometheus Server并不直接服务监控特定的目标，其主要任务负责数据的收集，存储并且对外提供数据查询支持。因此为了能够能够监控到某些东西，如主机的CPU使用率，我们需要使用到Exporter。Prometheus周期性的从Exporter暴露的HTTP服务地址（通常是/metrics）拉取监控样本数据。)\nGrafana 在很多地方都有应用，也许以后还会有用到的时候，有机会再分享关于它的用法的。\n属于是跑题跑偏了😂，最开始只想整个wsl，结果搞到容器部署 数据库 和资源监控了。\n","id":2,"section":"posts","summary":"之前安装docker时候惊讶其居然有windows版本的安装包，心想 docker 不是靠linux内核实现的资源控制空间隔离么，怎么会有windows版","tags":["linux","容器"],"title":"WSL docker 初探","uri":"https://liangkang233.github.io/2022/05/wsl%E5%88%9D%E6%8E%A2/","year":"2022"},{"content":"Emane开发文档\nEmane维基\nEmane仿真架构： Emane仿真流程 ​\t当仿真器实例化模型插件（即读取模型配置文件platform.xml），emane仿真器会将每个无线模型插件与仿真器物理层的专用实例一起封装在网络仿真模块 组成网络仿真中的最小单元Network Emulation Module（NEM）。\n​\t一个容器可以有多个NEM，一个NEM映射一个无线网卡（通过向 /dev/net/tun 写数据实现）。而网络接口部署在 platform (容器节点 或执行仿真的主机)上，底层原始数据在平台的网络接口 通过组播通道传输仿真数据。即所有 OTA（over the air multicast channel） 消息封装后的多播数据包都由使用同一 OTA 多播通道的每个模拟器实例platform进行处理。\n​\t这些无线仿真节点的物理层数据通过emane进程转发到主、辅控制网络的多播通道互连（两种网络都使用多播传输数据包）。\n​\t这就是仿真器物理层在异构无线电模型中考虑信号传播、天线效应和干扰源的方式，都在emane进程中处理。\n​\tEmane计算信噪比后通过设定规则的pcr曲线计算物理层是否可接收数据，路径损耗，gps位置 天线角度 通信损耗 等可以通过 emane事件触发。\ntransport layer transport layer 是应用程序/模拟传输边界的程序，负责在模拟器实例和一个或多个应用程序空间进程之间传递消息的模拟组件。\n传输程序为模拟器和应用程序空间消息提供入口点和出口点。\n传输插件既可以作为模拟器进程的一部分在内部实例化，也可以作为其他应用程序的一部分在外部实例化。Transport Daemon EMANE应用程序处理配置XML，以确定要实例化的外部传输插件的类型、应该如何配置插件以及应用什么通用的应用程序级别设置。\nEmane 包含两种传输模式：\nRaw Transport\n应用程序/模拟边界不限于由模拟器内部加载或由Transport Daemon外部加载的插件。在将软件定义无线电(SDR)波形连接到EMANE时，应开发自定义传输接口，并将其嵌入到Modem硬件抽象层(MHAL)的SDR中。SRSlte-emane模型就是如此，将sdr替换为emane物理层嵌入srslte中通信，上行mac层架构不变。\nVirtual Transport\n​\t默认使用的就是虚拟传输通道，容器节点中，虚拟传输使用 TUN/TAP 接口（一一映射到NEM）创建虚拟接口 （vif） 作为应用程序/仿真边界入口/出口点。在下行方向（发送端处理过程），内核将路由到 vif 的以太网帧被打包成emane消息转发至控制网接口即各个NEM实际相接网络接口中，发送到相应的 NEM 进行处理。在上行方向（接受端处理过程），直接接收到不需要转发至虚拟vif 处理，NEM 消息被解包并作为以太网帧写入 TUN/TAP 接口。\nEmane NEM layer 处理流程\n上层组件结构：\n组件 大致功能 TimerServiceUser emane定时器后台服务 EventServiceUser emane事件后台服务 Component 用于配置和控制所有组件的通用接口 UpstreamTransport UpstreamTransport允许处理上游数据和控制消息。上游数据包和控制消息被放置在NEMQueuedLayer函数队列中进行处理。 DownstreamTransport DownstreamTransport允许处理下游数据和控制消息 PlatformServiceUser 仿真平台服务的接口，提供对nem layer服务的访问 Buildable 使用应用程序范围构建唯一的Id标记对象的接口。构建器操作可构建对象来注册它们与其他应用程序对象的关联，并执行组合规则 RunningStateMutable RunningStateMutable接口用于允许在运行状态下对配置进行更改。配置被放置在NEMQueuedLayer函数队列中进行处理。 NEMQueuedLayer NEM数据层堆栈，每层之间有一个处理队列，以解耦到节点内部处理 NEMStatefulLayer 组件状态强制转换规则的层堆栈。有状态层并不是一个功能完整的层，它封装了只允许正确的转换和状态操作的NEM层。 PHYLayerImplementor 用于创建PHY层插件实现的接口 MACLayerImplementor 用于创建MAC层插件实现的接口 ShimLayerImplementor 用于创建Shim层插件实现的接口 Transport 传输边界程序的基类 注：使用emane版本为1.2.5 系统Ubuntu 18.04\n# emane 编译 安装教程 cd emane sudo apt install -y gcc g++ automake libtool libxml2-dev libprotobuf-dev libpcap-dev libpcre3-dev uuid-dev pkg-config protobuf-compiler git python3-protobuf python3-setuptools ./autogen.sh PYTHON=python3 ./configure --prefix=/usr make check # 检测编译 make -j$(nproc) sudo make install # 复制动态库 emane二进制程序 头文件 pcr模型xml 解析器 到对应系统目录 # 安装core内的python工具绑定 cd ../core/daemon poetry run pip install ~/emane/src/python 模型介绍及架构： 各无线模型均采用 通用物理层，无线模型主要设计其mac层。\nPHY layer 物理层大部分细节由 libemane include文件夹 内的otamanger commonphyheader downstreampacket 等等组件构成，其处理流程类似mac layer 处理上下游数据。可以构建自定义的物理层组件 phylayer 或者改造添加其细节。官方的建议是为了兼容性是不要自己构建新的phyapi 直接使用原生的进行改造或使用。 其间的物理层 OTA流量 (原始数据包) 是采用 src/libemane/otaheader.proto 定义 proto 序列化反序列化传输数据。\n​\t无线电模型可以使用 Spectrum Service 频谱服务访问仿真器物理层跟踪的每个频率的噪声信息。\n传播模型：2-Ray、Freespace、事件触发预计算\n接收功率计算\n天线增益的支持\n噪声处理\n频率分集\n协作传输\n​\t物理层接口主要使用这些 控制消息\nControlMessage 功能 FrequencyControlMessage 在 transport layer 中上下游消息 (UpstreamPacket DownstreamPacket) 的频率 TransmitterControlMessage 发送 下游 DownstreamPacket 控制消息 ReceivePropertiesControlMessage 接收 上游 UpstreamPacket 控制消息 TimeStampControlMessage 指定该无线信息开始传输时刻的传输时间戳 AntennaProfileControlMessage 配置接收下游数据时的天线参数 Radio Models (Mac layer) 绝大多模型库生成动态库由主程序加载的形式链接调用。\nRF Pipe\nIEEE802.11abg\nTDMA\nLTE/srsRAN-emane （嵌入型 emane 与srsRAN配套使用，与此处介绍的其他模型不同）\nUtility Models 使用shim类派生完成下列功能:\nComm Effect : Comm Effect 不是无线电模型。它使用模拟器接口将仿真效果应用于流量，而无需相关无线网络的特定概念 (构建虚拟shim layer实现，猜测是开发人员测试成功后将这些具体实现添加到无线模型中)\n​\tComm Effect 提供了定义以下无线网络传播的损失效果模拟:\nLoss: 使用均匀损失分布模型将被丢弃的包的百分比。 Latency: 数据包通过网络的延迟由一个固定的和可变的部分组成。固定的延迟量是通过一个延迟配置参数定义的，可变的量是通过一个抖动配置参数定义的。抖动是使用一个关于+/-抖动的均匀随机分布模型随机确定的。然后将随机生成的抖动值添加到固定的延迟中，以确定总延迟。 Duplicates: 在接收端复制接收的数据包的百分比。 Unicast Bitrate: 发送到NEM或以混杂模式处理的数据包的比特率。 Broadcast Bitrate: 发送到NEM广播地址的报文的比特率。 除此之外还有pathloss 天线 TDMA特有的时隙等影响无线传播的事件。这些统称为emane事件 交由定时器 查询检索 触发。\nPHYAPITest\n构建虚拟mac ShimLayer 来进行 phy api 的测试\nTimingAnalysis\n​\t定时器分析模块，计算shimlayer接收数据到发送给另一个shimlayer的延迟时间和定时采集事件信息。\nShimHeaderMessage\n包含模型的事件 及定时器事件的触发消息的序列化 反序列化\nShimLayer\n无线模型MAC开发流程： 创建 Radio Model 插件所需的实现的API清单。 派生创建自定义的 mac实现 MACLayerImplementor\nMACLayerImplementor 父类的 公共成员函数\nvoid setBuildId (BuildId bid) NEMId getNEMId () const BuildId getBuildId () const virtual void setUpstreamTransport (UpstreamTransport *pUpstreamTransport) virtual void setDownstreamTransport (DownstreamTransport *pDownstreamTransport) virtual ~MACLayerImplementor () virtual void initialize (Registrar \u0026amp;registrar)=0 virtual void configure (const ConfigurationUpdate \u0026amp;update)=0 virtual void start ()=0 virtual void postStart () virtual void stop ()=0 virtual void destroy ()=0 throw () void sendDownstreamControl (const ControlMessages \u0026amp;msgs) void sendUpstreamControl (const ControlMessages \u0026amp;msgs) void sendUpstreamPacket (UpstreamPacket \u0026amp;pkt, const ControlMessages \u0026amp;msgs=empty) void sendDownstreamPacket (const CommonMACHeader \u0026amp;hdr, DownstreamPacket \u0026amp;pkt, const ControlMessages \u0026amp;msgs=DownstreamTransport::empty) virtual void processUpstreamPacket (const CommonMACHeader \u0026amp;hdr, UpstreamPacket \u0026amp;pkt, const ControlMessages \u0026amp;msgs=UpstreamTransport::empty)=0 virtual void processUpstreamControl (const ControlMessages \u0026amp;msgs)=0 virtual void processDownstreamPacket (DownstreamPacket \u0026amp;pkt, const ControlMessages \u0026amp;msgs=empty)=0 virtual void processDownstreamControl (const ControlMessages \u0026amp;msgs)=0 virtual void processEvent (const EventId \u0026amp;eventId, const Serialization \u0026amp;serialization) virtual void processTimedEvent (TimerEventId eventId, const TimePoint \u0026amp;expireTime, const TimePoint \u0026amp;scheduleTime, const TimePoint \u0026amp;fireTime, const void *arg) virtual void processConfiguration (const ConfigurationUpdate \u0026amp;update) 重写(覆盖)所有组件状态的转换方法:\ninitialize 注册插件配置项和一个可选的配置验证器 注册无线模型的统计信息和统计表 注册无线模型需要的emane事件 configure 处理所有已加载的配置 start 仿真从该方法开始，启动无线模型仿真内定时器等。 postStart NEM层堆栈中的所有组件现在都处于“启动”状态。跟踪或配置相邻层的组件。 stop 与 start 相反，执行停止行为 destroy 与 initialize 相反，执行清理销毁操作。 重写(覆盖)所有处理数据包和控制消息的方法:\nprocessDownstreamPacket processDownstreamControl processUpstreamPacket processUpstreamControl 如果你的插件要处理Emane事件，也需要重写覆盖下面函数:\nprocessEvent 如果你的插件要调度Emane定时器事件，也需要重写覆盖下面函数:\nprocessTimedEvent 如果你的插件允许运行状态下的进行配置修改，需要重写该api:\nprocessConfiguration 使用 DECLARE_MAC_LAYER 宏函数 来完成mac模型 Implementor 的声明与实例化\n可以看看 基础模型 bypass 的搭建流程\nphylayer\nbypass 是 类似 hello world 的无线模型来介绍 emane无线模型 的开发流程 其具有处理步骤为空的 未对无线数据包做处理的 phy mac 库\nEmane 新模型开发示例： Emane源码修改: 仿照 rfpipe 创建一个 新的自定义模型:\n将要发送的 downstream 封装至使用通用物理层的原始数据包 downstreamqueue 需要自己设计发送形式来触发 sendDownstreamPacket，而upstream的数据 直接 sendUpstreamPacket 不需要设计数据队列。\n需要完成如下5个类：\nDownstreamqueue 下游数据的定义\nDownstreamQueueEntry 队列数据入队定义\nMACHeaderMessage Mac head数据结构及成员定义，mac数据对象大部分都是使用 Google Protocol Buffers 来进行序列化 如下是 rfpipemacheader.proto，对应上下游数据有两类构造函数。\n数据类型虽然为string 但是内部是二进制的 非打印数据流 Protobuf简易教程\nsyntax = \u0026quot;proto2\u0026quot;; package EMANEMessage; option optimize_for = SPEED; message RFPipeMACHeader { required uint64 dataRate = 1; } Maclayer 进行实例化的对象\npcrmanager: 基础射频模型 对物理层 PCR 的管理, 其中xml数据由DTD (document type definition) 定义结构。简易教程： DTD的编写 platform.xml 定义了全局的emane 组播地址 事件 及nem映射设备等，具体配置依赖nem.xml。 一般情况下，nem.xml定义了 transport phy mac 层的配置。platform 的 dtd 如下所示\n\u0026lt;?xml encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!ELEMENT platform ((param|paramlist)*, nem+)\u0026gt; \u0026lt;!ATTLIST platform name CDATA #IMPLIED\u0026gt; \u0026lt;!ENTITY % nemcontents SYSTEM \u0026quot;nemcontents.dtd\u0026quot;\u0026gt; %nemcontents; \u0026lt;!ELEMENT nem (%alllayers;)\u0026gt; \u0026lt;!ATTLIST nem name CDATA #IMPLIED id CDATA #REQUIRED definition NMTOKEN #REQUIRED transport (external | internal) \u0026quot;internal\u0026quot;\u0026gt; \u0026lt;!ENTITY % param SYSTEM \u0026quot;param.dtd\u0026quot;\u0026gt; %param; \u0026lt;!ELEMENT shim (param|paramlist)*\u0026gt; \u0026lt;!ATTLIST shim definition NMTOKEN #REQUIRED\u0026gt; \u0026lt;!ELEMENT mac (param|paramlist)*\u0026gt; \u0026lt;!ATTLIST mac definition NMTOKEN #REQUIRED\u0026gt; \u0026lt;!ELEMENT phy (param|paramlist)*\u0026gt; \u0026lt;!ATTLIST phy definition NMTOKEN #IMPLIED\u0026gt; \u0026lt;!ELEMENT transport (param|paramlist)*\u0026gt; \u0026lt;!ATTLIST transport definition NMTOKEN #REQUIRED group CDATA #IMPLIED 整个 基础的rfpipe模型构建的必要文件大致如下所示：\nlk233@vm-5gc:~/emane/src/models/mac/myrfpipe$ tree . ├── downstreamqueue.cc\t# 定义了 downstream queue 的数据格式 及 插入弹出数据队列类 ├── downstreamqueue.h\t# ├── maclayer.cc\t# 整个无线模型的实例化 启动 销毁的流程定义 ├── maclayer.h\t# mac layer 类的 api 必须 重写 ├── Makefile.am\t# 编译配置文件 项目使用 autoconfig 完成编译 ├── pcrmanager.cc\t# pcr配置文件的读取与设定 ├── pcrmanager.h\t# ├── rfpipemacheadermessage.cc\t# 调用下面 probuf 的api进行序列化 反序列化 这里只有一个参数 daterate ├── rfpipemacheadermessage.h\t# ├── rfpipemacheader.proto\t# 定义mac head消息数据结构。使用protoc *.proto --cpp_out=./ 生成 对应数据序列化、反序列化的pb.cc pb.h ├── myrfpipemac.xml.in\t# mac库参数 以及 在源码dtd/中加入 DOCTYPE 解析 （注意 library 最好与 pzLayerName 小写名统一） ├── myrfpipenem.xml.in\t# nem配置的参数示例 以及 在源码dtd/中加入 DOCTYPE 解析 (此处nem中的mac 依赖rfpipemac rfpipemac依赖pcr) └── myrfpipepcr.xml.in\t# 默认pcr曲线配置示例 以及 在源码dtd/中加入 DOCTYPE 解析 Mac layer 使用 Virtual Transport 的数据大致处理过程\n此处的Rfpipe模型就是通过定时器控制队列入队出队 来限制无线数据dataRate\nautomake 和 autoconf 使用简明教程，下面介绍 myrfpipe 的 autoconfig 配置实例 （以下相对目录皆是emane源码路径的相对目录）\n添加新模型一般需要修改 autoconfig 的 configure.ac, 在该文件的 AC_OUTPUT 添加如下路径 来在构建过程指定输出文件\nAC_OUTPUT( *** src/models/mac/rfpipe/Makefile src/models/mac/myrfpipe/Makefile *** ) 编写并修改 makefile.am Makefile.am 中指明当前目录如何编译。\n修改 Makefile.am 安装 卸载的hook (可选)\nsrc/models/mac/Makefile.am 添加 myrfpipe 子目录\n在 /dtd/ 中定义dtd的数据格式，并在 /dtd/Makefile.am 添加 myrfpipepcr.dtd\n在 /scripts/emanegenmanifests.sh 中添加 需要生成的库名 myrfpipemaclayer。其原理是调用 emaneinfo -m 导出插件或模型的类内注册 配置和统计信息 的参数。生成的xml给core解析就可以得到模型的所有参数。\n编写 src/models/mac/myrfpipe/Makefile.am\nlib_LTLIBRARIES = libmyrfpipemaclayer.la # cpp 编译的选项 -I指定头文件目录等等 libmyrfpipemaclayer_la_CPPFLAGS= \\ -I@top_srcdir@/include \\ $(AM_CPPFLAGS) \\ $(libemane_CFLAGS) libmyrfpipemaclayer_la_LIBADD= \\ $(libuuid_LIBS) \\ $(libxml2_LIBS) \\ $(protobuf_LIBS) \\ @top_srcdir@/src/libemane/.libs/libemane.la libmyrfpipemaclayer_la_LDFLAGS= \\ $(AM_LDFLAGS) \\ -avoid-version # 源码监听文件 libmyrfpipemaclayer_la_SOURCES = \\ maclayer.cc \\ downstreamqueue.cc \\ pcrmanager.cc \\ rfpipemacheadermessage.cc \\ maclayer.h \\ downstreamqueue.h \\ pcrmanager.h \\ rfpipemacheadermessage.h nodist_libmyrfpipemaclayer_la_SOURCES = \\ rfpipemacheader.pb.cc \\ rfpipemacheader.pb.h # 定义非动态库编译的其他文件 EXTRA_DIST= \\ myrfpipenem.xml.in \\ myrfpipemac.xml.in \\ myrfpipepcr.xml.in \\ rfpipemacheader.proto BUILT_SOURCES = \\ myrfpipenem.xml \\ myrfpipemac.xml \\ myrfpipepcr.xml \\ $(nodist_libmyrfpipemaclayer_la_SOURCES) edit = sed \\ -e 's|@datadir[@]|$(pkgdatadir)|g' # 定义模板xml的生成 sed 加 文本重定向 myrfpipenem.xml: myrfpipenem.xml.in $(edit) $\u0026lt; \u0026gt; $@ myrfpipemac.xml: myrfpipemac.xml.in $(edit) $\u0026lt; \u0026gt; $@ myrfpipepcr.xml: myrfpipepcr.xml.in $(edit) $\u0026lt; \u0026gt; $@ # 定义proto 的生成 rfpipemacheader.pb.cc rfpipemacheader.pb.h: rfpipemacheader.proto protoc -I=. --cpp_out=. $\u0026lt; clean-local: rm -f $(BUILT_SOURCES) # 创建 相应模型目录, 并定义 make install 复制的模板xml install-exec-hook:\t$(mkinstalldirs) $(DESTDIR)$(datadir)/$(PACKAGE)/xml/models/mac/myrfpipe cp -f myrfpipenem.xml $(SCHEMAS) $(DESTDIR)$(datadir)/$(PACKAGE)/xml/models/mac/myrfpipe cp -f myrfpipemac.xml $(SCHEMAS) $(DESTDIR)$(datadir)/$(PACKAGE)/xml/models/mac/myrfpipe cp -f myrfpipepcr.xml $(SCHEMAS) $(DESTDIR)$(datadir)/$(PACKAGE)/xml/models/mac/myrfpipe uninstall-local: rm -f $(DESTDIR)$(datadir)/$(PACKAGE)/xml/models/mac/myrfpipe/myrfpipenem.xml rm -f $(DESTDIR)$(datadir)/$(PACKAGE)/xml/models/mac/myrfpipe/myrfpipemac.xml rm -f $(DESTDIR)$(datadir)/$(PACKAGE)/xml/models/mac/myrfpipe/myrfpipepcr.xml makefile 编写完成后\n./autogen.sh # 或者 autoreconf --install 生成相应makefile PYTHON=python3 ./configure --prefix=/usr make check # 检测编译 make -j$(nproc) # 按照核心数多线程编译 sudo make install # 复制动态库 emane二进制程序 头文件 pcr模型xml 解析器 到对应系统目录 关于 emane 的xml配置路径:\n/usr/share/emane$ tree -L 1 . ├── dtd\t# Document Type Definition路径 ├── manifest # 所有无线模型 mac phy 和其他插件的参数类型定义xml ├── schema\t# tdma 时隙专用 └── xml\t# 无线模型插件pcr与其他插件的默认xml core中调用mac library 命名规则为 mac层主初始化的文件及其上级路径 (小写)。其具体定义在 makefile.am 的 lib_LTLIBRARIES 定义 需要加上前缀 lib\nmac library 相对路径 DECLARE_MAC_LAYER bypassmaclayer src/models/mac/bypass/maclayer.cc EMANE::Models::Bypass::MACLayer ieee80211abgmaclayer src/models/mac/ieee80211abg/maclayer.cc EMANE::Models::IEEE80211ABG::MACLayer rfpipemaclayer src/models/mac/rfpipe/maclayer.cc EMANE::Models::RFPipe::MACLayer tdmaeventschedulerradiomodel src/models/mac/tdma/eventscheduler/radiomodel.cc TDMAEventSchedulerRadioModel 调试相关\nmakefile中默认配置了 gdb，所以可以通过 gdb ~/emane/src/applications/emane/.libs/emane -tui 来debug调试程序。\n甚至也可使用 vscode 做到类似 Visual Studio 界面的调试：/home/lk233/emane/.vscode/launch.json 配置如下\n{ // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;, \u0026quot;configurations\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;g++ - 生成和调试活动文件\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;cppdbg\u0026quot;, \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;, // \u0026quot;program\u0026quot;: \u0026quot;${fileDirname}/${fileBasenameNoExtension}\u0026quot;, \u0026quot;program\u0026quot;: \u0026quot;/home/lk233/emane/src/applications/emane/.libs/emane\u0026quot;, \u0026quot;args\u0026quot;: [], \u0026quot;stopAtEntry\u0026quot;: false, \u0026quot;cwd\u0026quot;: \u0026quot;${fileDirname}\u0026quot;, \u0026quot;environment\u0026quot;: [], \u0026quot;externalConsole\u0026quot;: false, \u0026quot;MIMode\u0026quot;: \u0026quot;gdb\u0026quot;, \u0026quot;setupCommands\u0026quot;: [ { \u0026quot;description\u0026quot;: \u0026quot;为 gdb 启用整齐打印\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;-enable-pretty-printing\u0026quot;, \u0026quot;ignoreFailures\u0026quot;: true } ], // \u0026quot;preLaunchTask\u0026quot;: \u0026quot;C/C++: g++ 生成活动文件\u0026quot;, \u0026quot;miDebuggerPath\u0026quot;: \u0026quot;/usr/bin/gdb\u0026quot; } ] } 之后按下f5即可调试，当然要想生成主程序的 make 也可以在这里进行配置，需要写 task.json 这么搞属实更麻烦\n如果 core 安装时使用 虚拟环境 (默认)，则emane make install 生成的脚本包默认使用真实环境的python，需要修改或者这些py脚本的解析器路径，否则无法运行。\t这里分享一个简易指令:\npy_path=$(cat $(which core-python) | awk 'NR==2 {print $2}') py_path='#!'${py_path:1:-1} old_path='#!.*' files=(\u0026quot;emaneevent-fadingselection\u0026quot; \u0026quot;emanecommand-eel\u0026quot; \u0026quot;emaneevent-location\u0026quot; \\ \u0026quot;emaneota-publisher\u0026quot; \u0026quot;emaneevent-antennaprofile\u0026quot; \u0026quot;emaneevent-pathloss\u0026quot; \\ \u0026quot;emanesh\u0026quot; \u0026quot;emaneevent-commeffect\u0026quot; \u0026quot;emaneevent-tdmaschedule\u0026quot;\\ \u0026quot;emaneevent-dump \u0026quot;\u0026quot;emanegentransportxml\u0026quot;) for f in ${files[@]} do a=$(which $f) sudo sed -i \u0026quot;1s|$old_path|$py_path|\u0026quot; $a done 无线模型绑定至core\n设定自定义模型路径\n​\tCORE 通过动态加载用户创建的模型的 python 来支持自定义开发的 EMANE 模型。自定义 EMANE 模型应放置在 CORE 配置文件 /etc/core/core.conf 中 emane_models_dir 定义的路径中。例如 emane_models_dir = /home/lk233/core/mytools/myemane_modules 此路径不能以 /emane 结尾。\n设定emane参数 对应core配置界面\n​\t该路径下应当设置为一个模块，类似如下结构\n├── CRradio.py ├── mybypass.py └── __init__.py ​\t其中 一个调用emane模型的模板 如下所示，具体选项由自定义模型决定：\n\u0026quot;\u0026quot;\u0026quot; 自定义 emane model 示例 \u0026quot;\u0026quot;\u0026quot; from pathlib import Path from typing import Dict, Optional, Set, List from core.config import Configuration from core.emane import emanemanifest, emanemodel class ExampleModel(emanemodel.EmaneModel): \u0026quot;\u0026quot;\u0026quot; :参数 name: 定义将显示在GUI中的emane模型名称，必须加上前缀 emane_ :参数 config_ignore: 忽略 mac phy 参数的列表，添加至此列表的参数将不会序列化至emane配置xml中，这些配置一般是core的界面或其他额外设定 Mac 定义: :参数 mac_library: 定义模型将引用的 emane MAC库 :参数 mac_xml: 定义将被解析以获得默认配置选项的MAC清单xml，将显示在GUI中 :参数 mac_defaults: 覆盖上述的mac层默认值 :参数 mac_config: 解析xml并转换生成的core支持的列表 Phy 定义: phy一般配置为通用模型，如下所示，下面的参数都是可选的。 :参数 phy_library: 定义模型将引用的phy库，也可使用自定义phy :参数 phy_xml: 定义将被解析以获得配置选项的phy清单xml，将显示在GUI中 :参数 phy_defaults: 覆盖上述的phy层默认值 :参数 phy_config: 解析xml并转换生成的core支持的列表 \u0026quot;\u0026quot;\u0026quot; # 一定为emane_前缀 name: str = \u0026quot;emane_myrfpipe\u0026quot; # 设置mac库模型 mac_library: str = \u0026quot;myrfpipemaclayer\u0026quot; # 解析获取模型所有配置 mac_xml: str = \u0026quot;/usr/share/emane/manifest/myrfpipemaclayer.xml\u0026quot; # 覆盖默认值 mac_defaults: Dict[str, str] = { \u0026quot;pcrcurveuri\u0026quot;: \u0026quot;/usr/share/emane/xml/models/mac/myrfpipe/myrfpipepcr.xml\u0026quot; } mac_config: List[Configuration] = [] # phy 类似mac配置，使用默认phy模型 无需设置library phy_library: Optional[str] = None phy_xml: str = \u0026quot;/usr/share/emane/manifest/emanephy.xml\u0026quot; phy_defaults: Dict[str, str] = { \u0026quot;subid\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;propagationmodel\u0026quot;: \u0026quot;2ray\u0026quot;, \u0026quot;noisemode\u0026quot;: \u0026quot;none\u0026quot;, } phy_config: List[Configuration] = [] config_ignore: Set[str] = set() @classmethod def load(cls, emane_prefix: Path) -\u0026gt; None: \u0026quot;\u0026quot;\u0026quot; Called after being loaded within the EmaneManager. Provides configured emane_prefix for parsing xml files. :param emane_prefix: configured emane prefix path :return: nothing \u0026quot;\u0026quot;\u0026quot; # load mac configuration cls.mac_config = emanemanifest.parse(cls.mac_xml, cls.mac_defaults) # load phy configuration cls.phy_config = emanemanifest.parse(cls.phy_xml, cls.phy_defaults) TDMA 模型 添加注意项 TDMA无线模型 实现了专门的时隙调度器和消息队列管理器模块 来对的TDMA模型开发。\n除了引用 include/emane/ 下的基础的计算邻居节点等头文件定义 (类似 #include \u0026ldquo;emane/models/tdma/basemodel.h\u0026rdquo;)\n包含了 通过解析emane事件用于调度时隙 的事件消息结构定义 (类似\u0026quot;emane/events/slotstructure.h\u0026quot;)\n还包含了 include/emane/models/tdma/* 的tdma模型独有变种文件 (类似 #include \u0026ldquo;emane/maclayerimpl.h\u0026rdquo;)\nTDMA 与其他模型不同 并非在 maclayer.cc 中创建mac层 Implementor, 而是通过 MACLayerImplementor SchedulerUser 派生出 tdma 包含时隙通信的。TDMA 模型(radiomodel) 从逻辑上可以分为\n基础tdma无线模型 basemodel\n动态更新时隙模块 eventscheduler 和其处理 时隙切割报文队列管理模块 queuemangager\n大致结构如下所示:\n查看文件结构\ninclude/emane/events 部分内容 emane/include/emane/events ├── slotinfo.h ├── slotinfo.inl ├── slotstructure.h ├── slotstructure.inl └── tdmascheduleevent.h # tdma 时隙事件可以用 emane 安装后生成的 emaneevent-tdmaschedule 来触发新时隙更新调度, 其组件与emane进程通信的数据也是通过 protobuf 序列化生成的。 emane/include/emane/models/tdma ├── radiomodel.h # TDMA 动态时隙无线模型 的头文件 include basemodel.h ├── basemodel.h # maclayerimpl 的变种 包含 TDMA 的 scheduler.h 和 queuemanager.h ├── basicqueuemanager.h # QueueManager 的变种 包含 queuemanager.h ├── Makefile.am ├── messagecomponent.h # 消息缓存组件，其内容根据是否启用了聚合 来确定 data 或 control message 是否完整或部分传输 无线模型每次传输将传输一个或多个组件。在时隙和消息数据大小上的消息组件可以是一个或多个包的组合。 ├── messagecomponent.inl ├── packetstatuspublisher.h ├── packetstatuspublisheruser.h ├── queuemanager.h # 包含上述包处理的消息队列变种处理的头文件 ├── scheduler.h # BaseModel用于通信的调度器接口与调度器(Scheduler)模块 包含 scheduleruser.h ├── scheduleruser.h └── types.h # 包含了mac的基础消息类似 还包含的时隙 SlotInfo TxSlotInfo RxSlotInfo 相关的定义 一个tdma示例的实现 emane/src/models/mac/mytdma ├── eventscheduler │ ├── radiomodel.cc # 最终打包的动态库实例，生成动态时隙模型 │ ├── eventscheduler.cc # 时隙调度器实例 │ ├── eventscheduler.h │ ├── eventtablepublisher.cc # 通过emane tdma事件 来进行 动态调度的实例 │ ├── eventtablepublisher.h │ ├── Makefile.am │ ├── slotter.h # 时隙成员声明 │ ├── slotter.inl │ ├── tdmanem.xml.in # 初始时隙表 模板示例 │ └── tdmaradiomodel.xml.in # 基础无线参数 模板示例 ├── aggregationstatuspublisher.cc # 消息片段聚合状态 统计实例 ├── aggregationstatuspublisher.h ├── basemodel.cc # 包含了 根据时隙来处理上下游关系的基础无线tdma模型 ├── basemodelimpl.cc ├── basemodelimpl.h ├── basemodelmessage.h ├── basemodelmessage.inl ├── basicqueuemanager.cc ├── Makefile.am ├── packetstatuspublisherimpl.cc # 报文状态发布实例 ├── packetstatuspublisherimpl.h ├── pormanager.cc ├── pormanager.h ├── priority.h # 下游数据入队列的优先级声明 ├── queue.cc ├── queue.h ├── queuestatuspublisher.cc ├── queuestatuspublisher.h ├── receivemanager.cc # 将分离的时隙的数据重新聚合 ├── receivemanager.h ├── slotstatustablepublisher.cc # 时隙表统计实例 ├── slotstatustablepublisher.h ├── tdmabasemodelmessage.proto # 模型mac层消息的数据结构定义 可以使用 文件夹内make 更新，也可调用 protoc -I=. --cpp_out=. *.proto ├── tdmabasemodelpcr.xml # 默认无线模型的pcr曲线定义，其解析与 其他模型交由emane组件解析不同，由模型自己做解析处理 ├── txslotinfosformatter.cc # 格式化 发送消息时隙的对象 └── txslotinfosformatter.h 修改 configure.ac AC_OUTPUT 添加这两行 生成 makefile 选项\nsrc/models/mac/mytdma/Makefile src/models/mac/mytdma/eventscheduler/Makefile 其余 makefile.am 的修改类似 之前 myrfpipe 的创建过程\n注意\nxml解析由模型自己模块的 pormanager.cc 实现, 无需添加dtd\n为了后面可能需要的定制修改, 将 emane/models/mytdma/ 复制一份放入 header 中, 并并修改其中的调用路径\nemane/src/models/mac/mytdma/eventscheduler/Makefile.am 里的动态库包含的上级目录的 libtdmabase 需要修改 libmytdmabase\n","id":3,"section":"posts","summary":"Emane开发文档 Emane维基 Emane仿真架构： Emane仿真流程 ​ 当仿真器实例化模型插件（即读取模型配置文件platform.xml）","tags":["C/C++"],"title":"Emane模型调研","uri":"https://liangkang233.github.io/2022/05/emane%E6%A8%A1%E5%9E%8B%E8%B0%83%E7%A0%94/","year":"2022"},{"content":"推荐一些个人觉得比较好用的工具\n语音识别工具 之前也分享过百度ai提供的api的SDk，虽然免费 但是不太够用。所以找了找有没有类似的替代品。这个项目使用tensorFlow.keras基于深度卷积神经网络和长短时记忆神经网络、注意力机制以及CTC实现。 ASRT star 数很多，看起来也挺好用的。\n该工具原理即 调用深度学习训练的 DCNN + CTC 声学模型 将语音模拟信号数据生成拼音序列 再利用 统计语言模型 生成文字。\n提供了一个 demo 页面以及对应的 sdk 对应调用其网站后端的识别 api 供开发(api接口说明)。同时也很贴心的准备了录音工具 dockerfile 来生成镜像直接部署执行。\n如果想自己改进算法或训练模型，需要数据集 开源的中文语音数据集 和最低要求 1080ti的显卡，我直接开摆🏃‍🏃‍，好在 Release 压缩包内包含训练好的语音模型，直接拿来用吧。\n# 安装环境 pip install -r requirements.txt 部分文件功能介绍 ASRT_v1.2.0\u0026gt;:. │ asrserver.py # 启用http后台服务器 对应 client.py │ asrserver_http.py # 启用flask 框架的 restful 风格 的 http后台服务器 对应 client_http.py │ asrt_config.json # 数据集对应位置配置 │ speech_model.py # 声学模型基础功能模板定义 │ speech_model_zoo.py # 声学模型模型的实现 │ speech_recorder.py # 一个配置为可用于ASRT语音识别系统的录音程序 | dict.txt # 音标对应文字 字典 | ├─assets │ default.html │ ├─model_language # 统计语言模型 │ dic_pinyin.txt │ language_model1.txt │ language_model2.txt │ ├─save_models # 语音识别训练模型 h5可视化 可以用 vitables python 程序浏览层次化数据 │ SpeechModel251bn.model.base.h5 │ SpeechModel251bn.model.h5 pip install pywin pipwin install pyaudio python3 speech_recorder.py # 即可录制声音 默认是output.wav文件 安装 pyaudio 包如果报错可以使用pipwin来安装 （windows缺少对应编译打包环境）参考stackoverflow回答）\n# 如下会识别当前目录下的 filename.wav python3 predict_speech_file.py 测试语音：二毛你今天沒课嘛还和李霞聊天\n文档说的80%正确率看来不是谦虚😂 转拼音识别率不错 就是转语句仍需训练\n基本测试完毕后就可以进行改造和调用了。\nMD转换工具 markdown 拿来写手册做记录还是很不错的，排版简洁 语法简单。\n某次分享记录时，对方没有MD阅读软件，想用 Typora 导出pdf或html格式的文件分享给其他人，可惜格式不太好看。\ngithub上找了找，找到个轻量简单的 MD文档转html格式的 小工具 MDcat，其html模板也可以修改生成的html具有黑暗模式，支持语法高亮。导出\n看了下源码 是直接调用像 github的 https://api.github.com/markdown 接口发送post请求生成的html。生成的 html 渲染风格和 github 一样。\n这不直接clone试试好不好用。\n执行主文件直接生成在当前目录\npython3 mdcat.py md文件名 # 注意关闭网络代理 效果还不错，推荐。\n","id":4,"section":"posts","summary":"推荐一些个人觉得比较好用的工具 语音识别工具 之前也分享过百度ai提供的api的SDk，虽然免费 但是不太够用。所以找了找有没有类似的替代品。这个","tags":["python"],"title":"工具推荐：语音识别 MD转换","uri":"https://liangkang233.github.io/2022/04/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/","year":"2022"},{"content":"刷题时总是写了又忘，所以专门整理了一个题目记录本。\n刷题记录本\n做到 二分算法 的专题时，对于其边界的处理非常棘手。所以写了这篇博客对二分的实现、应用进行一个全面的总结。\n标准二分 int binarySearch(Element array[], int len, int key){ int low = 0, high = len - 1, middle; while(low \u0026lt;= high){ middle = (low + high) / 2; if(array[middle] == key){ //找到,返回下标索引值 return middle; }else if(array[middle] \u0026gt; key){ //查找值在低半区 high = middle - 1; }else{ //查找值在高半区 low = middle + 1; } } return -1; //找不到 } 说实话 这样做扩展性不好，不推荐这么写\n扩展性强的 二分 按照 std upper_bound lower_bound 库的效果设计的二分函数\nmylower_bound 寻找数组中 第一个大于等于 目标值的 下标\n// last 初始值 = size时 target超出上限范围会返回 end下标 int mylower_bound(int* array ,int size,int key){ int first = 0, middle ,last = size-1; while(first\u0026lt;last){ middle = (first+last) \u0026gt;\u0026gt; 1; if(array[middle] \u0026lt; key ) //当middle小于要找的位置 ， first +1 也不会超过key的位置，最多相同 first = middle + 1; else last = middle ; //middle有可能等于要找的位置 ， last = middle ， 用first不断逼近 } return first; } myupper_bound 寻找数组中 第一个大于 目标值的 下标\n// last 初始值 = size 时 target超出上限范围会返回 end下标 int myupper_bound(int* array ,int size,int key){ int first = 0, middle ,last = size-1; while(first\u0026lt;last){ middle = (first+last) \u0026gt;\u0026gt; 1; if(array[middle] \u0026lt;= key ) //此时的middle一定大于要找的位置。用first不断逼近 first = middle +1; //当middle等于要找的位置， 我们记录first = middle+1 else last = middle ; } return first; } 实际使用 35.搜索插入位置\n// 这个标准二分的改版 等价求出 lower_bound 写法风格不同，效果一样的 class Solution { public: int searchInsert(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int l = 0, r = nums.size()-1; while(l \u0026lt;= r) { int mid = (l + r) \u0026gt;\u0026gt; 1; if(nums[mid] \u0026lt; target) l = mid+1; else r = mid-1; } return l; } }; std库函数 自定义 引入头文件 #include \u0026lt;algorithm\u0026gt; 即可使用\n以下面的实际使用举例 说明 库函数的使用方法\n注意自定义 比较函数 两者的区别 ，使用 upper_bound lower_bound\n对于同一参数 是不需要修改比较函数的，都是 return i \u0026lt; j;\n#include \u0026lt;iostream\u0026gt; // std::cout #include \u0026lt;algorithm\u0026gt; // std::upper_bound #include \u0026lt;vector\u0026gt; // std::vector using namespace std; //以普通函数的方式定义查找规则 等价operator bool mycomp(int i, int j) { return i \u0026gt; j; } auto mycomp1 = [](int i, int j)-\u0026gt;bool { return i \u0026gt; j; }; class mycomp2 { public: bool operator()(const int\u0026amp; i, const int\u0026amp; j) { return i\u0026lt;j; } }; int main() { int x = 1; int a[5] = {3,7,9,12,15}; // 若是输入指针则 注意不能超出数组有效范围 没有那个end属性 查找大于数组最大值时返回的也是最后一个元素的指针 // 返回值是对应元素的下标或迭代器 找不到对应值时会返回 vector.end() int *p = upper_bound(a, a + 4, x); cout \u0026lt;\u0026lt; \u0026quot;*p = \u0026quot; \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; p = lower_bound(a, a + 4, x); cout \u0026lt;\u0026lt; \u0026quot;*p = \u0026quot; \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; // 以函数对象的形式定义查找规则 j为容器遍历值 i为输入的查找值 // low是找出大于等于指定值，即找出i\u0026gt;=j才停 i是遍历值 函数内不成立跳出循环 vector\u0026lt;int\u0026gt; myvector{ 1,2,3,4,5 }; vector\u0026lt;int\u0026gt;::iterator iter = upper_bound(myvector.begin(), myvector.end(), x, mycomp2()); if(iter==myvector.end()) cout \u0026lt;\u0026lt; \u0026quot;error\u0026quot;\u0026lt;\u0026lt;endl; else cout \u0026lt;\u0026lt; \u0026quot;*iter = \u0026quot; \u0026lt;\u0026lt; *iter; // uper找出大于指定值，即找出j\u0026gt;i才停 j是遍历值 函数内成立跳出循环 // 以函数对象的形式定义查找规则 i为容器遍历值 j为输入的查找值 vector\u0026lt;int\u0026gt;::iterator iter1 = upper_bound(myvector.begin(), myvector.end(), x, mycomp2()); if(iter1==myvector.end()) cout \u0026lt;\u0026lt; \u0026quot;error\u0026quot;\u0026lt;\u0026lt;endl; else cout \u0026lt;\u0026lt; \u0026quot;*iter1 = \u0026quot; \u0026lt;\u0026lt; *iter1; return 0; } 二维容器 注意点: int target = 1; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; myvector{{1,3,5,7}, {10,11,16,20}, {23,30,34,60}}; //第二个形参不设const会报错 auto row = [](const vector\u0026lt;int\u0026gt;\u0026amp; a, const vector\u0026lt;int\u0026gt;\u0026amp; b) {return a[0] \u0026lt; b[0];}; //目标值一定要与遍历元素类型相同，此处目标值转为 一维容器 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;::iterator iter = lower_bound(myvector.begin(), myvector.end(), vector\u0026lt;int\u0026gt;{target}, row); 练习 74.搜索二维矩阵 class Solution { public: // 以第一列即行首为目标二分 后对该行进行列二分 bool searchMatrix(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix, int target) { auto row = [](const vector\u0026lt;int\u0026gt;\u0026amp; a, const vector\u0026lt;int\u0026gt;\u0026amp; b) {return a[0] \u0026lt; b[0];}; // 注意第二个形参一定要 const 建议全部写成const, 第三个比较参数的类型要与前面容器元素类型一致 即target 要从int -\u0026gt; vector auto it = upper_bound(matrix.begin(), matrix.end(), vector\u0026lt;int\u0026gt;{target}, row); int index = distance(matrix.begin(), it); // 以行首二分 寻找第一个大于 target 值 没找到返回的it为end index--; if(index \u0026lt; 0) return false; auto it1 = lower_bound(matrix[index].begin(), matrix[index].end(), target); // 对该行进行列的二分查找 return it1 != matrix[index].end() \u0026amp;\u0026amp; *it1 == target; } }; 240.搜索二维矩阵II // 74题进阶，由题意 任意坐标右下方 全部大于等于该坐标值 左上方全部小于等于该值 时间复杂度O(logm + logn) // 所以先对第一行列二分删除多余大于target的列 再行二分删除小于target的行 不断迭代下去 class Solution { public: int myupper_bound(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix, int row, int column, int target) { int L = 0, R = column + 1; while (L \u0026lt; R) { int mid = (L + R) \u0026gt;\u0026gt; 1; if(matrix[row][mid] \u0026lt;= target) L = mid+1; else R = mid; } return L; } int mylower_bound(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix, int row, int column, int target) { int L = row, R = matrix.size(); while (L \u0026lt; R) { int mid = (L + R) \u0026gt;\u0026gt; 1; if(matrix[mid][column] \u0026lt; target) L = mid+1; else R = mid; } return L; } bool searchMatrix(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; matrix, int target) { // 有效范围 行为 row-\u0026gt;matrix.end()-1 列为 0-cloumn int row = 0, column = matrix[0].size()-1; while (1) { // std库做法 // auto it = upper_bound(matrix[row].begin(), matrix[row].begin()+column+1, target); // if(it == matrix[row].begin()) // break; // column = distance(matrix[row].begin(), it) - 1; // column 右边删去 column = myupper_bound(matrix, row, column, target) - 1; // column 右边删去 if(column \u0026lt; 0) //target 比范围内最小值还小 break; row = mylower_bound(matrix, row, column, target); if(row == matrix.size()) //target 比范围内最大值还大 break; if(matrix[row][column] == target) return true; } return false; } }; 410.分割数组的最大值 class Solution { public: // 二分法 绝了 bool isok(vector\u0026lt;int\u0026gt;\u0026amp; nums, int mid, int m) { int count = 1, temp = 0; for(auto num : nums) { if ( temp + num \u0026lt;= mid) temp += num; else { temp = num; count ++; } } return count \u0026gt; m; } int splitArray(vector\u0026lt;int\u0026gt;\u0026amp; nums, int m) { int L = -1,R = 0, mid; // L为整个数组的最大值 R为整个数组的总和 分割的子数组和的最大值 取值范围即在L R之中 // 由于分割次数 m 和 分割子数组和的最大值 成线性负相关 关系 所以可以采用二分的方法 靠近测试 for (auto num : nums) { L = max(L, num); R += num; } while(L \u0026lt; R) { mid = (L + R)/2; if(isok(nums, mid, m)) L = mid+1; else R = mid; } return L; // L==R } }; ","id":5,"section":"posts","summary":"刷题时总是写了又忘，所以专门整理了一个题目记录本。 刷题记录本 做到 二分算法 的专题时，对于其边界的处理非常棘手。所以写了这篇博客对二分的实现、应","tags":["C/C++","算法"],"title":"二分小结","uri":"https://liangkang233.github.io/2022/04/%E4%BA%8C%E5%88%86%E5%B0%8F%E7%BB%93/","year":"2022"},{"content":"发现一个简易的使用qq推送消息的工具，原本打算用来做网盘的提醒助手，最后放弃了。\n不过感觉这个玩具挺好玩的，做个记录。\nQmsg首页 qq登录即注册qmsg的账号添加对应账号机器人，获取key之后就可以用它做消息的提醒。\n文档写的很简单 就做一个get/post请求即可\n用go来封装 http请求 模拟http请求在线测试工具\n复习相关知识 （可以直接跳过） Go 的 HTTP 标准库-基本工作原理\n当然简单的操作，可以直接用curl to go将curl命令行转换为对应go代码\ngo http包 有简易的 get post，若是发送较长的数据 推荐使用postform发送表单 或者转为json数据post指定json格式发送\n以下是通过post发送表单和解析json数据的示例代码\n注意 接收的resp.Body不要忘记关闭\n实现 package main import ( \u0026quot;encoding/json\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;net/url\u0026quot; \u0026quot;strings\u0026quot; \u0026quot;time\u0026quot; ) const key = \u0026quot;***\u0026quot; // 申请的key const url1 = \u0026quot;https://qmsg.zendee.cn/send/\u0026quot; // 私聊消息推送接口： // const ur2 =\u0026quot;https://qmsg.zendee.cn/group/\u0026quot; // 群消息推送接口： type infodetail struct { Lmyidc string } type QmsgResult struct { Reason string Success bool Code int // Info interface{}\t//嵌套类型json暂不处理直接给此类型 等价为map[string] interface{} Info infodetail } func main() { log.SetFlags(log.Ldate | log.Lshortfile) myurl := url1 + key client := \u0026amp;http.Client{Timeout: time.Second * 15} params := url.Values{} params.Add(\u0026quot;msg\u0026quot;, \u0026quot;有没有这么一种可能@face=172@\u0026quot;) // params.Add(\u0026quot;msg\u0026quot;, \u0026quot;解析json测试@face=177@\u0026quot;) params.Add(\u0026quot;key2\u0026quot;, `value:2`) body := strings.NewReader(params.Encode()) resp, err := client.Post(myurl, \u0026quot;application/x-www-form-urlencoded\u0026quot;, body) if err != nil { log.Println(err) } defer resp.Body.Close() DataPrint(resp) } func DataPrint(resp *http.Response) { if resp.StatusCode != http.StatusOK { log.Printf(\u0026quot;http response failed: %s\\n\u0026quot;, resp.Status) } var result QmsgResult if err := json.NewDecoder(resp.Body).Decode(\u0026amp;result); err != nil { //底层unmarshal log.Println(err) } log.Println(result.Reason, result.Code, result.Info.Lmyidc, result.Success) } 测试无误后只需要将这一小段嵌入到业务代码即可，\n很多人用法是写成js插件做到前端页面例如博客的评论区回复提醒等 基于Leancloud或javascript推送Valine评论\n其他备忘 get post用法\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; ) const url = \u0026quot;https://baidu.com\u0026quot; func main() { // 方式一，直接通过 Get 函数 resp, err := http.Get(url) ErrPrint(err) defer resp.Body.Close() // 拿到数据 bytes, err := ioutil.ReadAll(resp.Body) ErrPrint(err) // 这里要格式化再输出，因为 ReadAll 返回的是字节切片 fmt.Println(\u0026quot;------------- 方法一 ---------------\u0026quot;) fmt.Printf(\u0026quot;%s\u0026quot;, bytes) // 方式二，通过 client 结构体的 Get 方法 // client := new(http.Client) 等价下式 client := \u0026amp;http.Client{} resp, err = client.Get(url) ErrPrint(err) defer resp.Body.Close() res, err := ioutil.ReadAll(resp.Body) ErrPrint(err) fmt.Println(\u0026quot;\\n\\n\\n------------- 方法二 ---------------\u0026quot;) fmt.Printf(\u0026quot;%s\u0026quot;, res) } func ErrPrint(err error) { if err != nil { log.Fatalln(err) os.Exit(1) } } post 普通字串 json用法\n/* post client */ package main import ( \u0026quot;encoding/json\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strings\u0026quot; ) // json包解析变量只能解析首字母大写的 type Mytest struct { Type int Desc string Name string UserId string } const url = \u0026quot;http://localhost:8080/hello\u0026quot; func main() { // 方式一，直接通过 Post 函数 fmt.Println(\u0026quot;------------- 方法一 ---------------\u0026quot;) resp, err := http.Post(url, \u0026quot;application/x-www-form-urlencoded\u0026quot;, strings.NewReader(\u0026quot;name=Bro Qiang\u0026quot;)) ErrPrint(err) defer resp.Body.Close() DataPrint(resp.Body) // 方式二，通过 client 结构体中的 Post 方法 fmt.Println(\u0026quot;------------- 方法二 ---------------\u0026quot;) client := \u0026amp;http.Client{} resp, err = client.Post(url, \u0026quot;application/x-www-form-urlencoded\u0026quot;, strings.NewReader(\u0026quot;name=New Bro Qiang\u0026quot;)) ErrPrint(err) defer resp.Body.Close() DataPrint(resp.Body) // 方式一发送json fmt.Println(\u0026quot;------------- 方法一json ---------------\u0026quot;) info := Mytest{ Type: 1, UserId: \u0026quot;lsj\u0026quot;, Name: \u0026quot;lk233\u0026quot;, Desc: \u0026quot;test_UserInfo\u0026quot;, } bytes, _ := json.Marshal(info) resp, err = http.Post(url, \u0026quot;application/json\u0026quot;, strings.NewReader(string(bytes))) if err != nil { log.Println(\u0026quot;query info failed\u0026quot;, err.Error()) } defer resp.Body.Close() DataPrint(resp.Body) } func DataPrint(body io.ReadCloser) { bytes, err := ioutil.ReadAll(body) ErrPrint(err) fmt.Printf(\u0026quot;%s\u0026quot;, bytes) } func ErrPrint(err error) { if err != nil { log.Fatalln(err) os.Exit(1) } } /* get 的server与 post server类似 添加 下面的类似模块 if req.Method == \u0026quot;GET\u0026quot; { err := req.ParseForm() if err != nil { http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError) return } for k, v := range req.Form { } */ /* post_server */ package main import ( \u0026quot;encoding/json\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; ) type Mytest struct { Type int Desc string UserId string Name string } func main() { http.HandleFunc(\u0026quot;/hello\u0026quot;, func(w http.ResponseWriter, req *http.Request) { if req.Method == \u0026quot;POST\u0026quot; { // if req.Context() // fmt.Fprintf(w,\u0026quot;Hello %s\\n\u0026quot;,req.FormValue(\u0026quot;name\u0026quot;)) 此函数可以直接获取对应键值 底层实际也是调用 ParseForm err := req.ParseForm() if err != nil { http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError) return } // fmt.Println(req.Header[\u0026quot;Content-Type\u0026quot;][0]) if req.Header[\u0026quot;Content-Type\u0026quot;][0] == \u0026quot;application/x-www-form-urlencoded\u0026quot; { formData := req.Form fmt.Fprintf(w, \u0026quot;Hello %s\\n\u0026quot;, formData.Get(\u0026quot;name\u0026quot;)) } else { //post数据是json需要其他处理 body, _ := ioutil.ReadAll(req.Body) // read req之后 req的其他解析全为空 myjson := Mytest{} if json.Unmarshal(body, \u0026amp;myjson) != nil { fmt.Fprintf(w, \u0026quot;error json\\n\u0026quot;) } else { fmt.Fprintf(w, \u0026quot;json Hello %s\\n\u0026quot;, myjson.Name) } } return } http.NotFound(w, req) }) log.Fatalf(\u0026quot;%v\u0026quot;, http.ListenAndServe(\u0026quot;localhost:8080\u0026quot;, nil)) } postform用法\n/* postform server */ package main import ( \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; ) func main() { http.HandleFunc(\u0026quot;/form\u0026quot;, MyForm) log.Fatalf(\u0026quot;%v\u0026quot;, http.ListenAndServe(\u0026quot;localhost:8080\u0026quot;, nil)) } func MyForm(w http.ResponseWriter, r *http.Request) { err := r.ParseForm() if err != nil { http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError) return } formData := r.Form log.Printf(\u0026quot;收到的数据： %v\u0026quot;, formData) fmt.Fprintf(w, \u0026quot;提交成功\u0026quot;) } /* client */ package main import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; ) const url = \u0026quot;http://localhost:8080/form\u0026quot; func main() { data := map[string][]string{\u0026quot;name\u0026quot;: {\u0026quot;Bro|\u0026quot;, \u0026quot;Qiang\u0026quot;}, \u0026quot;gender\u0026quot;: {\u0026quot;male\u0026quot;}} // 方法一：PostForm 函数 resp, err := http.PostForm(url, data) ErrPrint(err) defer resp.Body.Close() DataPrint(resp.Body) // 方法二：client 结构体的 PostForm 方法 client := \u0026amp;http.Client{} resp, err = client.PostForm(url, data) ErrPrint(err) defer resp.Body.Close() DataPrint(resp.Body) } func DataPrint(body io.ReadCloser) { // 拿到数据 bytes, err := ioutil.ReadAll(body) ErrPrint(err) // 这里要格式化再输出，因为 ReadAll 返回的是字节切片 fmt.Printf(\u0026quot;%s\\n\u0026quot;, bytes) } func ErrPrint(err error) { if err != nil { log.Fatalln(err) os.Exit(1) } } ","id":6,"section":"posts","summary":"发现一个简易的使用qq推送消息的工具，原本打算用来做网盘的提醒助手，最后放弃了。 不过感觉这个玩具挺好玩的，做个记录。 Qmsg首页 qq登录即注","tags":["go","开发"],"title":"Qmsg消息推送助手","uri":"https://liangkang233.github.io/2022/03/qmsg%E6%B6%88%E6%81%AF%E5%8A%A9%E6%89%8B/","year":"2022"},{"content":"树的概念 树由有限个节点，组成具有层次关系的集合。每个结点或者无子结点或者只有有限个子结点;\n有一个特殊的结点,它没有父结点，称为根结点。每一个非根节点有且只有一个父节点。并且树里面没有环路。\n结点的度: 一个结点含有的子结点个数称为该结点的度;\n树的度: 一棵树中，最大结点的度称为树的度;\n按照有序性，可以分为有序树和无序树：\n无序树：树中任意节点的子结点之间没有顺序关系 有序树：树中任意节点的子结点之间有顺序关系\n按照节点包含子树个数，可以分为B树和二叉树\n二叉树 二叉树（英语：Binary tree）是每个节点最多只有两个分支（即不存在分支度大于2的节点）的树结构。通常分支被称作“左子树”或“右子树”。二叉树的分支具有左右次序，不能随意颠倒。\n二叉树可以分为以下几种：\n(完)满二叉树：\n叶节点除外的所有节点均含有两个子树的树被称为满二叉树;\n完全二叉树：\n如果一颗二叉树除去最后一层节点为满二叉树，且最后一层的结点依次从左到右分布\n霍夫曼树：\n带权路径最短的二叉树，哈夫曼树应用于通讯及数据传送中对信息的二进制编码。\n在计算机数据处理中，霍夫曼编码使用变长编码表对源符号(如文件中的一个字母)进行编码，其中变长编码表是通过一种评估来源符号出现机率的方法得到的，出现机率高的字母使用较短的编码，反之出现机率低的则使用较长的编码，这便使编码之后的字符串的平均长度、期望值降低，从而达到无损压缩数据的目的。\n二叉查找树：\n首先它是一颗二叉树，若左子树不空，则左子树上所有结点的值均小于它的根结点的值;\n若右子树不空，则右子树上所有结点的值均大于它的根结点的值;左、右子树也分别为二叉排序树;\n红黑树：\n红黑树是一颗特殊的二叉查找树，每个节点都是黑色或者红色，根节点、叶子节点是黑色。如果一个节点是红色的，则它的子节点必须是黑色的。\n平衡二叉查找树(AVL)：\n一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树\n完全二叉树 完美二叉树 总节点k $2^{h-1}$ \u0026lt;= k \u0026lt;= $2^{h} - 1$ k = $2^{h} - 1$ 树高h h = $log_{2}k + 1$ h = $log_{2}(k+1)$ 基础应用： 以此树为例：\n// 二叉树节点 struct Node { int value; struct Node* left; struct Node* right; Node(int data) : value(data), left(nullptr), right(nullptr) {}; }; bfs 层次遍历 // 利用队列来做。 void LevelOrder(Node* head) { if (head) { queue\u0026lt;Node*\u0026gt; queue; queue.push(head); Node* cur; while (!queue.empty()) { cur = queue.front(); queue.pop(); cout \u0026lt;\u0026lt; cur-\u0026gt;value \u0026lt;\u0026lt; \u0026quot; \u0026quot;; if (cur-\u0026gt;left) queue.push(cur-\u0026gt;left); if (cur-\u0026gt;right) queue.push(cur-\u0026gt;right); } } } dfs 前中后 序 // 先序遍历 void PreOrder(Node* head) { if (head == nullptr) return; cout \u0026lt;\u0026lt; head-\u0026gt;value \u0026lt;\u0026lt; \u0026quot; \u0026quot;; PreOrder(head-\u0026gt;left); PreOrder(head-\u0026gt;right); } // 中序遍历 void InOrder(Node* head) { if (head == nullptr) return; InOrder(head-\u0026gt;left); cout \u0026lt;\u0026lt; head-\u0026gt;value \u0026lt;\u0026lt; \u0026quot; \u0026quot;; InOrder(head-\u0026gt;right); } // 后序遍历 void PosOrder(Node* head) { if (head == nullptr) return; PosOrder(head-\u0026gt;left); PosOrder(head-\u0026gt;right); cout \u0026lt;\u0026lt; head-\u0026gt;value \u0026lt;\u0026lt; \u0026quot; \u0026quot;; } 使用栈实现的前中后序遍历 vector\u0026lt;int\u0026gt; preorderTraversal(TreeNode* root) { vector\u0026lt;int\u0026gt; retvec; stack\u0026lt;TreeNode*\u0026gt; stk; while (root != NULL || !stk.empty()) { while (root != NULL) { retvec.push_back(root-\u0026gt;val); stk.push(root); root = root-\u0026gt;left; } root = stk.top(); stk.pop(); root = root-\u0026gt;right; } } // 中序遍历. vector\u0026lt;int\u0026gt; preorderTraversal(TreeNode* root) { vector\u0026lt;int\u0026gt; retvec; stack\u0026lt;TreeNode*\u0026gt; stk; while (root != NULL || !stk.empty()) { while (root != NULL) { stk.push(root); root = root-\u0026gt;left; } root = stk.top(); stk.pop(); retvec.push_back(root-\u0026gt;val); root = root-\u0026gt;right; } } /* 补充: 后序遍历 前序遍历 =\u0026gt; 根, 左, 右. 后序遍历 =\u0026gt; 左, 右, 根. 仿照前序遍历方法求解出 =\u0026gt; 根, 右, 左. reverse =\u0026gt; 得到后序遍历. */ vector\u0026lt;int\u0026gt; postorderTraversal(TreeNode* root) { stack\u0026lt;TreeNode*\u0026gt; stk; vector\u0026lt;int\u0026gt; vec; while (root != NULL || !stk.empty()) { while (root != NULL) { vec.push_back(root-\u0026gt;val); stk.push(root); root = root-\u0026gt;right; } root = stk.top(); stk.pop(); root = root-\u0026gt;left; } reverse(vec.begin(), vec.end()); return vec; } 二叉树应用： 蓝桥杯：挑选工厂 /* 问题描述 最近，WYF正准备参观他的点卡工厂。WYF集团的经理氰垃圾需要帮助WYF设计参观路线。现在，氰垃圾知道一下几件事情： 1.WYF的点卡工厂构成一颗二叉树。 2.一共有n座工厂。 3.他需要把这颗树上的点以后序遍历的方法列出来，才能绘制地图。 还好，最近他的属下给了他先序遍历和中序遍历的数据。可是，氰垃圾最近还要帮㊎澤穻解决一些问题，没有时间。 请你帮帮他，替他完成这项任务。由于氰垃圾的一些特殊的要求，WYF的参观路线将会是这棵树的后序遍历。 输入格式 第一行一个整数n，表示一共又n座工厂。 第二行n个整数，表示先序遍历。 第三行n个整数，表示中序遍历。 输出格式 输出共一行，包含n个整数，为后序遍历。 样例输入 8 1 2 4 5 7 3 6 8 4 2 7 5 1 8 6 3 样例输出 4 7 5 2 8 6 3 1 数据规模和约定 0\u0026lt;n\u0026lt;100000,。保证先序遍历和中序遍历合法，且均为1～n。 */ /* 此题即为由先、中序排列确定 后序排序; 首先要知道一个结论，前序/后序+中序序列可以唯一确定一棵二叉树，所以自然而然可以用来建树。 看一下前序和中序有什么特点，前序1,2,4,7,3,5,6,8 ，中序4,7,2,1,5,3,8,6； 有如下特征： 前序中左起第一位1肯定是根结点，我们可以据此找到中序中根结点的位置rootin；（后序中最后一位肯定是根节点。） 中序中根结点左边就是左子树结点，右边就是右子树结点，即[左子树结点，根结点，右子树结点]，我们就可以得出左子树结点个数为int left = rootin - leftin;； 前序中结点分布应该是：[根结点，左子树结点，右子树结点]；（后序中分布：[左子树节点, 右子树节点, 根节点]） 根据前一步确定的左子树个数，可以确定前序中左子树结点和右子树结点的范围； 如果我们要前序遍历生成二叉树的话，下一层递归应该是： 左子树：root-\u0026gt;left = pre_order; (前序左子树范围，中序左子树范围，前序序列，中序序列) 右子树：root-\u0026gt;right = pre_order; (前序右子树范围，中序右子树范围，前序序列，中序序列) 每一层递归都要返回当前根结点root； */ #include\u0026lt;iostream\u0026gt; #include\u0026lt;vector\u0026gt; using namespace std; struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode() : val(0), left(NULL), right(NULL) {} TreeNode(int x) : val(x), left(NULL), right(NULL) {} TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} }; TreeNode *OrderToTree(int L_Pre, int R_Pre, int L_In, int R_In, vector\u0026lt;int\u0026gt; \u0026amp;Pre, vector\u0026lt;int\u0026gt; \u0026amp;In) { if (L_Pre \u0026gt; R_Pre || L_In \u0026gt; R_In) return NULL; TreeNode *root = new TreeNode(Pre[L_Pre]); //前序排列中 最左位为根节点 int in_root = L_In; while (In[in_root] != Pre[L_Pre]) { in_root++; } int left = in_root - L_In; root-\u0026gt;left = OrderToTree(L_Pre + 1, L_Pre + left, L_In, L_In + left, Pre, In); root-\u0026gt;right = OrderToTree(L_Pre + left +1, R_Pre, L_In + left +1, R_In, Pre, In); return root; } //打印逆序排序 void PosOrder (TreeNode* root) { if(root == NULL) return; PosOrder(root-\u0026gt;left); PosOrder(root-\u0026gt;right); cout \u0026lt;\u0026lt; root-\u0026gt;val \u0026lt;\u0026lt; ' '; } int main () { int n; // 0\u0026lt;n\u0026lt;=1000000 // int PreNumber[100000] = {0}, InNumber[100000] = {0}, PosNumber[100000] = {0}; vector\u0026lt;int\u0026gt; PreNumber, InNumber, PosNumber; cin \u0026gt;\u0026gt; n; for (int i = 0; i \u0026lt; n; i++) { int j; cin \u0026gt;\u0026gt; j; PreNumber.push_back(j); } for (int i = 0; i \u0026lt; n; i++) { int j; cin \u0026gt;\u0026gt; j; InNumber.push_back(j); } TreeNode *root = OrderToTree(0, n-1, 0, n-1, PreNumber, InNumber); PosOrder (root); return 0; } 889. 根据前序和后序遍历构造二叉树 - 力扣（LeetCode) struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode() : val(0), left(nullptr), right(nullptr) {} TreeNode(int x) : val(x), left(nullptr), right(nullptr) {} TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {} }; // @lc code=start #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; // 注意题中说明 二叉树中的各个值不相同,不需要考虑不成立的情况 // 前序/后序+中序序列可以唯一确定一棵二叉树，只知道前序和后序不唯一确定 // 前序是 root + 左树节点 + 右树节点 // 后序是 左树节点 + 右树节点 + root // 所以后序的倒数第二个是前序中右树的根节点 前序的第二个是后续的前树的根节点最后一位 如此递推就有规律 class Solution { public: // l1 r1限定pre的子树区域，l2 r2限定post的子树区域。 // 此法默认优先生成左子树（即只有一边子树时默认是左子树） TreeNode* build_tree(vector\u0026lt;int\u0026gt;\u0026amp; pre, vector\u0026lt;int\u0026gt;\u0026amp; post, int l1, int r1, int l2, int r2) { if(l1 \u0026gt; r1) return nullptr; TreeNode *root = new TreeNode(pre[l1]); //或post[r2] for (int i = r2-1; i \u0026gt;= l2; i--) { if(pre[l1+1] == post[i]) { int len = i - l2; root-\u0026gt;left = build_tree(pre, post, l1+1, l1+len+1, l2, i); root-\u0026gt;right = build_tree(pre, post, l1+len+2, r1, i+1, r2-1); break; } } return root; } TreeNode* constructFromPrePost(vector\u0026lt;int\u0026gt;\u0026amp; preorder, vector\u0026lt;int\u0026gt;\u0026amp; postorder) { TreeNode* ans = build_tree(preorder, postorder, 0, postorder.size()-1, 0, preorder.size()-1); return ans; } }; 173. 二叉搜索树迭代器 - 力扣（LeetCode) class BSTIterator { private: TreeNode* cur; stack\u0026lt;TreeNode*\u0026gt; stk; public: BSTIterator(TreeNode* root): cur(root) {} int next() { while (cur != nullptr) { stk.push(cur); cur = cur-\u0026gt;left; } cur = stk.top(); stk.pop(); int ret = cur-\u0026gt;val; cur = cur-\u0026gt;right; return ret; } bool hasNext() { return cur != nullptr || !stk.empty(); } }; 红黑树 图解红黑树\n常用规则\n红黑树是一种自平衡的二叉搜索树，并且其附加定义如下：\n节点有且只有两种颜色，红色和黑色 根节点和叶子节点必须是黑色，其中，叶子节点是虚拟存在的空节点NULL 红色节点的两个子节点必须是黑色 任意节点到叶子节点的路径上，必须包含相同数目的黑色节点 map multimap 的底层是红黑树 中序遍历会是有序的，不是哈希表，但是std::set、std::multiset 依然使用哈希函数来做映射，只不过底层的符号表使用了红黑树来存储数据，\n所以使用这些数据结构来解决映射问题的方法，我们依然称之为哈希法。 map也是一样的道理。\nunordered_map 的底层是用哈希表来实现的 无序，通过key的哈希路由到每一个桶（即数组）用来存放内容。通过key来获取value的时间复杂度就是O（1）。\n因为key的哈希容易碰撞，所以需要对碰撞做处理。map里的每一个数组（桶）里面存的其实是一个链表，key的哈希冲突以后会加到链表的尾部，\n这是再通过key获取value的时间复杂度就变成O(n），当碰撞很多的时候查询就会变慢。为了优化这个时间复杂度，map的底层就把这个链表转换成了 平衡树，\n这样虽然插入增加了复杂度，但提高了频繁哈希碰撞时的查询效率，使哈希碰撞时查询效率变成O(log n)。\n前缀树 trie tree 根节点不包含字符，除根节点外每一个节点都只包含一个字符。 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符都不相同。 又称为字典树 trie tree，是一种是一种树形结构，是一种哈希树的变种。典型应用是用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。\n它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较。Trie的核心思想是空间换时间。利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。\n下面给出一个小写字符串映射的 tire tree 简易实现:\n208. 实现 Trie (前缀树) - 力扣（LeetCode）\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;unordered_map\u0026gt; using namespace std; struct TrieNode { bool flag; // 为true 表示存在以该节点为尾部的值 unordered_map\u0026lt;char, TrieNode*\u0026gt; son; TrieNode(): flag(false) {} }; class Trie { private: TrieNode* root = nullptr; public: Trie() { root = new TrieNode(); } void insert(string word) { TrieNode* now = root; for (const char\u0026amp; w : word) { if(now-\u0026gt;son.find(w) == now-\u0026gt;son.end()) now-\u0026gt;son[w] = new TrieNode(); now = now-\u0026gt;son[w]; } now-\u0026gt;flag = true; } bool search(string word) { TrieNode* now = root; for (const char\u0026amp; w : word) { if(now-\u0026gt;son.find(w) == now-\u0026gt;son.end()) return false; now = now-\u0026gt;son[w]; } return now-\u0026gt;flag; } bool startsWith(string prefix) { TrieNode* now = root; for (const char\u0026amp; w : prefix) { if(now-\u0026gt;son.find(w) == now-\u0026gt;son.end()) return false; now = now-\u0026gt;son[w]; } return now; } }; 基数树 radix tree radix树 简单来说就是 tire 树的压缩路径版本，Trie树一般用于字符串到对象的映射（Trie树看成是一个基为26的Radix树），而radix树一般用于长整数到对象的映射。\n对于长整型数据的映射，怎样解决Hash冲突和Hash表大小的设计是一个非常头疼的问题。radix树就是针对这对这样的稀疏长整型数据查找，能高速且节省空间地完成映射。借助于Radix树，我们能够实现对于长整型数据类型的路由。利用radix树能够依据一个长整型（比如一个长ID）高速的找到其相应的对象指针。这比用hash映射来的简单，也更节省空间，使用Hash映射hash函数难以设计，不恰当的hash函数可能增大冲突，或浪费空间。\nradix tree是一种多叉搜索树，树的叶子节点是实际的数据条目。每一个节点有一个固定的、2^n指针指向子节点（每一个指针称为slot，n为划分的基的大小）。\nredis之radix tree_happytree001的博客 介绍了c编写的 redis 如何实现 radix 树\n其主要区别实现在于 iscompr 字段记录该key是否为压缩字符串\n平衡二叉树 图解平衡二叉树\nB树 理解B+树 视频\nMySQL索引底层：B+树详解 包含内容:\nB-树、B+树简介 B+树插入 B+树查找 B+树删除 B+树经典面试题 ","id":7,"section":"posts","summary":"树的概念 树由有限个节点，组成具有层次关系的集合。每个结点或者无子结点或者只有有限个子结点; 有一个特殊的结点,它没有父结点，称为根结点。每一个","tags":["C/C++","数据结构"],"title":"树 相关结构 (TODO)","uri":"https://liangkang233.github.io/2022/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%91%E7%9B%B8%E5%85%B3/","year":"2022"},{"content":"Docker 、Lxc介绍 docker是一个比较成熟好用的开源免费应用容器引擎，用于在一个集中的平台上创建、部署和工作应用程序。这使得主机的操作系统通过容器运行具有相同Linux内核的应用程序，而不是创建一个完整的虚拟机。使用docker容器，你不需要关心Ram和磁盘空间的分配。它能够自己处理需求。Docker容器将应用和其依赖环境全部打包到一个单一对象中，在不包含完整的操作系统的情况下就能运行普通应用，更加轻量级，可移植性更好。所以它成为了PaaS（比如Kubernates）平台的基石。\nDocker高效且容易配置。 技术可行性和提高生产力。 可以创建更加安全的服务例如通过 secret inspect 和 secret create等。 提供应用程序隔离，并且各个容器互相独立没有依赖。 在介绍LXD之前先介绍LXC，因为LXD可以视作LXC的升级版。LXD的管理命令和LXC的管理命令大多相同。LXC起源于cgroup和namespaces，使得进程之间相互隔离，即进程虚拟化。LXC有一些缺点，比如无法有效支持跨主机之间的容器迁移、管理复杂。而LXD很好地解决了这些问题。LXC/LXD和docker不同的地方在于LXC/LXD中包含完整的操作系统。\nLXC是Linux Containers的缩写，用于通过单个Linux内核在受控主机上虚拟地运行多个 \u0026ldquo;Linux系统\u0026rdquo; 。LXC与内核的Cgroups捆绑在一起，为进程和网络空间提供功能，而不是创建一个完整的虚拟机，并为应用程序提供一个独立的环境。\n它提供了内核名称空间，如IPC、mount、PID、network和user。 它提供内核功能。 控制组 (Control groups \u0026ndash; Cgroups) Seccomp概要文件 (Seccomp profiles ) Docker 和 LXD/LXC 区别 LXD/LXC是一个系统容器。Docker是一个应用程序容器，LXC不能跨机器上进行移植，而Docker可以跨机器甚至跨平台移植。lxc 是 Linux 内核容器虚拟化的一项技术，可以实现资源的隔离和控制，也就是对 Cgroup 和 Namespace 两个属性的控制。对于 docker 而言，它发展到现在不仅仅是容器的代名词了，不过它的基础技术是需要依赖内核的 Cgroup 和 Namespace 特性。docker 出现之初，便是采用了 lxc 技术作为 docker 底层，对容器虚拟化的控制。后来随着 docker 的发展，它自己封装了 libcontainer （golang 的库）来实现 Cgroup 和 Namespace 控制，从而消除了对 lxc 的依赖。\nParameter LXC Docker 开发者 LXC was created by IBM, Virtuozzo, Google and Eric Biederman. Docker was created by Solomon Hykes in 2003. 数据检索 LXC不支持处理后的数据检索。 Docker支持数据检索。 可用性 它是一个多用途的虚拟化解决方案。 它是单一目的的解决方案。 平台 LXC仅在Linux平台上支持。 Docker的实现依赖于平台。 虚拟化 LXC为我们提供了完整的系统虚拟化 。 Docker提供了应用虚拟化。 云支持 不需要云存储，因为是Linux提供了这些特性。 云存储的需求是一个相当大的生态系统所必需的。 流行性 由于一些限制，LXC在开发人员中并不是很流行。 Docker因容器而流行，它将容器提升到了一个新的层次。 cgroup：Cgroup 是 Control group 的简称，是 Linux 内核提供的一个特性，用于限制和隔离一组进程对系统资源的使用。对不同资源的具体管理是由各个子系统分工完成的。\n子系统 作用 devices 设备权限控制 cpuset 分配指定的CPU和内存节点 CPU 控制CPU使用率 cpuacct 统计CPU使用情况 memory 限制内存的使用上限 freezer 暂停Cgroup 中的进程 net_cls 配合流控限制网络带宽 net_prio 设置进程的网络流量优先级 perf_event 允许 Perf 工具基于 Cgroup 分组做性能检测 huge_tlb 限制 HugeTLB 的使用 Namespace：Namespace 是将内核的全局资源做封装，使得每个namespace 都有一份独立的资源，因此不同的进程在各自的namespace内对同一种资源的使用互不干扰。\nNamespace 作用 IPC 隔离 System V IPC 和 POSIX 消息队列 Network 隔离网络资源 Mount 隔离文件系统挂载点 PID 隔离进程ID UTS 隔离主机名和域名 User 隔离用户和用户组 常见问题 Container内不需要OS，为何需要OS的基础镜像？\nVscode 插件无法查看镜像\n默认情况下，docker 命令会使用 Unix socket (opens new window)与 Docker 引擎通讯。 而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑， 一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。\n# 建立 docker 组： sudo groupadd docker # 将当前用户加入 docker 组： sudo usermod -aG docker $USER Docker网络管理 （导出端口，多容器间通信 等问题分析）\n配置代理\n国内特殊环境，pull 镜像可能比较麻烦，换镜像源。\nnano /etc/docker/daemon.json # 写入以下内容 { \u0026quot;registry-mirrors\u0026quot;: [ \u0026quot;https://hub-mirror.c.163.com\u0026quot;, \u0026quot;https://mirror.baidubce.com\u0026quot; ] } # 之后重启docker sudo service docker restart 自定义网桥\n可以用 docker port 容器id 查看容器导出接口端口port，或者直接 docker ps 由于之前手贱，ip link del docker0 网桥导致后面的容器无法导出端口，使用此法加回来\nip link add docker0(名字与下面 *daemon.json* 使用相同的名字) sudo ip addr add 192.168.5.1/24 dev docker0 sudo ip link set dev docker0 up nano /etc/docker/daemon.json # 添加以下内容 { \u0026quot;bridge\u0026quot;: \u0026quot;docker0\u0026quot;, } # 之后重启docker sudo service docker restart 常用命令 Docker build options\nDocker run options\n命令 功能 docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 默认地址是 Docker Hub(docker.io)。 这里的仓库名是两段式名称，即 \u0026lt;用户名\u0026gt;/\u0026lt;软件名\u0026gt;。 对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 docker container ls -a 查看全部容器 删除rm docker docker image ls -a 查看全部镜像 删除镜像用rm docker build -t nginx:v1 . 编译镜像 -t 设定容器名及tag 后面的 . 设定的是上下文的路径 docker build -t koa-demo:0.1 . -f ./koa-docker/Dockerfile 可以使用 dockerfile 取消跟踪拷贝文件 注意默认dockfile是在设定上下文目录中寻找，copy的文件只能是上下文目录及其子目录 -f 可以指定dockefile ： docker image prune 删除悬浮镜像 docker system df/ prune / events 显示各项数据磁盘占用 清除无用数据 查看docker server实时事件 docker history image名 查看镜像操作历史记录 docker run \u0026ndash;name webserver -d -p 1080:80 nginx:v1 使用镜像生成新容器并直接运行（命名为webserver -p 物理机1080代理容器80端口 -d deatch ） docker run \u0026ndash;rm -it \\ -v /var/sflowtrend-pro:/var/local/sflowtrend-pro \\ koa-demo:0.2 bash -i绑定终端输入 -t生成虚拟终端tty -i -t 等价-it \u0026ndash;rm：这个参数是说容器退出后随之将其删除 -d 后台运行 -v 将主机的/var/sflowtrend-pro目录挂载到/var/local/sflowtrend-pro中 docker container start/stop laughing_jennings/或者容器id 启动/中止 容器 laughing_jennings docker container logs 容器名或id 查看容器运行输出 docker diff 容器名或id 查看容器修改文件 docker attach 243c 进入容器执行操作 使用 attach 进入容器 当这个终端停止或exit时容器也会停止 docker exec -i 69d1 bash 使用exec则无影响，仅仅是执行bash并定向到当前stdin 其他参数使用docker exec -h 查看 docker commit \\ \u0026ndash;author \u0026ldquo;Tao Wang twang2218@gmail.com\u0026rdquo; \\ \u0026ndash;message \u0026ldquo;修改了默认网页\u0026rdquo; \\ webserver \\ nginx:v2 提交容器内改变编译生成镜像 commit生成的镜像为黑箱镜像还是推荐用dockerfile做是维护用的镜像 dockerfile使用 docker export 7691a814370e \u0026gt; ubuntu.tar 导出容器的快照到本地归档文件 cat ubuntu.tar | docker import - test/ubuntu:v1.0 或者指定url下载并导入 docker import http://example.com/exampleimage.tgz example/imagerepo 将容器归档文件导入为镜像 用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 docker save alpine -o filename docker save alpine | gzip \u0026gt; alpine-latest.tar.gz docker load -i alpine-latest.tar.gz save load为镜像的保存与导入，现在已经不推荐，镜像迁移应该直接使用 Docker Registry，无论是直接使用 Docker Hub 还是使用内网私有 Registry 都可以） docker ps -aq 显示docker所有容器 （-a 为全部否则默认只有运行容器 -q只显示容器id） docker top 容器id 查看容器内进程 docker inspect \u0026ndash;format \u0026lsquo;{{ .NetworkSettings.IPAddress }}\u0026rsquo; 容器id 查看容器ip docker inspect \u0026ndash;format=\u0026rsquo;{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026rsquo; $(docker ps -aq) 查看全部容器ip 如果我们结合这两个命令以及 ssh 甚至 pv 的话，利用 Linux 强大的管道，我们可以写一个命令完成从一个机器将镜像迁移到另一个机器，并且带进度条的功能:\ndocker save \u0026lt;镜像名\u0026gt; |bzip2 |pv |ssh \u0026lt;用户名\u0026gt;@\u0026lt;主机名\u0026gt; 'cat |docker load'\n其实有很多插件可以方便快捷操作，例如vscode中的docker插件，这里推荐一下。\n","id":8,"section":"posts","summary":"Docker 、Lxc介绍 docker是一个比较成熟好用的开源免费应用容器引擎，用于在一个集中的平台上创建、部署和工作应用程序。这使得主机的操作系统通过","tags":["容器"],"title":"Docker容器相关","uri":"https://liangkang233.github.io/2021/12/%E5%AE%B9%E5%99%A8%E7%9B%B8%E5%85%B3/","year":"2021"},{"content":"OVS 介绍 Open virtual Switch 是一个在 Apache2许可授权的 开源多层软件交换机。目标是实现一个产品质量的交换机平台，支持标准的管理接口，并开放转发功能，以供编程扩展和控制。\novs简言之就是使用openflow表做datapath，将底层数据端口的数据流的控制面导入上层openflow交换机做路由转发，数据传输的软件层面虚拟交换机。\nOVS实现 其中， ovs-vswitchd 和 datapath 共同构成了 OVS 的数据面，控制面由 controller 模块来完成，controller 一般表示的是 OpenFlow 控制器，在 OVS 中，它可以借由第三方来完成，只要支持 OpenFlow 协议即可。\novs-vswitchd\novs-vswitched与它的内核模块datapth共同构成了OVS的数据面。它使用OpenFlow协议与OpenFlow控制器通信，使用 OVSDB 协议与 ovsdb-server 通信，使用 netlink 和 datapath 内核模块通信。\novsdb-server\novsdb-server 是 OVS 轻量级的数据库服务，用于整个 OVS 的配置信息，包括接口、交换内容、VLAN 等，ovs-vswitchd 根据这些配置信息工作。\nOpenFlow 控制器\nOpenFlow 控制器可以通过 OpenFlow 协议连接到任何支持 OpenFlow 的交换机，比如 ovs-ofctl 。控制器通过向交换机下发流表规则来控制数据流向。\nKernel Datapath\ndatapath 内核模块和 ovs-vswitchd 是相互协作工作的，datapath 负责具体的收发包，而 ovs-vswitchd 通过 controller 下发的流表规则指导 datapath 如何转发包。\n数据面就是以用户态的 ovs-vswitchd 和内核态的 datapath 为主的转发模块，以及与之相关联的数据库模块 ovsdb-server，控制面主要是由 ovs-ofctl 模块负责，基于 OpenFlow 协议与数据面进行交互。而管理面则是由 OVS 提供的各种工具来负责\nOVS架构 OVS的主要组件是：\novs-vswitchd，一个实现交换机的守护程序，以及一个用于基于流的切换的配套 Linux 内核模块。 ovsdb-server，一个轻量级的数据库服务器，它通过 ovs-vswitchd 查询来获取其配置。 ovs-dpctl，一个用于配置交换机内核模块的工具，可以控制转发规则。 ovs-vsctl，一个用于查询和更新 ovs-vswitchd 配置的实用程序。 ovs-appctl，一个向运行 Open vSwitch 守护程序发送命令的实用程序。 为 Citrix XenServer 和 Red Hat Enterprise Linux 构建 RPM 的脚本和规范。XenServer RPM 允许将 Open vSwitch 安装在 Citrix XenServer 主机上，作为其交换机的直接替代品，并具有其他功能。 Open vSwitch 还提供了一些工具：\novs-ofctl，一个用于查询和控制 OpenFlow 交换机和控制器的实用程序。 ovs-pki，用于创建和管理 OpenFlow 交换机公钥基础结构的实用程序。 ovs-testcontroller，一个简单的OpenFlow控制器，可能对测试有用（尽管不适用于生产）。 tcpdump 的扩展程序，使其能够解析 OpenFlow 消息。 所有工具的手册,内容与 linux 中的manual一致。\n一些基础概念 Bridge: Bridge，linux 网桥是 Linux 上用来做 TCP/IP 二层协议交换的设备，一个主机中可以创建一个或者多个 Bridge 设备。 Port: 端口与物理交换机的端口概念类似，每个 Port 都隶属于一个 Bridge。 Interface: 连接到 Port 的网络接口设备。在通常情况下，Port 和 Interface 是一对一的关系, 只有在配置 Port 为 bond 模式后，Port 和 Interface 是一对多的关系。 Controller: OpenFlow 控制器。OVS 可以同时接受一个或者多个 OpenFlow 控制器的管理。 datapath: 在 OVS 中，datapath 负责执行数据交换，也就是把从接收端口收到的数据包在流表中进行匹配，并执行匹配到的动作。 Flow table: 每个 datapath 都和一个“flow table”关联，当 datapath 接收到数据之后， OVS 会在 flow table 中查找可以匹配的 flow，执行对应的操作, 例如转发数据到另外的端口。支持 OpenFlow 协议的交换机应该包括一个或者多个流表，流表中的条目包含：数据包头的信息、匹配成功后要执行的指令和统计信息 Flow ： 在 OpenFlow 的白皮书中，Flow 被定义为某个特定的网络流量。例如，一个 TCP 连接就是一个 Flow，或者从某个 IP 地址发出来的数据包，都可以被认为是一个 Flow。 OpenFlow介绍 OpenFlow是一种控制面和数据面通信的网络通信协议，应用于SDN架构中控制器和转发器之间的通信。\n软件定义网络SDN的一个核心思想就是“转发、控制分离”，要实现转、控分离，就需要在控制器与转发器之间建立一个通信接口标准， 允许控制器直接访问和控制转发器的转发平面。OpenFlow引入了“流表”的概念，转发器通过流表来指导数据包的转发。 控制器正是通过OpenFlow提供的接口在转发器上部署相应的流表，从而实现对转发平面的控制。\n链路及交换机 cisco网络中，交换机在局域网中最终稳定状态的接口类型主要有四种：access/trunk/ multi/ dot1q-tunnel。\naccess: 主要用来接入终端设备，如PC机、服务器、打印服务器等。 trunk: 主要用在连接其它交换机，以便在线路上承载多个vlan。 multi: 在一个线路中承载多个vlan，但不像trunk,它不对承载的数据打标签。主要用于接入支持多vlan的服务器或者一些网络分析设备。现在基本不使用此类接口，在cisco的网络设备中，也基本不支持此类接口了。 dot1q-tunnel: 用在Q-in-Q隧道配置中。 vlan的链路类型可以分为接入链路和干道链路。\n接入链路（access link）指的交换机到用户设备的链路，即是接入到户，可以理解为由交换机向用户的链路。由于大多数电脑不能发送带vlan tag的帧，所以这段链路可以理解为不带vlan tag的链路。 干道链路（trunk link）指的交换机到上层设备如路由器的链路，可以理解为向广域网走的链路。这段链路由于要靠vlan来区分用户或者服务，所以一般都带有vlan tag。 隧道介绍 隧道技术介绍：\n是在现有的物理网络之上构建一层虚拟网络，上层应用只与虚拟网络相关，以此实现的虚拟网络比物理网络配置更加灵活， 并能够实现跨主机的L2通信以及必要的租户隔离。不同隧道技术其大体思路均是将以太网报文使用隧道协议封装， 然后使用底层IP网络转发封装后的数据包，其差异性在于选择和构造隧道的协议不同。 常见隧道技术有两种gre或vxlan\nGeneral Router Encapsulation 在GRE中，需要被传输和封装的报文称之为payload packet，而用于封装和传输的协议则成为delivery protocol。 GRE在封装的时候，除了payload和delivery协议的header外，会生成一个GRE header。GRE header + payload一起被delivery协议封装用于传输，GRE header会包含payload的一些信息，包括checksum、version、payload的协议类型等。可以看到，通过这个GRE header的协议类型字段，当脱取这一层delivery层后，就可以解析为原数据包格式，通过GRE header中的协议类型我们就能知道协议类型了，既然知道了协议类型，那么就有能力解析了。\n由于GRE是一种通用的格式，我们可以使用GRE进行很多不同种类的封装。比如我们可以使用PPTP协议来进行VPN，可以使用IPv4来包裹IPv6。比较常见的delivery协议一般是IP协议。 不过GRE在设计的时候有一个问题，那就是没有考虑加密。因此现在常见的需要加密的封装一般是用的IPsec协议。\nVirtual eXtensible Local Area Network 简单的说就是扩充了的VLAN，相比于GRE的通用性，VXLAN主要用于封装、转发2层报文。 其使得多个通过三层连接的网络可以表现的和直接通过一台一台物理交换机连接配置而成的网络一样处在一个LAN中。 其将二层报文加上个vxlan header，封装在一个UDP包中进行传输。vxlan header会包括一个24位的ID（称为VNI）， 含义类似于VLAN id或者上面提到的GRE的tunnel id。\n在上面GRE的例子中，是通过路由器来进行GRE协议的封装和解封的， 在VXLAN中这类封装和解封的组件有个专有的名字叫做VTEP。相比起VLAN来说，好处在于其突破了VLAN只有4094子网的限制， 同时架设在UDP协议上后其扩展性提高了不少（因为UDP是高层协议，屏蔽了底层的差异，换句话说屏蔽了二层的差异）。\nOVS 安装与使用 linux可以直接安装sudo apt-get install openvswitch-switch,但是执行ovs-tcpdump报错：\nlk233@vm-5gc:~$ sudo ovs-tcpdump Traceback (most recent call last): File \u0026quot;/usr/bin/ovs-tcpdump\u0026quot;, line 27, in \u0026lt;module\u0026gt; import netifaces ImportError: No module named netifaces 可是我python3使用pip3 -l查看的包里有netifaces\n检查发现系统默认pip是python3，可是执行python默认是python2 😅\n# 如下检查版本和 使用alternatives选择默认版本 pip -V python -V sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1 sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.6 2 sudo update-alternatives --config python ovs-tcpdump -h ERROR: Please install the correct Open vSwitch python support libraries (version 2.9.0). Alternatively, check that your PYTHONPATH is pointing to the correct location. # 如果之后报如上的错误安装ovs python 支持包 pip3 install ovs # 或者这里下源码包执行安装 https://pypi.org/project/ovs/#modal-close sudo python3 ./setup.py install 一切安装完毕后，可以检测到后台服务与控制版本信息 OVS 基础教程: docker容器使用OVS教程\nOVS OpenFlow 教程 OVS IPsec隧道 教程 OVS 高级功能 (包含gdb调试 vlan入口处理 输出处理细节等) OVS Conntrack 教程 (Conntrack是一个用于检查报文状态的连接跟踪模块) 当然OVS的功能不局限于这些，没有必要花费大量事件学习如何使用这个工具，知道大致的思路和运行逻辑，就需要思考怎么将ovs运用到实际中。 下面是一些基础应用:\nOpen vSwitch with KVM Encrypt Open vSwitch Tunnels with IPsec Open vSwitch with SELinux Open vSwitch with Libvirt Open vSwitch with SSL Using LISP tunneling Connecting VMs Using Tunnels Connecting VMs Using Tunnels (Userspace) Isolating VM Traffic Using VLANs Quality of Service (QoS) Rate Limiting How to Use the VTEP Emulator Monitoring VM Traffic Using sFlow Using Open vSwitch with DPDK 实际应用-多主机间容器通信 方案选型 我最近需要做分布式容器间的通信相关工作，如果按照传统的方案建立隧道维护相当麻烦，于是想到采用ovs的方案来做。\n下面是物理场景的大概的示意图：\n方案1：gre隧道 ovs的gre与命令行的直接搭建gre隧道做点对点链路无异，该方案即为 Connecting VMs Using Tunnels，在实际测试中我添加多个相同主机间隧道会报错，所以没法用多个网桥配多个gre隧道间隔主机对间的流量。\n方案2: vlan 使用vlan（Isolating VM Traffic Using VLANs）可以做到全部主机attach到一个网桥上从而多主机通信，但是主机间的接入网卡由于工作在二层设备下ip地址及绑定其ip程序都会失效，不是很推荐使用这个。\n方案3: vxlan隧道 所以应该用 ovs 管理一个vxlan隧道局域网, OVS在计算和网络节点上建立隧道Port来连接各节点上的网桥br-int（br-int是举例的网桥名），这样所有网络和计算节点上的br-int互联形成了一个大的虚拟的跨所有节点的逻辑网桥(内部靠tunnel id或VNI隔离不同子网)，这个逻辑网桥对虚拟机和qrouter是透明的，内部数据不变转发出机器的数据就像交换机根据tag进行转发传递数据。\n于是参考了这个 Connecting VMs Using Tunnels (Userspace) 方案\n多个主机上桥接到br-vxlan的虚拟机就像连接到同一个交换机一样，可以实现跨主机的L2连接，同时又完全与物理网络隔离。 所有数据都到达中间主机转发寻路 与gre隧道类似，相同主机间添加多个vxlan隧道会报错。\n疑惑： vxlan问题在于主控主机作为 OVS交换机，若是host2内容器2向host3主机容器3发送数据，host1依旧会接收并转发数据包，但实际上host1向host3的数据完全走物理交换机一跳即可，不知道数据量大了后所有数据都汇总在host1进行处理转发是否会达到性能瓶颈。\n具体实施 # 查看OVS网桥及其端口 sudo ovs-vsctl show # 设定主网桥 br-vxlan # 主机 192.168.163.134 上 sudo ovs-vsctl add-br br-vxlan # 主机 192.168.163.140 上 sudo ovs-vsctl add-br br-vxlan # 主机 192.168.163.141 上 sudo ovs-vsctl add-br br-vxlan # 网卡添加至对应网桥 sudo ovs-vsctl add-port br-vxlan veth1.0.df sudo ovs-vsctl add-port br-vxlan veth2.0.2e sudo ovs-vsctl add-port br-vxlan veth3.0.ec 添加通信隧道（双向添加） # 主机 192.168.163.140上 添加连接到 192.168.163.134 141 的Tunnel Port sudo ovs-vsctl add-port br-vxlan tun0 -- set Interface tun0 type=vxlan options:remote_ip=192.168.163.134 sudo ovs-vsctl add-port br-vxlan tun1 -- set Interface tun1 type=vxlan options:remote_ip=192.168.163.141 # 主机 192.168.163.134上 添加连接到 192.168.163.140 的Tunnel Port sudo ovs-vsctl add-port br-vxlan tun0 -- set Interface tun0 type=vxlan options:remote_ip=192.168.163.140 # 主机 192.168.163.141上 添加连接到 192.168.163.140 的Tunnel Port sudo ovs-vsctl add-port br-vxlan tun0 -- set Interface tun0 type=vxlan options:remote_ip=192.168.163.140 当在用户空间运行Open vSwitch而不是基于内核的Open vSwitch时，需要这个额外的网桥br-phy。这个网桥的目的是允许使用内核网络堆栈进行路由和ARP解析。数据路径需要查找路由表和ARP表，准备隧道头并将数据发送到输出端口。\n添加phy网桥后原有容器内数据无法ping通，可能是由于路由没配好？ 但是按照手册加不上路由 所以最后我是跳过phy和ens33attach步骤，结果也正常。\n# 设定phy网桥（） sudo ovs-vsctl --may-exist add-br br-phy \\ -- set Bridge br-phy datapath_type=netdev \\ -- br-set-external-id br-phy bridge-id br-phy \\ -- set bridge br-phy fail-mode=standalone \\ other_config:hwaddr=\u0026lt;mac address of eth33 interface\u0026gt; sudo ovs-vsctl add-br br-phy \\ -- set bridge br-phy fail-mode=standalone \\ other_config:hwaddr=00:0c:29:ef:1b:c5 # 将物理网卡ens33 attach 上 br-phy网桥 sudo ovs-vsctl --timeout 10 add-port br-phy ens33 sudo ip addr add 192.168.163.140/24 dev br-phy sudo ip link set br-phy up sudo ip addr flush dev eth1 2\u0026gt;/dev/null sudo ip link set ens33 up sudo iptables -F # 添加 VXLAN 路由 # 按照手册 ovs-appctl ovs/route/add 添加路由失败，暂时未解决。 # 显示 VXLAN 路由 ovs-appctl ovs/route/show 检验现象：可以在容器内互相ping通172网段ip即可\ngre隧道的做法与vxlan中不加br-phy的做法基本一样，就不复述了，vlan的方案上面的教程写的很详细。\n抓包测试 若不是使用容器或者其他网络空间（netns ）的设备是抓不到下面的port的包，而且传输的数据可能是封装过后的，不太好分析。所以试试手册里提到的ovs-tcpdump。它是用python实现的捕获ovs的数据包的tcpdump补丁。（ovs−tcpundump程序从stdin读取tcpdump−xx输出，查找十六进制数据包数据，并在stdout上将每个以太网转储为一个十六进制字符串）\n感觉这个程序很久不维护了，使用python3执行有很多问题。\n# 首先使用管理员模式, 否则下述报错 Exception: Unable to connect to /var/run/openvswitch/db.sock # 之后的报错是因为rw不支持，推荐将 rw 改为 r+b File \u0026quot;/usr/bin/ovs-tcpdump\u0026quot;, line 65, in _install_tap_linux tapdev_fd = open('/dev/net/tun', 'rw') ValueError: must have exactly one of create/read/write/append mode # 后面又报错，查询资料说是python3不兼容的问题，把缓冲改为0 即open函数 传参 buffering = 0 io.UnsupportedOperation: File or stream is not seekable #最后依旧是有问题无法抓包 抓包失败并且提示关闭监听端口 Please use ovs-vsctl to remove the ports and mirrors created. ex: ovs-vsctl --db=unix:/var/run/openvswitch/db.sock del-port mib.4.db 修改后的代码：\n之后的抓包依旧有问题，且没有报错提醒 暂时无法解决\n实在是太折腾了，一个工具用的这么麻烦 😒我用的是lxc容器各链路使用ovs链接，完全可以执行容器内的tcpdump。\n看到还有其他方法：使用端口镜像来抓包， ovs-tcpdump应该也是这么监听的所以直接按照这篇博客试了试,实践后确定可以抓没有tag流的原始包\n注意: tcpdump 抓包时加-l可以不缓存实时刷新\n最后 Vxlan方案 的host1的容器1内的抓包结果验证了我之前的问题\n数据包包含vlan tag且中间的主控主机参与了数据的处理转发，host2与host3间的容器互相ping，都会是host1转发了该icmp包。request和reply都传送了两次即host1-host2、host1-host3两条隧道都走了。在host2、host3间加直达隧道也无效，依旧host1参与处理转发。\n也许直达链路最好的还是添加隧道做直达处理，如果多个主机接入一个虚拟交换机处理，该虚拟交换机是需要处理所有流经的数据包的。\n关于下属子节点间的数据区分，可以像vlan一样直接加个tag vxlan添加tag，总之 做ovs交换机的主机必然是需要接收所有数据 由它做数据区分 转发。\n流表监听 下面是一些常用的监听命令:\n查看流表: ovs-ofctl dump-flows br-tun 查看port收发包情况: ovs-ofctl dump-ports br-tun 当然参考了这篇文章后Monitoring VM Traffic Using sFlow监听数据更方便了。\n为了防止Java环境设置、安装软件等一系列配置环境的问题，后面的 sFlow 监听我使用 sflowtrend docker，确保具备docker环境。之后我会写一篇关于docker、lxc容器的文章。\n配置完docker必要环境后，直接pull镜像并运行即可。\ndocker pull sflow/sflowtrend docker run -v \u0026lt;你的映射路径\u0026gt;:/var/local/sflowtrend-pro \\ -p 6343:6343/udp -p 8087:8087 -p 8443:8443 \\ -h sflowtrend-pro -e TZ=Asia/Chungking\u0026lt;使用北京时间时区改为Asia/Shanghai\u0026gt; -d \\ --restart unless-stopped sflow/sflowtrend 以如下网络做示例监听： 后面以第一种情况做示例\n查询docker网卡ip:\ndocker ps #查看运行容器 docker inspect --format '{{ .NetworkSettings.IPAddress }}' 容器id #查看容器ip 开始设定监听sFlow\n# 收集监听数据的容器或应用进程主机的ip 及端口（默认6343） COLLECTOR_IP=192.168.254.2 COLLECTOR_PORT=6343 # 发送监听数据的网桥的主机与收集数据的监听主机通信使用的接口 # 由于是同主机使用的docker，所以所有容器都attach在docker0网桥上，一般此处为ens33 AGENT_IP=docker0 HEADER_BYTES=128 # 帧头长度 SAMPLING_N=64 # 采样率 POLLING_SECS=10 # 轮询时间 # 监听ovs网桥 m_bridge=b.5.35 sudo ovs-vsctl -- --id=@sflow create sflow agent=${AGENT_IP} \\ target=\u0026quot;\\\u0026quot;${COLLECTOR_IP}:${COLLECTOR_PORT}\\\u0026quot;\u0026quot; header=${HEADER_BYTES} \\ sampling=${SAMPLING_N} polling=${POLLING_SECS} \\ -- set ${m_bridge} sflow=@sflow # 执行成功后返回 sFlow UUID # 删除sFlow监听项目 sudo ovs-vsctl remove bridge ${m_bridge} sflow \u0026lt;sFlow UUID\u0026gt; # 查看全部监听 sudo ovs-vsctl list sflow 浏览器打开 http://localhost:8087 或 https://localhost:8443, 如果是远程主机访问将localhost改为运行这个容器/app的主机IP\n这里有一些基本的使用说明\n最后结果采集的很详细，但是主机负载之类的数据没有采集，应该是需要snmp协议监听才有。\nsFlow、NetFlow、SNMP三者之间有什么不同？\n网络拓扑: 筛选流量: ","id":9,"section":"posts","summary":"OVS 介绍 Open virtual Switch 是一个在 Apache2许可授权的 开源多层软件交换机。目标是实现一个产品质量的交换机平台，支持标准的管理接口，并开放转发功能，以供","tags":["linux","network"],"title":"OVS 学习笔记","uri":"https://liangkang233.github.io/2021/12/ovs%E5%AD%A6%E4%B9%A0/","year":"2021"},{"content":"最近在做一个关于应用上云的测试，于是看到有华为云的免费服务器试用就注册了一个，记录下操作备忘。\n个人用户实名注册即可领取一个低性能的2核4g的服务器，试用15天。领取链接\n初始化操作 领取成功后，按照创建步骤即可。如果没有设定登录密码的，在控制台设置即可。弹性公网即为服务器的公网IP，与其链接通信试用这个ip。 远程登录可以试用 CloudShell VNC Xshell shell 等登录，先使用VNC设置初始密码，网络安全组的入站等规则。 此页面也可查询服务器详细一段时间内运行状态 需要的初步操作： 添加普通用户\nroot 用户权限太大，为了以防误操作和开发需要，需要新建一个有root权限的普通用户。\n# 创建用户 sudo adduser username ## 命令将向你询问一系列的问题。密码是必需的，其他字段都是可选的。 Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully Changing the user information for username Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] # 最后，输入Y确认信息是否正确。 # 如果您希望新创建的用户具有管理权限，请将用户添加到sudo组： sudo usermod -aG sudo username # 您可以使用两个命令行工具来删除用户帐户：userdel和deluser。在Ubuntu上，建议您使用deluser命令，因为它比userdel 更友好。 # 要删除用户而不删除用户文件，请运行： sudo deluser username # 如果要删除并且用户的家目录和邮件使用--remove-home选项： sudo deluser --remove-home username ssh公钥免密登录\n我更习惯直接使用ssh登录远程服务器，所以设置免密登录很有必要\napt-get install openssh-server openssh-client # 如果没有或者需要一个新公私钥的创建命令 ssh-keygen -t rsa -f ~/.ssh/cloud # 复制公钥，需要登录那个用户就复制到哪 ssh-copy-id -i ~/.ssh/cloud.pub root@弹性公网IP X11图形界面允许\n如果需要符合传输X11协议的图形界面需要确保ssh登录后：\n环境说明： A主机ssh连接B主机，A使用X11服务显示使用B主机的code等界面 a. 首先确保A可以连接上B主机 b. 设置主机A运行其他服务器的 X11 界面： xhost + c. 设置主机A sudo vim /etc/ssh/ssh_config ForwardAgent yes ForwardX11 yes ForwardX11Trusted yes d. 设置主机B的 daemon 配置X11转发 sudo vim /etc/ssh/sshd_config #补充下面这行,我这台服务器是已经配置好的。 X11Forwarding yes #确保正确后重启ssh daemon sudo systemctl restart sshd 最后连接B主机即可 ssh -X username@B主机(IP) 更改主机名\n如果你在一个云实例上运行 Ubuntu，并且安装了cloud-init软件包，你也可以编辑/etc/cloud/cloud.cfg文件。这个软件包由云服务器厂商提供，通常默认被安装，并且它可以被用来处理云服务器实例的初始化。如果文件存在于你的系统上，打开它：sudo nano /etc/cloud/cloud.cfg搜索\u0026quot;preserve_hostname”,并且将值从false修改到true。\n#This will cause the set+update hostname module to not operate (if true) preserve_hostname: true # 保存文件，并且关闭编辑器运行命令 hostnamectl sethostname YOUR_define_name 远程Vscode 虽然服务器自带vim等编辑器，但是还是vscode用的顺手，下面是配置远端登录vscode的记录。（用x11打开的vscode太卡，不推荐如此使用）\n打开本地主机的vscode扩展商店，搜索安装 Remote - SSH: Editing Configuration Files ms-vscode-remote.remote-ssh-edit 之后打开此扩展设定远程登录的IP和用户 可是启动远程登录时ssh Server卡在Setting up SSH Host XX: Downloading VS Code Server\n重新连接后有detail选项，打开显示的部分日志如下：\n[14:30:07.314] Log Level: 2 [14:30:07.317] remote-ssh@0.66.0 [14:30:07.318] linux x64 [14:30:07.321] SSH Resolver called for \u0026quot;ssh-remote+cloud-huawei-root\u0026quot;, attempt 1 [14:30:07.322] \u0026quot;remote.SSH.useLocalServer\u0026quot;: true [14:30:07.322] \u0026quot;remote.SSH.path\u0026quot;: undefined [14:30:07.322] \u0026quot;remote.SSH.configFile\u0026quot;: undefined [14:30:07.322] \u0026quot;remote.SSH.useFlock\u0026quot;: true [14:30:07.323] \u0026quot;remote.SSH.lockfilesInTmp\u0026quot;: false [14:30:07.323] \u0026quot;remote.SSH.localServerDownload\u0026quot;: auto [14:30:07.323] \u0026quot;remote.SSH.remoteServerListenOnSocket\u0026quot;: false [14:30:07.323] \u0026quot;remote.SSH.showLoginTerminal\u0026quot;: false [14:30:07.324] \u0026quot;remote.SSH.defaultExtensions\u0026quot;: [] [14:30:07.324] \u0026quot;remote.SSH.loglevel\u0026quot;: 2 [14:30:07.325] SSH Resolver called for host: cloud-huawei-root [14:30:07.325] Setting up SSH remote \u0026quot;cloud-huawei-root\u0026quot; [14:30:07.331] Acquiring local install lock: /tmp/vscode-remote-ssh-fd33cb2f-install.lock [14:30:07.352] Looking for existing server data file at /home/lk233/.config/Code/User/globalStorage/ms-vscode-remote.remote-ssh/vscode-ssh-host-fd33cb2f-b4c1bd0a9b03c749ea011b06c6d2676c8091a70c-0.66.0/data.json [14:30:07.356] Using commit id \u0026quot;b4c1bd0a9b03c749ea011b06c6d2676c8091a70c\u0026quot; and quality \u0026quot;stable\u0026quot; for server [14:30:07.368] Install and start server if needed [14:30:07.379] PATH: /home/lk233/.local/bin:/home/lk233/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/lk233/.local/bin:/home/lk233/go/bin:/usr/local/go/bin:/home/lk233/.local/bin:/home/lk233/.local/bin [14:30:07.380] Checking ssh with \u0026quot;ssh -V\u0026quot; [14:30:07.418] \u0026gt; OpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n 7 Dec 2017 [14:30:07.429] askpass server listening on /run/user/1000/vscode-ssh-askpass-40f6502d1f6ea56e214539b4c7f7cd72b715cc8b.sock [14:30:07.430] Spawning local server with {\u0026quot;serverId\u0026quot;:1,\u0026quot;ipcHandlePath\u0026quot;:\u0026quot;/run/user/1000/vscode-ssh-askpass-2918dcdc514eef86200f16b5db8a75360fbea57c.sock\u0026quot;,\u0026quot;sshCommand\u0026quot;:\u0026quot;ssh\u0026quot;,\u0026quot;sshArgs\u0026quot;:[\u0026quot;-v\u0026quot;,\u0026quot;-T\u0026quot;,\u0026quot;-D\u0026quot;,\u0026quot;45283\u0026quot;,\u0026quot;-o\u0026quot;,\u0026quot;ConnectTimeout=15\u0026quot;,\u0026quot;cloud-huawei-root\u0026quot;],\u0026quot;dataFilePath\u0026quot;:\u0026quot;/home/lk233/.config/Code/User/globalStorage/ms-vscode-remote.remote-ssh/vscode-ssh-host-fd33cb2f-b4c1bd0a9b03c749ea011b06c6d2676c8091a70c-0.66.0/data.json\u0026quot;} [14:30:07.430] Local server env: {\u0026quot;DISPLAY\u0026quot;:\u0026quot;:0\u0026quot;,\u0026quot;ELECTRON_RUN_AS_NODE\u0026quot;:\u0026quot;1\u0026quot;,\u0026quot;SSH_ASKPASS\u0026quot;:\u0026quot;/home/lk233/.vscode/extensions/ms-vscode-remote.remote-ssh-0.66.0/out/local-server/askpass.sh\u0026quot;,\u0026quot;VSCODE_SSH_ASKPASS_NODE\u0026quot;:\u0026quot;/usr/share/code/code\u0026quot;,\u0026quot;VSCODE_SSH_ASKPASS_MAIN\u0026quot;:\u0026quot;/home/lk233/.vscode/extensions/ms-vscode-remote.remote-ssh-0.66.0/out/askpass-main.js\u0026quot;,\u0026quot;VSCODE_SSH_ASKPASS_HANDLE\u0026quot;:\u0026quot;/run/user/1000/vscode-ssh-askpass-40f6502d1f6ea56e214539b4c7f7cd72b715cc8b.sock\u0026quot;} [14:30:07.447] Spawned 11142 [14:30:07.653] \u0026gt; local-server-1\u0026gt; Spawned ssh, pid=11150 [14:30:07.659] stderr\u0026gt; OpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n 7 Dec 2017 [14:30:07.914] stderr\u0026gt; debug1: Server host key: ecdsa-sha2-nistp256 SHA256:TeikcLf0gyEyeAnlAgObhrs6PKRrfQQeW6zLEFgFiA4 [14:30:08.172] stderr\u0026gt; Authenticated to 123.60.23.165 ([123.60.23.165]:22). [14:30:08.977] \u0026gt; Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-70-generic aarch64) \u0026gt; \u0026gt; * Documentation: https://help.ubuntu.com \u0026gt; * Management: https://landscape.canonical.com \u0026gt; * Support: https://ubuntu.com/advantage \u0026gt; \u0026gt; System information as of Sun Nov 14 14:30:08 CST 2021 \u0026gt; \u0026gt; System load: 0.05 Processes: 99 \u0026gt; Usage of /: 10.2% of 38.63GB Users logged in: 0 \u0026gt; Memory usage: 6% IP address for eth0: 192.168.0.20 \u0026gt; Swap usage: 0% \u0026gt; ***** 查了下果然是这个vscode-server包需要科学上网，所以云服务器无法连接上。 只能按照How can I install vscode-server in linux offline类似的安装了。不过里面问题提问的人的是x86架构的包，我使用的是ARM的包。\n上面日志可以看到有一句Using commit id \u0026ldquo;b4c1bd0a9b03c749ea011b06c6d2676c8091a70c\u0026rdquo; and quality \u0026ldquo;stable\u0026rdquo; for server，这个等价替换上面问题的解决方案的commitid即可。其实直接查看主机运行的code 相关进程即可看到：\nroot@cloud:~# ps aux | grep code root 507 0.0 0.1 11488 5940 ? S 14:27 0:00 wget --tries=1 --connect-timeout=7 --dns-timeout=7 -nv -O vscode-server.tar.gz https://update.code.visualstudio.com/commit:b4c1bd0a9b03c749ea011b06c6d2676c8091a70c/server-linux-arm64/stable root 5321 0.0 0.0 5672 664 pts/0 S+ 14:31 0:00 grep --color=auto code 总结下解决方案：\n本地下好对应包 我的版本的 commit id = b4c1bd0a9b03c749ea011b06c6d2676c8091a70c，使用stable版本（inside预览不推荐） 浏览器或wget下载https://update.code.visualstudio.com/commit:b4c1bd0a9b03c749ea011b06c6d2676c8091a70c/server-linux-arm64/stable scp复制该压缩包上传云服务器 $ scp /home/localuser/vscode-server-linux-arm64.tar.gz user@123.60.23.165:/home/user/ 解压并设定状态 如果之前下载失败了记得把commit对应文件夹清空，或者新建一个。user对应云服务器用户名一般为 /root/.vscode-server-insiders/bin/${commit_id} 或者 /home/user/.vscode-server-insiders/bin/${commit_id} tar zxvf ./vscode-server-linux-x64.tar.gz -C /home/user/.vscode-server-insiders/bin/${commit_id} --strip 1 touch /home/user/.vscode-server-insiders/bin/${commit_id}/0 最后，安装完毕，登录成功如下所示 当然，要记得关闭后台更新。\n","id":10,"section":"posts","summary":"最近在做一个关于应用上云的测试，于是看到有华为云的免费服务器试用就注册了一个，记录下操作备忘。 个人用户实名注册即可领取一个低性能的2核4g的","tags":["linux"],"title":"华为云服务器折腾记录","uri":"https://liangkang233.github.io/2021/11/%E5%8D%8E%E4%B8%BA%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8A%98%E8%85%BE%E8%AE%B0%E5%BD%95/","year":"2021"},{"content":"先简单介绍几个基础概念： 递归 递归是重复调用函数自身实现循环。迭代是函数内某段代码实现循环。 其中，迭代与普通循环的区别是：迭代时，循环代码中参与运算的变量同时是保存结果的变量，当前保存的结果作为下一次循环计算的初始值。典型的应用有深度搜索dfs\n迭代 递归循环中，遇到满足终止条件的情况时逐层返回来结束。迭代则使用计数器结束循环。 当然很多情况都是多种循环混合采用，这要根据具体需求.在循环的次数较大的时候，迭代的效率明显高于递归,但是不易于理解。典型应用有bfs中遍历队列。\n对于斐波那契数列\n// 递归方法 int fibonacci_sequence_recursion(int n) { return (n \u0026amp;lt; 2) ? n : fibonacci_sequence_recursion(n - 1) + fibonacci_sequence_recursion(n - 2); } // 迭代方法 int fibonacci_sequence_loop(int n) { if (n \u0026amp;lt; 2) return n; int before = 0; int last = 1; while (1 \u0026amp;lt; n--) { last = before + last; before = last - before; } return last; } 五大基本算法： 穷举 enumerate 枚举的思想是不断地猜测，从可能的集合中一一尝试，然后再判断题目的条件是否成立。 枚举的时候要想清楚：可能的情况是什么？要枚举哪些要素？ 枚举的范围是什么？是所有的内容都需要枚举吗？\n在用枚举法解决问题的时候，一定要想清楚这两件事，否则会带来不必要的时间开销。\n贪心 greedy 在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望导致结果是最好或最优的算法。比如在旅行推销员问题中，如果旅行员每次都选择最近的城市，那这就是一种贪心算法。\n贪心算法与动态规划的不同在于它对每个子问题的解决方案都做出选择，不能回退。动态规划则会保存以前的运算结果，并根据以前的结果对当前进行选择，有回退功能。\n分治 divide-and-conquer 把问题分解成规模小的问题，再去递归(或迭代)解决。\n注意二分搜索(binary-search)每次都要舍弃一半，从留下的一半中寻找目标；而分治法把一个大问题分成两个或多个小问题\n归并排序 void merge_sort_recursive(int arr[], int reg[], int start, int end) { if (start \u0026gt;= end) return; int len = end - start, mid = (len \u0026gt;\u0026gt; 1) + start; int start1 = start, end1 = mid; int start2 = mid + 1, end2 = end; merge_sort_recursive(arr, reg, start1, end1); merge_sort_recursive(arr, reg, start2, end2); int k = start; while (start1 \u0026lt;= end1 \u0026amp;\u0026amp; start2 \u0026lt;= end2) reg[k++] = arr[start1] \u0026lt; arr[start2] ? arr[start1++] : arr[start2++]; while (start1 \u0026lt;= end1) reg[k++] = arr[start1++]; while (start2 \u0026lt;= end2) reg[k++] = arr[start2++]; for (k = start; k \u0026lt;= end; k++) arr[k] = reg[k]; } void merge_sort(int arr[], const int len) { int reg[len]; merge_sort_recursive(arr, reg, 0, len - 1); } 汉诺塔问题 #!/usr/bin/env python3 # -*- coding: utf-8 -*- def move(n, a, b, c): if n == 1: print(a, '--\u0026gt;', c) return move(n-1, a, c, b) print(a, '--\u0026gt;', c) move(n-1, b, a, c) a = input(\u0026quot;请输入汉尼塔A的个数: \u0026quot;) move(int(a), 'A', 'B', 'C') \u0026quot;\u0026quot;\u0026quot; 总次数一定为 2^n - 1 可以把盘子看成两部分，最下面的第n个和上面的n-1个，完成所有盘子的从a到c可以分解为3步: 1.把上面n-1个盘子从a移动到b 2.把最下面的第n个盘子从a移动到c 3.把在b上的n-1个盘子移动到c 这样从最后一步往前n-1个分解，只不过步骤1和3中的移动前n-1个不是借助b从a移动到c，而分别是，借助c从a到b和借助a从b到c。 这样就分解成了n-1个盘子的汉诺塔问题，一直用这三步迭代分解一直到n等于1。 \u0026quot;\u0026quot;\u0026quot; 回溯 backtracking 回溯法简单来说就是按照深度优先的顺序，穷举所有可能性的算法，但是回溯算法比暴力穷举法更高明的地方就是回溯算法可以随时判断当前状态是否符合问题的条件。一旦不符合条件，那么就退回到上一个状态，省去了继续往下探索的时间。所以根据这类问题，一般会有优化剪枝策略以及启发式搜索策略。\n多说无益，给出几个具体例子：\n经典八皇后问题\n八皇后问题是一个以国际象棋为背景的问题：如何能够在8×8的国际象棋棋盘上放置八个皇后， 使得任何一个皇后都无法直接吃掉其他的皇后？为了达到此目的，任两个皇后都不能处于同一条横行、纵行或斜线上。八皇后问题可以推广为更一般的n皇后摆放问题：这时棋盘的大小变为n×n，而皇后个数也变成n。当且仅当n = 1或n ≥ 4时问题有解[1]。*/\n#include \u0026lt;iostream\u0026gt; using namespace std; const int N = 8; int arr[10], total_cnt; // arr记录每一行(X)皇后的Y坐标 bool isPlaceOK(int *a, int n, int c) { for (int i = 1; i \u0026lt;= n - 1; ++i) { if (a[i] == c || a[i] - i == c - n || a[i] + i == c + n) return false; //检查位置是否可以放 (n行c列)是将要放置的位置 //a[i] == c如果放在同一列，false //a[i] -+ i = c -+ n 如果在对角线上，（处在同一左(右)对角,行列值只差(和)相同） false } return true; } void printSol(int *a) { for (int i = 1; i \u0026lt;= N; ++i) { //遍历每一行 for (int j = 1; j \u0026lt;= N; ++j) { //遍历每一列 cout \u0026lt;\u0026lt; (a[i] == j ? \u0026quot;X\u0026quot; : \u0026quot;-\u0026quot;) \u0026lt;\u0026lt; \u0026quot; \u0026quot;;; } //如果标记数组中这一行的皇后放在j位置，则输出X，否则输出-， //用空格分隔 cout \u0026lt;\u0026lt; endl; //每一行输出一个换行 } cout \u0026lt;\u0026lt; endl; //每一组数据一个换行分隔 } void addQueen(int *a, int n) { if (n \u0026gt; N) { //n代表从第一行开始放置 printSol(a); total_cnt++; return ; } for (int i = 1; i \u0026lt;= N; ++i) { //i从第1列到第N列遍历 if (isPlaceOK(a, n, i)) { a[n] = i; //如果可以放置，就把皇后放在第n行第i列 addQueen(a, n + 1); } } } int main() { addQueen(arr, 1); cout \u0026lt;\u0026lt; \u0026quot;total: \u0026quot; \u0026lt;\u0026lt; total_cnt \u0026lt;\u0026lt; \u0026quot; solutions.\\n\u0026quot;; return 0; } 分割回文串 class Solution { public: vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; ans; bool isHui(string a) { int size = a.size(); for (int i = 0; i \u0026lt; size / 2; i++) { if (a[i] != a[size - i - 1]) return false; } return true; } void find(string s, int index, vector\u0026lt;string\u0026gt; temp) { if (index == s.size()) ans.push_back(temp); for (int i = 1; index + i \u0026lt;= s.size(); i++) { if (isHui(s.substr(index, i))) { vector\u0026lt;string\u0026gt; temp1(temp); temp1.push_back(s.substr(index, i)); find(s, index + i, temp1); } } } vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; partition(string s) { vector\u0026lt;string\u0026gt; temp; find(s, 0, temp); return ans; } }; 动态规划 dynamic-programming 动态规划在刷题中经常遇到，有很多种变形题但是基本都是这么个思路，自顶向下 拆分问题 找出状态转移方程。 动态规划就是一种聪明的穷举，记录其中部分过程的状态。非常重要，多做多思考。\n经典背包问题 #include\u0026lt;stdio.h\u0026gt; int V[200][200];//前i个物品装入容量为j的背包中获得的最大价值 int max(int a,int b) { if(a\u0026gt;=b) return a; else return b; } int KnapSack(int n,int w[],int v[],int x[],int C) { int i,j; //填表,其中第一行和第一列全为0 for(i=0;i\u0026lt;=n;i++) V[i][0]=0; for(j=0;j\u0026lt;=C;j++) V[0][j]=0; for(i=1;i\u0026lt;=n;i++) { printf(\u0026quot;物品编号%d 重量%d 价值%d \u0026quot;,i,w[i-1],v[i-1]); for(j=1;j\u0026lt;=C;j++) { if(j\u0026lt;w[i-1]) //当前编号物品比整个背包容量还大 { V[i][j]=V[i-1][j]; printf(\u0026quot;[%d][%d]=%2d \u0026quot;,i,j,V[i][j]); } else // 用max比较要不要放下当前物品 { V[i][j]=max(V[i-1][j],V[i-1][j-w[i-1]]+v[i-1]); printf(\u0026quot;[%d][%d]=%2d \u0026quot;,i,j,V[i][j]); } } printf(\u0026quot;\\n\u0026quot;); } //判断哪些物品被选中 j=C; for(i=n;i\u0026gt;=1;i--) { if(V[i][j]\u0026gt;V[i-1][j]) { x[i]=1; j=j-w[i-1]; } else x[i]=0; } printf(\u0026quot;选中的物品是:\\n\u0026quot;); for(i=1;i\u0026lt;=n;i++) printf(\u0026quot;%d \u0026quot;,x[i]); printf(\u0026quot;\\n\u0026quot;); return V[n][C]; } void main() { int s;//获得的最大价值 int w[15];//物品的重量 int v[15];//物品的价值 int x[15];//物品的选取状态 int n,i; int C;//背包最大容量 n=5; printf(\u0026quot;请输入背包的最大容量:\\n\u0026quot;); scanf(\u0026quot;%d\u0026quot;,\u0026amp;C); printf(\u0026quot;输入物品数:\\n\u0026quot;); scanf(\u0026quot;%d\u0026quot;,\u0026amp;n); printf(\u0026quot;请分别输入物品的重量:\\n\u0026quot;); for(i=0;i\u0026lt;n;i++) scanf(\u0026quot;%d\u0026quot;,\u0026amp;w[i]); printf(\u0026quot;请分别输入物品的价值:\\n\u0026quot;); for(i=0;i\u0026lt;n;i++) scanf(\u0026quot;%d\u0026quot;,\u0026amp;v[i]); s=KnapSack(n,w,v,x,C); printf(\u0026quot;最大物品价值为:\\n\u0026quot;); printf(\u0026quot;%d\\n\u0026quot;,s); } KMP算法 在计算机科学中，Knuth-Morris-Pratt字符串查找算法（简称为KMP算法）可在一个字符串S内查找一个词W的出现位置。 一个词在不匹配时本身就包含足够的信息来确定下一个匹配可能的开始位置，此算法利用这一特性以避免重新检查先前配对的字符。\n阮一峰的博客分析的很好，这里将具体实现分享下。\n注意size() 返回的是无符号数，其与负数比较大小时一定要转为有符号的，否则负数会先转变为无符号数之后比较大小结果错误。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; const int Maxn = 1024; class Solution { public: int next[Maxn] = { 0 }; //维护p等价前缀长度的记录数组,p匹配失败就跳转到该位置 即匹配了p的个数-1 // 关键在于计算next数组 这里基于最大长度表(字符串的前缀后缀的公共元素的最大长度)来做 // next数组是 除当前字符外 的最长相同前缀后缀。所以为最大长度表向右移一位，初值赋为-1的数组 void GetNextval(string p) { next[0] = -1; int i = -1, j = 0; // i表示前缀 j遍历index后缀 求出需要匹配的字符串P的next数组 while (j \u0026lt; int(p.size()) - 1) { if (i == -1 || p[i] == p[j]) { ++i; ++j; // next[j] = i; //优化如下所示, 当p[i] == p[j] 时，KmpSearch里不匹配调用next会重复调用，所以这里直接处理 if(p[i] != p[j]) next[j] = i; else next[j] = next[i]; } else i = next[i]; } } int KmpSearch(string s, string p) { int i = 0, j = 0; GetNextval(p); // 注意！ size() 返回的是无符号数，一定要转为有符号的 否则j为-1时会先转变为无符号数比较大小会错误 while ( i \u0026lt; int(s.size()) \u0026amp;\u0026amp; j \u0026lt; int(p.size()) ) { // j为-1 或 匹配成功 s、p的下标都向后走 if (j == -1 || s[i] == p[j]) { i++; j++; } // 否则字符匹配失败，i不变 j转为next记录值，再用原来的s[i] 与 新的p[j]匹配 // 当j==-1即该字符前不可能有相同前后缀时 还不匹配 说明 i 需要+1 而j=0 else j = next[j]; } if (j == p.size()) return i - j; return -1; } }; int main() { Solution sol; string s1, s2; while (1) { cin \u0026gt;\u0026gt; s1 \u0026gt;\u0026gt; s2; cout \u0026lt;\u0026lt; sol.KmpSearch(s1, s2) \u0026lt;\u0026lt; endl; } } 关于字符匹配的动态规划题 10.正则表达式匹配\nclass Solution { public: bool isMatch(string s, string p) { int sl = s.size(), pl = p.size(); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f_map; f_map.assign(sl + 1, vector\u0026lt;int\u0026gt;(pl + 1, 0)); f_map[0][0] = 1; // p为正则表达式字符串 // 匿名函数用法 这样做可减少内存的拷贝 auto matches = [\u0026amp;](int i, int j) -\u0026gt; bool{ if(i == 0) return false; else if(p[j - 1] == '.') return true; else return s[i - 1] == p[j - 1]; }; for (int i = 0; i \u0026lt;= sl; i++) { // i j代表第几个字符，若为0 表示字符为空 for (int j = 1; j \u0026lt;= pl; j++) { // j为0时除非i=0否则必定匹配失败,初始化时已经给所有除f_map[0][0]外赋0 if(p[j-1] == '*') { if( matches(i, j-1) ) // f_map[i][j] = f_map[i-1][j]; i-1表示*复制一份前字符，j-2表示*和之前字符代表空 f_map[i][j] = f_map[i-1][j] || f_map[i][j-2]; //加上或，防止当前s头不能减少的情况 else f_map[i][j] = f_map[i][j-2]; // } else{ if( matches(i, j) ) f_map[i][j] = f_map[i-1][j-1]; } } } return f_map[sl][pl]; } }; 44.通配符匹配\nclass Solution { public: // s为输入测试值,测试是否与p匹配 p,包含a-z ? * // 此题与 10.正则表达式匹配.cpp 类似。不过此处通配符是匹配任意一段字符串，且*前可无字符 // 正则表达式是 *匹配前一个字符N次 bool isMatch(string s, string p) { int sl = s.size(), pl = p.size(); // dp[i][j] 表示 s的i长度 与 p的j长度 是否匹配 i、j为0表示长度为0的空的字符串 auto match = [\u0026amp;](int i, int j) -\u0026gt; bool { if (i == 0) return false; //进入match判断时必定不为* 所以可以直接return false else if (p[j-1] == '?') return true; return s[i-1] == p[j-1]; }; vector\u0026lt;vector\u0026lt;bool\u0026gt;\u0026gt; dp(sl + 1, vector\u0026lt;bool\u0026gt;(pl + 1, false)); dp[0][0] = true; for (int i = 0; i \u0026lt;= sl; i++) { for (int j = 1; j \u0026lt;= pl; j++) { if (p[j-1] == '*') dp[i][j] = dp[i][j-1] || (i\u0026gt;0 \u0026amp;\u0026amp; dp[i-1][j]); //等价 *不存在 或者 *前面匹配成功 else dp[i][j] = match(i, j) \u0026amp;\u0026amp; dp[i-1][j-1]; } } return dp[sl][pl]; } }; ","id":11,"section":"posts","summary":"先简单介绍几个基础概念： 递归 递归是重复调用函数自身实现循环。迭代是函数内某段代码实现循环。 其中，迭代与普通循环的区别是：迭代时，循环代码中参","tags":["C/C++","算法"],"title":"五大基本算法","uri":"https://liangkang233.github.io/2021/11/%E4%BA%94%E5%A4%A7%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/","year":"2021"},{"content":"内存模型 对于C/C++ 等语言来说，内存空间大致使用在\n栈区（stack）：又编译器自动分配释放，存放函数的参数值，局部变量的值等，其操作方式类似于数据结构的栈。\n堆区（heap）：一般是由程序员分配释放，若程序员不释放的话，程序结束时可能由OS回收，值得注意的是他与数据结构的堆是两回事.\n全局区（static）：也叫静态数据内存空间，存储全局变量和静态变量，全局变量和静态变量的存储是放一块的，初始化的全局变量和静态变量放一块区域，没有初始化的在相邻的另一块区域，程序结束后由系统释放。\n文字常量区(const)：常量字符串就是放在这里，程序结束后由系统释放。\n程序代码区：存放函数体的二进制代码。\n堆中的对象对于Go 以及 Java 等编程语言来说由工程师和编译器共同管理，堆内存对象由内存分配器分配并由垃圾收集器 gc *(garbage collection)*回收。\n在多线程编程下，追求更高内存管理效率：更快的分配是主要目的。\n引入虚拟内存后，让内存的并发访问问题的粒度从多进程级别，降低到多线程级别。 为线程预分配缓存需要进行1次系统调用，后续线程申请小内存时，从缓存分配，都是在用户态执行，没有系统调用，缩短了内存总体的分配和释放时间， 多个线程同时申请小内存时，从各自的缓存分配，访问的是不同的地址空间，无需加锁，把内存并发访问的粒度进一步降低 接下来介绍go的具体内存模型：\n内存分配方法 线性分配器（Sequential Allocator，Bump Allocator）\n实现简单，直接在内存中维护一个指向可用地址的指针。其GC需要与具有拷贝特性的回收方法:标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法,所以像C、C++这样暴漏内存地址指针的无法使用。\n空闲链表分配器（Free-List Allocator）\n大致分为以下四种策略：go使用的是第四种\n首次适应（First-Fit）— 从链表头开始遍历，选择第一个大小大于申请内存的内存块； 循环首次适应（Next-Fit）— 从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块； 最优适应（Best-Fit）— 从链表头遍历整个链表，选择最合适的内存块； 隔离适应（Segregated-Fit）— 将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块；举例：将内存分割成由 4、8、16、32 字节的内存块组成的链表，当我们向内存分配器申请 8 字节的内存时，它会在8字节链表中找到满足条件的空闲内存块并返回。隔离适应的分配策略减少了需要遍历的内存块数量，提高了内存分配的效率。 除此之外，go的内存分配器还借鉴了TCMalloc(毕竟都是google做的)的设计理念——使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略\n类别 大小 微对象 (0, 16B) 小对象 [16B, 32KB] 大对象 (32KB, +∞) Page：操作系统对内存管理以页为单位，TCMalloc也是这样，只不过TCMalloc里的Page大小与操作系统里的大小并不一定相等，而是倍数关系。《TCMalloc解密》里称x64下Page大小是8KB。 Span：一组连续的Page被称为Span，比如可以有2个页大小的Span，也可以有16页大小的Span，Span比Page高一个层级，是为了方便管理一定大小的内存区域，Span是TCMalloc中内存管理的基本单位。 ThreadCache：每个线程各自的Cache，一个Cache包含多个空闲内存块链表，每个链表连接的都是内存块，同一个链表上内存块的大小是相同的，也可以说按内存块大小，给内存块分了个类，这样可以根据申请的内存大小，快速从合适的链表选择空闲内存块。由于每个线程有自己的ThreadCache，所以ThreadCache访问是无锁的。 CentralCache：是所有线程共享的缓存，也是保存的空闲内存块链表，链表的数量与ThreadCache中链表数量相同，当ThreadCache内存块不足时，可以从CentralCache取，当ThreadCache内存块多时，可以放回CentralCache。由于CentralCache是共享的，所以它的访问是要加锁的。 PageHeap：PageHeap是堆内存的抽象，PageHeap存的也是若干链表，链表保存的是Span，当CentralCache没有内存的时，会从PageHeap取，把1个Span拆成若干内存块，添加到对应大小的链表中，当CentralCache内存多的时候，会放回PageHeap。如上图，分别是1页Page的Span链表，2页Page的Span链表等，最后是large span set，这个是用来保存中大对象的。毫无疑问，PageHeap也是要加锁的。 垃圾回收 gc(garbage collection)在几乎所有的现代编程语言中，垃圾收集器都是一个复杂的系统，为了在不影响用户程序的情况下回收废弃的内存需要付出非常多的努力，Java 的垃圾收集机制是一个很好的例子，Java 8 中包含线性、并发、并行标记清除和 G1 四个垃圾收集器，想要理解它们的工作原理和实现细节需要花费很多的精力。\n垃圾收集器将存储器视为一张有向可达图。图中的节点可以分为两组：一组称为根节点，对应于不在堆中的位置，这些位置可以是寄存器、栈中的变量，或者是虚拟存储器中读写数据区域的全局变量；另外一组称为堆节点，对应于堆中一个分配块，如下图：\n当堆节点不可达时即可视为垃圾，因为已经访问不到了。\n介绍几种基础的GC算法：\n引用计数：\nObjective-C 选择了自动引用计数（智能指针），即创建的堆空间维护一个计数器，每当有新的引用指向它就计数器加一。反之指向其的引用置空或指向其他对象计数器减一，减少至0则释放，实现动态回收内存空间。\n而其缺点是若存在对象的循环引用，无法释放这些对象。并且多个线程同时对引用计数进行增减时，引用计数的值可能会产生不一致的问题，必须使用并发控制机制解决这一问题，也是一个不小的开销。\n标记清除\n这个算法也称为Mark \u0026amp; Sweep算法，为McCarthy独创。它也是目前公认的最有效的GC方案。Mark\u0026amp;Sweep垃圾收集器由标记阶段和回收阶段组成，标记阶段标记出根节点所有可达的对节点，清除阶段释放每个未被标记的已分配块，其执行过程可以分成标记（Mark）和清除（Sweep）两个阶段：\n标记阶段 — 从根对象出发查找并标记堆中所有存活的对象； 清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表； 一般的地，块头部中空闲的低位中的一位用来表示这个块是否已经被标记了。通过Mark\u0026amp;Sweep算法动态申请内存时，先按需分配内存，当内存不足以分配时，从寄存器或者程序栈上的引用出发，遍历上述的有向可达图并作标记（标记阶段），然后再遍历一次内存空间，把所有没有标记的对象释放（清除阶段）。因此在收集垃圾时需要中断正常程序STW*(Stop the world)*，在程序涉及内存大、对象多的时候中断过程可能有点长。当然，收集器也可以作为一个独立线程不断地定时更新可达图和回收垃圾。\n该算法不像引用计数可对内存进行即时回收，但是它解决了引用计数的循环引用问题，因此有的语言把引用计数算法搭配Mark \u0026amp; Sweep 算法构成GC机制。\n节点复制\nMark \u0026amp; Sweep算法的缺点是在分配大量对象时，且对象大都需要回收时，回收中断过程可能消耗很大。而节点复制算法则刚好相反，当需要回收的对象越多时，它的开销很小，而当大部分对象都不需要回收时，其开销反而很大。算法的基本思路是这样的：从根节点开始，被引用的对象都会被复制到一个新的存储区域中，而剩下的对象则是不再被引用的，即为垃圾，留在原来的存储区域。释放内存时，直接把原来的存储区域释放掉，继续维护新的存储区域即可。\n分代回收\n以上三种基本算法各有各的优缺点，也各自有许多改进的方案。通过对这三种方式的融合，出现了一些更加高级的方式。而高级GC技术中最重要的一种为分代回收。它的基本思路是这样的：程序中存在大量的这样的对象，它们被分配出来之后很快就会被释放，但如果一个对象分配后相当长的一段时间内都没有被回收，那么极有可能它的生命周期很长，尝试收集它是无用功。为了让GC变得更高效，我们应该对刚诞生不久的对象进行重点扫描，这样就可以回收大部分的垃圾。为了达到这个目的，我们需要依据对象的”年龄“进行分代，刚刚生成不久的对象划分为新生代，而存在时间长的对象划分为老生代，根据实现方式的不同，可以划分为多个代。\n一种回收的实现策略可以是：首先从根开始进行一次常规扫描，扫描过程中如果遇到老生代对象则不进行递归扫描，这样可大大减少扫描次数。这个过程可使用标记清除算法或者复制收集算法。然后，把扫描后残留下来的对象划分到老生代，若是采用标记清除算法，则应该在对象上设置某个标志位标志其年龄；若是采用复制收集，则只需要把新的存储区域内对象设置为老生代就可以了。而实际的实现上，分代回收算法的方案五花八门，常常会融合几种基本算法。\ngo的垃圾回收 为了高效的标记对象缩短stw时间，go使用三色标记法（标记清除的一种改良）来做；\n三色对象定义：\n白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收；\n黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象；\n灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；\n在垃圾收集器开始工作时，垃圾收集的根对象会被标记成灰色，其他对象标记为白色，垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。\n三色标记垃圾收集器的工作原理很简单，我们可以将其归纳成以下几个步骤：\n从灰色对象的集合队列中选择一个灰色对象并将其标记成黑色并进行步骤2； 将黑色对象指向的所有对象都标记成灰色，保证该对象和被该对象引用的对象都不会被回收； 重复上述两个步骤直到对象图中不存在灰色对象； 垃圾收集器一旦开始执行就会浪费大量的计算资源，为了减少应用程序暂停的最长时间和垃圾收集的总暂停时间，我们会使用下面的策略优化现代的垃圾收集器：\n增量垃圾收集 — 增量地标记和清除垃圾，降低应用程序暂停的最长时间；\n增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间：\n并发垃圾收集 — 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾；\n并发（Concurrent）的垃圾收集不仅能够减少程序的最长暂停时间，还能减少整个垃圾收集阶段的时间，通过开启读写屏障、利用多核优势与用户程序并行执行，并发垃圾收集器确实能够减少垃圾收集对应用程序的影响：\n因为增量和并发两种方式都可以与用户程序交替运行，使用并发或增量执行，有可能会生成悬挂指针——即不该被回收的对象被回收了。所以我们需要使用屏障技术保证垃圾收集的正确性；与此同时，应用程序也不能等到内存溢出时触发垃圾收集，因为当内存不足时，应用程序已经无法分配内存，这与直接暂停程序没有什么区别，增量和并发的垃圾收集需要提前触发并在内存不足前完成整个循环，避免程序的长时间暂停。\n内存屏障技术是一种屏障指令，它可以让 CPU 或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，但是该技术能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存屏障后执行的操作。\n想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的一种：\n强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象； 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径 垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。\n","id":12,"section":"posts","summary":"内存模型 对于C/C++ 等语言来说，内存空间大致使用在 栈区（stack）：又编译器自动分配释放，存放函数的参数值，局部变量的值等，其操作方式类","tags":["go"],"title":"Go内存模型","uri":"https://liangkang233.github.io/2021/10/go%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","year":"2021"},{"content":"如果需要快速的求多次 一个数组A内的 某些区间和，最快的方法是用前缀和来记录为数组B\n差分数组的主要适用场景是频繁对原始数组的某个区间的元素进⾏增减。\n前缀和数组 差分数组\n但是 如果数组A是会变化的，每次修改某个元素，区间和B(假设有n个元素)每个元素都要修改，时间复杂度O(n)\n为了解决这个问题，使用树状数组，其查询 A区间 和 修改区间元素 的时间复杂度皆为 O(log n)\n树状数组 树状数组简单来说就是一个维护了一段数据和的数组，其记录值规律如下所示。\n关键在于lowbit函数 a \u0026amp; -a，即：取出a的二进制表达中的最后一位1的值（负数在计算机中以补码表示）\n原数组为a[i]，c[i]树状数组。\n所以，对于一个树状数组，添加新元素、计算前n项和的时间复杂度都是O(log n)。\n其进阶操作为线段树，以后遇到合适案例再补充记录。\n实现 添加值就是递归的加lowbit添加，相反查询的话就是递归的减lowbit累加和即为区间和。\n实际使用时不用推导，直接拿来用。\n视频源码：\nint t[maxn]; // t数组为维护的树状数组 void add(int x, int k) { for(; x \u0026lt;= n; x += (x\u0026amp;-x) ) { t[x] += k; } } int ask(int x) { int ans; for (; i \u0026gt; 0; x -= (x\u0026amp;-x)) { ans += t[x]; } return ans; } // 单点修改、单点查询 add(x, k); ask(x) - ask(x-1); // 单点修改，区间查询 add(x, k); ask(r) - ask(l-1); // 区间[l,r]内 // 区间查询修改 需要两个树状数组维护 // t1[]维护b[i]前缀和,t2[]维护i*b[i]前缀和 int t1[maxn], t2[maxn]]; void add1(int x, int k) { for(; x \u0026lt;= n; x += (x\u0026amp;-x) ) { t1[x] += k; } } int ask1(int x) { int ans; for (; i \u0026gt; 0; x -= (x\u0026amp;-x)) { ans += t1[x]; } return ans; } void add2(int x, int k) { for(; x \u0026lt;= n; x += (x\u0026amp;-x) ) { t2[x] += k; } } int ask2(int x) { int ans; for (; i \u0026gt; 0; x -= (x\u0026amp;-x)) { ans += t2[x]; } return ans; } // 区间修改，区间查询 // 在区间[l, r]修改 add1(l, d); add1(r+1, -d); add2(l, l*d); add2(r+1, -(r+1)*d); sum[r] - sum[l-1]; //即为下式 (r+1)*ask1[r] - ask2[r] + (l-1+1)*ask1[l-1] - ask2[l-1]; 应用 蓝桥杯题目：蓝桥杯-历届试题 小朋友排队 （树状数组） (lagou.com)\n/* 问题描述 n 个小朋友站成一排。现在要把他们按身高从低到高的顺序排列，但是每次只能交换位置相邻的两个小朋友。 每个小朋友都有一个不高兴的程度。开始的时候，所有小朋友的不高兴程度都是0。 如果某个小朋友第一次被要求交换，则他的不高兴程度增加1，如果第二次要求他交换，则他的不高兴程度增加2（即不高兴程度为3）， 依次类推。当要求某个小朋友第k次交换时，他的不高兴程度增加k。 请问，要让所有小朋友按从低到高排队，他们的不高兴程度之和最小是多少。 如果有两个小朋友身高一样，则他们谁站在谁前面是没有关系的。 输入格式 输入的第一行包含一个整数n，表示小朋友的个数。 第二行包含 n 个整数 H1 H2 … Hn，分别表示每个小朋友的身高。 输出格式 输出一行，包含一个整数，表示小朋友的不高兴程度和的最小值。 样例输入 3 3 2 1 样例输出 9 样例说明 首先交换身高为3和2的小朋友，再交换身高为3和1的小朋友，再交换身高为2和1的小朋友，每个小朋友的不高兴程度都是3，总和为9。 数据规模和约定 对于10%的数据， 1\u0026lt;=n\u0026lt;=10； 对于30%的数据， 1\u0026lt;=n\u0026lt;=1000； 对于50%的数据， 1\u0026lt;=n\u0026lt;=10000； 对于100%的数据，1\u0026lt;=n\u0026lt;=100000，0\u0026lt;=Hi\u0026lt;=1000000。 */ // 用求逆序数的思想去做，定义前面的数大于当前数的个数为逆序数， // 后面的数小于当前数的个数为逆序数2号， // 小朋友的不高兴值 = 逆序数1 等差和 + 逆序数2 等差和 // 逆序数定义可知，一个数的逆序数是往前挪几次，相应的逆序数2号就是被后面的数挪动的次数， // 如果是求交换次数，只需要求逆序数1 或 2 的累加即可 // 其实 左右遍历 逆序数和 一定是相同的， // 只不过这里要累计的是不高兴值 是一个等差数列的n项和 所以只能逆序数的两个方向分开来求 // 使用树状数组来做 以 身高+1 为树状数组下标 这样遍历下去就只会统计到身高比它小的值 // https://www.lagou.com/lgeduarticle/508.html #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstring\u0026gt; using namespace std; // 小朋友身高居然可以为0 // 由于树状数组结构设计无法向tree[0]存储值所以存树状值下标为身高值加1 // 堆空间申请返回的是单个元素的指针，切不可使用memset(tree, 0, sizeof(tree)); // 而是 memset(tree, 0, maxn * sizeof(int)); 同理传参也是如此 #define maxn 1000002 void add(int i, int k, int* tree) { for (; i \u0026lt; maxn; i += (i \u0026amp; -i)) { tree[i] += k; } } int sum (int i, int *tree) { int sum = 0; for (; i \u0026gt; 0; i -= (i \u0026amp; -i)) { sum += tree[i]; } return sum; } int main() { int N; long long count = 0; int* tree = new int[maxn]; int* temp = new int[maxn]; long long* num = new long long[maxn]; memset(temp, 0, maxn * sizeof(int)); memset(num, 0, maxn * sizeof(long long)); cin \u0026gt;\u0026gt; N; for (int i = 0; i \u0026lt; N; i++) cin \u0026gt;\u0026gt; temp[i]; // 从左往右 记录左边比它高的 memset(tree, 0, maxn * sizeof(int)); for (int j = 0; j \u0026lt; N; j++) { add(temp[j]+1 , 1, tree); num[j] = j+1 - sum(temp[j]+1, tree); } // 从右往左 记录右边比他矮的 memset(tree, 0, maxn * sizeof(int)); for (int j = N-1; j \u0026gt;= 0; j--) { add(temp[j]+1, 1, tree); num[j] += sum(temp[j], tree); } for (int i = 0; i \u0026lt; N; i++) { count += num[i] * (num[i]+1) / 2; } delete[] tree; delete[] temp; delete[] num; return 0; } ","id":13,"section":"posts","summary":"如果需要快速的求多次 一个数组A内的 某些区间和，最快的方法是用前缀和来记录为数组B 差分数组的主要适用场景是频繁对原始数组的某个区间的元素进⾏增","tags":["C/C++","数据结构"],"title":"数据结构-树状数组","uri":"https://liangkang233.github.io/2021/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/","year":"2021"},{"content":"并查集 并查集是一种树形的数据结构，用于处理不交集（Disjoint sets）的合并和查询问题。\n案例：初始状态n个元素，每个元素位于独立的集合，之后进行合并操作将集合合并。合并过程中判断集合中是否有重复元素。\n所以并查集主要的两个操作：\n查询: find 确定某个元素处于哪个子集 合并: union 将两个子集合合并成一个集合 并查集的实现 思路:使用数组等结构记录每一个节点的父节点，查询操作就是递归的查询该节点的父节点找寻其root，合并操作就是把两个节点的中一个作为另一个节点的父节点这样就完成了合并。\n一开始每个节点就是一个集合，随着所有节点迭代下去的合并，合并两个节点就相当于合并包含该节点的两个集合。每两个节点合并时查询两个节点的的root节点。如果相同说明两个这两个集合有相同的子节点，合并后必定会产生环。\n优化：\n路径压缩：查找root节点的时候就直接把他的父节点改为root，省的下次重复查找 按秩合并：维护一个秩数组，记录该节点下的子树深度。这样合并两个节点时，让秩大的做父节点避免子树过长。 视频的解析很清楚，做个提纲防止忘记\n视频的源码：\n#include\u0026lt;stdio.h\u0026gt; #include\u0026lt;stdlib.h\u0026gt; #include\u0026lt;string.h\u0026gt; #define VERTICES 6 #define _CRT_SECURE_NO_WARNINGS int find_root(int x, int parent[]) // 找到根节点 { if (parent[x] != x) { //当父节点是自己说明已经是根节点 parent[x] = find_root(parent[x], parent); //路径压缩,找父节点的同时更新自己的父节点为root节点 } return parent[x]; } int union_vertices(int x, int y, int parent[],int rank[]) // 让两个集合合并 { int x_root = find_root(x, parent); int y_root = find_root(y, parent); if (x_root == y_root) return 0; else { if (rank[x_root] \u0026gt; rank[y_root]) // 让 少的指向多 的 parent[y_root] = x_root; else if (rank[x_root] \u0026lt; rank[y_root]) parent[x_root] = y_root; else { parent[x_root] = y_root; // 这个随便可以 rank[y_root]++; } return 1; } } int main(void) { int parent[VERTICES] = { 0 }; int rank[VERTICES] = { 0 }; memset(rank, 0, sizeof(rank)); // memset(parent, -1, sizeof(parent)); for (int i = 0; i \u0026lt; VERTICES; i++) //初始父节点就是自己 parent[i] = i; int edges[6][2] = { {0,1},{1,2},{1,3},{2,4},{3,4},{2,5} }; for (int i = 0; i \u0026lt; 6; i++) { int x = edges[i][0]; int y = edges[i][1]; if (union_vertices(x, y, parent,rank) == 0) { printf(\u0026quot;Cycle detected!\\n\u0026quot;); system(\u0026quot;pause\u0026quot;); exit(0); } } printf(\u0026quot;No cycle found.\\n\u0026quot;); system(\u0026quot;pause\u0026quot;); return 0; } 并查集的应用 leetcode 547题目\nclass Solution { public: int find(int i) { if (parent[i] != i) //递归寻找root节点并把root赋值 parent[i] = find(parent[i]); return parent[i]; } void merge(int i, int j) { int root1 = find(i), root2 = find(j); if(root1 == root2) // 若相等则两个集合有交集，相当于在同一个省份内的两个城市相连（成环） return; // 这里不做任何处理 ans省份树不会减少 ans--; // 接下来进行合并 if(rank[root1] \u0026gt;= rank[root2]) parent[root2] = root1; else parent[root1] = root2; if (rank[root1] == rank[root2]) rank[root1]++; } int ans; vector\u0026lt;int\u0026gt; parent, rank; int findCircleNum(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; isConnected) { ans = isConnected.size(); //初始视作每个城市都是一个省份 rank.resize(ans, 0); for (int i = 0; i \u0026lt; isConnected.size(); i++) parent.push_back(i); for (int i = 0; i \u0026lt; isConnected.size(); i++) { for (int j = 0; j \u0026lt; isConnected.size(); j++) { if (isConnected[i][j] == 0 || i == j) continue; merge(i, j); } } return ans; } }; 题外话：双指针判断链表是否有环，看起来类似也是找环，但是用的双指针找的。141. 环形链表\n堆 这里说的堆指的时数据结构堆，不是程序申请的堆空间。\n堆（heap）是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵树的数组对象。\n堆总是满足下列性质：\n小根堆Min-heap: 父节点的值小于或等于子节点的值； 大根堆Max-heap: 父节点的值大于或等于子节点的值；\n堆中某个结点的值总是不大于或不小于其父结点的值；\n堆总是一棵完全二叉树1\n其插入添加元素的时间复杂度都为O(log n)。查询最大、小值的时间复杂度为O(1)\n堆的实现 由于堆是一颗完全二叉树，所以完全可以用一个数组准确并唯一的表示该二叉树。\n用数组表示该完全二叉树由上到下、由做到右的记录时，有以下性质：\n父节点 = (i - 1) / 2 左子节点 = 2 * i + 1 右子节点 = 2 * i + 2 C++ STL库优先队列的使用方式 头文件: #include \u0026lt;queue\u0026gt;\npriority_queue\u0026lt;point, vector\u0026lt;point\u0026gt;, greater\u0026lt;point\u0026gt;\u0026gt; que; // 第一个参数是存储对象的类型，第二个参数是存储元素的底层容器，第三个参数是函数对象，第二第三参数可以不填入 // 与sort刚好相优先队列反队列默认采用的是less生成的是大根堆，sort 默认是 less 从小到大升序排序 堆的应用 用于堆排序 时间复杂度O(nlog n)，额外空间复杂度O(1)\n// 对一个节点做heapify的时候，必须保证它的所有子树都已经是堆。 void swap(int *a, int *b) { int temp = *b; *b = *a; *a = temp; } void max_heapify(int arr[], int start, int end) { int dad = start; int son = dad * 2 + 1; while (son \u0026lt;= end) { if (son + 1 \u0026lt;= end \u0026amp;\u0026amp; arr[son] \u0026lt; arr[son + 1]) // 判断右子节点是否存在，并比较大小 son++; if (arr[dad] \u0026gt; arr[son]) //如果父节点大于子节点代表调整完毕，直接跳出函數 return; else { // 否则交换父子节点 swap(\u0026amp;arr[dad], \u0026amp;arr[son]); dad = son; son = dad * 2 + 1; } } } void heap_sort(int arr[], int len) { int i; // 初始化，从最后一个父节点开始调整 for (i = (len-2) / 2; i \u0026gt;= 0; i--) max_heapify(arr, i, len - 1); // 取出最大值(堆头)，然后重新heapify 这里优化为将堆头换到最后一位，然后最后一个节点不参加heapify // 迭代全部堆头后，就是排序后的列表 for (i = len - 1; i \u0026gt; 0; i--) { swap(\u0026amp;arr[0], \u0026amp;arr[i]); max_heapify(arr, 0, i - 1); } } 用优先队列解决的案例：23. 合并K个升序链表 - 力扣（LeetCode） (leetcode-cn.com)\nclass Solution { public: //题目23 \u0026quot;重载结构体的\u0026lt;\u0026quot;，用默认的less（所以省略了该参数） struct Status { int val; ListNode *ptr; bool operator \u0026lt; (const Status \u0026amp;rhs) const { return val \u0026gt; rhs.val; } }; priority_queue \u0026lt;Status\u0026gt; q; ListNode* mergeKLists(vector\u0026lt;ListNode*\u0026gt;\u0026amp; lists) { for (auto node: lists) { if (node) q.push({node-\u0026gt;val, node}); } ListNode head, *tail = \u0026amp;head; while (!q.empty()) { auto f = q.top(); q.pop(); tail-\u0026gt;next = f.ptr; tail = tail-\u0026gt;next; if (f.ptr-\u0026gt;next) q.push({f.ptr-\u0026gt;next-\u0026gt;val, f.ptr-\u0026gt;next}); } return head.next; } }; // \u0026quot;也可以重载()\u0026quot; 其实 greater 和 less 就是一个模板调用的模板类，里面重载了元素的() 返回\u0026gt; 或\u0026lt;的bool // STRUCT TEMPLATE greater template \u0026lt;class _Ty = void\u0026gt; struct greater { _CXX17_DEPRECATE_ADAPTOR_TYPEDEFS typedef _Ty _FIRST_ARGUMENT_TYPE_NAME; _CXX17_DEPRECATE_ADAPTOR_TYPEDEFS typedef _Ty _SECOND_ARGUMENT_TYPE_NAME; _CXX17_DEPRECATE_ADAPTOR_TYPEDEFS typedef bool _RESULT_TYPE_NAME; _NODISCARD constexpr bool operator()(const _Ty\u0026amp; _Left, const _Ty\u0026amp; _Right) const { return _Left \u0026gt; _Right; } }; // 重载()如下所示 struct com{ bool operator()(pair\u0026lt;int,int\u0026gt;\u0026amp;a,pair\u0026lt;int,int\u0026gt;\u0026amp;b){ return a.second\u0026gt;b.second; } }; priority_queue\u0026lt;pair\u0026lt;int,int\u0026gt;,vector\u0026lt;pair\u0026lt;int,int\u0026gt;\u0026gt;,com\u0026gt; q; 一棵深度为k的有n个结点的二叉树，对树中的结点按从上至下、从左到右的顺序进行编号，如果编号为i（1≤i≤n）的结点与满二叉树中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":14,"section":"posts","summary":"并查集 并查集是一种树形的数据结构，用于处理不交集（Disjoint sets）的合并和查询问题。 案例：初始状态n个元素，每个元素位于独立的集合","tags":["C/C++","数据结构"],"title":"并查集、堆(优先队列)","uri":"https://liangkang233.github.io/2021/10/%E5%B9%B6%E6%9F%A5%E9%9B%86%E5%A0%86%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/","year":"2021"},{"content":"介绍 最近在做一个关于无线移动自组织网络相关的内容，移动自组织网络是由彼此已经发现和互相接近的且有通信需求的移动设备构成的。由于网内节点的移动拓扑是不可知的，所以各自组网结构是动态变化的。要根据其各个实时动态形成的自组网开发新的内容，这就需要一个可以探测网内节点数量的工具来设定当前自组网内状态。在网上找寻相关工具资料的时候想到OSPF的hello组播包，觉得这个实现很不错，于是尝试用go写了个udp组播实现的探测网内节点的工具，分享下。\n其实现原理就是使用定时器定时触发helllo组播包给组播域，如果节点接收到其他节点发送的组播包就记录下。每一个总检测周期内查询接收的节点，根据接收到的节点名就可以知道该节点的自组网下节点有哪些。例如场景中有1-10个节点，1节点能够收到2-7节点的组播包说明1-7节点在同一自组网内属于该自组网的存活节点。（非存活节点并不是表示该节点down，仅仅是代表该节点例如节点8不在这个自组网内）\n实现过程 go中对udp等套接字的官方包实现类似unix，基本的套接字知识就不在这回顾了，总之要了解下udp也是可以使用connect函数做有连接的请求，并不是说如tcp那般握手提供可靠连接，仅仅是单方面的确定源目标地址的连接。\n组播定义：组播是指在IP网络中将数据包以尽力传送的形式发送到某个确定的节点集合（即组播组），其基本思想是：源主机（即组播源）只发送一份数据，其目的地址为组播组地址；组播组中的所有接收者都可收到同样的数据拷贝，并且只有组播组内的主机可以接收该数据，而其它主机则不能收到。\n基础的用go的套接字示例实现看看深入Go UDP编程这篇博客即可，简单易用。组播部分代码也是使用在这篇文章的通用多播编程代码1改写的\n// 组播服务器代码 func main() { //如果第二参数为nil,它会使用系统指定多播接口，但是不推荐这样使用 addr, err := net.ResolveUDPAddr(\u0026quot;udp\u0026quot;, \u0026quot;224.0.0.250:9981\u0026quot;) if err != nil { fmt.Println(err) } listener, err := net.ListenMulticastUDP(\u0026quot;udp\u0026quot;, nil, addr) if err != nil { fmt.Println(err) return } fmt.Printf(\u0026quot;Local: \u0026lt;%s\u0026gt; \\n\u0026quot;, listener.LocalAddr().String()) data := make([]byte, 1024) for { n, remoteAddr, err := listener.ReadFromUDP(data) if err != nil { fmt.Printf(\u0026quot;error during read: %s\u0026quot;, err) } fmt.Printf(\u0026quot;\u0026lt;%s\u0026gt; %s\\n\u0026quot;, remoteAddr, data[:n]) } } // 组播客户端代码 func main() { ip := net.ParseIP(\u0026quot;224.0.0.250\u0026quot;) srcAddr := \u0026amp;net.UDPAddr{IP: net.IPv4zero, Port: 0} dstAddr := \u0026amp;net.UDPAddr{IP: ip, Port: 9981} conn, err := net.DialUDP(\u0026quot;udp\u0026quot;, srcAddr, dstAddr) if err != nil { fmt.Println(err) } defer conn.Close() conn.Write([]byte(\u0026quot;hello\u0026quot;)) fmt.Printf(\u0026quot;\u0026lt;%s\u0026gt;\\n\u0026quot;, conn.RemoteAddr())} build代码后运行发现客户端运行报错:dial udp 0.0.0.0:0-\u0026gt;224.0.0.250:9981: connect: network is unreachable.\n客户端的错误应该路由不可达没配路由所以无法到达224网段。可以设置路由解决问题，例如ip route add 224.0.0.0/8 dev ens33但这在用户层面操作太蠢了，而且会干扰原有的路由表。应该在代码处指定发送方网卡用该网卡ip发送组播包。所以修改了下客户端的代码，其中客户端传参需要发送组播ip的网卡。\n其中获取网卡ip的函数gain_ip是参考这篇文章2改的。我这里的功能修改为读出输入网卡的任意一个有效的ipv4地址。\n//DialUDP的srcAddr设置0.0.0.0:0 或nil会自己找匹配路由 端口号为0表示系统分配端口 func main() { //选择使用那张网卡发送组播包(取出其ip作源地址), 不输入参数网卡设定为空 eg. eth0 var ethAddr net.IP = nil if len(os.Args) \u0026gt; 1 { ethAddr = gain_ip(os.Args[1]) } if ethAddr == nil { fmt.Printf(\u0026quot;Failed to retrieve valid ipv4 address as source address,\\nsearch for matching route to send\\n\u0026quot;) ethAddr = net.IPv4zero } srcAddr := \u0026amp;net.UDPAddr{IP: ethAddr, Port: 0} dstAddr, _ := net.ResolveUDPAddr(\u0026quot;udp\u0026quot;, \u0026quot;224.0.0.250:9981\u0026quot;) conn, err := net.DialUDP(\u0026quot;udp\u0026quot;, srcAddr, dstAddr) if err != nil { fmt.Println(err) return } defer conn.Close() conn.Write([]byte(\u0026quot;hello\u0026quot;)) fmt.Printf(\u0026quot;\u0026lt;%s\u0026gt;\\n\u0026quot;, conn.RemoteAddr()) } // 取得网卡的任意一个有效ipv4地址 func gain_ip(ethname string) net.IP { eth, _ := net.InterfaceByName(ethname) Addrs, err := eth.Addrs() if err != nil { // fmt.Println(err) //网卡无效 return nil } for _, Addr := range Addrs { if ipnet, ok := Addr.(*net.IPNet); ok \u0026amp;\u0026amp; !ipnet.IP.IsLoopback() { //接口转为结构体 if ipnet.IP.To4() != nil { return ipnet.IP.To4() } } } return nil //找不到有效网卡地址 } 运行服务器端发现也有报错：setsockopt:no such device ，查看了ListenMulticastUDP函数的源码，发现上面的例程ListenMulticastUDP没有传入第二个接口参数，会使得程序找寻默认到该组播域的路由所以配路由也能解决该问题。我这里还是传参一个网卡名称解决。\nfunc main() { var ethname string = \u0026quot;\u0026quot; if len(os.Args) \u0026gt; 1 { ethname = os.Args[1] } /* listener, err := net.ListenMulticastUDP(\u0026quot;udp\u0026quot;, nil, Multicast_addr) ListenMulticastUDP监听本地系统的所有可用IP地址，包括组播组IP地址。 如果ifi(第二个参数)为零，ListenMulticastUDP使用系统分配的多播接口，但不建议这样做， 因为分配取决于平台，有时可能需要路由配置。如果gaddr的端口字段为0，则会自动选择一个端口号。 */ eth, _ := net.InterfaceByName(ethname) //选择使用那张网卡加入组播域 Multicast_addr, _ := net.ResolveUDPAddr(\u0026quot;udp\u0026quot;, \u0026quot;224.0.0.250:9981\u0026quot;) listener, err := net.ListenMulticastUDP(\u0026quot;udp\u0026quot;, eth, Multicast_addr) if err != nil { fmt.Println(err) return } defer listener.Close() fmt.Printf(\u0026quot;Listener Multicast addr: \u0026lt;%s\u0026gt; \\n\u0026quot;, Multicast_addr.String()) data := make([]byte, 1024) for { n, remoteAddr, err := listener.ReadFromUDP(data) if err != nil { fmt.Printf(\u0026quot;error during read: %s\u0026quot;, err) } fmt.Printf(\u0026quot;\u0026lt;src ip: %s\u0026gt; %s\\n\u0026quot;, remoteAddr, data[:n]) } } 示例代码 准确的相对时间触发对分布式系统尤为重要，虽然只是简单的调用定时器，但是这位大佬的博客3对go中定时器的有比较好的分析，打日志的参考文章4也标注出来。\n最后整合了下客户端和服务器接收，每个移动设备运行该程序（定时发动组播包，后台协程监听来自组播域其他节点包消息）就能探测各网内存活/在线设备。关于接收数据的处理我这里故意只打日志不做其他处理，关于接收的数据如何处理，处理数据具体干啥就看你自己的用途了。就像我参考的这些文章一样，希望能对读者有所帮助。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net\u0026quot; \u0026quot;os\u0026quot; \u0026quot;time\u0026quot; ) type myconn struct { send *net.UDPConn recv chan int } var ( Info *log.Logger Warning *log.Logger Error *log.Logger ) func init() { logfile, err := os.OpenFile(\u0026quot;Nodes_multicast.log\u0026quot;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil { log.Fatalln(\u0026quot;打开日志文件失败：\u0026quot;, err) } Info = log.New(logfile, \u0026quot;Info: \u0026quot;, log.Lmicroseconds|log.Lshortfile) Warning = log.New(io.MultiWriter(os.Stdout, logfile), \u0026quot;Warning: \u0026quot;, log.Lmicroseconds|log.Lshortfile) Error = log.New(io.MultiWriter(os.Stderr, logfile), \u0026quot;Error: \u0026quot;, log.Lmicroseconds|log.Lshortfile) } func main() { // 使用参数1的网卡发送和监听组播包(取出其ip作源地址), 不输入参数使用默认路由 // 参数2代表运行客户端nem节点号，默认为1 var ethname, nemid string = \u0026quot;\u0026quot;, \u0026quot;1\u0026quot; if len(os.Args) \u0026gt; 2 { ethname = os.Args[1] nemid = os.Args[2] } else { Warning.Println(\u0026quot;No parameter is entered,now using default route and nemid:\u0026quot;, nemid) } conn, err := multicast_init(ethname) if err != nil { Error.Println(\u0026quot;multicast init error:\u0026quot;, err) return } defer conn.send.Close() Info.Println(\u0026quot;Nodes start multicast :\u0026quot;) send_interval := time.Tick(time.Second * 3) check_interval := time.Tick(time.Second * 15) for { select { case \u0026lt;-send_interval: Info.Println(\u0026quot;\\\u0026quot;send msg\\\u0026quot;\u0026quot;) // s := []byte(fmt.Sprintf(\u0026quot;Hello,I'm %s\u0026quot;, nemid)) s := []byte(\u0026quot;Hello,I'm \u0026quot; + nemid) conn.send.Write(s) case \u0026lt;-check_interval: Info.Println(\u0026quot;\\\u0026quot;check schedul\\\u0026quot;\u0026quot;) case num := \u0026lt;-conn.recv: Info.Println(\u0026quot;\\\u0026quot;recv msg\\\u0026quot; \u0026quot;, num) } } } // 取得网卡的任意一个有效ipv4地址 func gain_ip(ethname string) net.IP { eth, _ := net.InterfaceByName(ethname) Addrs, err := eth.Addrs() if err != nil { // Warning.Println(err) //网卡无效 return nil } for _, Addr := range Addrs { if ipnet, ok := Addr.(*net.IPNet); ok \u0026amp;\u0026amp; !ipnet.IP.IsLoopback() { //接口强转为结构体 if ipnet.IP.To4() != nil { return ipnet.IP.To4() } } } return nil } // udp组播的发送初始化，并开始监听组播域 func multicast_init(ethname string) (myconn, error) { ethAddr := gain_ip(ethname) if ethAddr == nil { Warning.Printf(\u0026quot;Failed to retrieve valid ipv4 address as source address,\\nsearch for matching route to send\\n\u0026quot;) ethAddr = net.IPv4zero } srcAddr := \u0026amp;net.UDPAddr{IP: ethAddr, Port: 0} Multicast_addr, _ := net.ResolveUDPAddr(\u0026quot;udp\u0026quot;, \u0026quot;224.0.0.250:9981\u0026quot;) Info.Println(\u0026quot;send addr is\u0026quot;, srcAddr, \u0026quot;ListenMulticast is\u0026quot;, Multicast_addr) send, err := net.DialUDP(\u0026quot;udp\u0026quot;, srcAddr, Multicast_addr) if err != nil { return myconn{}, err } eth, _ := net.InterfaceByName(ethname) listener, err := net.ListenMulticastUDP(\u0026quot;udp\u0026quot;, eth, Multicast_addr) if err != nil { send.Close() return myconn{}, err } data := make([]byte, 1024) datach := make(chan int, 0) go func() { // go的匿名函数默认捕获上下文变量 defer listener.Close() for { n, remoteAddr, err := listener.ReadFromUDP(data) if err != nil { Warning.Printf(\u0026quot;error during read: %s\u0026quot;, err) continue } s := string(data[:n]) if remoteAddr.IP.Equal(ethAddr) { continue // 排除自身发出的组播包 } // Info.Printf(\u0026quot;receive %s %d bytes: %s\\n\u0026quot;, remoteAddr, n, s) _, err = fmt.Sscanf(s, \u0026quot;Hello,I'm %d\u0026quot;, \u0026amp;n) if err != nil { Warning.Printf(\u0026quot;error during Sscanf: %s\u0026quot;, err) continue } datach \u0026lt;- n } }() return myconn{send: send, recv: datach}, nil } 后续内容 其实我使用这个工具只是做的TDMA动态时隙的统计，大致做法是将各个节点的接收数据做记录存入map中。没到检测时间的管道计时到达后开始处理map数据生成时隙表。注意go中的map并不是并发安全的，需要加sync.Mutex互斥锁或sync.RWMutex读写锁来避免竞争冒险。不过好在我是分开在select中处理不会出现上述问题，go中也有人做了并发安全的set5。\n关于go的文件读写还是要提下，*bufio.Writer *os.File这两个接口都实现可writestring函数，下面的写文件代码为了提升效率新建了bufio,bufio 在一定场景下还是很能提升效率的，不过还是需要注意与直接写入文件的异同，防止缓存数据未同步的状况发生。如下，写完文件后需要调用Flush刷新。\nfunc write_schedule(filepath string, newdata []string) error { file, err := os.Create(filepath) if err != nil { return err } defer file.Close() writer := bufio.NewWriter(file) for _, str := range newdata { _, err = writer.WriteString(str + \u0026quot;\\n\u0026quot;) } //注意，bufio 通过flush操作将缓冲写入真实的文件的，在关闭文件之前先flush，否则会造成数据丢失的情况。 writer.Flush() return err } 之后有可能会分享下后续具体动态时隙内容。\n组播探测程序：\n组播部分： 每个节点都会通过指定网卡向组播域中发送hello包，定时间隔为 'send_interval_time' 通过加入该组播域监听该组播域内消息，做到类似探测网内存活节点数量目的 定时检测时隙(组播域中成员是否有变化),检测时间为 'check_interval_time' 即一次检测时隙周期内接收到对应nemid组播包即认为该节点存活 收发包格式为 \u0026quot;Hello,I'm $nemid\u0026quot; 发送控制网时隙消息： 确定主控制网网桥IP，例如172.16.0.254 接收的组播记录存储至 并发安全set中，我这里的实现采用map(并发不安全) 这是因为我使用select管道传输数据再进行修改map就不会出现竞争冒险，造成并发的读写 各个节点信息综合格式为 I'm 1,recv 2 3 4 5 时隙统计程序：\n首先打开当前场景的时隙分配xml文件，获取基本参数信息 然后定时检测各个节点发送的节点监测消息，根据优先级固定的顺序分配时隙 一定是先排列完全部节点后再继续按照节点优先级顺序排列时隙， 所以优先级高的节点其分配到时隙的可能性越大 当前优先级 简单的处理为 nemid，id越小 优先级越高,具体参考myschedule_create的实现 检测时间间隔与多播程序的时间间隔相同 'check_interval' 注意：这里仅仅是为了处理方便将所有节点时隙数据整合在一起 其实实际各个节点的时隙是单独分派的，例如若两节点n1 n15分别在两个网内（组播域中未互相探测到） 所以他们的时隙很可能是会有重合冲突的部分，但由于组播无法互相探测到可认为是无影响的。 // 根据时隙表规则，设定以节点id为优先级 固定顺序的排列时隙表，举例 时隙为10 // 1收到 2 3：\t顺序：1 2 3 1 2 3 1 2 3 1\t1的时隙：0,3,6,9 // 7收到 8 9 4：\t顺序：4 7 8 9 4 7 8 9 4 7\t7的时隙：1,5,9 // 要推算节点 datas.id 的时隙分布，只要知道时隙个数，优先级排名(id越小，优先级越高)即可推算 鸟窝. 深入Go UDP编程 (colobu.com) 通用多播编程\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n不二星空. GO实现获取本地IP地址(csdn.net) 获取网卡ip\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nDraveness. Go 语言设计与实现(draveness.me) 并发编程与计时器\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n飞雪无情. Go语言实战笔记(flysnow.org) 定制go日志\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n波罗学. Go 中如何使用 set - 掘金 (juejin.cn)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","id":15,"section":"posts","summary":"介绍 最近在做一个关于无线移动自组织网络相关的内容，移动自组织网络是由彼此已经发现和互相接近的且有通信需求的移动设备构成的。由于网内节点的移动","tags":["go","network","开发"],"title":"网内存活节点测试工具","uri":"https://liangkang233.github.io/2021/09/%E7%BD%91%E5%86%85%E5%AD%98%E6%B4%BB%E8%8A%82%E7%82%B9%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/","year":"2021"},{"content":" 其实网上有很多关于扩容的文章，但是没有解决我的问题所以当扩容后成功后还是决定做个记录方便解决类似问题。不论是虚拟机还是物理机的扩容都可以试试下面的方法。\n问题分析 Ubuntu的图形界面非常直观，上手难度也不大，所以使用VM虚拟机装了个Ubuntu系统，搭建专门跑实验室的一些linux软件环境，用到后面 / 挂载的磁盘仅剩500M不到，根本不够用就很难受。但是重配环境又很麻烦所以还是决定扩容分区。\n扩容首先得有空间，虚拟机就直接如下图般添加空间即可（需要删除所有快照），如果有未分配的空间直接拿来用不用此步。\n物理机的话就准备新的硬盘挂载分区。实在不行也可以从其他分区挤出些空间。\n注意除非是windows的动态磁盘，否则分区物理分配逻辑是从左到右的顺序，不可以跨分区分配给其他空间。\nUbuntu有图形分区工具 gparted ,我这里添加了20g的空间（固态空间剩的不多了，所以也没扩多少）\n所以搞过windows分区的话看起来很快就能搞定，图形界面点两下就完事了。\n上锁的分区需要卸载后操作完毕再挂载。\n# 查看挂载分区空间命令 df -Th # 安装 分区工具 sudo apt-get install gparted 文件系统 类型 容量 已用 可用 已用% 挂载点 udev devtmpfs 1.9G 0 1.9G 0% /dev tmpfs tmpfs 391M 2.2M 389M 1% /run /dev/sda6 ext4 9.4G 8.4G 475M 95% / tmpfs tmpfs 2.0G 111M 1.9G 6% /dev/shm tmpfs tmpfs 5.0M 4.0K 5.0M 1% /run/lock tmpfs tmpfs 2.0G 0 2.0G 0% /sys/fs/cgroup /dev/loop1 squashfs 2.5M 2.5M 0 100% /snap/gnome-system-monitor/163 /dev/loop2 squashfs 219M 219M 0 100% /snap/gnome-3-34-1804/66 /dev/loop3 squashfs 219M 219M 0 100% /snap/gnome-3-34-1804/72 /dev/loop4 squashfs 640K 640K 0 100% /snap/gnome-logs/103 /dev/loop5 squashfs 2.5M 2.5M 0 100% /snap/gnome-calculator/884 /dev/loop6 squashfs 242M 242M 0 100% /snap/gnome-3-38-2004/70 /dev/loop7 squashfs 2.5M 2.5M 0 100% /snap/gnome-system-monitor/160 /dev/loop0 squashfs 640K 640K 0 100% /snap/gnome-logs/106 /dev/loop10 squashfs 66M 66M 0 100% /snap/gtk-common-themes/1515 /dev/loop9 squashfs 56M 56M 0 100% /snap/core18/2128 /dev/loop11 squashfs 768K 768K 0 100% /snap/gnome-characters/726 /dev/loop12 squashfs 768K 768K 0 100% /snap/gnome-characters/723 /dev/loop13 squashfs 62M 62M 0 100% /snap/core20/1081 /dev/loop14 squashfs 56M 56M 0 100% /snap/core18/2074 /dev/loop15 squashfs 33M 33M 0 100% /snap/snapd/12883 /dev/sda1 ext4 268M 118M 132M 48% /boot /dev/loop16 squashfs 33M 33M 0 100% /snap/snapd/12704 /dev/sda3 ext4 15G 5.2G 8.2G 39% /home /dev/loop17 squashfs 62M 62M 0 100% /snap/core20/1026 /dev/loop18 squashfs 65M 65M 0 100% /snap/gtk-common-themes/1514 /dev/sda4 ext4 3.9G 63M 3.6G 2% /tmp /dev/loop19 squashfs 2.5M 2.5M 0 100% /snap/gnome-calculator/748 tmpfs tmpfs 391M 40K 391M 1% /run/user/1000 /dev/loop20 squashfs 243M 243M 0 100% /snap/gnome-3-38-2004/76 一开始我是想直接把home分区（看上面的记录 home分区基本没用多少）复制挂载到扩容硬盘新建立分区。然后把home分区删除分给 /。 但是也不知道当时为啥这么憨😓 装系统时 home 交换空间 tmp boot都拿来做主分区，拿一个10g的逻辑分区挂载 / 。而且系统分区表选的是mbr导致一个磁盘置多四个主分区。所以这个计划根本不可行，不能在当前系统下操作加新主分区。（我在当前系统下肯定是不太好操作当前系统的磁盘的）\n回想起windows有pe工具，说不定Ubuntu也有类似的工具。网上一查ubuntu启动盘自身就是一个linux系统，可以直接使用这些linux软件包，说干就干准备启动盘。\n解决步骤 如果是虚拟机：\n找到安装该系统对应的iso镜像，并在虚拟机硬件设置中选项cd/dvd中选中该镜像并勾选启动时连接时。然后如下图直接进bios设置启动项即可。\n如果是物理机，就跟装系统一样做一个你当前主板bios能识别的启动盘即可，镜像要与当前系统一样，这里就不赘述启动盘的制作了。之后进入bios设置启动盘。\n成功进入启动盘后，选择试用Ubuntu就进入到启动盘中的linux系统了，由于与主硬盘分离所以可以操作挂载的路径分区等。\n同样的进入 gparted中，没有就联网安装一个。\n接下来就可以随心改变分区了不过有几个注意点，重要数据一定要先备份，数据无价。（虚拟机的话直接加个快照，有问题就还原回来）\n有些仍挂载的分区上锁状态要先禁用或卸载，之后再启用或是挂载 例如我的swap交换空间。\n逻辑分区的大小扩容要先扩容其主分区大小，再操作逻辑分区 例如我这挂载 / 的sda6扇区就是逻辑分区。\n移动分区时，如果改变了扇区头要注意该扇区内是否挂载了 boot uefi等启动分区可能回造成启动项无法识别。\n​\t您可以在GParted FAQ中学习如何修复启动配置。http://gparted.org/faq.php。我使用的mbr分区表没有uefi启动分区，bios是单独的扇区挂载上去的所以可以放心操作。\n最后扩容就完成了，图形界面的操作没啥说的。只能感叹linux的强大，windows to go要是也能如此功能强大、配置方便就好了。\n","id":16,"section":"posts","summary":"其实网上有很多关于扩容的文章，但是没有解决我的问题所以当扩容后成功后还是决定做个记录方便解决类似问题。不论是虚拟机还是物理机的扩容都可以试试","tags":["linux"],"title":"Ubuntu分区扩容","uri":"https://liangkang233.github.io/2021/09/ubuntu%E5%88%86%E5%8C%BA%E6%89%A9%E5%AE%B9/","year":"2021"},{"content":"对go的基础学习中，也了解了些相关热点问题。\n发现篇非常好的文章详细介绍了go中的并发设计原理、内存模型。写些读后感。\n并发编程 上下文 上下文简单的理解为代码运行的环境，上下文 context.Context 在 Go 语言中用来设置截止日期、同步信号，传递请求相关值的结构体。context.Context是 Go 语言在 1.7 版本中引入标准库的接口，该接口定义了四个需要实现的方法，其中包括：\n方法 概述 Deadline 返回 context.Context 被取消的时间，也就是完成工作的截止日期； Done 返回一个 Channel，这个 Channel 会在当前工作完成或者上下文被取消后关闭，多次调用 Done 方法会返回同一个 Channel； Err 返回 context.Context 结束的原因，它只会在 Done 方法对应的 Channel 关闭时返回非空的值；如果 context.Context 被取消，会返回 Canceled 错误；如果 context.Context 超时，会返回 DeadlineExceeded 错误； Value 如果 context.Context 超时，会返回 DeadlineExceeded 错误；从 context.Context 中获取键对应的值，对于同一个上下文来说，多次调用 Value 并传入相同的 Key 会返回相同的结果，该方法可以用来传递请求特定的数据； Go 语言中的 context.Context 的主要作用还是在多个 Goroutine 组成的树中同步取消信号以减少对资源的消耗和占用，例如使用context.WithCancel 函数能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数。一旦我们执行返回的取消函数，当前上下文以及它的子上下文都会被取消，所有的 Goroutine 都会同步收到这一取消信号，父上下文取消时子上下文也会被取消。虽然它也有传值的功能，但是这个功能我们还是很少用到。\n在真正使用传值的功能时我们也应该非常谨慎，使用 context.Context 传递请求的所有参数一种非常差的设计，比较常见的使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。\nchannel channel常用来做协程间的信息同步，是个建立时设定缓冲区（默认是0）用于共享消息先入先出的队列。\ntype hchan struct { qcount uint\t// Channel 中的元素个数； dataqsiz uint\t// Channel 中的循环队列的长度； buf unsafe.Pointer // Channel 的缓冲区数据指针； elemsize uint16 closed uint32 elemtype *_type sendx uint\t// Channel 的发送操作处理到的位置 recvx uint\t// Channel 的发送操作处理到的位置 recvq waitq sendq waitq lock mutex } 具体细节网上资料很详细，这里记录几个易错点：\n当一个channel被关闭后，再向该channel发送数据将导致panic异常。当一个被关闭的channel中已经发送的数据都被成功接收后，后续的接收操作将不再阻塞，它们会立即返回一个零值。关闭上面例子中的naturals变量对应的channel并不能终止循环，它依然会收到一个永无休止的零值序列，然后将它们发送给打印者goroutine。\n没有办法直接测试一个channel是否被关闭，但是接收操作有一个变体形式：它多接收一个结果，多接收的第二个结果是一个布尔值ok，ture表示成功从channels接收到值，false表示channels已经被关闭并且里面没有值可接收。使用这个特性，我们可以修改squarer函数中的循环代码，当naturals对应的channel被关闭并没有值可接收时跳出循环，并且也关闭squares对应的channel.\ngo func() { for { x, ok := \u0026lt;-naturals if !ok { break // channel was closed and drained } squares \u0026lt;- x * x } close(squares) }() 因为上面的语法是笨拙的，而且这种处理模式很常见，因此Go语言的range循环可直接在channels上面迭代。使用range循环是上面处理模式的简洁语法，它依次从channel接收数据，当channel被关闭并且没有值可接收时跳出循环。（channel不关闭 将一直堵塞在range处）\ngo func() { for x := range naturals { squares \u0026lt;- x * x } close(squares) }() chan要用make生成，对空值的ch调用会造成堵塞\n例如var tick \u0026lt;-chan time.Time tick就是一个空值的channel（nil）对其写入或读取操作都会造成堵塞\n函数形参的单向channel 就是普通 channel 由编辑器检查传输方向来确保单向而实现的，传参会进行隐式转换 双向变为单向 单向不可变为双向\nnaturals := make(chan int) 无缓存 缓存为0\nnaturals := make(chan int, 3) 缓存为3 cap(naturals)=3 len(naturals)=0\n举例： out in 为形参名\n参数：只发送 ch func count (out chan \u0026lt;- int) {} 参数：只接收 ch func counter (in \u0026lt;- chan int) {} 参数：普通双向 func counter (chan int) {} 共享变量 Go 语言也有类似unix中实现的那些共享变量的内容。在 sync 包中提供了用于同步的一些基本原语，包括常见的 sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Once 和 sync.Cond。\n只要在go build，go run或者go test命令后面加上-race的flag，就会使编译器创建一个你的应用的“修改”版或者一个附带了能够记录所有运行期对共享变量访问工具的test，并且会记录下每一个读或者写共享变量的goroutine的身份信息。另外，修改版的程序会记录下所有的同步事件，比如go语句，channel操作，以及对(*sync.Mutex).Lock，(*sync.WaitGroup).Wait等等的调用。\n这些互斥锁与c中的一样，且都不支持重入锁，再次上锁会死锁。这些锁主要是应对竞争条件下对变量的读写，介绍几个常见的锁用法：\nsync.Mutex互斥锁\nvar mu sync.Mutex mu.Lock() mu.Unlock() // 锁记得要释放 sync.RWMutex读写锁\n// 其允许多个只读操作并行执行，但写操作会完全互斥。 var mu sync.RWMutex mu.RLock() // readers lock mu.RUnlock() // 调用了RLock和RUnlock方法来获取和释放一个读取或者共享锁。(上锁时，RLock不堵塞) mu.Lock() mu.Unlock() // 调用mu.Lock和mu.Unlock方法来获取和释放一个写或互斥锁。（上锁时其他任何锁堵塞） sync.Once单次锁\n// 一般用于初始化，只上锁一次 var loadIconsOnce sync.Once var icons map[string]image.Image // Concurrency-safe. func Icon(name string) image.Image { loadIconsOnce.Do(loadIcons)\t//loadIcons为调用的其他函数 return icons[name] } sync.WaitGroup 等待开锁组\n// 递增的计数器，这个计数器需要在多个goroutine操作时做到安全并且提供在其完成之前一直等待。 var wg sync.WaitGroup // number of working goroutines wg.Add(1) wg.Done() wg.Wait() //堵塞等待上锁组内全部done gorutine与线程 在学习协程 时关于线程 与 cpu处理之间有认知不太清晰的地方，看看这位大佬的介绍就能有个理性的认知\n协程英文名Coroutine。但在 Go 语言中，协程的英文名是：gorutine。它常常被用于进行多任务，即并发作业。\n协程的特点：\n多个协程可由一个或多个线程管理，协程的调度发生在其所在的线程中。 可以被调度，调度策略由应用层代码定义，即可被高度自定义实现。 执行效率高。 占用内存少。 线程 协程 数据存储 内核态的内存空间 一般是线程提供的用户态内存空间 切换操作 操作最终在内核层完成，应用层需要调用内核层提供的 syscall 底层函数 应用层使用代码进行简单的现场保存和恢复即可 任务调度 由内核实现，抢占方式，依赖各种锁 由用户态的实现的具体调度器进行。例如 go 协程的调度器 语音支持程度 绝大部分编程语言 部分语言：Lua，Go，Python \u0026hellip; 实现规范 按照现代操作系统规范实现 无统一规范。在应用层由开发者实现，高度自定义，比如只支持单线程的线程。不同的调度策略，等等 OS线程会被操作系统内核调度。每几毫秒，一个硬件计时器会中断处理器，这会调用一个叫作scheduler的内核函数。这个函数会挂起当前执行的线程并将它的寄存器内容保存到内存中，检查线程列表并决定下一次哪个线程可以被运行，并从内存中恢复该线程的寄存器信息，然后恢复执行该线程的现场并开始执行线程。因为操作系统线程是被内核所调度，所以从一个线程向另一个“移动”需要完整的上下文切换，也就是说，保存一个用户线程的状态到内存，恢复另一个线程的到寄存器，然后更新调度器的数据结构。这几步操作很慢，因为其局部性很差需要几次内存访问，并且会增加运行的cpu周期。\nGo的运行时包含了其自己的调度器，这个调度器使用了一些技术手段，比如m:n调度，因为其会在n个操作系统线程上多工（调度）m个goroutine。Go调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的Go程序中的goroutine（译注：按程序独立）。\n和操作系统的线程调度不同的是，Go调度器并不是用一个硬件定时器，而是被Go语言“建筑”本身进行调度的。例如当一个goroutine调用了time.Sleep，或者被channel调用或者mutex操作阻塞时，调度器会使其进入休眠并开始执行另一个goroutine，直到时机到了再去唤醒第一个goroutine。因为这种调度方式不需要进入内核的上下文，所以重新调度一个goroutine比调度一个线程代价要低得多。\ngo拥有其协程调度器，调度器的三个基本对象：\nG (Goroutine)，代表协程，也就是每次代码中使用 go 关键词时候会创建的一个对象\nM (Work Thread)，工作线程\nP (Processor)，代表一个处理器，又称上下文\n每一个运行的 M 都必须绑定一个 P，线程M 创建后会去检查并执行G (goroutine)对象。每一个 P 保存着一个协程G 的队列。除了每个 P 自身保存的 G 的队列外，调度器还拥有一个全局的 G 队列。M 从队列中提取 G，并执行P 的个数就是GOMAXPROCS（最大256），启动时固定的，一般不修改。（ go 1.5 版本之前的 GOMAXPROCS 默认是 1，go 1.5 版本之后的 GOMAXPROCS 默认是 Num of cpu）M 的个数和 P 的个数不一定一样多（会有休眠的M 或 P不绑定M ）（最大10000）。P 是用一个全局数组（255）来保存的，并且维护着一个全局的 P 空闲链表\nGOMAXPROCS 就是 go 中 runtime 包的一个函数。它设置了 P 的最多的个数。这也就直接导致了 M 最多的个数是多少，而 M 的个数就决定了各个 G 队列能同时被多少个 M 线程来进行调取执行！如下演示\nfor{ gofmt.Print(0) fmt.Print(1) } // $ GOMAXPROCS=1gorun hacker-cliché.go111111111111111111110000000000000000000011111... // $ GOMAXPROCS=2gorun hacker-cliché.go010101010101010101011001100101011010010100110... 在第一次执行时，最多同时只能有一个goroutine被执行。初始情况下只有main goroutine被执行，所以会打印很多1。过了一段时间后，GO调度器会将其置为休眠，并唤醒另一个goroutine，这时候就开始打印很多0了，在打印的时候，goroutine是被调度到操作系统线程上的。在第二次执行时，我们使用了两个操作系统线程，所以两个goroutine可以一起被执行，以同样的频率交替打印0和1。我们必须强调的是goroutine的调度是受很多因子影响的，而runtime也是在不断地发展演进的，所以这里的你实际得到的结果可能会因为版本的不同而与我们运行的结果有所不同。\n","id":17,"section":"posts","summary":"对go的基础学习中，也了解了些相关热点问题。 发现篇非常好的文章详细介绍了go中的并发设计原理、内存模型。写些读后感。 并发编程 上下文 上下文简单","tags":["go"],"title":"Go并发解析","uri":"https://liangkang233.github.io/2021/09/go%E5%B9%B6%E5%8F%91%E8%A7%A3%E6%9E%90/","year":"2021"},{"content":"常用小技巧 leetcode刷题遇到的一些问题，关于算法的结构文字描述的有限，记录些常用的单元的代码，备忘。\n防止溢出求平均数 一般求平均数时会 (a+b)/2 或 (a+b)\u0026gt;\u0026gt;1 来做，但是若数较大时 a + b 会出现溢出情况，可以使用以下几种方法来做：\nc = a + (b - a) / 2; a\u0026amp;b + ((a^b) \u0026gt;\u0026gt; 1 ) a\u0026amp;b : 获取两个数同为1的位\na^b: 获取两个数不同为1的位\n两个数的平均值为两个数的每一位平均值的和\n最小公倍数 最大公约数 利用最大公约数求最小公倍数\n定理: 已知a,b最大公约数为X，最小公倍数为Y，则有公式为a*b=最大公约数X * 最小公倍数Y\n证明：由已知得a=Xc b=Xd 且c与d互为素数（否则X就不是c与d的最大公因数）所以Y=Xcd, 即a*b = c * X * X * d = X * Y\n辗转相除法求最大公约数: 用较大数除以较小数，再用出现的余数（第一余数）去除除数，再用出现的余数（第二余数）去除第一余数，如此反复，直到最后余数是0为止。如果是求两个数的最大公约数，那么最后的除数就是这两个数的最大公约数\n定理：两个整数的最大公约数等于其中较小的那个数和两数相除余数的最大公约数。最大公约数（Greatest Common Divisor）缩写为GCD。gcd(a,b) = gcd(b,a mod b) (不妨设a\u0026gt;b 且r=a mod b ,r不为0)\n证明： a可以表示成a = kb + r（a，b，k，r皆为正整数，且r\u0026lt;b），则r = a mod b 假设d是a,b的一个公约数，记作d|a,d|b，即a和b都可以被d整除。 而r = a - kb，两边同时除以d，r/d=a/d-kb/d=m，由等式右边可知m为整数， 因此d也是b,a mod b的公约数。(a,b)和(b,a mod b)的公约数相等，则其最大公约数也相等，得证。\nint MinBei(int a, int b) {\tint tmp, count = a * b; // 求最大公约数 迭代写法 while (b) { tmp = b; b = a % b; a = tmp; } return count / a ; //两数相乘等于 最大公约数乘最小公倍数 } // 求最大公约数的递归写法 int gcd (int a, int b) { return b ? gcd(b, a % b) : a; } int main() {\tint a, b, c, temp; cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b \u0026gt;\u0026gt; c; temp = MiniBei(a, b); // cout \u0026lt;\u0026lt; temp \u0026lt;\u0026lt; endl; temp = MiniBei(c, temp); // cout \u0026lt;\u0026lt; temp \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; temp; return 0; } 质(因)数 哥德巴赫猜想：任一大于2的偶数，都可表示成两个素数之和。\n合数性质：\n所有大于2的偶数都是合数，也就是在正整数中除了2以外，其余数的个位数为0、2、4、6、8者均为合数。4为最小的合数。 每一合数都可以以唯一形式被写成质数的乘积。（算术基本定理） 所有合数都有至少3个正因数，例如4有正因数1、2、4，6有正因数1、2、3、6。 对任一大于5的合数n，(n-1)!==0（威尔逊定理） 对于任意的正整数n，都可以找到一个正整数x，使得x、x+1、x+2、…、x+n 都是合数。 快速计算是否为质数方法：\n根据性质2，任何一个合数都能能分解成质数相乘，那么可以表示为N＝a1*a2*...*ak，（ak均为质数） 上述质因数拆分中 k \u0026gt;= 2,所以最小质因数为a1，容易知道a1小于 sqrt(N) 即合数一定存在一个小于sqrt(N)的质因数 6x 6x-2 6x-3 6x-4肯定不是质数。 所以如果 n 是6 倍数两侧的数，那么n才有可能是质数。 即结论 质数(大于3时)一定是6x-1 或6x-5（x\u0026gt;=1） #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; // 最原始 bool isPrime(int n){ if (n \u0026lt;= 3) { return n \u0026gt; 1; } for(int i = 2; i \u0026lt; n; i++){ if (n % i == 0) { return false; } } return true; } // 初步优化 // 若不是质数 其一定存在因数p1\u0026lt;=sqrt(n)，p2\u0026gt;=sqrt(n) bool isPrime1(int n) { if (n \u0026lt;= 3) { return n \u0026gt; 1; } int s = (int)sqrt(n); for (int i = 2; i \u0026lt;= s; i++) { if(n % i == 0) { return false; } } return true; } // 质数还有一个特点，就是它总是等于 6x-1 或者 6x-5，其中 x 是大于等于1的自然数。 bool isPrime2(int num) { if (num \u0026lt;= 3) { return num \u0026gt; 1; } // 不在6的倍数两侧的一定不是质数 if (num % 6 != 1 \u0026amp;\u0026amp; num % 6 != 5) { return false; } int s = (int)sqrt(num); // 若这个数是合数，则必有质因数i,i \u0026lt;= sqrt(num) // 且i为质数一定为6倍数两侧，以6为步长寻找 // 寻找在 根号n 内是否存在 类似因数 6i+1 6i+5 for (int i = 6; i \u0026lt;= s; i += 6) { if (num % (i-1) == 0 || num % (i+1) == 0) { return false; } } return true; } 若是求范围内质数的个数 则可以用这个方法求解\n埃拉托色尼筛选法\n其原理也十分易懂:从1到n遍历，假设当前遍历到m,则把所有小于n的、且是m的倍数的整数标为和数;\n遍历完成后，没有被标为和数的数字即为质数。\n// 求 [1,n) 范围内质数个数 可以采用此方法 int countPrimes(int n) { if (n \u0026lt;= 2) return 0; vector\u0026lt;bool\u0026gt; prime(n, true) ; int count = n - 2; //去掉不是质数的1 和范围外的n for(int i = 2; i \u0026lt; n; ++i){ if (prime[i]) { for (int j = 2*i; j \u0026lt; n; j += i){ // 将i的整数倍删除 if (prime[j]) { prime[j] = false; --count; } } } } return count; } // 优化版本 int countPrimes1(int n) { if (n \u0026lt;= 2) return 0; vector\u0026lt;bool\u0026gt; prime(n, true); int i = 3, sqrtn = sqrt(n), count = n / 2; // i\u0026gt;=3的偶数一定不是质数 for (int i = 3; i \u0026lt;= sqrtn; i+=2) { if(prime[i]) { // 只对当前是未被标记的质数才进行 平方后累加2i的数设定为合数 减少重复遍历 // i为3开始的奇数 进入合数统计时 +i必定为偶数数没必要遍历 已经提前把偶数个数减少了 for (int j = i*i; j \u0026lt; n; j += 2*i){ // j不断 + 2i 为了避免偶数 的遍历 if (prime[j]) { --count ; prime[j] = false; } } } } return count; } 平方根函数 用牛顿法实现快速求平方根的近似函数。\n计算机通常使用循环来计算 x 的平方根。从某个猜测的值 z 开始，我们可以根据 z² 与 x 的近似度来调整 z，产生一个更好的猜测：\nz -= (z * z - x) / (2*z)\n上面的 z² − x 是 z² 到它所要到达的值（即 x）的距离， 除以的 2z 为 z² 的导数，我们通过 z² 的变化速度来改变 z 的调整量。X在上式中为固定值。\n当求A的平方根时 设f(x) = x^2\n上问题即为求 f(x) = A的解\n构造函数 F(X) = f(x) - A = x^2 - A\nA为所求的常数 用牛顿法求解不断迭代下去 直到 Xn+1 与 Xn 差值足够小\n即迭代求 Xn+1 = Xn - F(Xn) / F\u0026rsquo;(Xn)\n这种通用方法——牛顿法。 它对很多函数，特别是平方根而言非常有效。 int main() { double x1, x2; float a; scanf(\u0026quot;%f\u0026quot;, \u0026amp;a); x2 = 1.0; do { x1 = x2; x2 = (x1 + a / x1) / 2; // x2 -= (x2 + a / x2) / 2; 也可如此简写 } while (fabs(x1-x2)\u0026gt;pow(10,-5)); // } while (fabs(x1-x2) \u0026gt; 1e-5); printf(\u0026quot;value:%lf\u0026quot;, x2); system(\u0026quot;pause\u0026quot;); return 0; } 扩展，雷神之锤源码平方根调用方法，只看最后一部分即可。将 f(x)=y 转为 f(y)=x 来简化运算\n回文数 求回文时，若是字符串就法1比较，若是数字利用迭代乘、余来做\n// 法1 while (start \u0026lt; end) { if (nums[start++] != nums[end--]) return false; } return true; //法2 bool isPalindrome(int x) { if (x \u0026lt; 0 || (x % 10 == 0 \u0026amp;\u0026amp; x != 0)) return false; int revertedNumber = 0; while (x \u0026gt; revertedNumber) { revertedNumber = revertedNumber * 10 + x % 10; x /= 10; } // 当数字长度为奇数时，我们可以通过 revertedNumber/10 去除处于中位的数字。 // 例如，当输入为 12321 时，在 while 循环的末尾我们可以得到 x = 12，revertedNumber = 123， // 由于处于中位的数字不影响回文（它总是与自己相等），所以我们可以简单地将其去除。 return x == revertedNumber || x == revertedNumber / 10; } 位运算 注意：左移运算用零填充右边空缺的bit位，无符号数的右移运算也是用0填充左边空缺的bit位，但是有符号数的右移运算会用符号位的值填充左边空缺的bit位。\n因为这个原因，最好用无符号运算，这样你可以将整数完全当作一个bit位模式处理。\n! 逻辑非 ~ 位非 ^ 异或 | 或 \u0026amp; 与 功能 使用方法 参考链接 树状数组中的求 一个数二进制的1的最低位置 直接 return = x\u0026amp;(-x) lowbit 树状数组关键函数 求某个数据出现次数 使用 \u0026amp;操作，复杂的添加状态表 https://leetcode-cn.com/problems/single-number/ 将x的最低的一个非零的bit位清零 使用 x\u0026amp;(x-1) 查询一个64位数据的二进制1个数 建表查，省的每次都循环64次 右边main文件内含建表代码 移位查数据，除了直接 \u0026raquo; 也可如右边 x\u0026amp;(1\u0026laquo;i) 标准二分查找及其衍生 //二分法查找/折半查找 int binarySearch(Element array[], int len, int key){ int low = 0, high = len - 1, middle; while(low \u0026lt;= high){ middle = (low + high) / 2; if(array[middle] == key){ //找到,返回下标索引值 return middle; }else if(array[middle] \u0026gt; key){ //查找值在低半区 high = middle - 1; }else{ //查找值在高半区 low = middle + 1; } } return -1; //找不到 } std库 lower_bound 寻找第一个大于等于num的值的下标 自实现 (未添加 超出上下限的判断)：\nint mylower_bound(int* array ,int size,int key){ int first = 0, middle ,last = size-1; while(first\u0026lt;last){ middle = (first+last) \u0026gt;\u0026gt; 1; if(array[middle] \u0026lt;key ) //当middle小于要找的位置 ， first +1 也不会超过key的位置，最多相同 first = middle + 1; else last = middle ; //middle有可能等于要找的位置 ， last = middle ， 用first不断逼近 } return first; } leetcode: 35.搜索插入位置\n// 有重复数据也可排出结果 可以返回值范围为 0-size class Solution { public: int searchInsert(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int l = 0, r = nums.size()-1; while(l \u0026lt;= r) { int mid = (l + r) \u0026gt;\u0026gt; 1; if(nums[mid] \u0026lt; target) l = mid+1; else r = mid-1; } return l; } }; ","id":18,"section":"posts","summary":"常用小技巧 leetcode刷题遇到的一些问题，关于算法的结构文字描述的有限，记录些常用的单元的代码，备忘。 防止溢出求平均数 一般求平均数时会 (a+b)/2","tags":["C/C++","算法"],"title":"编程题中常见技巧","uri":"https://liangkang233.github.io/2021/08/%E5%B8%B8%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/","year":"2021"},{"content":"shell脚本在linux使用用的十分广泛，写篇总结学习性的文章做记录。\n这个运维手册写的比较详细，可以做参考。\n另一个比较全的参考\n基本语法 if else： # then 与 if 同一行时要加 ; if [ `whoami` != \u0026quot;root\u0026quot; ];then echo \u0026quot;Please run it as a superuser\u0026quot; exit 0 elif $something -gt 2 ; then echo \u0026quot;else if\u0026quot; else echo \u0026quot;else\u0026quot; fi switch： read -p $'Please input a number... \\n1 means icmp,2 means udp ,3 means tcp ' case $n in 1) echo \u0026quot;you will accept icmp data\u0026quot; tcpdump icmp -c 5 -i ens33 -l -w./aaa.cap \u0026amp; ;; 2) echo \u0026quot;you will accept udp data\u0026quot; tcpdump udp -c 5 -i ens33 ;; 3) echo \u0026quot;you will accept tcp data\u0026quot; tcpdump tcp -c 5 -i ens33 ;; *) echo \u0026quot;invail command\u0026quot; ;; esac for： datetime=`date +%F-%H:%M:%S` i=1 while [ $i -lt 5 ];do echo \u0026quot;start NO.$i capture data\u0026quot; # sudo tcpdump icmp -i ens33 -w ./$datetime.cap \u0026amp; # sudo tcpdump icmp -i ens33 -w ./`date +%F-%H:%M:%S` \u0026amp; tdid=`pgrep tcpdump` sleep 10s echo \u0026quot;$tdid\u0026quot; kill -9 $tdid ((i++)) done for i in ${!IdArry[@]} do echo ${IdArry[i]:1} # echo ${IdArry[i]:i:j} 表示打印第i位到第j位数据，j省略表示第i位到最后一位 done 关系运算符，如下： 注意： 使用 [] 就可以使用c中常用的关系符, # [ ]符号旁必须有空格，否则会被shell认为是命令执行\n-gt：大于，greater than。 -eq：等于，equal。 -lt：小于，less than。 -ge：大于等于，greater than or equal。 -le：小于等于，less than or equal。 -ne：不等于，not equal。 连接符，如下：\n-a：且，and。 -o：或，or。 条件判断，逻辑运算符，如下：\n\u0026amp;\u0026amp;：用来执行条件成立后执行的命令。 ||：用来执行条件不成立后的执行命令。 函数、传参、返回值 给定的参数以$1，$2，$3,...$n的形式访问，对应于函数名后参数的位置。$0变量的值是函数的名称。 $? 表示上次运行的结果，非0表示异常 $# 变量用于保存赋予函数的位置自变量/参数的数量。其中 $* 和 $@ 变量用于保存赋予函数的所有参数。 传参时，若$cmd中带空格需要加\u0026quot;\u0026quot; , 不加双引号会自动以空格为分割符号传参 数组传参数使用 ${Mymap[*]} 或 ${Mymap[@]}，区别为${Mymap[*]} 是传入一个参数， 例如“1 2 3”${Mymap[@]} 是传入多个参数，例如\u0026quot;1\u0026quot;,\u0026quot;2\u0026quot;,\u0026quot;3\u0026quot; # 声明函数的语法有两种格式定义： # 第一种方法：以函数名称开头，后跟括号。这是最优选且最常用的方法，语法如下： function_name () { commands } # 单行语法如下： function_name () { commands; } # 第二种方法：以函数保留字开头，后跟函数名称： function function_name { commands } # 单行语法如下： function_name () { commands; } 数组、关联数组（字典）变量 索引-1是最后一个元素的参考\ndeclare -a ARRAY_NA 声明数组 declare -A ARRAY_NAME 声明关联数组 local temp 声明局部变量\n注意脚本中哪怕函数内定义变量默认是全局的，在函数内定义的local变量会结束作用域后销毁。\n关联数组用法示例:\n# 访问元素类似数组 Mymap[${NameArry}] # 添加元素 Mymap[${NameArry}] = 12 # 删除元素 unset Mymap[$findkey] 删除操作 # 遍历元素 for i in ${IdArry[@]} do echo i done # ${!Mymap[@]}为数组或字典全部index ${Mymap[@]}为全部value # \u0026amp;() 与 ｀｀区别 在操作上，这两者都是达到相应的效果。在bash中，$( )与｀｀（反引号,博客格式有问题，这里打中文的代替）都是用来作命令替换的。命令替换与变量替换差不多，都是用来重组命令行的，先完成引号里的命令行，然后将其结果替换出来，再重组成新的命令行。\n$ echo today is $(date \u0026quot;+%Y-%m-%d\u0026quot;) today is 2021-08-01 在多层次的复合替换中，｀｀必须要额外的跳脱处理（反斜线），而$( )比较直观。 最后，$( )的弊端是，并不是所有的类unix系统都支持这种方式，但反引号是肯定支持的。\n# 将cmd1执行结果作为cmd2参数，再将cmd2结果作为cmd3的参数 cmd3 $(cmd2 $(cmd1)) # 如果是用反引号，直接引用是不行的，还需要作跳脱处理 cmd3 `cmd2 \\`cmd1\\`` trap 详细trap介绍\n在shell中，使用内置命令trap(中文就翻译为陷阱、圈套)也可以布置所谓的陷阱，这个陷阱当然不是捕老鼠的，而是捕捉信号。\n通常trap都在脚本中使用，主要有2种功能：\n(1).忽略信号。当运行中的脚本进程接收到某信号时(例如误按了CTRL+C)，可以将其忽略，免得脚本执行到一半就被终止 (2).捕捉到信号后做相应处理。主要是清理一些脚本创建的临时文件，然后退出\n进程结束临时文件销毁示例\n# XXX会被随即字符代替保证唯一，-d生成目录，-t表示生成在/temp中， # 脚本临时文件全部存在此处，程序捕获到EXIT后执行finish删除临时文件夹 scratch=$(mktemp -d -t coretmp.XXX) function finish { rm -rf \u0026quot;$scratch\u0026quot; } trap finish EXIT 调用core api示例 awk grep sed 是处理文本的三大利器，后面示例用到了用到了awk，直接将其返回一个变量会传输到数组中。\n#!/bin/bash scratch=$(mktemp -d -t coretmp.XXX) function finish { rm -rf \u0026quot;$scratch\u0026quot; } trap finish EXIT function ApiCall { local nodeId=$1; local cmd=$2; # tee一边重定向到文件一边打印，防止等待response卡死，也方便打印报错信息 coresendmsg execute flags=tty node=$nodeId number=1001 command=\u0026quot;$cmd\u0026quot; -l | tee $scratch/core_msg res=$(awk -F ': ' '{if($1 ~ /RESULT/) print $2}' $scratch/core_msg) if [ \u0026quot;$res\u0026quot; == \u0026quot;\u0026quot; ]; then exit 0 else echo -e \u0026quot;excute core api command: \\n$res\\n\u0026quot; fi eval $res } function SetMap { file=$1 Mymap=$2 local IdArry=(`awk '$1==\u0026quot;node\u0026quot; {print $2}' $file`) local NameArry=(`awk '$1==\u0026quot;hostname\u0026quot; {print $2}' $file`) for i in ${!IdArry[@]} do Mymap[${NameArry[i]}]=${IdArry[i]:1} done # echo ${!Mymap[@]} ${Mymap[@]} } # 默认命令、场景文件参数 nodeId='1' protocol='icmp' interface='eth0' imnPwd=$(echo $HOME/.core/configs/) scene='sample1' declare -A Mymap # 读取参数 if [ $# == 0 ]; then echo -e \u0026quot;The required parameters are imn scenario name and node name\\n\\ When \\$3 is CMD, \\$4 is the command to execute... Otherwise, \\$3 indicates the NIC ID and \\$4 indicates the packet capture protocol (optional).\\n\\ !! default: nodename=n1, interface=$interface, protocol=$protocol(options) !! sense file: echo $imnPwd$scene.imn\u0026quot; else scene=$1 file=$(echo $imnPwd$scene.imn) echo -e \u0026quot;sense file: $file\u0026quot; SetMap $file ${Mymap[*]} # echo \u0026quot;场景节点名: ${!Mymap[@]} \\n 场景节点id: ${Mymap[@]}\u0026quot; nodeId=${Mymap[$2]} interface=$3 protocol=$4 if [ ! -n \u0026quot;$nodeId\u0026quot; ]; then echo \u0026quot;node name error!\u0026quot; exit 0 fi fi if [ \u0026quot;$3\u0026quot; == \u0026quot;cmd\u0026quot; ] ; then ApiCall $nodeId \u0026quot;$4\u0026quot; elif [ $# -ge 3 ] || [ $# == 0 ]; then cmd=$(echo tcpdump $protocol -i $interface -l) ApiCall $nodeId \u0026quot;$cmd\u0026quot; else echo \u0026quot;Invalid input parameter\u0026quot; exit 0 fi ","id":19,"section":"posts","summary":"shell脚本在linux使用用的十分广泛，写篇总结学习性的文章做记录。 这个运维手册写的比较详细，可以做参考。 另一个比较全的参考 基本语法 if e","tags":["linux"],"title":"SHELL脚本语法示例","uri":"https://liangkang233.github.io/2021/08/shell%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B/","year":"2021"},{"content":"基础太薄弱，最近做一个关于主机路由转发的东西折腾了挺久。做个记录 😕\n默认网关、路由 区别 两者其实是一类功能，在不同应用的产生的不同叫法。\n内网主机向公网发送数据包时，由于目的主机跟源主机不在同一网段，所以数据包暂时发往内网默认网关处理，而本网段的主机对此数据包不做任何回应。\n由于源主机ip是私有的，禁止在公网使用，所以必须将数据包的源发送地址修改成公网上的可用ip，这就是网关收到数据包之后首先要做的工作\u0026ndash;ip转换。\n然后网关再把数据包发往目的主机。目的主机收到数据包之后，只认为这是网关发送的请求，并不知道内网主机的存在，也没必要知道，目的主机处理完请求，把回应信息发还给网关。网关收到后，将目的主机发还的数据包的目的ip地址修改为发出请求的内网主机的ip地址，并将其发给内网主机。\n这就是网关的第二个工作\u0026ndash;数据包的路由转发。内网的主机只要查看数据包的目的ip与发送请求的源主机ip地址相同，就会回应，这就完成了一次请求。 出于安全考虑，Linux系统默认是禁止数据包转发的。所谓转发即当主机拥有多于一块的网卡时，其中一块收到数据包，根据数据包的目的ip地址将包发往本机另一网卡，该网卡根据路由表继续发送数据包。这通常就是路由器所要实现的功能。\n场景介绍 以下图为例\n一共有三个场景：\n场景一：右上角为路由器做转发无需任何配置的局域网，\n场景二：其下为三台主机分别桥接的局域网，其中n10左右桥接的两个网卡对应两个网段，n10做路由转发\n场景三： 左边的场景为上方桥接局域网与下方桥接局域网通过中间两台机器的无线互相转发路由\n配置主机路由转发 Linux系统缺省并没有打开IP转发功能，要确认IP转发功能的状态，可以查看/proc文件系统， 使用下面命令： cat /proc/sys/net/ipv4/ip_forward 查看是否开启\n在测试中是n10 n1 n4 都开启了IP forward\n这里采用core仿真的配置来设定转发\n# auto-generated by IPForward service (utility.py) sysctl -w net.ipv4.conf.all.forwarding=1 sysctl -w net.ipv4.conf.default.forwarding=1 sysctl -w net.ipv6.conf.all.forwarding=1 sysctl -w net.ipv6.conf.default.forwarding=1 sysctl -w net.ipv4.conf.all.send_redirects=0 sysctl -w net.ipv4.conf.default.send_redirects=0 sysctl -w net.ipv4.conf.all.rp_filter=0 sysctl -w net.ipv4.conf.default.rp_filter=0 sysctl -w net.ipv4.conf.eth0.forwarding=1 sysctl -w net.ipv4.conf.eth0.send_redirects=0 sysctl -w net.ipv4.conf.eth0.rp_filter=0 sysctl -w net.ipv4.conf.eth1.forwarding=1 sysctl -w net.ipv4.conf.eth1.send_redirects=0 sysctl -w net.ipv4.conf.eth1.rp_filter=0 配置后主机就开启了上面路由器默认开启的路由转发服务（ip_forward）\n配置转发网关路由 经过多次测试，发现一直钻了死胡同，只配中转的路由而不是网关路由所以没有将路由转发出去。抓n10包只有一端有数据，还以为是网卡转发未开启成功。\n错误复盘： 场景二节点 n6 n7配默认路由都是指向自己的网卡，以为只要配n10的路由转发就能正确传输。 即在n10设定右边网卡收到的10.0.0.0/24网段全由左网卡出去，左网卡收到的10.0.2.0/24由右边网卡发出。 这样是无法通过测试的。 对于节点n6，只配默认路由到本地网卡10.0.2.20是无法让主机n10转发该数据的，应该配n6路由为下一跳网关。 n10无需配置路由只要开ip转发即可。 其实仔细想想，本地路由只是针对当前网段局域网内的转发，跨网段会找不到路直接丢弃包的 路由配置方法，统一使用 ip route，route命令当然也可配置，不推荐。\n在场景2中\n# (网关ip要为下一跳地址) # 配置到网段的静态路由 ip route add 10.0.2.20/24 via 10.0.0.20 # 配置特定到特定主机的网关/路由 ip route add ip 目标主机 via 网关 # 配置默认网关/路由 ip route add default via 10.0.2.21 在场景3中，类比场景2\n分别配置 n2 -\u0026gt; n4 n4 -\u0026gt; n1 n1 -\u0026gt; n4 n11 -\u0026gt;n1 这四条默认网关即可 ","id":20,"section":"posts","summary":"基础太薄弱，最近做一个关于主机路由转发的东西折腾了挺久。做个记录 😕 默认网关、路由 区别 两者其实是一类功能，在不同应用的产生的不同叫法。 内网主机","tags":["Linux","network"],"title":"linux配置主机路由转发","uri":"https://liangkang233.github.io/2021/07/linux%E4%B8%BB%E6%9C%BA%E8%B7%AF%E7%94%B1%E8%BD%AC%E5%8F%91/","year":"2021"},{"content":" 笔记实时更新中。。\nCore、Emane 介绍 官方文档\n一句话概括: CORE侧重于模拟如网络层传输层、会话层和应用层，提供了用户构建虚拟网络的图形用户界面；在一台或多台计符机上进行网络模拟的工具，实时运行的模拟。这些模拟的网络可以实时连接到物理网络和路由器，可以在使用相对廉价的硬件的前提下，保证在模拟网络上运行实时的应用程序的真实性。\nEMANE主要针对物理层和数据链路层工作，为模拟链路层和物理层的无线网络提供了必需的可插拔框架。关于网络层路由协议可以选用适用移动自组网的 OSPF MDR 协议。\nCore Core源码\n通用开放式研究仿真器（Common Open Research Emulator）是一种构建虚拟网络的工具。作为模拟器，CORE 构建了实时运行的真实计算机网络的表示，而不是使用抽象模型的模拟。实时运行的仿真可以连接到物理网络和路由器。它提供了运行真实应用程序和协议的环境，利用了 Linux 操作系统提供的工具。\nCORE 通常用于网络和协议研究、演示、应用程序和平台测试、评估网络场景、安全研究以及增加物理测试网络的规模。\n以下所有记录基于 core版本 7.5.1 Ubuntu20.4系统测试\n主题 描述 总结或翻译 Architecture 体系结构概述，介绍如何使用Python、gRPC直接控制Core 架构 Installation CORE的安装方法及要求 环境搭建 GUI 如何使用GUI 界面教程 Node Types CORE支持的节点类型概述 节点类型 (BETA) Python GUI 如何使用基于Python的BETA GUI Python API 介绍如何使用Python直接控制Core (自己实现core-daemon) Python API gRPC API 介绍如何使用gRPC控制Core (连接core-daemon 调用其api) gRPC API Distributed 在多个服务器上运行CORE的分布式细节 分布式 CTRLNET 如何控制网络从主机与节点通信 控制网络 Services 概述所提供的服务并创建自定义服务 服务配置 Performance 使用CORE时的性能说明 Core 性能分析 Developers Guide 概述如何对CORE开发 Core 开发相关 Core Emane CORE中运行和使用EMANE的高级主题和示例 Emane Emane开发手册 Emane的架构介绍 开发相关 Emane模型调研 绑定SDT-3D到core仿真中，源码 SDT 3D安装 Core 常见问题 基础内容学习 TLV编码格式详解\n了解 gRPC协议\n什么是GRE隧道\nOSPF MDR OSPF即开放最短路径优先(Open Shortest Path First)是为有线网络设计的标准路由协议。\n每个自治系统AS（Autonomous System）内部的路由选路协议，位于网络层。\nOSPF MDR即OSPF指定路由器移动自组网协议（OSPF MANET Designated Routers）也是美国海军研究实验室(NRL)开发，其源码在这可以找到。Quagga 中OSPFv3的OSPF MDR是依照移动自组织网络(MANETs: Mobile Ad Hoc Networks)中有效路由的 RFC 5614 (OSPF MDR), RFC 5243 (OSPF Database Exchange Optimization), 和 RFC 5838 (OSPFv3 Address Families)来实现的。\n该软件基于开源的Quagga路由套件，最初由Richard Ogier和波音幻影工程公司开发，现在由NRL的移动路由项目维护。\nLinux基础网络设备详解：Core的链路实现就是依赖这些虚拟网络设备，利用Linux命名空间特性创建各个独立的虚拟节点。\nCore 开发相关 源码概述 由于历史原因，CORE源代码由几种不同的编程语言组成。目前的开发重点是Python模块和守护进程。下面是源目录的简要描述。(netns = network nodes)\n目录 描述 daemon 处理接收API调用和创建容器的Python CORE daemon（守护进程）代码 docs 托管在GitHub上的使用文档 gui Tcl/Tk GUI man 为各种CORE命令行实用程序创建手册页的模板文件 netns 用于创建CORE容器的C程序 其切换开发版本分支\ngit clone https://github.com/coreemu/core.git cd core git checkout develop 安装开发环境 此命令将自动安装系统依赖项、克隆和构建 OSPF-MDR, 搭建CORE, 设置CORE poetry 环境, 然后安装 pre-commit hooks.您可以参考install docs来了解不同发行版的相关问题。\n./install -d 其中pre-commit帮助自动运行工具检查修改的代码。每次提交时，都会运行python实用程序来检查代码的有效性，可能会失败并退出提交。这些更改目前是作为当前CI的一部分强制执行的，因此添加更改并再次提交。\n运行core 您现在可以像平常一样运行core，或者利用一些调用任务来方便地运行测试等。\n# run core-daemon sudo core-daemon # run python gui core-pygui # run tcl gui core-gui # run mocked 单元测试 cd \u0026lt;CORE_REPO\u0026gt; inv test-mock 容器命令 Linux namespace containers通常使用Linux容器工具或lxc-tools包进行管理。lxc-tools网站可在这里http://lxc.sourceforge.net/获得更多信息。CORE不使用这些管理core实用工具(utilities)，core自己实现了一组用于实例化和配置网络名称空间容器的工具。这些工具大体分为：\nvnoded (Virtual nodes daemon )\nvnoded daemon是用于创建新名称空间的程序，并在控制通道上侦听可能实例化其他进程的命令。这个守护进程在容器中作为PID 1运行。它由CORE守护进程自动启动。控制通道是UNIX域套接字，通常命名为/tmp/pycore。对于运行在CORE会话23098上的节点3，例如:23098/n3。创建一个新的命名空间需要Root特权。\nvcmd (Virtual cmd )\nvcmd程序用于连接Linux网络命名空间中的vnoded，用于运行命名空间容器中的命令。CORE守护进程使用相同的通道设置节点并在其中运行进程。这个程序有两个必需的参数，控制通道名和要在命名空间中运行的命令行。该命令不需要以root权限运行。\n当你在运行模拟中双击一个节点时，CORE会使用如下命令打开该节点的shell窗口:\ngnome-terminal -e vcmd -c /tmp/pycore.50160/n1 -- bash 类似地，IPv4路由观察者小部件将运行一个命令来显示路由表，使用如下命令:\nvcmd -c /tmp/pycore.50160/n1 -- /sbin/ip -4 ro core-cleanup 脚本\n提供了一个名为 core-cleanup 的脚本来清理任何正在运行的CORE仿真。它将试图杀死任何剩余的vnoded进程，杀死任何EMANE进程，删除 :file:/tmp/pycore.* 会话目录。删除任何bridge或ebtables规则。使用*-d*选项，它也将杀死任何正在运行的CORE守护进程。\nnetns 命令\nCORE不直接使用netns命令。此实用程序可用于在新的网络名称空间中运行命令，以进行测试。它不会打开一个控制通道来接收进一步的命令。\n其他常用命令\n# 查看Linux网桥配置 ip link show type bridge # 查看某网桥被attach设备 brctl show bridge_name # 查看用于应用链接效果的netem规则 tc qdisc show # 查看使无线局域网工作的规则 ebtables -L Core 性能分析 关于CORE性能的首要问题通常是它能处理多少个节点?答案取决于几个因素:\n因素 性能影响 硬件 计算机中处理器的数量和速度、可用的处理器缓存、RAM内存和前端总线速度可能会极大地影响整体性能。 系统版本 Linux的发行和所使用的特定内核版本将影响整体性能。 活动进程 所有节点共享相同的CPU资源，因此如果一个或多个节点执行CPU密集型任务，整体性能将受到影响。 网络流量 在虚拟网络中发送的数据包越多，CPU使用率就越高。 GUI使用 定期运行的小部件、移动场景和其他GUI交互通常会消耗模拟所需的CPU周期。 在典型的单cpu 3.0GHz Xeon服务器上，2GB RAM运行Linux，我们发现运行30-75个节点运行OSPFv2和OSPFv3路由是合理的。在这个硬件上，CORE可以实例化100个或更多的节点，但是在这一点上，每个节点在做什么就变得至关重要了。\n因为这个软件主要是一个网络模拟器，所以更合适的问题是它能处理多少网络流量?在上面描述的3.0GHz服务器上，运行Linux，大约每秒可以通过系统推送30万个包。跳数和报文大小不那么重要。限制因素是操作系统需要处理数据包的次数。300,000pps表示系统作为一个整体需要处理一个数据包的次数。随着更多的网络跳数的增加，上下文切换的数量会增加，并且会降低整个网络路径上的吞吐量。\n注意: 问题关键在于是能跑多少流量? 而不是多少节点\n有关CORE性能的更详细研究，请参阅以下出版物:\nJ. Ahrenholz, T. Goff, and B. Adamson, Integration of the CORE and EMANE Network Emulators, Proceedings of the IEEE Military Communications Conference 2011, November 2011. Ahrenholz, J., Comparison of CORE Network Emulation Platforms, Proceedings of the IEEE Military Communications Conference 2010, pp. 864-869, November 2010. J. Ahrenholz, C. Danilov, T. Henderson, and J.H. Kim, CORE: A real-time network emulator, Proceedings of IEEE MILCOM Conference, 2008. 节点类型 CORE中可以配置不同的节点类型，每个节点类型都表示节点在运行时将如何表示的机器类型。不同的机器类型允许不同的选择。\nNetns 节点 netns(net nodes) 类型是默认的节点类型， 这是用于由 Linux 网络命名空间支持的节点。这种机器类型很少使用系统资源来模拟网络。这被指定为默认机器类型的另一个原因是，此技术通常不需要更改内核，它可从最新的主流Linux发行版中开箱即用。\n物理 节点 physical 机器类型用于表示真正的基于linux的机器的节点，这些机器将参与模拟的网络场景。该节点通常用于合并来自模拟测试平台的服务器机组。物理节点是运行CORE守护进程(CORE-daemon)的节点，它不会被进一步分区到容器中。在物理节点上运行的服务不是在一个隔离的环境中运行，而是直接在操作系统上运行。\n必须给物理节点分配服务器，与使用分布式仿真（Distributed Emulation）将节点分配仿真服务器的方式相同。可用物理节点列表当前与仿真服务器共享同一个对话框和列表，可以使用Session菜单中的emulation servers…条目进行访问。\n对物理节点的支持正在开发中，并可能在未来的版本中得到改进。目前，当任何节点连接到一个物理节点时，会画一条虚线来表示网络隧道。将在物理节点上创建一个GRE隧道接口，用于隧道通信流进出模拟世界。\n在运行时双击物理节点将打开一个终端，该终端带有指向该节点的SSH shell。用户应该像使用仿真服务器那样配置公钥SSH登录。\nSDT 3D安装 首先安装对应Java环境，推荐java8，根据源码手册下面为Ubuntu的安装教程\ngit clone https://github.com/USNavalResearchLaboratory/sdt sudo apt-get install openjdk-8-jdk export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ source $HOME/.bashrc # jdk变量生效 当前用户 # source $HOME/.profile # jdk变量生效 全部用户 update-alternatives --display java update-alternatives --display javac update-alternatives --display jar sudo apt-get install libvecmath-java sudo apt-get install libpcap-dev sudo apt-get install libnetfilter-queue-dev # \u0026lt;arm64\u0026gt; 替换为安装软件的系统架构 cd sdt/makefiles make -f Makefile.linux_\u0026lt;arm64\u0026gt; sdt3d sdtcmd make -f Makefile.linux_\u0026lt;arm64\u0026gt; distclean #卸载包，有问题需要清理时运行 #绑定脚本至core中 sudo make -f Makefile.linux_amd64 install /usr/local/bin/ #修改 /usr/local/bin/sdt3d.sh 内容： THISDIR=/home/$USER/sdt/makefiles/build/sdt3d Core 常见问题： core安装、卸载重装等报错问题\n不能使用sudo 运行install.sh 否则后面装依赖包及生成虚拟环境目录权限为root用户，肯定会报错。\n似乎 ARM 架构的 ubuntu 无法安装该软件的虚拟环境，真实环境下也是各种不包的依赖环境不对。\n自动化安装脚本依赖invoke，其执行流程由core源码根目录的task.py脚本定义。其写法是一旦遇到装过pipx等就直接退出安装脚本，所以可以修改其执行语句（添加 \u0026ndash;force）来强制安装已经装过的包。或者简单的做法就是把装的虚拟环境删除即可，删pipx的venv文件夹(~/.local/pipx/venvs/*) 和poetry生成的虚拟环境文件夹(~/.cache/pypoetry/virtualenvs/core-3XChpotV-py3.6)或使用命令\ncd ~/core/daemon poetry env list # 查看安装位置 poetry remove venv1 pipx uninstall poetry pipx uninstall invoke pip3 uninstall pipx poetry或pip安装满导致的超时错误\npython换源\n/home/lk233/core/daemon/pyproject.toml [[tool.poetry.source]] name = \u0026quot;tsinghua\u0026quot; default = true url = \u0026quot;https://pypi.tuna.tsinghua.edu.cn/simple\u0026quot; # 更新 poetry 锁文件 poetry lock --no-update # 如果是安装本地直接如下 pip config set global.index-url http://pypi.tuna.tsinghua.edu.cn/simple pip config set global.trusted-host pypi.tuna.tsinghua.edu.cn 安装 pyymal 报错\n将pip降级可以解决pip install --upgrade --force-reinstall pip==9.0.3\npoetry 安装 cffi 报错\nBuilding wheel for cffi (setup.py) error XXX.. Package libffi was not found in the pkg-config search path. 安装缺少的包sudo apt-get install libffi6 libffi-devsudo local 安装 lxml 时报错\n安装缺少的包\nsudo apt-get install libxml2 sudo snap install libxslt 无法使用子节点终端的图形界面：\n# 报错提示 No protocol specified Error: Can't open display: :0 解决：Xserver默认情况下，不允许别的用户的图形程序的图形显示在当前屏幕上。在图形正常的用户终端中输入 xhost +\nxhost + # access control enabled, only authorized clients can connect xhost - # access control disabled, only authorized clients can connect Xterm下的Tcpdump 抓包不刷新问题：\n使用 -l 选项，设置stdout行缓冲， 这样也可以有效搭配如下命令\ntcpdump -l | tee dat tcpdump -l \u0026gt; dat \u0026amp; tail -f dat\t#终止时tcpdump未终止 记得kill pid iperf3等流量测试工具在走分布式场景时会发生数据无法传输问题：\n由于分布式之间的数据通过隧道链接，而建立的隧道默认MTU为1458字节。所以当分布式服务器的路由包的MTU过大时，不会转发数据。\n以iperf3为例，设定传输流量包mss为1024就能解决无法传输跨分布式服务器的包的数据\niperf -c 192.168.131.161 -M 1024 #注意，这里的-M设定的是MSS为TCP、STCP传输层概念，MTU为传输层传递的最大IP包 容器隔离问题\n注意虽然容器节点与外部物理机系统隔离有独立的网络、进程堆栈，但是部分文件系统是与外界共享的。例如家目录都是设置为外界用户的家目录，其他系统文件例如配置路由的转发的文件/proc/sys/net/ipv4/ip_forward却又是独立的（在终端使用sysctl不影响外面运行仿真的系统）\nemanesh脚本无导入库问题\n由于是安装在虚拟环境的python，所以执行得用core-python执行。有些脚本例如emanesh还是使用外部物理环境的python执行，将第一行的 执行文件修改成对应core-python路径。或者执行时加上core-python即可。\n#!/usr/bin/python3 =\u0026gt; 修改为类似的下面的执行路径 #!/home/user/.cache/pypoetry/virtualenvs/core-3XChpotV-py3.6/bin/python core后台运行batch问题\n有一条issue提到了该问题： 程序自带的batch选项后续没有维护，运行带有移动拓扑及emane无线模型直接报错或是不加载。解决该问题需要使用前台gui启动或者带有虚拟帧缓冲区的启动，使用Xvfb可以正常运行，Xvfb 在虚拟内存中执行所有图形操作，而不显示任何屏幕输出，运行时部分ui报错可忽略。\n使用方法：xvfb-run core-gui -s ~/.core/configs/sample1.imn，提示没有这个包就apt-get安装即可。\n或者直接使用 grpc api open一个场景后台执行。\n如果是生成一个场景并后台执行，个人推荐使用 gRPC API Python API 直接构建场景实例化运行，并且也能调用savexml保存。\n分布式场景初始化问题\n​\t由于 boot_nodes 和 boot service 默认是调用线程池大小为10的非堵塞任务，所以瞬时业务的并发量特别大造成ssh通道饱和连接失败。具体问题示例如此处[SSH BUG] · Issue #622 · coreemu/core (github.com)。需要修改coreservices.py下的 boot_services 和 session.py下的 boot_nodes 的调用线程数量。当然也可以重构分布式通信部分，将多个连接命令合并之后解析ssh。\n","id":21,"section":"posts","summary":"笔记实时更新中。。 Core、Emane 介绍 官方文档 一句话概括: CORE侧重于模拟如网络层传输层、会话层和应用层，提供了用户构建虚拟网络的图形","tags":["仿真"],"title":"Core 学习笔记","uri":"https://liangkang233.github.io/2021/07/core%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","year":"2021"},{"content":"CORE/EMANE Emane模型调研 无线仿真基本内容学习： 衰落模型\nemane只能使用事件或nakagami模型\ncore设定的默认值是有问题的，m值越大信道越理想\n路径损耗\nemane可设定为2-RAY、freespace\n注意：针对大尺度场景下的路径损耗需要使用freespace，例如高度变化差异大的场景，否则效果不明显。\n当propagationmodel设置为precomputed 预定义模型，其路径损耗通过pathloss事件触发。\n上述概念切勿混淆，其本质为信道衰落反映的是接收机观察到的信道强弱变化。\n它通常是大尺度衰落（路径损耗、阴影）和小尺度衰落（多径效应）的综合。\nemane无线干扰\n根据下面的式子无线物理层处理是否接受该数据包（rxPower \u0026gt; rxSensitivity 即接收）\nrxPower = txPower + txAntennaGain + rxAntennaGain − pathloss` rxSensitivity = −174 + noiseFigure + 10log(bandWidth) 对于frequencyofinterest监视的频率接收到后，根据设定不同的subid然后区分为带内外信号。\n节点设定noisemod会设定物理层能够根据噪声模式配置参数记录所有信号能量、带外信号能量或无信号能量(即该节点是否接受带内外信号影响造成干扰)。当在给定的请求间隔内没有记录信号能量或没有发生信号能量时，接收机灵敏度被用作底噪。802.11abg 具体例子\n最后计算信噪比SINR在mac层对应具体模型（例如rfpipe模型）再得到丢包率，采集有效包向core传输。\nemane相关注意点： 场景配置中的云并不是类似有线场景的路由器，仅仅是配置链接上的节点的ip、无线模型、等phy mac的默认配置。关于节点是否可通信除了上面信号强度要达到rxSensitivity外，还要监听频率符合。所以发射频率和接收频率（phy层的frequency和frequencyofinterest）不同会组成上行下行信道，这样就不产生带内干扰。 Emane 介绍 EMANE 源码\nEmane 架构\nEMANE 教程测试\n可扩展移动自组织网络仿真器 (The Extendable Mobile Ad-hoc Network Emulator) 允许使用可插拔 MAC 和 PHY 层架构进行异构网络仿真。EMANE是由美国海军研究实验室(NRL)代号5522和 Adjacent Link 有限责任公司开发的。EMANE 框架提供了一种实现架构，用于以网络仿真模块 (NEM: Network Emulation Modules) 的形式对不同的无线电接口类型进行建模，并将这些模块合并到在分布式环境中运行的实时仿真中。\nhttp://www.adjacentlink.com/ 可以使用 EMANE 绑定到虚拟设备的 EMANE 来模拟高保真无线网络，而不是使用 CORE 构建 Linux 以太网网桥。CORE 仿效第 3 层及以上（网络、会话、应用程序）及其虚拟网络堆栈和处理空间，用于协议和应用程序，而 EMANE 则使用其可插入的 PHY 和 MAC 模型模拟物理层和数据链路层。它为无线网络实验人员提供了一个高度灵活的模块化环境，用于设计、开发和测试简单和复杂的网络架构。EMANE采用物理层模型来考虑信号传播、天线轮廓效应和干扰源，以便为无线实验提供一个真实的环境。单个无线电模型插件用于模拟波形的最低层，并可以与现有的软件定义无线电(SDR)相结合。\nCore和 EMANE 之间的接口是 TAP 设备。CORE 使用 Linux 网络名称空间构建虚拟节点，将 TAP 设备安装到名称空间中，并在名称空间中即时化一个 EMANE 过程。EMANE 过程将用户空间Socket与 TAP 设备绑定，以便从 CORE 发送和接收数据。\nEMANE 实例通过控制端口（例如ctrl0 ，ctrl1）发送和接收 OTA（空中）流量来往于其他 EMANE 实例。它还使用相同或不同的控制端口发送和接收事件来回事件服务。通过 CORE 的WLAN配置对话配置 EMANE 模型。每个支持的 EMANE 模型都有相相应的Emane Python 子类，以提供配置项目及其对 XML 文件的映射。这样，新配置就可以很容易地得到支持。当 CORE 开始模拟时，它会生成指定 EMANE NEM 配置的相应 XML 文件，并启动 EMANE daemon\n某些 EMANE 模型支持位置信息，以确定何时应丢弃数据包。EMANE 具有一个事件系统，其中位置事件广播给所有 NEM。当节点在画布上移动时，CORE 可以生成这些位置事件。画布大小和比例对话具有将 X，Y 坐标系统映射到 EMANE 使用的纬度、经度地理系统的控件。还可以在core.conf配置文件设定CORE订阅 EMANE 位置事件，这样core gui画布上的节点与EMANE 仿真中时节点的会同步移动。例如，当模拟脚本生成器运行移动脚本时，就会发生这种情况。\n下面的每个主题都假设已经安装了CORE、EMANE和OSPF MDR。演示文件将在 core-pygui 中找到\n主题 模型 描述 总结 XML Files RF Pipe 概述生成的用于驱动EMANE的XML文件 XML Files GPSD RF Pipe 概述gpsd与EMANE的运行和集成 gpsd Precomputed RF Pipe 概述如何使用预计算传播模型 预计算传播模型 EEL RF Pipe 概述如何使用仿真事件日志(EEL)生成器 EEL生成器 Antenna Profiles RF Pipe 概述如何在EMANE中使用天线配置文件 天线配置 EMANE Configuration CORE 配置文件 /etc/core/core.conf 包含EMANE特有选项，如下所示：\n# EMANE 配置 emane_platform_port = 8101 emane_transform_port = 8201 emane_event_monitor = False # emane_models_dir = /home/username/.core/myemane # EMANE log 范围[0,4] 默认: 2 emane_log_level = 2 emane_realtime = True # emane安装地址前缀 # emane_prefix = /usr 如果你有一个EMANE事件生成器(例如移动或路径损耗脚本)，并且想让CORE订阅EMANE位置事件，在 CORE.conf 配置文件中设置以下行。\n我这边测试可以不改此项，例如ns-2移动脚本gui与后端gps数据的同步，但是发送的emane事件无法触发gui的变化。\n# 如果要手动拖动画布上的节点来更新它们在EMANE中的位置，设置为 False emane_event_monitor = True 经过测试发现，此项设置为false，daemon打印log依旧显示core监听了emane event。 如果改了后会发生下面的报错，暂时未解决此问题，决定emane_event_monitor保持默认的false\nERROR - emanemanager:starteventmonitor - Warning: EMANE events will not be generated because the emaneeventservice binding was unable to load (install the python-emaneeventservice bindings) 另一个常见的问题是，如果从源代码安装EMANE，默认配置前缀将把DTD文件放在 /usr/local/share/emane/dtd\n而core.com希望他们在 /usr/share/emane/dtd\n更新EMANE前缀配置可以解决此问题。\nemane_prefix = /usr/local 自定义EMANE模型 CORE通过动态加载用户创建的表示模型的python文件来支持自定义开发的EMANE模型。\n自定义的EMANE模型应该放在CORE配置文件中 emane_models_dir 所定义的路径中。这个路径不能以 /emane 结尾。\n下面是一个用文档描述功能的示例模型:\n\u0026quot;\u0026quot;\u0026quot; Example custom emane model. \u0026quot;\u0026quot;\u0026quot; from typing import Dict, List, Optional, Set from core.config import Configuration from core.emane import emanemanifest, emanemodel class ExampleModel(emanemodel.EmaneModel): \u0026quot;\u0026quot;\u0026quot; 自定义 emane 模型. :cvar name: 定义将在GUI中显示的emane模型名称 Mac Definition: :cvar mac_library: 定义模型将引用的MAC库 :cvar mac_xml: 定义MAC清单文件，它将被解析以获得配置选项，这将在GUI中显示 :cvar mac_defaults: 允许您重写上面清单文件中维护的选项 :cvar mac_config: 解析清单文件并将配置转换为core支持的格式 Phy Definition: 注意: Phy配置将默认为通用模型如下所示，下面的部分非必须包括在内 :cvar phy_library: 定义模型将引用的phy库，在需要提供自定义phy时使用 :cvar phy_xml: 定义phy清单文件，该文件将被解析以获得配置选项，将在GUI中显示 :cvar phy_defaults: 允许您重写上面清单文件中维护的选项或默认通用模型的选项 :cvar phy_config: 解析清单文件并将配置转换为Core心支持的格式 Custom Override Options: 注意: 这些选项默认为下面所见的内容，不需要包括在内 :cvar config_ignore: 允许您忽略phy/mac中的选项，通常在您需要添加一个自定义选项以在GUI中显示时使用 \u0026quot;\u0026quot;\u0026quot; name: str = \u0026quot;emane_example\u0026quot; mac_library: str = \u0026quot;rfpipemaclayer\u0026quot; mac_xml: str = \u0026quot;/usr/share/emane/manifest/rfpipemaclayer.xml\u0026quot; mac_defaults: Dict[str, str] = { \u0026quot;pcrcurveuri\u0026quot;: \u0026quot;/usr/share/emane/xml/models/mac/rfpipe/rfpipepcr.xml\u0026quot; } mac_config: List[Configuration] = emanemanifest.parse(mac_xml, mac_defaults) phy_library: Optional[str] = None phy_xml: str = \u0026quot;/usr/share/emane/manifest/emanephy.xml\u0026quot; phy_defaults: Dict[str, str] = { \u0026quot;subid\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;propagationmodel\u0026quot;: \u0026quot;2ray\u0026quot;, \u0026quot;noisemode\u0026quot;: \u0026quot;none\u0026quot; } phy_config: List[Configuration] = emanemanifest.parse(phy_xml, phy_defaults) config_ignore: Set[str] = set() 单主机EMANE 本节描述在单个机器上运行CORE和EMANE。这是使用CORE构建EMANE网络时的默认操作模式。\nOTA管理器和Event服务接口被设置为使用ctrl0，虚拟节点使用主控制通道进行相互通信。\n当涉及到EMANE的场景时，主控制通道会自动激活。使用主控制通道可以防止模拟会话在本地\n网络上发送多播流量，并干扰其他EMANE用户。\nEMANE是通过一个WLAN节点配置的，因为它完全是关于模拟无线无线电网络的。\n一旦节点连接到使用EMANE模型配置的WLAN云，该节点上的无线电接口也可以单独配置(除了云之外)。\n双击WLAN节点以调用WLAN配置对话框。单击EMANE选项卡;正确安装EMANE后，EMANE无线模块应列在\nEMANE型号列表中。(如果在安装EMANE Python绑定之前运行CORE守护进程，则可能需要重新启动它)\n单击一个模型名称来启用它。\n当在 EMANE Models 列表中选择一个EMANE模型时，单击 model options 按钮导致GUI查询\nCORE daemon 以获取配置项。每个模型都会有不同的参数，请参考每个项目的解释的EMANE文档。\n默认值显示在对话框中。单击 Apply 将存储EMANE模型选择。\nEMANE options 按钮允许指定一些Emane 全局参数，其中一些是分布式操作所必需的。\nRF-PIPE 和 IEEE 802.11abg 模型使用支持地理位置信息的通用PHY来确定节点之间的路径损耗。\n一个默认的经纬度位置由CORE提供，这个基于位置的路径损耗默认启用;这是通用PHY的路径损耗模式设置。\n在模拟运行时移动画布上的节点将为EMANE生成位置事件。\n要查看或更改画布的地理位置或比例，请使用画布菜单中的“画布大小和比例”对话框。\n注意，地理坐标系和笛卡尔坐标系之间的转换是使用通用墨卡托投影(UTM: Universal Transverse Mercator)完成的，\n其中定义了6层不同的经度带区域。对于跨越多个UTM区域的非常大的场景，CORE生成的位置事件在区域边界附近可能变得不准确。\n在这种情况下，建议使用EMANE位置脚本来实现地理位置的准确性。\n单击绿色的 Start 按钮将启动模拟，并导致在连接到EMANE WLAN的虚拟节点中创建TAP设备。\n这些设备显示为接口名称，如eth0、eth1等。EMANE进程现在应该在每个名称空间中运行。如下为四个节点的场景:\nps -aef | grep emane root 1063 969 0 11:46 ? 00:00:00 emane -d --logl 3 -r -f /tmp/pycore.59992/emane4.log /tmp/pycore.59992/platform4.xml root 1117 959 0 11:46 ? 00:00:00 emane -d --logl 3 -r -f /tmp/pycore.59992/emane2.log /tmp/pycore.59992/platform2.xml root 1179 942 0 11:46 ? 00:00:00 emane -d --logl 3 -r -f /tmp/pycore.59992/emane1.log /tmp/pycore.59992/platform1.xml root 1239 979 0 11:46 ? 00:00:00 emane -d --logl 3 -r -f /tmp/pycore.59992/emane5.log /tmp/pycore.59992/platform5.xml 上面的示例显示了CORE启动的EMANE进程。要查看CORE生成的配置，请查看/tmp/pycore。\n这是一个用于存放 platform.xml 文件和其他 XML文件的 session目录。\n查看这些信息的一种简单方法是双击其中一个虚拟节点，然后键入cd ..在shell中转到会话目录。\n分布式 EMANE 在两个或多个模拟服务器中运行CORE和EMANE与在单个机器上运行类似。 为了仿真能够运行，需要设置一些关键的配置项，这里概述了这些配置项。\n维护 数据(OTA流量)和控制流量为独立的网络是一个好主意。例如，控制网络可能是一个共享的实验室网络， core不希望数据网络上的多播通信干扰其他EMANE用户。此外，控制流量可能会干扰OTA延迟和吞吐量， 并可能影响仿真的保真度。这里描述的示例将使用eth0作为控制接口，使用eth1作为数据接口， 尽管并不严格要求使用单独的接口。注意，这些接口名称指的是物理主机上的接口，而不是节点内的虚拟接口。\n重要事项:如果使用了辅助控制网络，则需要将主机上的一个接口分配给该网络\n作为模拟服务器的每台机器都需要安装CORE和EMANE。\n可用服务器的IP地址从核心仿真服务器对话框中配置(选择 Session 然后 Emulation servers\u0026hellip; )。 这个服务器列表存储在*~/.core/servers.conf*文件中。对话框显示了可用的服务器， 其中的一部分或全部可以分配给画布上的节点。\n需要将节点分配给仿真服务器。选择几个节点，右键单击它们，选择Assign to和所需服务器的名称。 当未将节点分配给任何仿真服务器时，将在本地对其进行仿真。GUI连接的本地机器被认为是“主”机器， 而主机器又连接到其他模拟服务器的“从属”。应该配置从主服务器到从服务器的公钥SSH登录 具体请看分布式\n注意 下面是使用EMANE进行分布式模拟的快速检查表。\n遵循常规CORE的步骤。 在EMANE WLAN的 EMANE 标签下，单击 EMANE options 。 打开 OTA Manager channel ，设置 OTA Manager device 。同时设置 Event Service device 。 选择节点组，右键单击它们，并使用 assign to 菜单将它们分配给主或从服务器。 在开始模拟之前，使用 ntp 或 ptp 同步机器的时钟。一些EMANE模型对时间很敏感。 按 Start 按钮启动分布式仿真。 现在，当使用Start按钮实例化模拟时，本地CORE Python守护进程将连接到已分配给节点的其他模拟服务器。 每个服务器都有自己的会话目录，其中生成platform.xml文件和其他EMANE XML文件。NEM id在服务器之间自动协调， 因此没有重叠。每个服务器还获得自己的平台ID。\n以太网设备用于传播组播EMANE事件，如 configure EMANE 对话框中所指定的。EMANE的事件服务可以通过移动性 或路径损耗脚本运行，如单主机Emane所述。 如果CORE没有订阅位置事件，它将在画布上移动节点时生成这些事件。\n在运行时双击节点将导致GUI尝试SSH到该节点的仿真服务器，并运行交互式shell。在启动模拟之前， 应该使用所有模拟服务器对公钥SSH配置进行测试。\nEmane架构 Emane架构主要由三部分组成：\nEmulation Processing(仿真服务过程) Emulation Processing 由 物理层模型 实例与一个或多个 无线电（波形）模型 实例配对。仿真器处理XML 配置文件以确定要实例化的无线电模型插件类型、应如何配置模型和物理层实例以及应用什么通用业务设置。\nEMANE 分布包括三种无线电模型：\nRF Pipe Model IE 802.11abg Model TDMA Model 和一个实用新型：\nComm Effect Model 当模拟器即时化模型插件时，它将每个插件放置在 网络模拟模块（NEM） 以及模拟器物理层的专用实例中。物理层实例使用 Over-The-Air （OTA）多广播通道相互连接。所有 OTA 消息均由每个模拟器实例使用相同的 OTA 多广播通道进行处理。这就是模拟器物理层如何负责异构无线电模型的信号传播、天线效应和干扰源。\n每个无线电模型的运行方式不同，但一般的想法是，模型从应用空间接收消息，进行空中传输，并将消息发送到其物理层实例，以便通过 OTA 多播通道传输（可能在无线电模型执行通道访问功能之后）。使用同一 OTA 多播通道的所有模拟器实例都会接收消息并执行接收功率测试。根据消息接收功率的物理层实例是否大于接收器灵敏度，可将消息归类为噪声或有效的带内波形信号。有效的波形信号被发送到接收无线电模型进行额外的处理。大多数无线电模型使用基于消息 Signal to Noise and Interference Ratio（SINR） 的 Bit Error Rate （BER） 曲线，作为决定是否将消息传递到相应的应用空间过程的决定的一部分。\n术语 application space process (应用空间过程)不应与内核和应用/用户空间的概念混淆。所有 EMANE 进程都在用户空间中运行。我们使用术语应用程序空间（通常作为 application/emulation boundary 主题的一部分）表示任何进程，该过程不是作为模拟器中的插件运行，而是以某种方式连接到（使用）模拟器。\n我们使用 下游 术语来表示所有指向 OTA 多播通道的消息，以及所有向应用空间过程交付的消息的 上游 术语。这并不意味着 OTA 多播通道或应用空间过程必须是最终消息目的地。当无线电模型向其相应的物理层实例发送控制消息时，我们称之为下游控制消息，当物理层实例向无线电模型发送数据包消息时，我们称之为 上游数据包消息 。一旦你开始分析无线电模型性能统计，你会理解其中的区别。\nApplication/Emulation Transport Boundary Processing (传输边界过程) 应用/模拟传输边界是负责在模拟器实例和一个或多个应用空间过程之间传递消息的仿真组件。我们称这个组件为 运输 工具。为模拟器和应用空间消息提供出入口点。\n运输插件可以作为模拟器过程的一部分在内部即时化，也可以作为其他应用的一部分在外部即时化。Transport DaemonEMANE 应用程序处理配置 XML，以确定要即时的外部传输插件类型、应如何配置插件以及应用什么一般应用级别设置。\nEMANE 包含两种传输数据的方式：\nRaw Transport Virtual Transport EMANE 支持 IP 和非 IP 无线仿真，因此个人传输支持的应用空间消息类型差异很大。但是，一旦传输有消息要传递，它们通常都必须做同样的事情。在下游方向，传输必须确定下一跳消息的 NEM ID（这可能是 NEM 广播地址），并将消息与源和目的地 NEM ID 一起发送到已连接的 NEM。在上游方向，传输必须确定应用空间过程才能接收并发送消息。\n当应用程序空间消息通过Transport传输时，它们将失去其形式，并作为指定大小的不透明有效负载通过仿真器发送。Transport是模拟器中唯一可以读写应用程序空间消息细节的组件。\n例如，Virtual Transport使用TUN/TAP接口创建 虚拟接口 （vif） 作为应用程序/模拟边界入口/出口点。在下游方向上，由内核路由到 vif 的以太网框架被打包成消息并发送到适当的 NEM 进行处理。在上游方向，NEM 消息被拆包并作为以太网帧写入到 TUN/TAP 界面。\n应用/模拟边界不限于由仿真器内部加载的插件或由运输守护进程从外部加载的插件。当将 软件定义无线电（SDR）波形连接到 EMANE 时，应开发自定义传输并嵌入*Modem Hardware Abstraction Layer *（MHAL） 的 SDR 中。EMANE 提供应用级别的 API，使开发自定义传输非常容易。\nEvent Processing (仿真事件过程) 为了有趣，运行模拟需要一个场景。场景是发送到一个或多个 NEM 以更改环境特征的一组事件。事件不透明地传递给注册的无线电模型实例，因此单个无线电模型可能需要自己的专业活动。只要有可能，我们主张重复使用 EMANE 标准事件，而不是创建做同样的事情的新事件。\nEMANE 分布包括以下事件：\nAntenna Profile Event Comm Effect Event Location Event Pathloss Event TDMA Schedule Event Fading Selection Event 事件由事件生成器创建。Event ServiceEMANE 应用程序处理XML配置文件以确定要即时处理的事件生成器插件的类型、应如何配置插件以及应用什么业务。\nEMANE 分布包含一个事件生成器，将创建所有标准事件：\nEEL Generator 并提供python modules，让您创建自己的事件生成器应用程序：\nemane.events.EventService emane.events.AntennaProfileEvent emane.events.CommEffectEvent emane.events.LocationEvent emane.events.PathlossEvent emane.events.TDMAScheduleEvent emane.events.FadingSelectionEvent Emane教程及测试 EMANE 教程 测试实例 Emane shell用法 本教程中的每个演示都旨在突出显示模拟器的特定功能。本教程提供了一个使用LXC Containers 创建一组测试节点的简单测试流，这些测试节点运行模拟器实例以及MANET(移动自组网)世界中通常使用的应用程序和服务。\n其中关于环境和测试用例的配置方法为了方便省事，直接用官方给的虚拟机来做测试。\n教程虚拟机 (Tutorial VM) 是一个CentOS 7 VirtualBox镜像，带有EMANE 1.2.1。教程演示的保真度将根据主机系统配置的不同而变化。\n用户名：emane 密码: emanedemo 虚拟机sha1sum: 9fb689eff14b43f700935e8514abb62aebc13761 # 首先进行编译安装 cd ~/emane-tutorial make 教程中有9个demo测试：\nDemo 容器数 模型 传输 描述 0 2 Bypass Virtual 介绍仿真器子系统和应用程序 1 10 RF Pipe Virtual 介绍事件生成、EMANE Shell和一般物理层的概念 2 7 RF Pipe Virtual 介绍射频管无线电模型(RF Pipe radio) 3 10 IEEE 802.11abg Virtual 介绍IEEE 802.11abg无线模型 5 4 IEEE 802.11abg, RF Pipe Virtual 了解仿真器频谱监测和噪声处理 6 4 RF Pipe Virtual 如何使用物理层天线配置文件 7 10 Comm Effect Raw 介绍了Comm Effect实用模型和黑盒测试 8 10 TDMA Virtual 介绍TDMA事件调度器无线电模型 注意：\n此教程仅仅展示Emane工作流程无需专门学习其配置流程，在core中配置节点Emane等操作有专门的控制流程。并且Emane的实现并不一定需要LXC容器，但是这里展示和core的节点实现是采用lxc容器做的。\n注意：之后的几章节测试使用corepygui打开图片路径不会报错，这几个emane测试场景路径为 ~/.coregui/xmls 注意：emane 的几个python程序默认用的是主机python，安装在虚拟环境的core需要将python运行路径替换为core-python，或者使用core-python运行。其使用说明在emane介绍中可以看到。\nXML Files 在配置好emane的场景或直接运行 emane-demo-files.xml 后，在会话的临时目录(例如/tmp/pycore.44151/n8.conf) 中就会生成对应emane配置的xml文件。就像 emane-demo 中配置的xml文件那样。（emane demo0）\n用于节点运行EMANE的根配置文件是 platform.xml 文件。其作用为：\n列出为Emane设定的所有总配置值 为节点创建的每个接口给定的唯一的 nem id 用于定义使用的 nem.xml 路径 nem.xml文件定义将包含对给定nem所使用的 transport mac phy xml文件的的定义及引用。\n文件名 描述 -platform.xml emane仿真实例化的配置文件 -nem.xml 创造NEM的配置文件 (NEM: Network Emulation Modules) -mac.xml 用于定义NEMs MAC层的配置 -phy.xml 用于定义NEMs PHY层的配置 -trans-virtual.xml 使用 virtual 传输时的配置 -trans.xml 使用 raw 传输时的配置 Gpsd GPSD是一个计算机软件程序，从全球定位系统（GPS）接收器收集数据，并通过互联网协议（IP）网络向服务器-客户端应用程序架构中潜在的多个客户端应用程序提供数据。Gpsd 可以作为一个daemon运行，以透明的方式运行为服务器的后台任务。网络界面为多个并发客户端应用程序（如Kismet或 GPS导航软件）提供了标准化的数据格式。Emane的位置数据就是如此获取的（EMANE仿真中运行gpsd位置代理，该代理将把位置输出到伪终端文件gps.pty。gpsd服务器可以读入该文件，使gpsd客户机可以使用EMANE位置事件。）\n物理机上安装gpsd软件：\nsudo apt-get install gpsd sudo apt-get install gpsd-clients gpsd客户端及daemon的官方介绍\n运行示例 emane-demo-gpsd.xml（emane demo0）\nEMANE GPSD Event Daemon 具体流程:\n首先在会话目录对应的n1节点文件夹下创建emane 的事件守护进程配置文件 eventdaemon.xml。 \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventdaemon SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventdaemon.dtd\u0026quot;\u0026gt; \u0026lt;eventdaemon nemid=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;param name=\u0026quot;eventservicegroup\u0026quot; value=\u0026quot;224.1.2.8:45703\u0026quot;/\u0026gt; \u0026lt;param name=\u0026quot;eventservicedevice\u0026quot; value=\u0026quot;ctrl0\u0026quot;/\u0026gt; \u0026lt;agent definition=\u0026quot;gpsdlocationagent.xml\u0026quot;/\u0026gt; \u0026lt;/eventdaemon\u0026gt; 上面的配置会生成如下的 gpsdlocationagent.xml 文件。 \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventagent SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventagent.dtd\u0026quot;\u0026gt; \u0026lt;eventagent library=\u0026quot;gpsdlocationagent\u0026quot;\u0026gt; \u0026lt;param name=\u0026quot;pseudoterminalfile\u0026quot; value=\u0026quot;gps.pty\u0026quot;/\u0026gt; \u0026lt;/eventagent\u0026gt; 启动EMANE事件代理。这将有助于将位置事件输出到上面定义的伪终端文件。 emaneeventd eventdaemon.xml -r -d -l 3 -f emaneeventd.log 启动gpsd，读取伪终端文件。 gpsd -G -n -b $(cat gps.pty) EMANE EEL Event Daemon 具体流程:\nEEL 事件将通过指定的控制网络接口从实际主机运行。在主机上的同一目录中创建以下文件，在主机终端打开对应文件夹\n注意：确保以下 eventservicedevice 与主机上用于 EMANE 的控制网络设备匹配\n创建 eventservice.xml 文件 \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventservice SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventservice.dtd\u0026quot;\u0026gt; \u0026lt;eventservice\u0026gt; \u0026lt;param name=\u0026quot;eventservicegroup\u0026quot; value=\u0026quot;224.1.2.8:45703\u0026quot;/\u0026gt; \u0026lt;param name=\u0026quot;eventservicedevice\u0026quot; value=\u0026quot;b.9001.1\u0026quot;/\u0026gt; \u0026lt;generator definition=\u0026quot;eelgenerator.xml\u0026quot;/\u0026gt; \u0026lt;/eventservice\u0026gt; 创建 eelgenerator.xml 文件 \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventgenerator SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventgenerator.dtd\u0026quot;\u0026gt; \u0026lt;eventgenerator library=\u0026quot;eelgenerator\u0026quot;\u0026gt; \u0026lt;param name=\u0026quot;inputfile\u0026quot; value=\u0026quot;scenario.eel\u0026quot; /\u0026gt; \u0026lt;paramlist name=\u0026quot;loader\u0026quot;\u0026gt; \u0026lt;item value=\u0026quot;commeffect:eelloadercommeffect:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;location,velocity,orientation:eelloaderlocation:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;pathloss:eelloaderpathloss:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;antennaprofile:eelloaderantennaprofile:delta\u0026quot;/\u0026gt; \u0026lt;/paramlist\u0026gt; \u0026lt;/eventgenerator\u0026gt; 创建 scenario.eel 文件 0.0 nem:1 location gps 40.031075,-74.523518,3.000000 0.0 nem:2 location gps 40.031165,-74.523412,3.000000 启动 EEL 事件服务，它将通过控制网络将上述文件中定义的事件发送到所有 EMANE 节点。这些位置事件将被接收并提供给 gpsd。这允许 gpsd 客户端连接并获取 gps 位置。 emaneeventservice eventservice.xml -l 3 传播模型 物理层模型中的路径损耗基于位置或路径损耗事件。当传播模型配置参数设置为2ray或freespace时，路径损耗是基于位置事件动态计算的，这将分别在2-ray flat earth或freespace传播模型之间进行选择。也可以使用外部传播的路径损耗事件计算实时的路径损耗，需要将propagationmodel参数设置为预先计算模型precomputed,以处理接收的路径损耗pathloss事件。\n介绍预先计算模型（EMANE Demo 1），运行 emane-demo-precomputed.xml 场景，（相对于上面的场景即改变rf-pipe选项-\u0026gt;PHY Parameters-\u0026gt;propagationmodel-\u0026gt;precomputed）\n打开n1中终端,由于使用了预计算的路径损耗事件，并且还没有发送任何路径损耗事件，节点之间还不能ping通。\n您可以利用 EMANE Shell 来调查数据包被丢弃的原因。\nroot@n1:/tmp/pycore.46777/n1.conf# emanesh localhost get table nems phy BroadcastPacketDropTable0 UnicastPacketDropTable0 nem 1 phy BroadcastPacketDropTable0 | NEM | Out-of-Band | Rx Sensitivity | Propagation Model | Gain Location | Gain Horizon | Gain Profile | Not FOI | Spectrum Clamp | Fade Location | Fade Algorithm | Fade Select | | 2 | 0 | 0 | 169 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | nem 1 phy UnicastPacketDropTable0 | NEM | Out-of-Band | Rx Sensitivity | Propagation Model | Gain Location | Gain Horizon | Gain Profile | Not FOI | Spectrum Clamp | Fade Location | Fade Algorithm | Fade Select | 在上面的例子中，我们可以看到数据包被丢弃的原因是由于传播模型，这是因为我们没有发出任何路径损耗事件。您可以运行另一个命令来验证您是否收到了任何路径损耗事件。\nroot@n1:/tmp/pycore.46777/n1.conf# emanesh localhost get table nems phy PathlossEventInfoTable nem 1 phy PathlossEventInfoTable | NEM | Forward Pathloss | Reverse Pathloss | Pathloss Events 在主机上，我们将从所有nem向所有其他nem发送路径损耗事件。\n注意:确保正确指定控制网络设备\nemaneevent-pathloss 1:2 90 -i \u0026lt;controlnet device\u0026gt; 现在，如果我们检查n2上的路径损耗事件，我们将看到刚才发送的内容。\nroot@n1:/tmp/pycore.46777/n1.conf# emanesh localhost get table nems phy PathlossEventInfoTable nem 1 phy PathlossEventInfoTable | NEM | Forward Pathloss | Reverse Pathloss | | 2 | 90.0 | 90.0 这之后就可以 ping 通n1 n2。（需要两边都添加默认网关路由 ip link default add 10.0.0.2[1]）\n其实直接看gui上有无绿线就知是否联通，有绿线ping不通大概率是路由问题。\nEEL生成器（Emulation Event Log） 介绍如何使用EMANE事件服务和eel文件提供事件。先加载场景 emane-demo-eel.xml（EMANE Demo 1）\n在n1上，我们将使用 EMANE event dump utility 监听事件。\nroot@n1:/tmp/pycore.46777/n1.conf# emaneevent-dump -i ctrl0 发送事件 使用以下内容创建eventservice.xml。（在外部主机创建运行）\n此法需要core开启监听emane事件。 测试发现发送改变节点gps位置事件，节点GPS的确改变，但是对应UI未改变。\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventservice SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventservice.dtd\u0026quot;\u0026gt; \u0026lt;eventservice\u0026gt; \u0026lt;param name=\u0026quot;eventservicegroup\u0026quot; value=\u0026quot;224.1.2.8:45703\u0026quot;/\u0026gt; \u0026lt;param name=\u0026quot;eventservicedevice\u0026quot; value=\u0026quot;b.9001.f\u0026quot;/\u0026gt; \u0026lt;generator definition=\u0026quot;eelgenerator.xml\u0026quot;/\u0026gt; \u0026lt;/eventservice\u0026gt; 接下来，我们将创建eelgenerator.xml文件。\nEEL Generator实际上是一个sentence加载并解析的插件。 解析插件知道如何将某些指令(commeffect、location、velocity、orientation、pathloss和antennaprofile )转换成相应的emane事件。\ncommeffect : eelloadercommeffect : delta location, velocity, orientation : eelloaderlocation:delta pathloss : eelloaderpathloss : delta antennaprofile : eelloaderantennaprofile : delta 这些配置项告诉EEL Generator 哪些 sentences 要映射到哪个插件，以及是发布增量更新还是完整更新。\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventgenerator SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventgenerator.dtd\u0026quot;\u0026gt; \u0026lt;eventgenerator library=\u0026quot;eelgenerator\u0026quot;\u0026gt; \u0026lt;param name=\u0026quot;inputfile\u0026quot; value=\u0026quot;scenario.eel\u0026quot; /\u0026gt; \u0026lt;paramlist name=\u0026quot;loader\u0026quot;\u0026gt; \u0026lt;item value=\u0026quot;commeffect:eelloadercommeffect:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;location,velocity,orientation:eelloaderlocation:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;pathloss:eelloaderpathloss:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;antennaprofile:eelloaderantennaprofile:delta\u0026quot;/\u0026gt; \u0026lt;/paramlist\u0026gt; \u0026lt;/eventgenerator\u0026gt; 最后,创建 scenario.eel\n0.0 nem:1 pathloss nem:2,90.0 0.0 nem:2 pathloss nem:1,90.0 0.0 nem:1 location gps 40.031075,-74.523518,3.000000 0.0 nem:2 location gps 40.031165,-74.523412,3.000000 emaneeventservice eventservice.xml -l 3 如果我们返回查看原始终端，我们将看到事件注销到终端。\nroot@n1:/tmp/pycore.46777/n1.conf# emaneevent-dump -i ctrl0 [1601858142.917224] nem: 0 event: 100 len: 66 seq: 1 [Location] UUID: 0af267be-17d3-4103-9f76-6f697e13bcec (1, {'latitude': 40.031075, 'altitude': 3.0, 'longitude': -74.823518}) (2, {'latitude': 40.031165, 'altitude': 3.0, 'longitude': -74.523412}) [1601858142.917466] nem: 1 event: 101 len: 14 seq: 2 [Pathloss] UUID: 0af267be-17d3-4103-9f76-6f697e13bcec (2, {'forward': 90.0, 'reverse': 90.0}) [1601858142.917889] nem: 2 event: 101 len: 14 seq: 3 [Pathloss] UUID: 0af267be-17d3-4103-9f76-6f697e13bcec (1, {'forward': 90.0, 'reverse': 90.0}) 天线配置 介绍在CORE中使用EMANE天线剖面，基于下面链接的EMANE演示示例。（EMANE Demo 6）\n在开始这个会话之前，我们需要创建一些文件。创建目录放置天线配置文件。\nmkdir /tmp/emane 创建 /tmp/emane/antennaprofile.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE profiles SYSTEM \u0026quot;file:///usr/share/emane/dtd/antennaprofile.dtd\u0026quot;\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile id=\u0026quot;1\u0026quot; antennapatternuri=\u0026quot;/tmp/emane/antenna30dsector.xml\u0026quot; blockagepatternuri=\u0026quot;/tmp/emane/blockageaft.xml\u0026quot;\u0026gt; \u0026lt;placement north=\u0026quot;0\u0026quot; east=\u0026quot;0\u0026quot; up=\u0026quot;0\u0026quot;/\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile id=\u0026quot;2\u0026quot; antennapatternuri=\u0026quot;/tmp/emane/antenna30dsector.xml\u0026quot;\u0026gt; \u0026lt;placement north=\u0026quot;0\u0026quot; east=\u0026quot;0\u0026quot; up=\u0026quot;0\u0026quot;/\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; 创建 /tmp/emane/antenna30dsector.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE antennaprofile SYSTEM \u0026quot;file:///usr/share/emane/dtd/antennaprofile.dtd\u0026quot;\u0026gt; \u0026lt;!-- 30degree sector antenna pattern with main beam at +6dB and gain decreasing by 3dB every 5 degrees in elevation or bearing.--\u0026gt; \u0026lt;antennaprofile\u0026gt; \u0026lt;antennapattern\u0026gt; \u0026lt;elevation min='-90' max='-16'\u0026gt; \u0026lt;bearing min='0' max='359'\u0026gt; \u0026lt;gain value='-200'/\u0026gt; \u0026lt;/bearing\u0026gt; \u0026lt;/elevation\u0026gt; /* 略 */ \u0026lt;elevation min='16' max='90'\u0026gt; \u0026lt;bearing min='0' max='359'\u0026gt; \u0026lt;gain value='-200'/\u0026gt; \u0026lt;/bearing\u0026gt; \u0026lt;/elevation\u0026gt; \u0026lt;/antennapattern\u0026gt; \u0026lt;/antennaprofile\u0026gt; 创建 /tmp/emane/blockageaft.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE antennaprofile SYSTEM \u0026quot;file:///usr/share/emane/dtd/antennaprofile.dtd\u0026quot;\u0026gt; \u0026lt;!-- blockage pattern: 1) entire aft in bearing (90 to 270) blocked 2) elevation below -10 blocked, 3) elevation from -10 to -1 is at -10dB to -1 dB 3) elevation from 0 to 90 no blockage--\u0026gt; \u0026lt;antennaprofile\u0026gt; \u0026lt;blockagepattern\u0026gt; \u0026lt;elevation min='-90' max='-11'\u0026gt; \u0026lt;bearing min='0' max='359'\u0026gt; \u0026lt;gain value='-200'/\u0026gt; \u0026lt;/bearing\u0026gt; \u0026lt;/elevation\u0026gt; /* 略 */ \u0026lt;/bearing\u0026gt; \u0026lt;/elevation\u0026gt; \u0026lt;/blockagepattern\u0026gt; \u0026lt;/antennaprofile\u0026gt; 加载场景 emane-demo-antenna.xml，双击 n1终端\n本演示将介绍如何运行EMANE事件服务来提供天线、位置和路径损耗事件，以演示如何使用天线剖面。\n与之前类似的配置文件 eventservice.xml eelgenerator.xml (外部主机运行emaneeventservice -l 3 eventservice.xml)\nscenario.eel 内容为\n0.0 nem:1 antennaprofile 1,0.0,0.0 0.0 nem:4 antennaprofile 2,0.0,0.0 # 0.0 nem:1 pathloss nem:2,60 nem:3,60 nem:4,60 0.0 nem:2 pathloss nem:3,60 nem:4,60 0.0 nem:3 pathloss nem:4,60 # 0.0 nem:1 location gps 40.025495,-74.315441,3.0 0.0 nem:2 location gps 40.025495,-74.312501,3.0 0.0 nem:3 location gps 40.023235,-74.315441,3.0 0.0 nem:4 location gps 40.023235,-74.312501,3.0 0.0 nem:4 velocity 180.0,0.0,10.0 # 30.0 nem:1 velocity 20.0,0.0,10.0 30.0 nem:1 orientation 0.0,0.0,10.0 30.0 nem:1 antennaprofile 1,60.0,0.0 30.0 nem:4 velocity 270.0,0.0,10.0 # 60.0 nem:1 antennaprofile 1,105.0,0.0 60.0 nem:4 antennaprofile 2,45.0,0.0 # 90.0 nem:1 velocity 90.0,0.0,10.0 90.0 nem:1 orientation 0.0,0.0,0.0 90.0 nem:1 antennaprofile 1,45.0,0.0 发送的事件将触发4种不同的状态。\n状态1 N2和N3相互看到 N4和N3指向外 状态2 N2和N3相互看到 N1和N2相互看到 N4和N3相互看到 状态3 N2和N3相互看到 N4和N3正对着对方，但是被阻塞了 状态4 N2和N3相互看到 N4和N3相互看到 ","id":22,"section":"posts","summary":"CORE/EMANE Emane模型调研 无线仿真基本内容学习： 衰落模型 emane只能使用事件或nakagami模型 core设定的默认值是有问题的，m值越大信道越","tags":["仿真"],"title":"Emane学习记录","uri":"https://liangkang233.github.io/2021/07/emane/","year":"2021"},{"content":"服务 CORE 使用服务的概念来指定节点启动时运行哪些进程或脚本。路由器和PC等第三层节点是由他们所运行的服务来定义的。\n可以为每个节点定制服务，也可以创造新的自定义服务。可以创建具有不同名称、图标和默认服务集的新节点类型。 每个服务定义每个节点的路径、配置文件、启动索引、启动命令、验证命令、关闭命令和与节点关联的元数据。\n注意: 使用 init, upstart, 或 systemd 框架时，网络名称节点空间不会经历正常的Linux引导过程 ，这些轻量节点使用已经配置好的CORE服务。\n提供的服务 服务组 服务 总结 BIRD BGP, OSPF, RADV, RIP, Static EMANE Transport Service FRR BABEL, BGP, OSPFv2, OSPFv3, PIMD, RIP, RIPNG, Zebra NRL arouted, MGEN Sink, MGEN Actor, NHDP, OLSR, OLSRORG, OLSRv2, SMF Quagga BABEL, BGP, OSPFv2, OSPFv3, OSPFv3 MDR, RIP, RIPNG, XPIMD, Zebra SDN OVS, RYU Security Firewall, IPsec, NAT, VPN Client, VPN Server Utility ATD, Routing Utils, DHCP, FTP, IP Forward, PCAP, RADVD, SSF, UCARP XORP BGP, OLSR, OSPFv2, OSPFv3, PIMSM4, PIMSM6, RIP, RIPNG, Router Manager 节点类型和默认服务 以下是默认节点类型和他们的服务:\n节点类型 服务 router 针对IGP链路状态路由的 zebra, OSFPv2, OSPFv3, and IPForward 服务。 host 默认路由和SSH服务, 其表示直接连接到路由器时，SSH具有默认路由。 PC 为拥有默认路由且直接连接到路由器的节点提供默认路由服务. mdr 针对无线优化的 MANET 指定路由的 zebra、 OSPFv3MDR 和 IPForward 服务。 prouter 和 路由器 节点类型具有相同默认服务的物理路由器; 用于将Linux测试平台设备合并到仿真中。 配置文件可以由每个服务自动生成。例如，CORE 会自动为路由器节点生成路由协议配置，来简化虚拟网络的创建。\n更改与节点相关联的服务，可以双击节点来调用配置对话框, 然后单击 服务\u0026hellip; 按钮，或者右键单击某个节点，从右键菜单中选择 服务\u0026hellip; 选项。通过单击服务的名称可以启用或禁止该服务。每个服务名称旁边的按钮允许您为该节点自定义此服务的所有方面。例如，可以将特殊的路由重分发命令插入到与 zebra 服务关联的 Quagga 路由配置中。\n若要更改与节点类型相关的默认服务, 请使用第三层节点工具栏末端的 编辑 按钮中的 节点类型\u0026hellip; 对话框，或是从 会话 菜单中选择 节点类型\u0026hellip;。 注意，如果已经定制了节点，那么所选择的任何新服务都不会应用于现有节点。\n节点类型被保存在 ~/.core/nodes.conf 文件中，而不是 .imn 文件。在更改现有节点的默认服务时请记住这一点; 最好只创建一个新的节点类型。并且建议不要更改默认的内置节点类型。可以在 CORE 设备之间复制nodes.conf 文件来保存你的自定义类型。\n定制服务 可以为特定节点完全定制服务。 从节点的配置对话框中，单击服务名称旁边的按钮，来调用该服务的服务定制对话框。该对话框有三个选项卡用于配置服务的不同方面：Files， Directories和tartup/shutdown。\n服务旁边的 黄色 自定义图标表示服务需要自定义（例如 Firewall 服务）。绿色 的自定义图标表示存在自定义配置。在自定义服务时单击 default 按钮会移除所有自定义选项。\nFiles选项卡用于显示或编辑用于该服务的配置文件或脚本。文件可以从下拉列表中选择，它们的内容将显示在下面的文本框中。文件的内容由 CORE daemon根据自定义对话框调用时存在的网络拓扑进程生成。\nDirectories选项卡显示该服务的每个节点的路径。对于默认类型，CORE节点共享相同的文件系统树，但被服务定义的每个节点除外。例如，对于每个运行 Zebra 服务的节点，其 /var/run/quagga 路径必须是唯一的，因为在每个节点运行的 Quagga 需要向该路径写入单独的 PID 文件。\n默认情况下， /var/log 和 /var/run 路径按照每个节点唯一挂载。每个节点的挂载目标可以在 /tmp/pycore.nnnnn/nN.conf/ （其中 nnnnn 是会话编号，N是节点编号）中找到。\nStartup/shutdown 选项卡列出用于启动和停止该服务的命令。 startup index允许在该服务启动时对为该节点启用的其他相关服务进行配置；Startup较低的服务先于Startup较高的服务. 由于Files选项卡生成的shell脚本没有执行权限设置，因此启动命令应包含shell名称，类似于 sh script.sh。\n注意! 其中的 start time 及index 选项我简单浏览了 core/daemon/core/services/coreservices.py 的 CoreService类，似乎作者移除了这两项的实现。在后续的 ServiceShim 的 tovaluelist 方法中直接填入写死的index = 0以及time = 0。可能是原有的bug导致作者放弃了实现这个功能。\nShutdown 命令可选择终止与此服务关联的进程。通常，它们使用 kill 或 killall 命令向正在运行的进程发送kill 信号。如果服务没有使用 Shutdown 命令终止正在运行的进程，那么当终止 vnoded 守护进程(使用 kill -9命令)并摧毁命名空间时，进程将被杀死。指定 shutdown 命令是一个很好的实践，这将允许适当的进程终止，以及停止和重启服务的运行控制。\nValidate 命令按照启动命令执行。 Validate 命令可以执行应返回0值的流程或者脚本，对于启动出现问题的服务返回非0值。例如，pidof 命令将检查某个进程是否正在运行，是则返回0值。当 Validate 命令生成了一个非零返回值，这将产生一个异常而导致在 Check Emulation Light 中显示一个错误。\n在运行时启动、停止和重启服务，需要右键单击节点并使用 服务\u0026hellip; 菜单。\n新的服务 服务可以节省配置节点所需的时间，特别是当大量节点都需要类似的配置程序时。此时可以引入新的服务来使任务自动化。\n如果使用tlv等界面api配置如下所示：\n其中File name和startup为必选项，其作用为节点容器初始化后复制一份脚本名为File name的脚本至于temp中的节点文件夹，startup等命令除了初始化仿真会调用也可通过界面选项来使用，具体参考其他server选项做法。\n利用用户自定义 将新流程的配置捕获到服务中的最简单方法是使用 UserDefined 服务。这是一个空白服务，可以自定义其中的任何方面。 UserDefined 服务便于在添加新的服务类型之前测试服务。\n创建新的服务 修改如下所示的实例服务，以便做您想做的事情。它可以生成配置/脚本文件、每个节点的挂载路径、启动进程/脚本等。sample.py 是一个 Python 文件，它定义了一个或更多需要导入的类。您可以创建多个将被导入的Python文件。将任何新文件名添加到 init.py 文件中。\n把这些文件放在诸如 /home/username/.core/myservices 这样的路径中。但应注意路径最后的名称 myservices 不应该命名为类似于与现有的Python名称冲突的 服务（使用的语法是 from myservices import *\u0026rsquo;）\n添加命令 custom_services_dir = /home/username/.core/myservices 到 /etc/core/core.conf 文件中。\n注意: 在 custom_services_dir 使用的路径名应该是唯一的，并且不应该对应于任何现有的Python模块名。例如，不要使用 subprocess 或是 services 名称。\n重启 CORE 守护进程 (core-daemon). 任何导入错误 (Python 语法)都应显示在 /var/log/core-daemon.log 日志文件上（或显示在屏幕上）。\n开始在节点上使用自定义服务吧。您可以创建使用您的服务的新节点类型，或者更改现有节点的默认服务，又或者更 改单个节点。\n如果您已经创建了一个可能对他人有用的新服务类型，请考虑将其贡献给 CORE 项目。\n自定义服务示例 下面是带有一些说明文档的自定义服务框架。大多数人可能只会设置所需的类变量 (name/group)。然后定义 configs （他们想要生成的文件），并实现 generate_config 函数来动态创建所需的文件。最后，被提供的 startup 命令通常倾向于运行生成的shell文件。\n\u0026quot;\u0026quot;\u0026quot; Simple example custom service, used to drive shell commands on a node. \u0026quot;\u0026quot;\u0026quot; from typing import Tuple from core.nodes.base import CoreNode from core.services.coreservices import CoreService, ServiceMode class ExampleService(CoreService): \u0026quot;\u0026quot;\u0026quot; Example Custom CORE Service :cvar name: name used as a unique ID for this service and is required, no spaces :cvar group: allows you to group services within the GUI under a common name :cvar executables: executables this service depends on to function, if executable is not on the path, service will not be loaded :cvar dependencies: services that this service depends on for startup, tuple of service names :cvar dirs: directories that this service will create within a node :cvar configs: files that this service will generate, without a full path this file goes in the node's directory e.g. /tmp/pycore.12345/n1.conf/myfile :cvar startup: commands used to start this service, any non-zero exit code will cause a failure :cvar validate: commands used to validate that a service was started, any non-zero exit code will cause a failure :cvar validation_mode: validation mode, used to determine startup success. NON_BLOCKING - runs startup commands, and validates success with validation commands BLOCKING - runs startup commands, and validates success with the startup commands themselves TIMER - runs startup commands, and validates success by waiting for \u0026quot;validation_timer\u0026quot; alone :cvar validation_timer: time in seconds for a service to wait for validation, before determining success in TIMER/NON_BLOCKING modes. :cvar validation_period: period in seconds to wait before retrying validation, only used in NON_BLOCKING mode :cvar shutdown: shutdown commands to stop this service \u0026quot;\u0026quot;\u0026quot; name: str = \u0026quot;ExampleService\u0026quot; group: str = \u0026quot;Utility\u0026quot; executables: Tuple[str, ...] = () dependencies: Tuple[str, ...] = () dirs: Tuple[str, ...] = () configs: Tuple[str, ...] = (\u0026quot;myservice1.sh\u0026quot;, \u0026quot;myservice2.sh\u0026quot;) startup: Tuple[str, ...] = tuple(f\u0026quot;sh {x}\u0026quot; for x in configs) validate: Tuple[str, ...] = () validation_mode: ServiceMode = ServiceMode.NON_BLOCKING validation_timer: int = 5 validation_period: float = 0.5 shutdown: Tuple[str, ...] = () @classmethod def on_load(cls) -\u0026gt; None: \u0026quot;\u0026quot;\u0026quot; Provides a way to run some arbitrary logic when the service is loaded, possibly to help facilitate dynamic settings for the environment. :return: nothing \u0026quot;\u0026quot;\u0026quot; pass @classmethod def get_configs(cls, node: CoreNode) -\u0026gt; Tuple[str, ...]: \u0026quot;\u0026quot;\u0026quot; Provides a way to dynamically generate the config files from the node a service will run. Defaults to the class definition and can be left out entirely if not needed. :param node: core node that the service is being ran on :return: tuple of config files to create \u0026quot;\u0026quot;\u0026quot; return cls.configs @classmethod def generate_config(cls, node: CoreNode, filename: str) -\u0026gt; str: \u0026quot;\u0026quot;\u0026quot; Returns a string representation for a file, given the node the service is starting on the config filename that this information will be used for. This must be defined, if \u0026quot;configs\u0026quot; are defined. :param node: core node that the service is being ran on :param filename: configuration file to generate :return: configuration file content \u0026quot;\u0026quot;\u0026quot; cfg = \u0026quot;#!/bin/sh\\n\u0026quot; if filename == cls.configs[0]: cfg += \u0026quot;# auto-generated by MyService (sample.py)\\n\u0026quot; for iface in node.get_ifaces(): cfg += f'echo \u0026quot;Node {node.name} has interface {iface.name}\u0026quot;\\n' elif filename == cls.configs[1]: cfg += \u0026quot;echo hello\u0026quot; return cfg @classmethod def get_startup(cls, node: CoreNode) -\u0026gt; Tuple[str, ...]: \u0026quot;\u0026quot;\u0026quot; Provides a way to dynamically generate the startup commands from the node a service will run. Defaults to the class definition and can be left out entirely if not needed. :param node: core node that the service is being ran on :return: tuple of startup commands to run \u0026quot;\u0026quot;\u0026quot; return cls.startup @classmethod def get_validate(cls, node: CoreNode) -\u0026gt; Tuple[str, ...]: \u0026quot;\u0026quot;\u0026quot; Provides a way to dynamically generate the validate commands from the node a service will run. Defaults to the class definition and can be left out entirely if not needed. :param node: core node that the service is being ran on :return: tuple of commands to validate service startup with \u0026quot;\u0026quot;\u0026quot; return cls.validate ","id":23,"section":"posts","summary":"服务 CORE 使用服务的概念来指定节点启动时运行哪些进程或脚本。路由器和PC等第三层节点是由他们所运行的服务来定义的。 可以为每个节点定制服务，也可以","tags":["仿真"],"title":"Core services","uri":"https://liangkang233.github.io/2021/07/services/","year":"2021"},{"content":"CORE 分布式仿真 概述 大型模拟场景可以部署在多个模拟服务器上由单个Core-GUI控制。表示整个拓扑的GUI可以是 其中一台模拟服务器或单独的只运行GUI的机器。\n作为模拟的每台机器都需要安装一个分布式CORE包和一些允许root用户使用ssh的配置。\nCORE 配置 使用分布式功能所需的核心配置设置：\n最好先了解CORE的控制网络章节内容\ncore运行的配置文件默认为 /etc/core/core.conf 可以修改该文件来配置core的相关参数，或者运行core-daemon时指定自定义的配置文件(-f 选项)\n# 取消注释并将其设置为远程服务器的地址 # 此地址用于主控网络返回至主机，即为主服务器真实IP地址 distributed_address = 129.168.0.101 # 不配置Emance默认所有分布式服务器和主控制服务器使用同一主控制网段 # 仿真中所有节点都会分配一个该网段内IP并将节点attach每台服务器对应的主控网桥上 # 各分布式主网桥数据会直接汇总到主服务器的控制网桥，服务器的主控制网络会自动建立一个隧道联通物理网卡eth0和主控网桥 controlnet = 172.16.0.0/24 若是单独跑分布式数据，这里主控网不配置也是能走通的，可不开启。\n分布式 EMANE 特定配置 EMANE 需要在 core.conf 中配置 controlnet 才能正确启动。 地址前的名称需要与配置的分布式服务器的名称相匹配。\n# 与上面所有分布式服务器的主控制网桥使用同一网段（在同一局域网内）不同 # 分布式Emance要求每一台分布服务器的主控制网桥工作在不同网段 # 最后各分布式服务器主控网桥的数据会通过隧道汇总到主控网络 controlnet = 172.16.0.0/24 controlnet1 = 172.16.1.0/24 emane_event_generate = True 配置 SSH 分布式CORE使用python fabric库在远程服务器上通过SSH运行命令。\n远程 GUI 终端 您需要确保每个服务器上的用户名相同，因为运行CORE GUI的用户会登录相同用户的远程bash（ssh）\nEdit -\u0026gt; Preferences\u0026hellip; -\u0026gt; Terminal program: 目前建议将此设置为xterm -e作为默认值，gnome-terminal无法工作。 如果没有安装，可能需要安装xterm\nsudo apt install xterm 分布式服务器SSH配置 首先，必须将分布式服务器配置为允许通过SSH进行无密码的root用户登录，或者分布式服务器插入主服务器的公钥免密登录。\n在分布式服务器上如此配置：\n# 安装 openssh-server sudo apt install openssh-server # 打开 sshd 配置 vi /etc/ssh/sshd_config # 验证这些配置是否启用 PermitRootLogin yes PasswordAuthentication yes # 如果需要，添加/修改以下行以允许SSH # 接受所有env变量 AcceptEnv * # 重启 sshd sudo systemctl restart sshd 在主服务器上：\n# 安装环境所需包 sudo apt install openssh-client 法1：公钥登录（推荐）\n# 在主服务器上生成SSH公、密钥 # 要确保生成的公钥密钥文件的绝对路径是 ~/.ssh，如下所示密钥文件为core，公钥文件为core.pub ssh-keygen -o -t rsa -b 4096 -f ~/.ssh/core 如果遇到类似 not a valid RSA private key file 的错误时使用此条命令。\nssh-keygen -o -m PEM -t rsa -b 4096 -f ~/.ssh/core 这是因为现在通过 ssh-keygen -o 使用新的OpenSSH格式而不是更兼容的PEM格式保存私钥。新格式增加了对暴力破解密码的抵抗力，但OpenSSH 6.5之前的版本不支持所以该模块无法识别。Ed25519密钥总是使用新的私钥格式。-m 支持格式有 “RFC4716”(RFC4716/SSH2)、“PKCS8”(PEM PKCS8)或“PEM”\n# 将公钥复制到从服务器地址server的authorized_keys文件中（需输入密码登录） ssh-copy-id -i ~/.ssh/core root@server # 当然运行core-gui的user用户也需要如上配置，否则无法使用远程终端界面 ssh-copy-id -i ~/.ssh/core user@server # 配置fabric使用Core SSH密钥 sudo vi /etc/fabric.yml # 添加/修改配置文件，其中路径中的user改为对应用户名 connect_kwargs: {\u0026quot;key_filename\u0026quot;: \u0026quot;/home/user/.ssh/core\u0026quot;} 法2：设置无需密码登录\n# 在分布式服务器上，打开 sshd 配置 vi /etc/ssh/sshd_config # 将root登录的配置更改为不需要密码 PermitRootLogin without-password # 重启 sshd sudo systemctl restart sshd 在 GUI 中添加仿真服务器 在 core-gui 的导航菜单中： Session -\u0026gt; Emulation servers\u0026hellip; 在出现的对话框中，添加或修改现有服务器（如果存在）以使用您计划使用的服务器的名称、地址和端口（真实环境下参数）\n服务器配置默认加载到下面的GUI 的配置文件 ~/.core/servers.conf\n# 名字 地址 端口 server2 192.168.0.2 4038 分配节点 用户需要为场景中的仿真服务器分配节点。不分配意味着节点将在主服务器上模拟。在每个节点的配置窗口中，位于Node name和Image按钮之间的下拉框将选择模拟服务器的名称。默认情况下，此菜单显示 (none)，表示该节点将在 master 上本地模拟。进入执行模式时，CORE GUI 将在其分配的仿真服务器上部署节点。\n分配仿真服务器的另一种方法是使用选择工具选择一个或多个节点（按住 Ctrl 键单击以选择多个），然后右键单击其中一个节点并选择 Assign to\u0026hellip;.\nCORE emulation servers对话框也可以用于为服务器分配节点。分配的服务器名称显示在节点名称旁边的括号中。要将所有节点分配给其中一台服务器，请单击服务器名称，然后单击all nodes按钮. 已分配节点的服务器在服务器列表中显示为蓝色. 另一种选择是先选择一个节点子集, 然后打开CORE emulation servers 选项并使用 selected nodes 按钮.\n注意: 如果要在主服务器上运行这些节点，则不要分配它们。无需显式地将节点分配给主服务器\nGUI 可视化 如果位于不同服务器上的两个节点之间存在链接，GUI将用虚线绘制链接。\n问题和局限性 无线模型\n只有当 EMANE 模型用于 WLAN 时，无线节点，即连接到 WLAN 节点的那些节点，才能被分配到不同的仿真服务器并参与相同的无线网络。由于使用了 Linux 网桥和 ebtables 规则，basic无线模型不能跨多个服务器工作\n主从服务器流量\n自己测试发现，所有仿真中节点跨从服务器数据都是先发送到主服务器上再转发至从服务器，而且主控制网络路由也是需要主服务器转发。从服务器数量增多后势必导致主服务器转发路由负荷过大。正在测试能否使用控制网间的隧道或其他方法使从服务器间有直接联通的链路，而非主服务器转发。\n注意: basic无线模型不支持分布式仿真，但EMANE支持\n当节点跨服务器链接时， core-daemons将在执行时自动在节点之间创建必要的隧道。应注意安排拓扑以使隧道的数量最小化。隧道在服务器之间传送数据以连接拓扑中指定的节点。这些隧道是使用 GRE 隧道创建的，类似于隧道工具\n分布式配置清单 在主服务器上安装 CORE 在所有需要的服务器上安装分布式 CORE 包 在所有服务器上安装和配置公钥 SSH 访问（如果想要使用双击打开终端或是窗口部件）为 GUI 用户（用于终端）和 root 运行 CORE 命令 根据需要更新 CORE 配置 选择参与分布式仿真的服务器 将节点分配给所需的服务器，若是节点在主服务器仿真则不分配（NONE）。 主服务器按start按钮启动分布式仿真，分服务器无须开启gui和daemon ","id":24,"section":"posts","summary":"CORE 分布式仿真 概述 大型模拟场景可以部署在多个模拟服务器上由单个Core-GUI控制。表示整个拓扑的GUI可以是 其中一台模拟服务器或单独的只运行","tags":[""],"title":"Core 分布式","uri":"https://liangkang233.github.io/2021/07/distributed/","year":"2021"},{"content":"CORE 控制网络（CTRL NET） 概述 CORE 控制网络允许虚拟节点与其宿主环境进行通信。有两种类型：主控制网络和辅助控制网络。主控制网络主要用于与主机的虚拟节点通信以及多服务器分布式环境中的主从通信。辅助控制网络的功能为将由命名空间托管的仿真软件流量路由至测试网络场景。\n激活主控制网络 在 Session Menu有一个选项来设置 control network prefix.\n这可以设置为网络前缀（网段），例如 172.16.0.0/24。将在网段范围内的最后一个地址（例如 172.16.0.254）的主机上创建一个网桥，并且每个节点将有一个额外的 ctrl0 控制接口，并配置一个与其节点号相对应的ip地址（例如172.16.0.3 表示 n3)\n还可以通过在 /etc/core/core.conf 配置文件中设置 controlnet 行来指定主控制网络的默认值，新会话将默认使用该行。要同时使用控制网络运行多个会话，应使用 session 选项而不是 core.conf 默认值\n注意: 如果您有超过 253 个节点的大型场景，请使用 /23 或更大的网段。\n注意: 如果前一个会话已设置控制网络并且其网桥仍在运行，则继续使用控制网络运行会话可能会失败。首先关闭上一个会话或等待它完成。如果不能，则可能需要重新启动核心守护程序并手动删除延迟的桥接器\n# 重启 CORE Daemon sudo /etc/init.d core-daemon restart # 移除残留的控制网桥 ctrlbridges=`brctl show | grep b.ctrl | awk '{print $1}'` for cb in $ctrlbridges; do sudo ifconfig $cb down sudo brctl delbr $cb done **注意:**如果在 /etc/core/core.conf 中对主控制网络配置所做的调整似乎没有生效，请检查Session Menu, the *Options\u0026hellip;*对话框中是否有任何设置，它们可能需要清除。这些会话的设置会覆盖 /etc/core/core.conf 中的默认值。\n分布式会话中的控制网络 当主控制网络做为分布式会话激活时，将在每个从服务器上创建一个控制网桥，并通过GRE隧道返回到主服务器的网桥。从控制网桥没有分配地址，可以从主机访问任何节点(本地或远程)，就像单个服务器的情况一样。\n在某些情况下，远程模拟节点需要与运行它们的主机而不是主服务器进行通信。可以在会话选项或 /etc/core/core.conf 中指定多个控制网络前缀，以空格分隔并以主服务器开头。每个条目的格式为 server:prefix 。如下所示，更改 /etc/core/core.conf 默认配置，为服务器 core1、core2 和 core3 分配了控制网络网段。也可在会话session选项中设定。\ncontrolnet=core1:172.16.1.0/24 core2:172.16.2.0/24 core3:172.16.1.0/24 然后，控制网桥将被分配如下\n* core1 = 172.16.1.254 （假设它是主服务器） * core2 = 172.16.2.254 * core3 = 172.16.3.254 仍将构建从服务器导向主服务器的隧道，但如果需要在控制网络前缀之间建立网络，则需要用户添加适当的路由。控制网络脚本可能对此有所帮助。\n控制网络脚本 可以使用 /etc/core/core.conf 文件中的 controlnet_updown_script 选项指定控制网络脚本。该脚本将在网桥建成（并分配地址）后运行，命令的第一个参数是网桥的名称，第二个参数是关键字 “startup”。该脚本将在移除桥时会再次被调用，命令的第一个参数是网桥的名称，命令的第二个参数是关键字 “shutdown”。该脚本默认位置在~/core/daemon/examples/controlnet_updown中。\n辅助控制网络 从 EMANE 0.9.2 开始，CORE 将在命名空间内运行 EMANE 实例。由于建议将 OTA 流量与其他流量分开，因此我们将需要多个从命名空间导出的通道。最多可以定义三个辅助控制网络。 /etc/core/core.conf 文件中设置了多个控制网络。线路 controlnet1、controlnet2 和 controlnet3 定义辅助网络。\n例如 /etc/core/core.conf 中配置如下\ncontrolnet = core1:172.17.1.0/24 core2:172.17.2.0/24 core3:172.17.3.0/24 controlnet1 = core1:172.18.1.0/24 core2:172.18.2.0/24 core3:172.18.3.0/24 controlnet2 = core1:172.19.1.0/24 core2:172.19.2.0/24 core3:172.19.3.0/24 # 经过测试发现，源码已经改变读取配置方式，辅助控制网只会接入第一个网段。如下配置即可 controlnet0 = 172.17.1.0/24 controlnet1 = 172.18.1.0/24 controlnet2 = 172.19.1.0/24 # controlnet配置且controlnet0未配置时，controlnet就是主控网，否则主控网网段为controlnet0 # 辅助控制网接口只在配置了emane的节点容器上生成，主控网间通信都是gre通向主服务器转发。 # 而辅助控制网接口attach节点外物理主机的网桥，并且各分布式辅助网在同一局域网配置路由后无视仿真拓扑可直接通信。 这将激活主控制网络controlnet和两个辅助控制网络，并向每个节点添加接口 ctrl0、ctrl1、ctrl2。例如在 EMANE 选项对话框中将 ctrl1 分配给 OTA 管理器设备，将 ctrl2 分配给事件服务设备，并将 ctrl0 留给 CORE 控制流量（主控网络）\nNOTE: controlnet0 可以用来代替 controlnet 来配置主控制网络\n与主控制网络不同，辅助控制网络不会使用隧道，因为它们的主要目的是有效地传输多播 EMANE OTA 和事件流量。\n请注意，辅助控制网络没有针对每个会话的配置\n为了在分布式测试环境中扩展辅助控制网络，需要向其中添加主机网络接口。 /etc/core/core.conf 中的以下几行将主机设备的 eth1、eth2 添加到 controlnet1、controlnet2：\ncontrolnetif1 = eth1 controlnetif2 = eth2 NOTE: 无需为主控制网络分配接口，因为使用servers.conf 中提供的IP 地址在主设备和从设备之间形成隧道\n下图是上述配置的示意图：\n","id":25,"section":"posts","summary":"CORE 控制网络（CTRL NET） 概述 CORE 控制网络允许虚拟节点与其宿主环境进行通信。有两种类型：主控制网络和辅助控制网络。主控制网络主要用于与主机的","tags":[""],"title":"Core 控制网络","uri":"https://liangkang233.github.io/2021/07/ctrlnet/","year":"2021"},{"content":"Core 环境搭建 推荐使用Vscode编辑代码，可以安装对应python扩展跳转定义声明等。\n# 更新软件包索引，并且安装依赖软件： sudo apt update # 启用 Visual Studio Code 源仓库，输入： sudo apt install software-properties-common apt-transport-https wget # 使用 wget 命令插入 Microsoft GPG key ： wget -q https://packages.microsoft.com/keys/microsoft.asc -O- | sudo apt-key add - # 启用 Visual Studio Code 源仓库: sudo add-apt-repository \u0026quot;deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main\u0026quot; sudo apt install code 安装抓包工具和ssh等组件\nsudo apt-get install openssh-client openssh-server isc-dhcp-server isc-dhcp-client \\ tcpdump openvpn traceroute wireshark iperf3 sudo setcap 'CAP_NET_RAW+eip CAP_NET_ADMIN+eip' /usr/bin/dumpcap sudo adduser $USER wireshark 安装Core 依照手册教程即可：列出遇到的问题。推荐安装core在虚拟环境中（默认选项）\n# 更新python和pip python3 -m pip install -U pip # 或者直接apt-get sudo apt install python3 python3-pip # clone CORE repo git clone https://github.com/coreemu/core.git cd core # 脚本用法: install.sh [-v] [-d] [-l] [-p \u0026lt;prefix\u0026gt;] # -v enable verbose install # -d enable developer install # -l enable local install, not compatible with developer install # -p install prefix, defaults to /usr/local # install core to virtual environment ./install.sh -p \u0026lt;prefix\u0026gt; # install core locally ./install.sh -p \u0026lt;prefix\u0026gt; -l 自动安装脚本install.sh将会执行以下工作\n安装安装所需的基础工具python3, pip, pipx, invoke, poetry 为构建Core安装系统依赖 clone/build/install OPSF MDR 的工作版本 通过传入参数标志，设定将Core安装到poetry管理的虚拟环境中或真实环境中 根据安装类型来安装适当的Python位置的指向脚本 根据安装类型来安装适当的Python位置的systemd服务 运行软件安装脚本install.sh报错或无效时会直接停止导致后续命令不执行。\n如果是因为模块已经安装过，打开脚本进行查看对应安装命令，卸载需要删掉的环境模块即可。\nInvok命令的使用：\n其实install脚本就是运行invoke对应选项的安装，使用如下教程来进行core的安装卸载\ninv --list #list 指令选项: daemon #运行 core-daemon install #安装 core, poetry, scripts, service, ospf mdr install-emane #安装 emane and the python bindings install-scripts #安装 core 脚本执行文件, 修改以利用虚拟环境 install-service #安装 systemd core 服务 test #运行 core tests test-emane #运行 core emane tests test-mock #运行 core tests 使用 mock 来避免以管理员(sudo)来执行 uninstall #卸载 core, scripts, service, virtual environment, 清理 build 目录 #安装的详细帮助信息 inv -h install Usage: inv[oke] [--core-opts] install [--options] [other tasks here ...] Docstring: install core, poetry, scripts, service, and ospf mdr Options: -d, --dev 安装开发模式 -p STRING, --prefix=STRING 设置脚本安装路径，默认是/usr/local -v, --verbose 启用 verbose 关于汉化gui界面的重装\n# 先卸载 sudo make uninstall make clean ./bootstrap.sh clean #安装 ./bootstrap.sh ./configure make sudo make install # 上述代码就是早期版本的生成和卸载 # 新版本直接使用invoke卸载重装整个即可,当然有需要可以在invole脚本对应的task.py中添加instal-core，如下所示 @task() def reinstall_core( c, dev=False, verbose=False, local=False, prefix=DEFAULT_PREFIX, install_type=None ): \u0026quot;\u0026quot;\u0026quot; reinstall core by LK233 \u0026quot;\u0026quot;\u0026quot; hide = not verbose p = Progress(verbose) c.run(\u0026quot;sudo -v\u0026quot;, hide=True) print(f\u0026quot;uninstalling core with prefix: {prefix}\u0026quot;) with p.start(\u0026quot;uninstalling core\u0026quot;): c.run(\u0026quot;sudo make uninstall\u0026quot;, hide=hide) with p.start(\u0026quot;cleaning build directory\u0026quot;): c.run(\u0026quot;make clean\u0026quot;, hide=hide) c.run(\u0026quot;./bootstrap.sh clean\u0026quot;, hide=hide) print(f\u0026quot;installing core with prefix: {prefix}\u0026quot;) with p.start(\u0026quot;building core\u0026quot;): build_core(c, hide, prefix) with p.start(\u0026quot;installing vcmd/gui\u0026quot;): install_core(c, hide) 整个core套件卸载重装时遇到的问题\n由于卸载脚本运行时没有卸载虚拟环境中的poetry，导致之后运行安装脚本invoke报错停止。可以通过在安装脚本添加\u0026ndash;force强制安装或卸载脚本添加卸载poetry代码解决，最快的解决办法（core安装在虚拟环境的情况）卸载后在core的根目录执行\npipx uninstall poetry\n安装Emane 自动安装脚本安装的Emane版本为1.25，Core虚拟环境安装仅支持Emane1.21以上版本\ninvoke脚本任务能自动安装Emane，它从源代码来构建安装Emane，但在较老的Protobuf编译器上的系统存在问题。\n# 安装Emane到core虚拟环境中 inv install-emane # 安装到真实python环境 inv install-emane -l 另外，EMANE可以从deb或RPM包或从源代码安装。详见EMANE GitHub。需要注意的是，如果不是本地python环境安装，python需要绑定到CORE的virtualenv中。(Emane安装教程)需要将EMANE python绑定安装到CORE虚拟环境virtualenv中。如下所示：（安装过程与invok脚本安装emane类似）\n# 克隆和构建Emane python绑定 git clone https://github.com/adjacentlink/emane.git cd emane ./autogen.sh PYTHON=python3 ./configure --prefix=/usr cd src/python make # 安装到core虚拟环境 cd \u0026lt;CORE_REPO\u0026gt;/daemon poetry run pip install \u0026lt;EMANE_REPO\u0026gt;/src/python 运行core 要测试CORE Network Emulator是否工作，请启动CORE守护进程和GUI。 首先，启动CORE守护进程:\nsudo service core-daemon start #直接开新终端运行，方便看日志 sudo core-daemon #守护进程帮助手册 -h -f CONFIGFILE, --configfile CONFIGFILE 读取配置文件CONFIGFILE，默认是/etc/core/core.conf -p PORT, --port PORT 设定port为守护进程监听端口，默认4038 --ovs 启用实验ovs模式，默认为false --grpc-port GRPCPORT 设定GRPCPORT为GRPC监听端口，默认50051 --grpc-address GRPCADDRESS 设定GRPCADDRESS为监听grpc地址;默认本地主机 -l LOGFILE, --logfile LOGFILE 设置LOGFILE为守护进程日志选项，默认为/etc/core/logging.conf，错误日志为core-daemon.log 如果在安装CORE后没有重新启动，此时可能会遇到错误。如果您看到告诉您文件core守护进程的错误。 服务不存在，请重新启动系统。重新启动后，再次尝试启动core守护进程服务。 然后，运行CORE GUI\ncore-gui 如果你创建自己的python脚本来直接运行CORE或者使用gRPC/TLV api，你需要确保你是在安装的虚拟环境的上下文中运行它们。为了帮助支持这个CORE提供了CORE-python可执行文件。这个可执行文件将允许你进入CORE的python虚拟环境解释器或在其中运行脚本。\ncore-python \u0026lt;script\u0026gt; 若是安装在真实环境中直接执行\npython3 \u0026lt;script\u0026gt; Core文件介绍 下面是运行自动安装后将安装的文件列表。\n**注:**默认的安装前缀是/usr/local，但可以更改如下所示\n执行文件 \u0026lt;prefix\u0026gt;/bin/{core-daemon, core-gui, vcmd, vnoded, etc} tcl/tk gui 文件 \u0026lt;prefix\u0026gt;/lib/core \u0026lt;prefix\u0026gt;/share/core/icons 示例场景 imn 文件 \u0026lt;prefix\u0026gt;/share/core/examples python 文件 poetry 虚拟环境 cd \u0026lt;repo\u0026gt;/daemon \u0026amp;\u0026amp; poetry env info ~/.cache/pypoetry/virtualenvs/ 本地python安装 default install path for python3 installation of a wheel python3 -c \u0026quot;import core; print(core.__file__)\u0026quot; 配置文件 /etc/core/{core.conf, logging.conf} ospf mdr 仓库文件 \u0026lt;repo\u0026gt;/../ospf-mdr emane 仓库文件 \u0026lt;repo\u0026gt;/../emane 执行文件 安装完成后，它将安装以下脚本。\n名称 描述 core-cleanup 删除工具，帮助删除Core创建的容器，网桥，目录 core-cli 运行支持的Core服务器，提供TLV和gRPC api core-daemon runs the backed core server providing TLV and gRPC APIs core-gui 运行传统的基于tcl/tk的GUI core-imn-to-xml 帮助自动将.imn文件转换为.xml格式的工具 core-manage 用于添加、移除或检查|中的服务、模型和节点类型的工具 core-pygui 运行新的的基于Python的GUI core-python 运行core虚拟环境内的python core-route-monitor 帮助监控节点间的流量并将其提供给SDT的工具 core-service-update 更新修改遗留服务以匹配当前命名的工具 coresendmsg 从命令行发送TLV API命令的工具 ","id":26,"section":"posts","summary":"Core 环境搭建 推荐使用Vscode编辑代码，可以安装对应python扩展跳转定义声明等。 # 更新软件包索引，并且安装依赖软件： sudo apt update # 启用 Visual Studio Code 源","tags":[""],"title":"Core Emane环境搭建","uri":"https://liangkang233.github.io/2021/07/installation/","year":"2021"},{"content":" Core 架构 Python API gRPC API Core架构 主要组件 Core守护(服务)进程 (core-daemon)\n该程序是利用小型C二进制文件来创建节点的Python仿真程序 管理网络节点、链路的仿真会话 使用Linux命名空间创建节点 链路是由Linux网桥和虚拟以太网设备TAP等创建的 链路数据包是通过流量控制来操纵的 仿真过程可以由CORE GUI控制 提供自定义TLV API和gRPC API Core-gui\nGUI和守护进程通过自定义TLV API进行通信 拖放节点和链接的创建 可以在运行的会话中启动仿真节点的终端 可以保存/打开场景文件重新创建以前的会话 TCL/TK 程序 Coresendmsg\n用于将TLV API消息发送到核心守护进程的命令行实用程序 虚拟命令终端 (vcmd)\n用于向节点发送shell命令的命令行实用程序 会话Sessions CORE可以同时创建和运行多个模拟会话，下面表格从左向右概述了典型GUI交互期间会话将转换的状态。\n定义初始化 配置参数 安装模拟节点 运行仿真 数据采集 停止仿真 XML/IMN 会话 Gui绘制脚本 配置hooks、配置服务、配置移动性和WLAN、配置Emance 创建节点、接口桥接链路、启动服务 移动性仿真、交互shell、状态设定脚本 关闭服务销毁接口、桥接链路、节点 工作原理 CORE框架运行在Linux上，并使用Linux命名空间创建节点容器。这些节点使用Linux网桥和虚拟接口连接在一起。CORE会话是一组节点和链接，它们出于特定目的一起工作。Linux网络名称空间(也称为netns: Linux network namespaces )是CORE使用的主要技术。大多数最新的Linux发行版都具有开箱即用的支持名称空间的内核。每个命名空间都有自己的进程环境和私有的网络堆栈。网络名称空间在CORE中共享相同的文件系统。CORE将这些名称空间与Linux以太网桥接结合起来，形成网络。使用Linux Netem排队规则应用链接特性。Ebtables是Linux桥上的以太网帧过滤方法，通过使用ebtables规则控制哪些接口可以发送和接收来模拟无线网络。\n之前的工作 Tcl/Tk CORE GUI最初起源于萨格勒布大学的开源IMUNES项目，作为波音研究与技术网络技术研究小组2004年的一个定制项目。从那时起，他们开发了使用Linux命名空间的CORE框架，开发了一个Python框架，并进行了大量的用户和内核空间开发，例如支持无线网络、IPsec、分布式仿真、仿真集成等等。IMUNES项目还包括用户空间和内核组件。\n开源项目和资源 CORE已经由波音在BSD许可下发布给开源社区。如果您发现CORE对您的工作有用，请返回到项目中。贡献可以像报告bug、向邮件列表提供鼓励或技术建议一样简单，也可以包括提交补丁或维护工具的各个方面。\nPython API 关键要理解上面的架构图，就能明白下面这些api的具体实现\n使用Python API可以完全控制仿真的所有方面，这些python脚本需要以 root 权限运行，因为它们会创建新的网络命名空间。\n一般情况下 使用这些python api 的CORE Python 程序不会连接到 CORE daemon（可以理解为它自己就是一个core-daemon），实际上，core-daemon 只是另一个使用 CORE Python api 模块并与 GUI 交换消息的 Python 脚本。相关api文件查看该路径 core/daemon/core/emulator/data.py 的 InterfaceData类。\n具体例子就不分析了，直接看使用gRPC协议的 api 如何使用。\ngRPC API core-pygui 与 coredaemon 的界面交互就是通过 gRPC api 来驱动core的所有功能，所以调用这些api需要启动 core-daemon。可以从包含在 CORE 中的原始生成的 grpc 文件创建一个 python client，或者可以利用 core 源码中 提供的 gRPC api 来帮助封装一些功能做进一步的开发。\ngRPC api是指使用了gRPC框架通信协议的api，其代码实现可以是python c++等语言(这里使用的还是python语言)与上述的Python api并非同种api。\nCoreGrpcClient 提供了一个 python 客户端包装器其封装了一些常用的api调用，下面的示例就是调用的它。由于 gRPC 基于 HTTP2，代理配置可能会导致问题。默认情况下，gRPC 客户端禁用代理支持以避免启用代理时出现问题。Proto 文件用于定义用于与此 API 接口的 API 和 protobuf 消息。 可以在此处找到它们以查看正在发生的事情的细节以及将返回的响应消息值。\n具体例子和python api的例子在同一目录中，可以看到其api的调用与功能与python api非常相似，个人猜测是原有的 coresendmsg core-gui 等程序调用的 tlv 协议作者想一步步弃用，所以为了兼容降低学习成本根据原来tlv格式的api使用方法 来设计封装 gRPC api。该上级目录其中还包含了docker、lxd映射到core仿真中的某个节点的示例，后续有可能会进行相关的开发。\n","id":27,"section":"posts","summary":"Core 架构 Python API gRPC API Core架构 主要组件 Core守护(服务)进程 (core-daemon) 该程序是利用小型C二进制文件来创建节点的Python仿真程序 管理网络节点、链路的","tags":[""],"title":"Core 仿真架构","uri":"https://liangkang233.github.io/2021/07/architecture/","year":"2021"},{"content":"使用 CORE GUI 下图显示 CORE GUI:\n概述 GUI 用于在画布上绘制节点和网络设备，将它们连接在一起，以创建模拟的网络会话。\n按下启动按钮后，CORE 将通过这些阶段进行，保持在运行时阶段。会话停止后，CORE 将进入数据收集阶段，然后卸载模拟状态。\nCORE 可自定义以在每个状态执行任何操作。有关何时达到这些会话状态，请参阅会话菜单上的Hooks\u0026hellip;\n必要条件 除了安装CORE之外，还必须运行CORE守护进程。\n在命令行中使用systemd或sysv。\n# systemd sudo systemctl daemon-reload sudo systemctl start core-daemon # sysv sudo service core-daemon start 还可以直接从命令行调用守护进程，如果您想直接查看日志输出，这很有用。\n# direct invocation sudo core-daemon 操作模式 核心GUI有两种主要操作模式，编辑和执行模式。运行GUI，通过键入没有选项Core-gui，从编辑模式开始。节点使用左侧的工具栏绘制在空白画布上，并从右键单击菜单或双击菜单进行配置。GUI 不需要作为root运行。\n编辑完成后，按下绿色开始按钮（或从会话菜单中选择执行）会因 Linux 内核中的拓扑，然后进入执行模式。在执行模式下，用户可以通过双击或右键单击运行模拟的计算机进行交互。编辑工具栏消失，由执行工具栏替换，该工具栏在运行仿真时提供工具。按下红色停止按钮（或从会话菜单中选择终止）将破坏运行模拟并将 CORE 返回到编辑模式。\nCORE可以通过指定 start 命令行直接在执行模式下启动场景：\ncore-gui --start ~/.core/configs/myfile.imn 一旦模拟开始运行，就可以关闭GUI，并出现提示询问是否应该终止仿真。之后运行时，GUI会提示重新连接到现有的会话。\nGUI可以在Linux上以普通用户的身份运行。GUI可以连接到不同的地址或TCP端口使用**\u0026ndash;address和/或\u0026ndash;port**选项。默认值如下所示。\ncore-gui --address 127.0.0.1 --port 4038 工具栏 工具栏是一排按钮，沿Core gui窗口的左侧垂直运行。工具栏会根据操作模式而变化。\n编辑工具栏 当 CORE 处于编辑模式（默认值）时，垂直编辑工具栏位于核心窗口的左侧。\n以下是从顶部开始的每个工具栏项的简要说明。大多数工具被分组到相关的子菜单中，当您单击其组图标时会出现这些子菜单。\n图标 名字 描述 选择工具 用于选择、移动、配置节点的工具。 启动按钮 开始执行模式，实例化模拟节点。 链接 允许通过单击和拖动鼠标在两个节点之间绘制网络链接。 核心节点 这些节点将创建一个新的节点容器并运行相关服务。\n图标 名字 描述 路由器 运行Quagga OSPFv2和OSPFv3路由转发数据包。 主机 模拟服务器机具有默认路线，运行SSH服务器。 个人电脑 具有默认路线的基本模拟机器，默认情况下不运行任何进程。 指定路由器移动自组网协议（ MANET Designated Routers） 运行 Quagga OSPFv3 MDR 路由，用于管理优化路由。（MANETs: Mobile Ad Hoc Networks 移动自组网） 物理路由器（PRouter） 物理路由器代表了一个真实的试验机器。 编辑 生成自定义节点对话。 网络节点 这些节点主要用于创建一个 Linux 网桥，用于以下目的。\n图标 名字 描述 集线器hub 以太网集线器将传入的数据包转发到每个连接的节点。 交换机Switch 以太网交换机使用以太网地址哈希表智能地将传入的数据包转发给附加主机。 Wireless LAN 当路由器连接到此 WLAN 节点时，它们会加入无线网络，并绘制天线而不是连接线：WLAN节点通常根据连接的距离控制连接无线节点之间的连接。 RJ45 RJ45物理接口工具，仿真节点可链接到真正的物理接口：使用此工具，真正的网络和设备可以物理连接到实时运行模拟。 Tunnel Tool allows connecting together more than one CORE emulation using GRE tunnels. 注释工具 图标 名字 描述 Marker 用于在画布上绘制标记。 Oval 用于在背景中显示的画布上绘制圆圈。 Rectangle 用于在背景中显示的画布上绘制矩形。 Text 用于在画布上放置文本字幕。 执行工具栏 按下\u0026quot;开始\u0026quot;按钮后，CORE 切换到\u0026quot;执行\u0026quot;模式，核心窗口左侧的编辑工具栏替换为执行工具栏，下面是此工具栏上的项，从顶部开始。\n图标 名字 描述 Selection Tool 在执行模式下，选择工具可用于在画布周围移动节点，在节点上双击将打开该节点的外壳窗口：右键单击节点会调用该节点的运行时间选项的弹出菜单。 Stop Button 停止执行模式，终止仿真，将 CORE 返回到编辑模式。 Observer Widgets Tool 单击此放大镜图标可调用菜单以轻松选择\u0026quot;观察者小部件\u0026quot;。当\u0026quot;观察者小部件\u0026quot;处于活动状态时，图标具有较深的灰色背景，在此期间，将鼠标移到节点上会弹出该节点的信息显示。 Marker 用于在画布上画手线，在演示期间有用：标记未保存。 Two-node Tool 单击以选择开始和结束节点，并在这些节点之间运行一次性跟踪路由或节点之间连续*ping-R。*输出实时显示在结果框中，而 IP 地址则解析，并在 CORE 显示屏上突出显示完整的网络路径。 Run Tool 此工具允许轻松地在所有节点的全部或子集上运行命令。列表框允许选择任何节点。文本输入框允许输入任何命令。命令应立即返回，否则显示屏将阻止等待响应。例如，没有参数的ping命令不是个好主意。每个命令的结果都显示在结果框中。特殊文本\u0026quot;NODE\u0026quot;的第一次出现将替换为节点名称。命令不会尝试在不是路由器、PC 或主机的节点上运行，即使它们被选中。 菜单 菜单栏沿 CORE GUI 窗口的顶部运行，并提供对各种功能的访问。某些菜单可以通过单击顶部的虚线来分离，例如小部件菜单。\n查看菜单 \u0026ldquo;视图\u0026quot;菜单包含用于控制绘图画布上显示的内容的项目。\nOption Description Show Opens a submenu of items that can be displayed or hidden, such as interface names, addresses, and labels. Use these options to help declutter the display. These options are generally saved in the topology files, so scenarios have a more consistent look when copied from one computer to another. Show hidden nodes Reveal nodes that have been hidden. Nodes are hidden by selecting one or more nodes, right-clicking one and choosing hide. Locked Toggles locked view; when the view is locked, nodes cannot be moved around on the canvas with the mouse. This could be useful when sharing the topology with someone and you do not expect them to change things. 3D GUI\u0026hellip; 运行Preferences， 3D GUI command下定义的命令启动3D GUI。这通常是一个运行SDT3D显示的脚本。SDT是NRL的脚本显示工具，它基于美国宇航局基于java的WorldWind虚拟地球软件。 Zoom In Magnifies the display. You can also zoom in by clicking zoom 100% label in the status bar, or by pressing the + (plus) key. Zoom Out Reduces the size of the display. You can also zoom out by right-clicking zoom 100% label in the status bar or by pressing the - (minus) key. 工具菜单 工具菜单列出了不同的实用功能。\n选择 描述 Autorearrange all 自动排列画布上的所有节点。具有更多链接的节点移动到中心。此模式可以在放置节点时继续运行。要关闭此自动重新排列模式，请单击带有选定工具的画布空白区域，或再次选择此菜单选项。 Autorearrange selected 自动排列画布上选定的节点。 Align to grid 将节点移动到网格形成中，从画布左上角的最小编号节点开始，在垂直柱中排列节点。 Traffic\u0026hellip; 调用 CORE 流量流对话框，允许为模拟配置、启动和停止 MGEN 流量流。 IP addresses\u0026hellip; 调用 IP 地址对话框来配置自动处理新接口时使用的 IPv4/IPv6 前缀。 MAC addresses\u0026hellip; 调用 MAC 地址对话框来配置生成每个接口 MAC 地址时用作最低分节的起始编号。在进行 CORE 模拟之间的隧道时，应更改此值，以防止 MAC 解决冲突。 Build hosts file\u0026hellip; 调用\u0026quot;构建主机文件\u0026quot;对话框，根据仿真中使用的 IP 地址生成 /etc/host 文件条目。 Renumber nodes\u0026hellip; 调用\u0026quot;重新编号节点\u0026quot;对话框，允许在点击数时将一个节点编号与另一个节点编号交换。 Experimental\u0026hellip; 实验选项的菜单，如转换ns-2脚本到IMUNES imn拓扑，只支持基本的ns-2功能，以及一个自动划分拓扑到分区的工具。 Topology generator 打开要生成的拓扑的子菜单。您可以首先选择拓扑应该包含的节点类型，否则将默认选择路由器。节点可以随机放置、在网格中对齐或各种其他拓扑模式。下表列出了所有受支持的模式。 Debugger\u0026hellip; 打开Core Debugger执行任意 Tcl/Tk 命令。 拓扑发生器 模式 描述 随机 节点随机放置在画布上，但未链接在一起。这可以与 WLAN 节点一起快速创建无线网络。 网格 节点位于水平行中，从左上角开始，均匀地向右间隔：节点之间不链接。 已连接的网格 节点位于 N x M（宽度和高度）矩形网格中，每个节点都连接到上面、下面、左侧和右侧的节点。 链 节点在链条中一个接一个地连接在一起。 星 一个节点放置在中心，N 节点以圆形模式环绕，每个节点都链接到中心节点。 周期 节点以圆形模式排列，每个节点都连接到其邻居，形成封闭的圆形路径。 轮子 车轮模式将节点连接在星形和循环模式的组合中。 立方体 生成节点的立方体图。 全连接 创建一个结点的分队图，每个节点都连接到所有其他节点。 二分图 创建两个节点的双分方图，具有两组脱节的顶点。 部件菜单 小部件是 GUI 元素，允许与运行模拟进行交互。小部件通常自动在模拟节点上运行命令，以报告某种类型的状态信息并在屏幕上显示这些信息。\n周期性部件 这些小部件是主小部件菜单中可用的。其中多个小部件可以同时运行。事件循环每秒发射一次，模拟正在运行。如果启用了其中一个小部件，则此时将调用其周期性例程。每个小部件可能有一个配置对话框，也可以从小部件菜单访问。\n下面是一些标准部件：\nAdjacency- 显示Quagga’s OSPFv2和OSPFv3路由协议的路由器对接状态。从每个路由器中抽取一条线，中途到相邻路由器的路由器 ID。线的颜色基于 OSPF 的对会状态，如Two-way 或 Full。要了解不同的颜色，请参阅Configure Adjacency…菜单项，vtysh命令用于转储 OSPF 邻居信息。只绘制了一半的线，因为每个路由器可能处于与另一个路由器不同的对等状态。 Throughput- 使用ng_pipe Netgraph节点收集的统计数据来实现显示每个链接上方的每秒千位吞吐量。如果吞吐量超过一定阈值，链接将变得突出显示。对于向范围内的所有节点广播数据的无线节点，吞吐率显示在节点旁边，如果阈值超出，节点将变得圆圈化。 观察部件 这些小部件可从小部件菜单的\u0026quot;观察者小部件\u0026quot;子菜单以及工具栏上的\u0026quot;小部件工具\u0026quot;中获取。一次只能使用一个观察者小部件。在会话运行时，鼠标在节点上弹出有关该节点的信息显示。\n可用的观察者小部件包括 IPv4 和 IPv6 路由表、socket信息、运行过程列表和 OSPFv2/v3 邻居信息。\n观察者小部件可以由用户编辑并重新排列。从\u0026quot;观察者小部件\u0026quot;菜单中选择编辑将调用\u0026quot;观察者小部件\u0026quot;对话。显示观察者小部件列表以及用于重新排列列表的上下箭头。控件可用于重命名每个小部件、更改鼠标运行期间运行的命令以及从列表中添加和删除项目。请注意，指定命令应立即返回，以避免 GUI 显示屏出现延迟。更改将保存到 CORE 配置目录中的widgets.conf文件。\n会话菜单 除了节点类型、注释、钩子、服务器和选项等全局选项外，会话菜单还有启动、停止和管理会话的条目。\nOption Description Start or Stop 启动或停止仿真，执行与绿色启动或红色停止按钮相同的功能。 Change sessions\u0026hellip; 调用包含守护进程的活动CORE会话列表的CORE Sessions对话框。显示会话的名称、节点数、起始时间和缩略图等基本信息。这个对话框允许连接到不同的会话，关闭会话，或启动一个新的会话等功能。 Node types\u0026hellip; 调用核心节点类型对话框，执行与网络层节点工具栏上的编辑按钮相同的功能。 Comments\u0026hellip; 调用CORE Session Comments窗口，其中可以指定可选的文本注释。这些注释保存在配置文件的顶部，对于描述拓扑或如何使用网络非常有用。 Hooks\u0026hellip; 调用CORE Session Hooks窗口，其中脚本可以配置为特定的会话状态。会话状态定义在下面的表格中。窗口的顶部有一个已配置的钩子列表，左下方的按钮允许添加、编辑和删除钩子脚本。新建或编辑按钮将打开一个钩子脚本编辑窗口。hook脚本是在主机上(不是在虚拟节点内)调用的shell脚本。 Reset node positions 如果您已经使用鼠标或通过移动模块移动了节点，选择该项目将重置所有节点到它们在画布上的原始位置。当您第一次按下Start按钮时，就已经记录节点位置。 Emulation servers\u0026hellip; 调用CORE仿真服务器对话框进行配置。 Options\u0026hellip; 提供每个会话的选项，如是否使用的IPv4前缀，控制网络保存会话目录的能力，SDT3D支持的开/关等。 会话状态 状态 描述 定义 : DEFINITION_STATE GUI 用来告诉后端清除会话的任何状态。 配置 : CONFIGURATION_STATE 当用户按下开始按钮时，节点、链接和其他配置数据将发送到后端。当用户自定义服务时，也会达到此状态。 实例 : INSTANTIATION_STATE 该状态在创建节点之后，启动service前。 运行 : RUNTIME_STATE 所有节点和网络都已构建并正在运行。(这与前面命名的全局实验脚本运行时的状态相同。) 数据收集 : DATACOLLECT_STATE 用户已按下停止按钮，但在服务停止和节点被关闭之前。这是从节点收集日志文件和其他数据的好时机。 关闭 : SHUTDOWN_STATE 所有节点和网络都已被关闭和销毁。 连接物理网络 CORE 的模拟网络可实时运行，因此可以连接到实时物理网络。RJ45 工具和隧道工具有助于连接到现实世界。这些工具可从链接层节点菜单中获取。\n当两个或多个CORE仿真连接在一起时，应该避免MAC地址冲突。开始仿真时，CORE自动为各接口分配MAC地址，起始地址为00:00:00:aa:00:00，从底字节开始递增。第二台机器上的CORE的MAC起始地址应该改变以避免冲突，使用Tool菜单的 MAC地址… 选项来设定。\nRJ45 工具 CORE中的RJ45节点代表真实CORE机器上的一个物理接口。 任何真实世界的网络设备都可以连接到该接口并进行通信实时使用CORE节点。\n其主要缺点是每个连接都需要一个物理接口。当物理接口被分配给CORE时，它可能无法用于其他任何事情。另一个需要考虑的问题是，您所连接的计算机或网络必须与运行CORE仿真的机器位于同一局域网。\n单击“链路层节点”工具栏上，在子菜单中选择“RJ45”。单击要连接到的节点附近的画布，例如路由器、集线器、交换机或WLAN。现在点击链接工具，在RJ-45和另一个节点之间做一条链接。该RJ45节点将显示“UNASSIGNED”。双击RJ45节点，分配物理接口。将显示可用接口列表，可以双击列表中的接口名称进行选择，也可以在文本框中输入接口名称。\n注意:当你按下Start按钮实例化你的拓扑时，分配给RJ45的接口将连接到CORE拓扑。系统无法再使用该接口。\n如果使用802.1x VLAN，可以在CORE内部使用多个RJ45节点，并将其分配到同一个物理接口。这允许RJ45节点比物理网口更多。 但(例如交换机)硬件连接到物理端口必须支持VLAN标签，可用的带宽将被共享。\n您需要在Linux主机上创建单独的VLAN虚拟设备，然后将这些设备分配给CORE内部的RJ45节点。 VLANning实际上是在CORE外部执行的，所以当CORE模拟节点收到传输给Vlan的数据包时，会自动将VLAN tag移除。VLAN基本知识\n以下是在Linux下创建VLAN设备的命令示例:\nip link add link PHYS_DEV name.1 type vlan id 1 ip link add link PHYS_DEV name.2 type vlan id 2 ip link add link PHYS_DEV name.3 type vlan id 3 隧道工具 隧道工具在CORE仿真或其他主机之间构建GRE隧道。 当物理接口的数量有限或对等体位于不同的网络时，隧道技术会很有帮助。 物理接口也不需要像RJ45工具那样专用于CORE。\n对端GRE隧道端点可能是另一台支持GRE隧道的CORE机器或另一台主机。 当放置一个Tunnel隧道节点时，该节点最初将显示“UNASSIGNED”。 此处需要替换为隧道对接处的IP地址。这是另一个CORE机器或物理机器的IP地址，而不是另一个虚拟节点的IP地址。\n注意 GRE设备可能存在的MTU(最大传输单元)问题。gre tap设备接口MTU为1458字节,当连接到Linux网桥时，网桥的MTU也变成1458字节。如果其他网桥端口具有更高的MTU(比如1500字节)，那个Linux网桥将不会对该大数据包执行分片。\nGRE密钥用于识别使用GRE隧道的流。这使得多个GRE隧道存在于同一对隧道对等体之间。 当多个隧道与同一个对等体使用时，应使用一个唯一的编号。 当配置隧道对端时，确保匹配的密钥为使用。\n下面是在Linux上构建隧道另一端的示例命令。 在这个例子中，CORE中的路由器拥有虚拟地址 10.0.0.20/24 ，Core主机（设为user1）的真实地址为192.168.163.130/24。 将与CORE机器连接的Linux机器（设为user2）可以通过真实的网络在192.168.163.133/24处访问。\n仿真路由器与Tunnel节点相连。在隧道节点配置对话框中，输入地址192.168.163.133，密钥为1。\n# 这些命令在匹配tunnel的用户user2上执行 sudo ip link add gt0 type gretap remote 192.168.163.130 local 192.168.163.133 key 1 # Linux机器上的gretap接口将从虚拟路由器节点的子网中分配一个地址10.0.0.22/24。 sudo ip addr add 10.0.0.22/24 dev gt0 sudo ip link set dev gt0 up 现在虚拟路由器应该可以ping通Linux机器User2了:\n# from the CORE router node ping 10.0.0.22 # 如果想要直接ping物理地址加条路由即可 ip route add 192.168.163.133 via 10.0.0.22 User2应该能够ping通内核仿真内部:\n# from the tunnel peer ping 10.0.0.20 要调试此配置，tcpdump可以在gretap设备上运行，也可以在CORE或Linux机器的物理接口上运行。 确保防火墙没有阻断GRE流量。\n与主机通信 节点不一定要可以访问到运行core-gui或core-daemon的主机。例如，在一个节点上运行一个X11应用程序可以使用特定的通信方式让应用程序连接到X服务器以进行图形化显示。有几种不同的方式可以从节点连接到主机，反之亦然。\n控制网络 通过控制网络是与主机连接的最快方式。 通过控制网络，主机可以在节点上启动X11应用程序。首先要在该节点上启用SSH服务，并且使用SSH来进行从主机到该节点的X11服务转发。\nSSH原理与运用（一）：远程登录 SSH原理与运用（二）：远程操作与端口转发\n# 节点n5使用ssh来转发主机运行x协议标准的时钟xclock程序界面 ssh -X 172.16.0.5 xclock 注意，可以使用coresendmsg将消息发送到主机上运行的CORE守护进程与运行的仿真交互 (需要 /etc/core/core.conf 的配置文件中设定监听地址为广播即 listenaddr = 0.0.0.0 ) 例如，一个节点可以通过上述方法移动自己或其他节点，或者根据某个节点的状态更改其图标。\n其他方法 还有其他方法可以将主机与节点连接起来。RJ-45工具可以配合虚拟接口访问节点:\n# 或者使用modprobe命令创建dummy设备 sudo modprobe dummy numdummies=1 # 但是使用ip link show无法查看到，不知是否失效， # 推荐使用ip命令创建 sudo ip link add dummy0 type dummy # 使用方法 ip link del dev \u0026lt;dummy-interface\u0026gt; ip link add dev \u0026lt;dummy-interface\u0026gt; type dummy ip addr add \u0026lt;IPv4\u0026gt;/32 dev \u0026lt;dummy-interface\u0026gt; ip link set \u0026lt;dummy-interface\u0026gt; up 主机上应该出现一个 dummy0 接口。使用RJ45工具分配给dummy0，并将其链接到您的场景中的一个节点。(相当于core仿真后会建立一个网桥，上述dummy0设备会attach到该网桥)会话启动后，需要在主机上配置地址。\nip link show type bridge # 根据上述命令确定core仿真的网桥名称 # 在与链接节点相同的网络上分配一个IP地址 sudo ip addr add 10.0.1.2/24 dev 该设备名 在上面的例子中，主机将有地址10.0.1.2，而连接到RJ45的节点可能有地址10.0.1.1。\n构建样本网络 有线网络 有线网络是使用链接工具创建的，以绘制两个节点之间的链接。这将自动绘制一条代表以太网链路的红线，并在网络层节点上创建新的接口。\n双击链接以调用链接配置对话框。在这里您可以更改该链路的带宽、延迟、丢失和重复速率参数。您还可以修改链接的颜色和宽度，从而影响其显示。\n链路层节点用于对有线网络进行建模。这些不会产生 一个单独的网络堆栈，而是使用Linux网桥实现。 这些是集线器、交换机和无线局域网节点。集线器从 每个连接的链路的传入链路，而交换机的行为更像是 以太网交换机，并跟踪连接的对等体的以太网地址， 只转发单播流量到适当的端口。\n无线网络 WLAN节点允许您构建无线网络，移动节点会影响它们之间的连接。一对节点之间越紧密，连接越强;节点之间越远连接越弱。无线局域网(WLAN)节点以小云的形式出现。根据您的建模需求，WLAN提供了多个级别的无线仿真保真度。\nWLAN工具可以通过插件进行扩展，以实现不同级别的无线保真度。基本的开/关范围是所有平台上可用的默认设置。其他插件以更高的复杂性和CPU使用量为代价提供更高的保真度。某些插件的可用性因平台而异。关于无线模型类型的简要概述，请参见下表。\n模型 类型 支持平台 保真度 描述 basic on/off Linux Low 使用ebtables的以太网桥接 EMANE Plug-in Linux High TAP设备连接到EMANE模拟器的可插拔的MAC和PHY无线射频模型 要快速构建无线网络，您可以首先将多个路由器节点放置在画布上。如果您安装了 Quagga MDR 软件，建议您使用mdr节点类型来减少开销路由。接下来从链接层节点子菜单选择无线局域网。首先通过双击云图标设置所需的 WLAN 参数。然后，您可以通过右键单击 WLAN 并选择链接到所有路由器来链接所有路由器。\n将路由器连接到 WLAN 会导致出现小天线，但不会绘制红色链接线。路由器可以具有多个无线链接以及无线和有线链接（但是您需要重新手动设置路由。mdr 节点类型将生成路由配置，使 OSPFv3 具有 MANET 扩展。这是波音公司开发的对QuaggaOSPFv3的扩展，可减少洪泛费用，并优化移动临时（MANET）移动自组网络的洪泛过程。\nWLAN 的默认配置设置为使用基本basic模型，使用 WLAN 配置对话框中的基本选项卡。选择此模型会导致core-daemon基于屏幕像素位置来计算节点之间的距离。使用 范围滑块（Range slider） 为无线网络设置屏幕像素的数字范围。当两个无线节点在它们之间画了一条绿线，它们是相连的。两个距离超过像素距离的无线节点不被连接。在执行模式中，用户可以通过单击和移动无线节点拖动它们，无线链接就会被动态创建或断开。\nEMANE 选项卡列出了可用于无线网络的可用 EMANE 模型。有关使用 EMANE 的详细信息，请参阅Emane。\n移动性脚本 CORE下述方法来设置脚本移动性。\n选项 描述 ns-2 script 该脚本指定了绝对位置或具有速度的路径点。位置用笛卡尔坐标给出。 CORE API 外部实体可以通过发送带有更新的X,Y坐标的CORE API Node消息来移动节点;coresendmsg实用程序允许shell脚本生成这些消息。 EMANE events 有关使用EMANE脚本移动节点的详细信息，请参见[EMANE .md]。位置信息通常以纬度、经度和高度给出。 对于第一种方法，可以使用文本编辑器或BonnMotion之类的工具创建移动脚本，并将脚本与使用WLAN配置对话框中的一个无线连接起来，点击 ns-2 mobility script\u0026hellip; 按钮, 并在 ns2script 中的配置对话框设置 mobility script file 字段\nBonnMotion安装教程：官网下载 BonnMotion 安装包，解压，进入目录运行./install即可(需要事先安装jdk，sudo apt-get install default-jdk)。官方使用指南点这里进行下载。\n下面是一个为10个节点创建BonnMotion脚本的示例:\nbm -f sample RandomWaypoint -n 10 -d 60 -x 1000 -y 750 bm NSFile -f sample # 第二行是将sample.movements转为sample.ns_movements ns脚本移动数据 # 自己测试发现 /usr/bin/中并没有 bm，执行文件在安装包文件夹下 ./bin/bm # 创建个软链接 sudo ln -s ~/桌面/bonnmotion-3.0.1/bin/bm /usr/bin 在启动Execute模式并且其中一个WLAN节点具有移动性时 脚本时，将出现一个移动脚本窗口。此窗口包含控件 启动、停止和重置移动性脚本的运行时间，loop 复选框设置脚本连续重复调用。分辨率resolution 文本框包含每个计时器事件之间的毫秒数;较低的值使移动性看起来更流畅，但消耗更多的CPU时间。\nns-2移动脚本的格式如下:\n# nodes: 3, max time: 35.000000, max x: 600.00, max y: 600.00 $node_(2) set X_ 144.0 $node_(2) set Y_ 240.0 $node_(2) set Z_ 0.00 $ns_ at 1.00 \u0026quot;$node_(2) setdest 130.0 280.0 15.0\u0026quot; 前三行设置节点2的初始位置。上面例子中的最后一行导致节点2以速度 15 向目的地 (130,280) 移动。所有单位都是屏幕坐标，速度以每秒为单位。总脚本时间是在所有节点到达它们的路径点之后得到的。 最初，移动脚本对话框中的时间滑块并不准确。\n示例移动脚本(及其相关的拓扑文件)可以在 configs/ 目录中找到。\n多画布 CORE 支持多个画布，用于组织模拟节点。在不同的画布上运行的节点可以链接在一起。要创建一个新的画布，从 canvas 菜单中选择 new 。一个新的画布标签出现在左下角。点击一个画布标签切换到它画布。双击其中一个选项卡来调用 Manage Canvases 对话框盒子。在这里，画布可以重命名和重新排序，你可以很容易地切换到并选择其中一幅画布。\n每个画布维护自己的一组节点和注释。画布之间要构建联系首先选择一个节点，右键单击它，选择 Create link to ，选择列表中的目标画布，以及该子菜单中的所需节点。之后将绘制一个伪链接，表示上两个节点之间的链接到不同的画布。双击箭头末端的标签即可跳转到它所链接的画布。\n检查仿真灯（CEL） CEL（Check Emulation Light）位于GUI的右下角，这是一个黄色图标，指示运行模拟中的一个或多个问题。单击CEL将调用CEL 对话框。Check Emulation Light对话框包含从CORE守护进程接收到的异常列表。异常列表包含有时间、严重级别、可选节点号和来源这些信息。当CEL闪烁时，这表示一个或多个致命异常。\n具有致命严重级别的异常表明无法创建模拟的一个或多个基本部分，例如无法创建桥或名称空间，或者无法为基于eman1的网络启动eman1进程。单击异常将显示该异常的详细信息。如果指定了节点号，当选中异常时，该节点将在画布上高亮显示。异常源是一个文本字符串，用于帮助跟踪异常发生的位置;例如，UserDefined服务的验证命令失败时，会出现 \u0026ldquo;service:UserDefined\u0026rdquo; 。\n对话框底部有一些按钮，用于清除异常列表和查看CORE守护进程和节点日志文件。\n注意: 在批处理模式下，从CORE守护进程接收到的异常将显示在控制台上。\n场景配置文件 场景配置拓扑文件保存为 .xml 或 .imn 。你可以轻松地编辑这些文件与文本编辑器。当您编辑拓扑时文件，您将需要停止模拟(如果它正在运行)并重新加载文件。\n.imn 文件格式来自IMUNES，主要成分是 节点、链接、etc的Tcl链表。 拓扑文件中的制表符Tab和空格有严格规范。该文件首先列出每个节点，然后列出链接、注释、画布和选项。每个实体都有一个包含在花括号中的块。第一个块缩进四个空格。 在 network-config 块(以及任何 custom\u0026ndash;config 块)中，缩进是一个制表符。\n注意: 有几个拓扑示例包括在CORE中的： ~/.core/configs, 如果Core安装到文件系统中则在 /usr[/local]/share/examples/configs.\n注意: 当使用 Imn 文件格式，特定文件路径： CORE_DATA_DIR = /usr/share/core, CONFDIR = ~/.core/configs\n注意: 您可以使用最喜欢的文本编辑器直接编辑文件。\n定制您的拓扑外观 提供多个注释工具来改变您的拓扑呈现方式。文字工具可以添加字幕。椭圆形和矩形可能绘制在后台，有助于在视觉上将节点分组在一起。\n在实时演示期间，标记工具可能有助于在画布上绘制可能很快被擦除的临时注释。选择标记工具时，工具栏底部会出现大小和调色板。标记只是暂时的，不会保存在拓扑文件中。\n基本节点图标可以替换为您选择的自定义图像。图标在使用具有透明背景的 GIF 或 PNG 格式时显示得最好。要更改节点的图标，请双击节点以调用其配置对话框，然后单击显示节点当前图标的节点名称右侧的按钮。\n画布的背景图像可以使用 canvas 菜单中的 Wallpaper… 设置。图像可以居中、平铺或以中心做缩放来适应画布大小。例如，可以使用现有的地形、地图或网络图可以用作背景，并将CORE节点绘制在顶部。。\n偏好 Preferences 对话框可以从 Edit_Menu 访问。此对话可以设置许多默认值，这些默认值存储在 ~/.core/prefs.conf 首选项文件中。\n","id":28,"section":"posts","summary":"使用 CORE GUI 下图显示 CORE GUI: 概述 GUI 用于在画布上绘制节点和网络设备，将它们连接在一起，以创建模拟的网络会话。 按下启动按钮后，CORE 将通过这些阶段进行","tags":[""],"title":"Core Gui","uri":"https://liangkang233.github.io/2021/07/gui/","year":"2021"},{"content":"go指南练习 新手初学Go语言，看到这个go指南网站在线测试很方便做了几道练习后就在上面学习。 其中最后一页的测试： go指南练习:web爬虫 学了go的并发基本使用方法后，觉得比c的多线程好写多了，所以最后的模拟web爬虫练习的代码贴出来，希望指教下怎么写更安全、高效。\n题目要求 /* 练习：Web 爬虫 在这个练习中，我们将会使用 Go 的并发特性来并行化一个 Web 爬虫。 修改 Crawl 函数来并行地抓取 URL，并且保证不重复。 提示：你可以用一个 map 来缓存已经获取的 URL， 但是要注意 map 本身并不是并发安全的！ */ // TODO: 并行的抓取 URL。 // TODO: 不重复抓取页面。 // Crawl 并没有实现上面两种情况： 修改部分 该代码其实是对伪造的fakeFetcher进行抓取，每个伪造结果map内的元素是一个结构体fakeResult。 该结构体元素由body字段（真正要展示的内容）和归属的urls。 Crawl函数调用Fetcher接口的fetcher方法对fakeResult的body字段匹配，并打印匹配到的body出来，没找到就打印报错。 若是匹配成功，Crawl深度减一递归的调用Crawl，url使用匹配body对应的fakeResult下的urls切片每一个url值。\n要求使用并发的实现 所以为了不改变原函数模板采用sync.WaitGroup来进行主进程等待子进程结束。 // sync.WaitGroup 用法 var wg sync.WaitGroup wg.Add(i int) //添加i个worker协程 wg.Done()\t//该子进程结束，做记录 wg.Wait() //当worker协程未全部执行结束，会一直堵塞 要求使用map记录已经爬取的页面避免重复抓取 由于map非并发安全（多个goroutine同时写入map会报错），添加互斥锁解决。 // 带互斥锁的map，防止并行的写入 type SafeUrlMap struct { set map[string]int mux sync.Mutex } func (myset SafeUrlMap) add(url string) { myset.mux.Lock() // elem, ok = set[url] myset.set[url]++ myset.mux.Unlock() } func (myset SafeUrlMap) have(url string) bool { myset.mux.Lock() if myset.set[url] != 0 { defer myset.mux.Unlock() return true } return false }\t完整代码 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;sync\u0026quot; ) type Fetcher interface { // Fetch 返回 URL 的 body 内容，并且将在这个页面上找到的 URL 放到一个 slice 中。 Fetch(url string) (body string, urls []string, err error) } // Crawl 使用 fetcher 从某个 URL 开始递归的爬取页面，直到达到最大深度。 func Crawl(url string, depth int, fetcher Fetcher) { if depth \u0026lt;= 0 { wg.Done() return } if myset.have(url) { wg.Done() return } body, urls, err := fetcher.Fetch(url) myset.add(url) // 无论该网页是否找到，都做一次记录防止下次重复抓取 if err != nil { fmt.Println(err) wg.Done() return } fmt.Printf(\u0026quot;found: %s %q\\n\u0026quot;, url, body) for _, u := range urls { wg.Add(1) go Crawl(u, depth-1, fetcher) } wg.Done() return } func main() { myset = SafeUrlMap{set: make(map[string]int)} wg.Add(1) Crawl(\u0026quot;https://golang.org/\u0026quot;, 4, fetcher) wg.Wait() } // 带互斥锁的map，防止并行的写入 type SafeUrlMap struct { set map[string]int mux sync.Mutex } // url记录的查询方法 func (myset SafeUrlMap) add(url string) { myset.mux.Lock() // elem, ok = set[url] myset.set[url]++ myset.mux.Unlock() } // url记录的添加方法 func (myset SafeUrlMap) have(url string) bool { myset.mux.Lock() if myset.set[url] != 0 { defer myset.mux.Unlock() return true } return false } // fakeFetcher 是返回若干结果的 Fetcher。 type fakeFetcher map[string]*fakeResult type fakeResult struct { body string urls []string } func (f fakeFetcher) Fetch(url string) (string, []string, error) { if res, ok := f[url]; ok { return res.body, res.urls, nil } return \u0026quot;\u0026quot;, nil, fmt.Errorf(\u0026quot;not found: %s\u0026quot;, url) } // 已采集的Url清单,采集进程组 var ( myset SafeUrlMap wg sync.WaitGroup ) // fetcher 是填充后的 fakeFetcher。 var fetcher = fakeFetcher{ \u0026quot;https://golang.org/\u0026quot;: \u0026amp;fakeResult{ \u0026quot;The Go Programming Language\u0026quot;, []string{ \u0026quot;https://golang.org/pkg/\u0026quot;, \u0026quot;https://golang.org/cmd/\u0026quot;, }, }, \u0026quot;https://golang.org/pkg/\u0026quot;: \u0026amp;fakeResult{ \u0026quot;Packages\u0026quot;, []string{ \u0026quot;https://golang.org/\u0026quot;, \u0026quot;https://golang.org/cmd/\u0026quot;, \u0026quot;https://golang.org/pkg/fmt/\u0026quot;, \u0026quot;https://golang.org/pkg/os/\u0026quot;, }, }, \u0026quot;https://golang.org/pkg/fmt/\u0026quot;: \u0026amp;fakeResult{ \u0026quot;Package fmt\u0026quot;, []string{ \u0026quot;https://golang.org/\u0026quot;, \u0026quot;https://golang.org/pkg/\u0026quot;, }, }, \u0026quot;https://golang.org/pkg/os/\u0026quot;: \u0026amp;fakeResult{ \u0026quot;Package os\u0026quot;, []string{ \u0026quot;https://golang.org/\u0026quot;, \u0026quot;https://golang.org/pkg/\u0026quot;, }, }, } ","id":29,"section":"posts","summary":"go指南练习 新手初学Go语言，看到这个go指南网站在线测试很方便做了几道练习后就在上面学习。 其中最后一页的测试： go指南练习:web爬虫 学了","tags":["go"],"title":"Go指南练习","uri":"https://liangkang233.github.io/2021/06/go%E6%8C%87%E5%8D%97%E7%BB%83%E4%B9%A0-web%E7%88%AC%E8%99%AB/","year":"2021"},{"content":"VScode是一款非常好用的代码编辑器，还拥有强大的在线扩展插件。甚至可以进行代码的debug，整理了下配置过程遇到的问题分享出来。 我使用的windows平台vscode版本为V1.56。\n通用配置 VS Code内置了对Node.js运行时的调试支持，可以调试JavaScript、TypeScript或JavaScript语言。\n要调试其他语言(包括PHP, Ruby, Go, c#， Python, C++， PowerShell等)时，在VS Code扩展中寻找调试器扩展，或者在顶级运行菜单中选择安装额外的调试器。\n确定安装可以编译调试的扩展或软件再进行以下步骤：\n右击工程文件夹使用VScode打开。 打开需要编译、运行的文件，点击顶部菜单-\u0026gt;运行-\u0026gt;添加配置\u0026hellip;选择需要debug的类型，之后根据语言及即可在 .vscode文件夹下生成launch.json文件。生成的json文件对整个文件夹和子文件夹生效。\n举例如何debug go 以go语言为例，路径切换至当前工程文件夹。首先安装调试软件推荐使用dlv，终端中输入\ngo get -u github.com/go-delve/delve/cmd/dlv # 未生成mod还得添加mod才能调试\tgo mod init yourProjectName 一切准备就绪后，点击上述步骤生成launch.json文件，此处会让你选择调试包还是附着到本地进程或远程服务器调试。 选择默认的调试package，这里打开生成的默认json\n{ // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;, \u0026quot;configurations\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;Launch Package\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;go\u0026quot;, \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;, \u0026quot;mode\u0026quot;: \u0026quot;auto\u0026quot;, \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}\u0026quot; } ] } 需要添加新的配置直接点击右下角即可，\u0026ldquo;name\u0026quot;的值为左标签页调试器的名字用于区分用。\n“type”语言类型设置为go，vs code 用于设定调试代码扩展类型。”mode“可以设置为 auto, debug, remote, test, exec 中的一个。\n”program“调试程序的路径（绝对路径），这里使用workspaceFolder说明对整个工作区目录文件进行调试。\n各配置变量的含义 其中有许多vscode定义的变量，这里列出常用的：\n${workspaceFolder} - 在VS Code中打开的文件夹路径 ${workspaceFolderBasename} - 在VS Code中打开的文件夹的名称没有任何斜杠(/) ${file} - 当前打开的文件名 ${fileWorkspaceFolder} - 当前打开的文件的工作区文件夹 ${relativeFile} - 当前打开的文件名相对于workspaceFolder ${relativeFileDirname} - 当前打开的文件的目录名相对于workspaceFolder ${fileBasename} - 当前打开的文件的基名 ${fileBasenameNoExtension} - 当前打开的文件的基名没有文件扩展名 ${fileDirname} - 当前打开文件的目录名 ${fileExtname} - 当前打开的文件的扩展名 ${cwd} - 任务运行器启动时的当前工作目录 ${lineNumber} - 当前选中的行号在活动文件中 ${selectedText} - 活动文件中当前选定的文本 ${execPath} - 运行VS Code可执行文件的路径 ${defaultBuildTask} - 默认构建任务的名称 ${pathSeparator} - 操作系统用于分隔文件路径中的组件的字符 ${pathSeparator} - 在macOS或linux系统为/, 在Windows上为\\ 关于debug C/C++ 该文件设置debug的各项配置根据语言的不同，设置也不尽相同。这里介绍c/c++的具体配置流程。 总结各文件作用 与其他语言类似的，debug的配置文件也是生成在.vscode文件夹中。 c/c++程序配置一般有三个文件：\ntasks.json（如何编译生成可执行程序） launch.json（调试设置） c_cpp_properties.json（编译器路径和vscode感知设置） 其中c_cpp_properties非常坑，由于我使用了自己写的头文件在c_cpp_properties.json的includePath项目配置各种路径类型都不生效，后面才看懂这个只是让vscode识别头文件该跳转的路径而已，真正要添加外部库或头文件的话要么放在系统默认库、头文件路径，要么在task.json中配置生成。 具体流程 c/c++代码需要先编译链接生成可执行程序（tasks.json），再使用gdb调试（launch.json），c_cpp_properties.json设置c/c++使用语言标准例如c++11等。注意：调试前确保系统环境已配置g++、gdb。验证方法：\n要检查您的 Mingw-w64 工具是否正确安装和可用，请打开新的命令提示并键入： g++ \u0026ndash;version gdb \u0026ndash;version 以此工程文件夹为例，main函数调用了lib文件夹下的stu_rw.h文件\n打开main.cpp文件，点击顶部菜单-\u0026gt;终端-\u0026gt;配置默认生成任务，选择使用g++生成活动文件。打开生成的task.json文件\n{ \u0026quot;version\u0026quot;: \u0026quot;2.0.0\u0026quot;, \u0026quot;tasks\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;cppbuild\u0026quot;, \u0026quot;label\u0026quot;: \u0026quot;C/C++: g++.exe 生成活动文件\u0026quot;, \u0026quot;command\u0026quot;: \u0026quot;C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin\\\\g++.exe\u0026quot;, \u0026quot;args\u0026quot;: [ \u0026quot;-g\u0026quot;, \u0026quot;-Wall\u0026quot;, //显示全部详细警告 \u0026quot;-std=c++11\u0026quot;, //支持C11 \u0026quot;${file}\u0026quot;,\t\u0026quot;-I\u0026quot;, \u0026quot;${workspaceFolder}\\\\lib\u0026quot;, \u0026quot;-o\u0026quot;, \u0026quot;${fileDirname}\\\\${fileBasenameNoExtension}.exe\u0026quot; ], \u0026quot;options\u0026quot;: { \u0026quot;cwd\u0026quot;: \u0026quot;${fileDirname}\u0026quot; }, \u0026quot;problemMatcher\u0026quot;: [ \u0026quot;$gcc\u0026quot; ], \u0026quot;group\u0026quot;: { \u0026quot;kind\u0026quot;: \u0026quot;build\u0026quot;, \u0026quot;isDefault\u0026quot;: true }, \u0026quot;detail\u0026quot;: \u0026quot;编译器: \\\u0026quot;C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin\\\\g++.exe\\\u0026quot;\u0026quot; } ] } 其中args选项即为g++编译链接选项，如上所示我已经添加了\u0026rdquo;-I\u0026quot;相关参数添加头文件路径，c11标准。静态库链接等就放-o选项后，除最后一行配置文件每行都得加逗号。\n之后打开main.cpp点击顶部菜单-\u0026gt;终端-\u0026gt;运行生成任务，看是否生成成功。\n之后设定debug选项，点击顶部菜单-\u0026gt;运行-\u0026gt;添加配置，选择gdb、之后选g++生成默认配置。 下面展示配置的说明：\n{ // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;, \u0026quot;configurations\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;g++.exe - 生成和调试活动文件\u0026quot;,\t// 配置名称，将会在启动配置的下拉菜单中显示 \u0026quot;type\u0026quot;: \u0026quot;cppdbg\u0026quot;, \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\t// 请求配置类型，可以为launch（启动）或attach（附加） \u0026quot;program\u0026quot;: \u0026quot;${fileDirname}\\\\${fileBasenameNoExtension}.exe\u0026quot;,\t// 将要进行调试的程序的路径 \u0026quot;args\u0026quot;: [],\t// 程序调试时传递给程序的命令行参数，一般设为空即可 \u0026quot;stopAtEntry\u0026quot;: false, \u0026quot;cwd\u0026quot;: \u0026quot;${fileDirname}\u0026quot;, \u0026quot;environment\u0026quot;: [], \u0026quot;externalConsole\u0026quot;: false, \u0026quot;MIMode\u0026quot;: \u0026quot;gdb\u0026quot;, \u0026quot;miDebuggerPath\u0026quot;: \u0026quot;C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin\\\\gdb.exe\u0026quot;, \u0026quot;setupCommands\u0026quot;: [ { \u0026quot;description\u0026quot;: \u0026quot;为 gdb 启用整齐打印\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;-enable-pretty-printing\u0026quot;, \u0026quot;ignoreFailures\u0026quot;: true } ], \u0026quot;preLaunchTask\u0026quot;: \u0026quot;C/C++: g++.exe 生成活动文件\u0026quot; } ] } 如果您想要对 C/C++扩展进行更多控制，c_cpp_properties.json将配置如编译器的路径，include路径、C++标准（默认值为 C++17）等等。\n通过命令终端（Ctrl+Shift+P）输入\u0026gt;c/c++，有两个选项一个是直接配置json一个是通过UI界面配置。\n这里的C/C++ 配置UI页面，基本保持默认即可。注意这里的配置编辑器是给vscode和扩展使用的，不影响task.json来配置真正生成可执行程序的过程。\n","id":30,"section":"posts","summary":"VScode是一款非常好用的代码编辑器，还拥有强大的在线扩展插件。甚至可以进行代码的debug，整理了下配置过程遇到的问题分享出来。 我使用的","tags":[""],"title":"Vscode配置debug","uri":"https://liangkang233.github.io/2021/06/vsode%E9%85%8D%E7%BD%AEdebug/","year":"2021"},{"content":"背景 我目前需要解决一个需求，将一个c工程中的特定数据转发到VUE前端框架上做界面展示，且该框架已经有后端为flask框架。\n所以得考虑如何将c工程中的数据发送到python中。容易知道，进程间通信的方式有管道、信号量、消息队列、共享内存、套接字等。为了简易实现上述功能和尽量不影响他们两边原先进程的功能，使用套接字发送封装的数据做http请求给flask后端，这样来实现数据转发。\nHTTP（超文本传输协议）是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP请求的资源由统一资源标识符（Uniform Resource Identifiers，URI）来标识。具体区别这篇博客讲的很详细。总而言之http连接=以http协议为通信协议的tcp连接，http协议可以由tcp协议封装报文而来，现在要解决的就是c的套接字如何封装成符合http协议的get/post请求。\n参考案例 最开始找了网上很多案例，tcp套接字细节此处不赘述。http请求就是其tcp传输附上对应http请求的报文，但是实际测试不对，没有相应返回。猜想到可能测试环境不同封装格式也要改变，所以使用wireshark抓包软件抓了个具体的数据包来分析。 使用的get、post请求的html页面\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;GET and POST\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action = \u0026quot;http://localhost:5000\u0026quot; method = \u0026quot;get\u0026quot;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Name\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type =\u0026quot;text\u0026quot; name =\u0026quot;username\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Password\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type =\u0026quot;password\u0026quot; name =\u0026quot;password\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type = \u0026quot;get submit\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;form action = \u0026quot;http://localhost:5000\u0026quot; method = \u0026quot;post\u0026quot;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Name\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type =\u0026quot;text\u0026quot; name =\u0026quot;username\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Password\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type =\u0026quot;password\u0026quot; name =\u0026quot;password\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type = \u0026quot;post submit\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 后端flask接收代码\nfrom flask import Flask, request app = Flask(__name__) @app.route('/', methods=['GET']) def index(): username = request.args.get('username') password = request.args.get('password') if username == \u0026quot;xugaoxiang\u0026quot; and password == \u0026quot;xugaoxiang\u0026quot;: return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;Welcome {username}\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; else: return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;Welcome!\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; @app.route('/', methods=['POST']) def index(): username = request.form['username'] password = request.form['password'] if username == \u0026quot;xugaoxiang\u0026quot; and password == \u0026quot;xugaoxiang\u0026quot;: return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;Welcome {username}\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; else: return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;Welcome!\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; if __name__ == '__main__': app.run(debug=True) 测试案例取自此教程，贴出教程源码链接：https://github.com/xugaoxiang/FlaskTutorial 其抓包结果如下所示： 只需要关注http数据包中的tcp报文内容即可。 具体实现 注：为了解决大小端和数据位数不统一的问题，我是将所有数据转为字符串来发送。如果想要发送json等数据格式同样用抓包看下具体如何封装即可，此处简易的实现先不考虑那些功能。 有了上面的数据样本，进行下面c代码的封装转发。使用环境不同，部分函数可能有所变化。这里只展示基础模板。 真正通用的是下面这段补齐信令的函数\nvoid addget(const char* str1) //补齐get信令数据 { strcat(str1, \u0026quot;Host: 127.0.0.1\\r\\n\u0026quot;);//cname记录不影响连接，此处不做修改 strcat(str1, \u0026quot;Content-Type: text/html\\r\\n\\r\\n\u0026quot;); } void addpost(char* str1, const char* data) //补齐post信令数据 { char postlength[128]; sprintf(postlength, \u0026quot;%d\\r\\n\u0026quot;, strlen(data + 1)); strcat(str1, \u0026quot;Host: 127.0.0.1\\r\\n\u0026quot;);//cname记录不影响连接，此处不做修改 strcat(str1, \u0026quot;Content-Type: application/x-www-form-urlencoded\\r\\n\u0026quot;); strcat(str1, \u0026quot;Content-Length: \u0026quot;); strcat(str1, postlength); strcat(str1, \u0026quot;\\r\\n\\r\\n\u0026quot;); strcat(str1, data + 1);\t} /* 调用方式 //data即为传输而来的数据 case get_test:{\t// 封装成http的get请求 strcpy(str1, \u0026quot;GET /getsometing?\u0026quot;); strcat(str1, data + 1); strcat(str1, \u0026quot; HTTP/1.1\\r\\n\u0026quot;); addget(str1); break; } case post_test:{\t// 封装成http的post请求 strcpy(str1, \u0026quot;POST /postsometing HTTP/1.1\\r\\n\u0026quot;); addpost(str1, data); break;\t} */ 请求代码模板 只讨论http请求方面内容，展示基础的tcp套接字绑定及封装http请求流程\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;winsock2.h\u0026gt; #include \u0026lt;windows.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #define PORT 5000\t// 设定发送端口 #define BUFSIZE 1024 #define DATASIZE 2000 enum send_flask_type { start=1, accomplish, get_test, post_test }; // 实现函数，flaskip为http请求的ip地址 此处为环回地址127.0.0.1 data为传输数据(例如type=start) send_type设定传输方式 int HandleFlask(const char* flaskip, const char* data, int send_type) { int i, sockfd_flask; fd_set t_set1; struct timeval timeset; struct sockaddr_in flaskaddr; char str1[2 * DATASIZE], buf[BUFSIZE]; //* 创建flask连接套接字 *// if ((sockfd_flask = socket(AF_INET, SOCK_STREAM, 0)) \u0026lt; 0 ) { printf(\u0026quot;创建网络连接失败,本线程即将终止!\\n\u0026quot;); return -1; } flaskaddr.sin_family = AF_INET; flaskaddr.sin_addr.s_addr = inet_addr(flaskip); flaskaddr.sin_port = htons(PORT); memset(\u0026amp;flaskaddr.sin_zero, 0, 8); if (connect(sockfd_flask, (struct sockaddr *)\u0026amp;flaskaddr, sizeof(flaskaddr)) \u0026lt; 0){ printf(\u0026quot;连接到flask服务器失败!\\n\u0026quot;); return -1; } // printf(\u0026quot;连接Flask服务器成功\\n\u0026quot;); switch(send_type) { case get_test:{\t/* 封装成http的get请求 */ strcpy(str1, \u0026quot;GET /getsometing?\u0026quot;); // if(SplitStr(data + 1, str1) \u0026lt; 0) { //将data中的tpye数字类型转成字符串并添加至str1 // printf(\u0026quot;需要转发的报文格式有误\\n\u0026quot;); // return -1; // } strcat(str1, data + 1); strcat(str1, \u0026quot; HTTP/1.1\\r\\n\u0026quot;); addget(str1); break; } case post_test:{\t/* 封装成http的post请求 */ strcpy(str1, \u0026quot;POST /postsometing HTTP/1.1\\r\\n\u0026quot;); addpost(str1, data); break;\t} default:{ printf(\u0026quot;接收到无效格式，舍弃\\n\u0026quot;); return 0; } } i = send(sockfd_flask, str1, strlen(str1), 0); if (i \u0026lt; 0) { // printf(\u0026quot;发送失败！错误代码是%d，错误信息是'%s'\\n\u0026quot;,errno, strerror(errno)); printf(\u0026quot;发送数据给flask失败！错误代码是%d\\n\u0026quot;, WSAGetLastError());//windows获取erron closesocket(sockfd_flask); return -1; } else { // printf(\u0026quot;消息发送至flask成功，共发送了%d个字节！send_type=%d \\n\u0026quot;, i, send_type); } // python安装插件eventlet后，外部http访问后flask不会立即关闭套接字 // (即falsk return后不会发送空的tcp报文)， // 所以此修改为不考虑复杂场景只接收一次flask的http返回数据后就关闭套接字 FD_ZERO(\u0026amp;t_set1); FD_SET(sockfd_flask, \u0026amp;t_set1); timeset.tv_sec= 0; timeset.tv_usec= 100000; //扫描堵塞时间100ms i= select(sockfd_flask +1, \u0026amp;t_set1, NULL, NULL, \u0026amp;timeset); if (i == 0) { // printf(\u0026quot;长时间未接收到flask http响应，跳过\\n\u0026quot;); // continue; // break; } else if (i \u0026lt; 0) { printf(\u0026quot;在读取flask数据报文时SELECT检测到异常，该异常导致线程终止！\\n\u0026quot;); closesocket(sockfd_flask); return -1; } else { memset(buf, 0, sizeof(buf) ); i = recv(sockfd_flask, buf, sizeof(buf), 0); if (i \u0026lt;= 0) { closesocket(sockfd_flask); if (i == 0) { // printf(\u0026quot;与flask通信的http套接字关闭\\n\u0026quot;); return 0; } else { printf(\u0026quot;接收flask数据报出现错误！错误代码是%d\\n\u0026quot;, WSAGetLastError()); //windows获取erron return -1; } } else { //对http返回值进行处理 // printf(\u0026quot;flask返回值%s\\n\u0026quot;, buf); // continue; // break; } } closesocket(sockfd_flask); return 0; } flask接收示例 # flask后端测试用 @app.route('/getsometing', methods=['GET']) def gettest(): type = request.args.get('type') src = request.args.get('src') dst = request.args.get('dst') print(f\u0026quot;get data: type={type},src={src},dst={dst}\u0026quot;) return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;get return: type={type},src={src},dst={dst}\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; @app.route('/postsometing', methods=['POST']) def posttest(): type = request.form['type'] src = request.form['src'] dst = request.form['dst'] print(f\u0026quot;post data: type={type},src={src},dst={dst}\u0026quot;) return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;post return: type={type},src={src},dst={dst}\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; 如果数据量比较大可以这样写\n@app.route('/getsometing', methods=['GET']) def gettest(): get_data=request.args.to_dict() type = get_data['type'] cur_time=time.strftime(\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot;, time.localtime()) if type == 'Start' : #自己定义的发送数据的type pass elif type == 'Accomplish' : pass elif type == 'change' : pass else : print (\u0026quot;接收到无效数据，将其丢弃\u0026quot;) with open(\u0026quot;log.txt\u0026quot;, \u0026quot;a+\u0026quot;) as f: f.write('\\n# ' + cur_time + ' ---------- get error：\\n' + json.dumps(get_data)) return \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; Flask access invalid data \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; return \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; data access \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; @app.route('/postsometing', methods=['POST']) def posttest(): post_data = request.form.to_dict() print (post_data) type = post_data['type'] cur_time=time.strftime(\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot;, time.localtime()) if type == \u0026quot;change\u0026quot;: pass else : print (\u0026quot;接收到无效数据，将其丢弃\u0026quot;) with open(\u0026quot;log.txt\u0026quot;, \u0026quot;a+\u0026quot;) as f: f.write('\\n# ' + cur_time + ' ---------- post error：\\n' + json.dumps(post_data)) return \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; Flask access invalid data \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; return \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; data access \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; ","id":31,"section":"posts","summary":"背景 我目前需要解决一个需求，将一个c工程中的特定数据转发到VUE前端框架上做界面展示，且该框架已经有后端为flask框架。 所以得考虑如何将c","tags":["C/C++"],"title":"C语言实现的http请求","uri":"https://liangkang233.github.io/2021/06/c%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0http%E8%AF%B7%E6%B1%82/","year":"2021"},{"content":"思路 python的特性支持快速开发实用小程序的能力，能让你做事效率大幅度提高。特别是在c++数据测试中，检验一个程序的可靠性需要大量数据进行测试可靠性。虽然c++也有随机函数等方法但是不方便移植更改，用Python编写数据生成器是再合适不过的了。接下来进行举例说明：下面的代码直接在python3终端中运行，生成一个长度在4 ~9之间， 恰好包含一个大写字母， 其他字符为小写字母的特殊串。\n\u0026gt;\u0026gt;\u0026gt; from random import* \u0026gt;\u0026gt;\u0026gt; from string import* \u0026gt;\u0026gt;\u0026gt; L = randint(4, 9) \u0026gt;\u0026gt;\u0026gt; s =''.join([choice(ascii_lowercase) for i in range(L)]) \u0026gt;\u0026gt;\u0026gt; p = randint(0, len(s)) \u0026gt;\u0026gt;\u0026gt; s[:p] + choice(ascii_uppercase) + s[p:] ' bdsqVgke' 列表解析Clist comprehension) 是一种构造列表的简单方法。range(5) 生成列表[0,1,2,3,4]。这条语句就是 “对于列表[0,1,2,3,4]中的每个数i调用一次 choice(lowercase)，把结果拼成一个列表” 。接下来用join函数把列表里的字符串连接起来。 .join(L)的作用是把字符串列表L中的各个字符串拼接起来。 最后随机出小写字符出现的位置p, 然后插入到大写字母串中。s[a:b]代表列表或者字符串的第a个元素到第b-1 个元素。a和b都可以省略，a默认为0, b默认为列表长度。L2 = L[:］的作用是创建一个和L 一样的数组。 由于Python 的所有值都是引用类型的， 因此L2=L只是把L中保存的引用拷贝（浅拷贝）到了L2，这点需要小心。例如下面的代码，求其地址id可以分析出来。\n\u0026gt;\u0026gt;\u0026gt; a,b=1,2 \u0026gt;\u0026gt;\u0026gt; a= [1,3,7] \u0026gt;\u0026gt;\u0026gt; b=[1,3,7] \u0026gt;\u0026gt;\u0026gt; c,d=a,a[:] \u0026gt;\u0026gt;\u0026gt; id (a), id (b), id (c), id (d) (12598008, 12517288, 12598008, 12517208) 计算 30!可以采用如下写法:\n\u0026gt;\u0026gt;\u0026gt; from functools import* \u0026gt;\u0026gt;\u0026gt; reduce(lambda x,y: x*y, range(1,31)) 265252859812191058636308480000000L 简单实现 类似的东西还有很多。 使用Python后， 能大大缩短编写数据生成器、对拍器、 “猜想验证器” 等小程序的时间，这里我打算把python生成的数据全部转为字符数据存入文本中(转字符数据就不用考虑int位数 浮点数精度等问题)。c++再读数据存入容器进行原本函数的测试。\npython生成数据代码 接下来的代码为进行测试写入文件的代码，作为参考：\n# !/usr/bin/env python3 # coding: utf-8 from random import * from string import * def create_element0(lines, a = 4, b = 7): elements = [] for i in range(lines): # ascii_lowercase在string中定义，为所有小写字符的列表 # choice(seq): 返回列表、元组或字符串seq的随机项str。（可重复） L = randint(a, b) s =''.join([choice(ascii_lowercase) for i in range(L)]) p = randint(0, len(s)) element = s[:p] + choice(ascii_uppercase) + s[p:] + '\\n' elements.append(element) return elements def create_element1(lines): elements = [] for i in range(lines): # sample: 不重复的取列表中i个元素，并返回这些元素组成的列表 # 不可像choice中列表添加for in，因为其返回的是列表 # 要生成m个不重复i元素列表得在外面加循环 username = ''.join(sample(ascii_letters + digits, 5)) password = randint(10000,99999) element= str(username) + \u0026quot;,\u0026quot; + str(password) + '\\n' elements.append(element) return elements def create_element2(lines): elements = [] allNum = list(range(-10000, 10000)) NumLen = len(allNum) #在allNum中抽取Len个不重复数字,最后依照题意排序，旋转。共lines组 for i in range(lines): s = [] num = randint(1, 256) for j in range(num) : index = randint(j, NumLen - 1) s.append(allNum[index]) # 把用过的元素到前面,以防再次选中 allNum[index], allNum[i] = allNum[i], allNum[index] # 模拟target是否存在，有1/36的几率必定不存在 suiji = randint(0,35) if suiji == 35: target = 10001 else : target = s[randint(0, num-1)] #排序取出的不重复数组并旋转 s.sort() k = randint(0, num-1) if k != 0 : s = list(reversed(s[0:k])) + list(reversed(s[k:num])) s.reverse() element = ' '.join([str(s[i]) for i in range(num)]) + '\\n' elements.append(element) elements.append(str(target) + '\\n') print(f\u0026quot;i = {i},\\t k = {k}, \\ttarget = {target}\u0026quot;) return elements C++读取文件代码 C++中各种流头文件说明 iostream处理控制台IO； fstream处理命名文件IO； stringstream完成内存string的IO。 类fstream和stringstream都是继承在类iostream的。 输入类都继承自istream，输出类都继承自ostream。 string流：sstream头文件定义了三个类型来支持内存IO， 这些类型可以向string写入数据，从string读取数据，就像string是一个IO流一样。 将所有行数据打印出： 该代码仅为读取数据并载入容器中作为模板使用，若要加入判断正确等功能可以根据实际情况添加\n// 导入文本至容器，将每一行的数据以空格为间隔输入一个字符容器，将所有行的数据输入 int main() { string temp; ifstream myfile(\u0026quot;./date.txt\u0026quot;); if( !myfile ) { cout \u0026lt;\u0026lt; \u0026quot;open file fail!\u0026quot; \u0026lt;\u0026lt; endl; return -1; } vector\u0026lt;string\u0026gt; res; while (getline(myfile, temp)) {\t//默认停止符\\n stringstream slices(temp); string slice; while (slices \u0026gt;\u0026gt; slice) {\t// 类似cin输入，将每行排除不可显字符 空格等字符输入容器，直到接收回车为止 res.push_back(slice); // stoi(int), stol(long), stof(float), stod(double) } // for( auto r : res) //\tcout \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl; res.clear(); } myfile.close(); return 0; } 实际测试案例 上述测试确定无问题后，开始实际做python数据导入c++中做测试： 其中c++代码为leetcode题目搜索旋转排序数组 python生成数据函数即为上述代码的create_element2用于测试判断c++代码是否正确 接下来是c++的读取文件并进行调用。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;fstream\u0026gt; using namespace std; // 自己写的跟官方的思路差不多，官方答案不用先找到最大临界值再二分 直接进行判断二分 // 下面为官方答案，注意 边界 等于 问题 class Solution { public: int search(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int n = (int)nums.size(); if (!n) return -1; else if (n == 1) return nums[0] == target ? 0 : -1; int l = 0, r = n - 1; while (l \u0026lt;= r) { int mid = (l + r) / 2; if (nums[mid] == target) return mid; // target判断是否为mid if (nums[0] \u0026lt;= nums[mid]) { // 说明0到mid是升序 if (nums[0] \u0026lt;= target \u0026amp;\u0026amp; target \u0026lt; nums[mid]) // target在该升序中 r = mid - 1; else l = mid + 1; } else { // 说明mid到n-1是升序 if (nums[mid] \u0026lt; target \u0026amp;\u0026amp; target \u0026lt;= nums[n - 1]) // target在该升序中 l = mid + 1; else r = mid - 1; } } return -1; } }; // 导入文本至容器测试，将每一行的数据以空格为间隔输入一个字符容器，将所有行的数据输入 int main() { string temp; ifstream myfile(\u0026quot;./date.txt\u0026quot;); if( !myfile ) { cout \u0026lt;\u0026lt; \u0026quot;open file fail!\u0026quot; \u0026lt;\u0026lt; endl; return -1; } vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ress; vector\u0026lt;int\u0026gt; res; vector\u0026lt;int\u0026gt; targets; while (getline(myfile, temp)) {\t//默认停止符\\n stringstream slices(temp); string slice; while (slices \u0026gt;\u0026gt; slice) {\t// 类似cin输入，将每行排除不可显字符 空格等字符输入容器，直到接收回车为止 res.push_back(stoi(slice)); // stoi(int), stol(long), stof(float), stod(double) } getline(myfile, temp); targets.push_back(stoi(temp)); // for( auto rio : res) // cout \u0026lt;\u0026lt; rio \u0026lt;\u0026lt; endl; ress.push_back(res); res.clear(); } myfile.close(); Solution su; for (int i = 0; i \u0026lt; ress.size(); i++) { int ans = su.search(ress[i], targets[i]); cout \u0026lt;\u0026lt; targets[i] \u0026lt;\u0026lt; ' ' \u0026lt;\u0026lt; ans \u0026lt;\u0026lt;endl; } return 0; } ","id":32,"section":"posts","summary":"思路 python的特性支持快速开发实用小程序的能力，能让你做事效率大幅度提高。特别是在c++数据测试中，检验一个程序的可靠性需要大量数据进行","tags":["python","C/C++"],"title":"Python随机数据生成","uri":"https://liangkang233.github.io/2021/05/python%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/","year":"2021"},{"content":"本人习惯使用onenote记录一些问题和做记录，最近发现开启本地http代理服务器后onenote无法同步，但是我代理配置是无误的。经过查询发现这个是uwp应用的特性：\nUWP 是微软在 Windows 10 中引入的新概念，由于所有 UWP 应用均运行在被称为 App Container 的虚拟沙箱环境中，其安全性及纯净度远胜于传统的 EXE 应用。但 App Container 机制同时也阻止了网络流量发送到本机（即 loopback）， 使大部分网络抓包调试工具无法对 UWP 应用进行流量分析。同样的，该机制也阻止了 UWP 应用访问 localhost，即使你在系统设置中启用了代理，也无法令 UWP 应用访问本地代理服务器。\n所以只要设置uwp应用可以访问本地代理服务器就能解决问题了。\n解决方法： 参考官方给的解决方案 要解决此问题，您需要使用PowerShell命令将有关应用添加到 Windows 10 回路豁免列表。 将带有\u0026quot;Microsoft.MinecraftUWP_8wekyb3d8bbwe\u0026quot;的包名的应用程序添加到循环回路豁免列表中。 要查找包名，您可以使用以下powershell命令：\nGet-AppxPackage #列出所有uwp应用程序。 Get-AppxPackage | Select-String -Pattern \u0026quot;Minecraft\u0026quot; #列出所有名字中含有“Minecraft”的应用程序。 CheckNetIsolation LoopbackExempt -d -n=\u0026quot;Microsoft.MinecraftUWP_8wekyb3d8bbwe\u0026quot; # 使用程序名字从豁免列表中剔除该程序 CheckNetIsolation LoopbackExempt -d -p=\u0026quot;sid编号\u0026quot; # 使用程序sid从豁免列表中剔除该程序 CheckNetIsolation LoopbackExempt -s #展示豁免列表 CheckNetIsolation LoopbackExempt -c #清除豁免列表 法1 查询注册表sid 举例：\nGet-AppxPackage | Select-String -Pattern \u0026quot;onenote\u0026quot;\t#查找onenote包名称 #查询到onenote 包名为 Microsoft.Office.OneNote_16001.13801.20202.0_x64__8wekyb3d8bbwe CheckNetIsolation LoopbackExempt -a -n=\u0026quot;Microsoft.Office.OneNote_16001.13801.20202.0_x64__8wekyb3d8bbwe\u0026quot; #添加至豁免列表 CheckNetIsolation LoopbackExempt -d -n=\u0026quot;Microsoft.Office.OneNote_16001.13801.20202.0_x64__8wekyb3d8bbwe\u0026quot; #从豁免列表中移除 法2 注册表查询程序包名 win+r 输入regedit，打开注册表编辑器，地址栏粘贴 HKEY_CURRENT_USER\\Software\\Classes\\Local Settings\\Software\\Microsoft\\Windows\\CurrentVersion\\AppContainer\\Mappings，里面的DisplayName值就是应用名称，查询对应程序的sid类似S-1-15-2-3445883232-1224167743-206467785-1580939083-2750001491-3097792036-3019341970形式\nCheckNetIsolation.exe loopbackexempt -a -p=UWP的SID CheckNetIsolation.exe loopbackexempt -d -p=UWP的SID #举例：豁免onenote走代理 CheckNetIsolation.exe loopbackexempt -a -p=S-1-15-2-3445883232-1224167743-206467785-1580939083-2750001491-3097792036-3019341970 onenote问题 可惜的是，法1对MinecraftUWP有效，对onenote失效。可能是其包名不对，该包名指向的是office套件中的onenote。打印如下的豁免表可知，法二生成的豁免表是生效的 法2生成\n列出环回免除的 AppContainer [1] ----------------------------------------------------------------- 名称: microsoft.office.onenote_8wekyb3d8bbwe SID: S-1-15-2-3445883232-1224167743-206467785-1580939083-2750001491-3097792036-3019341970 [2] ----------------------------------------------------------------- 名称: AppContainer NOT FOUND SID: S-1-15-2-3624051433-2125758914-1423191267-1740899205-1073925389-3782572162-737981194-4043415302-551583165-304772019-4009825106 [3] ----------------------------------------------------------------- 名称: 001 SID: S-1-15-2-3624051433-2125758914-1423191267-1740899205-1073925389-3782572162-737981194-4256926629-1688279915-2739229046-3928706915 法1生成\n列出环回免除的 AppContainer [1] ----------------------------------------------------------------- 名称: AppContainer NOT FOUND SID: S-1-15-2-883788003-1897955942-3642183005-638760255-2249287259-3707616651-3249579104 [2] ----------------------------------------------------------------- 名称: AppContainer NOT FOUND SID: S-1-15-2-3624051433-2125758914-1423191267-1740899205-1073925389-3782572162-737981194-4043415302-551583165-304772019-4009825106 [3] ----------------------------------------------------------------- 名称: 001 SID: S-1-15-2-3624051433-2125758914-1423191267-1740899205-1073925389-3782572162-737981194-4256926629-1688279915-2739229046-3928706915 ","id":33,"section":"posts","summary":"本人习惯使用onenote记录一些问题和做记录，最近发现开启本地http代理服务器后onenote无法同步，但是我代理配置是无误的。经过查询","tags":[],"title":"uwp应用代理","uri":"https://liangkang233.github.io/2021/04/uwp%E5%BA%94%E7%94%A8%E4%BB%A3%E7%90%86/","year":"2021"},{"content":"功能 之前想获得一段机器配音时，总是一句一句粘贴在翻译软件上读取，非常麻烦。 后来知道百度AI提供了免费的语音合成api，所以简单分享下使用方法。\n使用说明 百度智能云语音识别\n首先打开上述网址点击立即开始注册或登录账号\n创建一个应用并按照你的需求注册，当然不只是语音识别还有其他类似人脸识别图像处理等接口，但是大部分是要收费的。具体其他业务可以看看官方指南\n这些我们可以不管，只需要注册语音识别应用，文本转语音业务包含在其中。注册好可以如下图领取免费额度。 最后配置完成后，下载python的sdk来安装,使用python setup.py install\n其他组件 所有组件github地址: 百度AI python sdk地址. 其它功能也可类似调用接口实现，这里只是简单使用语音识别的文本语音转换功能。\n文本转语音测试 参考了官方的测试案例编写了下面的代码，有兴趣的可以试试其他api的调用，此代码python2 3皆可使用。\n# coding: utf-8 # 逐行读入source/test.txt文件，并创建audio1.mp3 audio2.mp3 audio3.mp3存入source文件夹中 ...... import sys import json IS_PY3 = sys.version_info.major == 3 if IS_PY3: from urllib.request import urlopen from urllib.request import Request from urllib.error import URLError from urllib.parse import urlencode from urllib.parse import quote_plus else: import urllib2 from urllib import quote_plus from urllib2 import urlopen from urllib2 import Request from urllib2 import URLError from urllib import urlencode API_KEY = '此处替换为你应用的API_KEY ' SECRET_KEY = '此处替换为你应用的SECRET_KEY' TEXT = \u0026quot;欢迎使用百度语音合成。\u0026quot; # 发音人选择，默认为度小美 # 基础音库：0为度小美，1为度小宇，3为度逍遥，4为度丫丫， # 精品音库：5为度小娇，103为度米朵，106为度博文，110为度小童，111为度小萌 PER = 3 # 语速，取值0-15，默认为5中语速 SPD = 6 # 音调，取值0-15，默认为5中语调 PIT = 5 # 音量，取值0-9，默认为5中音量 VOL = 7 # 下载的文件格式, 3：mp3(default) 4： pcm-16k 5： pcm-8k 6. wav AUE = 3 FORMATS = {3: \u0026quot;.mp3\u0026quot;, 4: \u0026quot;.pcm\u0026quot;, 5: \u0026quot;.pcm\u0026quot;, 6: \u0026quot;.wav\u0026quot;} FORMAT = FORMATS[AUE] CUID = \u0026quot;123456PYTHON\u0026quot; TTS_URL = 'http://tsn.baidu.com/text2audio' class DemoError(Exception): pass \u0026quot;\u0026quot;\u0026quot; TOKEN start \u0026quot;\u0026quot;\u0026quot; TOKEN_URL = 'http://openapi.baidu.com/oauth/2.0/token' SCOPE = 'audio_tts_post' # 有此scope表示有tts能力，没有请在网页里勾选 def fetch_token(): print(\u0026quot;fetch token begin\u0026quot;) params = {'grant_type': 'client_credentials', 'client_id': API_KEY, 'client_secret': SECRET_KEY} post_data = urlencode(params) if (IS_PY3): post_data = post_data.encode('utf-8') req = Request(TOKEN_URL, post_data) try: f = urlopen(req, timeout=5) result_str = f.read() except URLError as err: print('token http response http code : ' + str(err.code)) result_str = err.read() if (IS_PY3): result_str = result_str.decode() print(result_str) result = json.loads(result_str) print(result) if ('access_token' in result.keys() and 'scope' in result.keys()): if not SCOPE in result['scope'].split(' '): raise DemoError('scope is not correct') print('SUCCESS WITH TOKEN: %s ; EXPIRES IN SECONDS: %s' % (result['access_token'], result['expires_in'])) return result['access_token'] else: raise DemoError('MAYBE API_KEY or SECRET_KEY not correct: access_token or scope not found in token response') \u0026quot;\u0026quot;\u0026quot; TOKEN end \u0026quot;\u0026quot;\u0026quot; def tts(str, id): # tex = quote_plus(TEXT) tex = quote_plus(text[i]) # 此处TEXT需要两次urlencode print(tex) params = {'tok': token, 'tex': tex, 'per': PER, 'spd': SPD, 'pit': PIT, 'vol': VOL, 'aue': AUE, 'cuid': CUID, 'lan': 'zh', 'ctp': 1} # lan ctp 固定参数 data = urlencode(params) print('test on Web Browser' + TTS_URL + '?' + data) req = Request(TTS_URL, data.encode('utf-8')) has_error = False try: f = urlopen(req) result_str = f.read() headers = dict((name.lower(), value) for name, value in f.headers.items()) has_error = ('content-type' not in headers.keys() or headers['content-type'].find('audio/') \u0026lt; 0) except URLError as err: print('asr http response http code : ' + str(err.code)) result_str = err.read() has_error = True save_file = \u0026quot;error.txt\u0026quot; if has_error else \u0026quot;./source/result\u0026quot; + id + FORMAT #三目运算符 with open(save_file, 'wb') as of: of.write(result_str) if has_error: if (IS_PY3): result_str = str(result_str, 'utf-8') print(\u0026quot;tts api error:\u0026quot; + result_str) print(\u0026quot;result saved as :\u0026quot; + save_file) if __name__ == '__main__': token = fetch_token() text = [] file = open(\u0026quot;./source/test.txt\u0026quot;, 'r', encoding='UTF-8') while True: lines = file.readlines(100000) if not lines: break for line in lines: text.append(line) for i in range(len(text)): tts(text[i], str(i+1)) ","id":34,"section":"posts","summary":"功能 之前想获得一段机器配音时，总是一句一句粘贴在翻译软件上读取，非常麻烦。 后来知道百度AI提供了免费的语音合成api，所以简单分享下使用方法","tags":["python"],"title":"批量文字转语音 tts工具","uri":"https://liangkang233.github.io/2021/04/%E6%89%B9%E9%87%8F%E6%96%87%E6%9C%AC%E8%BD%AC%E8%AF%AD%E9%9F%B3/","year":"2021"},{"content":"功能 由于刚好有需求要更改配置文件参数，想到python简单易用的特点，所以边学边做了这个程序帮助修改参数。该程序功能为读取一个二进制文本其中的参数按照指定格式修改。\n参考教程 文件读写教程. 正则表达式教程. python的很多基础都是在廖雪峰老师这学的，写的很详细不错，所以后面的分析就不详细说了。\n源码 #!/usr/bin/python3 # coding: utf-8 speed = int(input(\u0026quot;Please enter the adjustment speed: \u0026quot;)) #修改test.config文件 with open('test.config', 'r', encoding='utf-8') as o_config : lines = o_config.readlines() # readlines返回每行字符串组成的list flen=len(lines) for i in range(flen): if lines[i].startswith(\u0026quot;SIMULATION-TIME\u0026quot;) : config_value = lines[i].split(' ') value = int( config_value[1][0:-2:1] ) # 用切片删去S和回车转成值 value = int(3600 / speed) lines[i] = config_value[0] + ' ' + str(value) + 'S\\n' break else : continue with open('test.config','w', encoding='utf-8') as new_config : new_config.writelines(lines) #修改test.nodes文件 with open('test.nodes', 'r', encoding='utf-8') as o_config : lines = o_config.readlines() # readlines返回每行字符串组成的list flen=len(lines) for i in range(flen): if lines[i] == '\\n' : break node_value = lines[i].split(' ', 2) if node_value[1] == '0' : continue else : value = int( node_value[1][0: -1:1] ) value = int( value / speed ) lines[i] = node_value[0] + ' ' + str(value) + 'S ' + node_value[2] with open('test.nodes','w', encoding='utf-8') as new_nodes : new_nodes.writelines(lines) print(\u0026quot;Modified to complete\u0026quot;) 代码分析 python修改文本暂时没找到直接更改办法，上述代码都是先读取文本复制到内存中的列表，修改后再将列表写入文件。 修改test.config文件代码，使用readlines返回每行字符串组成的list。当然也可以用readline和while读取每一行来进行操作。 使用startswith对每行行首判断寻找关键字符串类型，之后使用split空格分开为字符串列表后用切片提取出值对应的字符串。 例如下图中config文件会读取到lines[8]这行有待寻找关键字，用split生成list[\u0026lsquo;SIMULATION-TIME\u0026rsquo;, \u0026lsquo;3600S\\n\u0026rsquo;], 进行切片操作[1:-2:1]得到字符串'3600\u0026rsquo; (回车\\n也需要切片去除)，这样转化成int型处理完再转为字符串填充回原来列表中即可。 之后类似的对test.nodes进行操作!\n此处，由于其配置文件规则简单由空格区分，所以处理起来只需要split和列表切片，若是复杂的字符串数据还是得用上面教程中的正则表达式来处理。 此外，如果需要更改参数精度更好的案例这里也提供一份\n#!/usr/bin/python3 #coding: utf-8 #修改 1.nodes文件 speed = 100 with open('1.nodes', 'r', encoding='utf-8') as o_config : lines = o_config.readlines() # readlines返回每行字符串组成的list flen=len(lines) for i in range(flen): if lines[i] == '\\n' : break node_value = lines[i].split(' ', 5) valuex = round( float( node_value[2][1: -1:1]) / speed,14 ) valuey = round( float( node_value[3][1: -1:1]) / speed,14 ) valuez = round( float( node_value[4][1: -1:1]) / speed,14 ) # lines[i] = node_value[0] + ' ' + node_value[1] + ' (' + \\ # str(valuex) + ', ' + str(valuey) + ', ' + str(valuez) + ') ' + node_value[5] lines[i] = node_value[0] + ' ' + node_value[1] + ' (' + \\ '%.014f'%valuex + ', ' + '%.014f'%valuey + ', ' + '%.014f'%valuez + ') ' + node_value[5] with open('1.nodes','w', encoding='utf-8') as new_nodes : new_nodes.writelines(lines) print(\u0026quot;Modified to complete\u0026quot;) ","id":35,"section":"posts","summary":"功能 由于刚好有需求要更改配置文件参数，想到python简单易用的特点，所以边学边做了这个程序帮助修改参数。该程序功能为读取一个二进制文本其中","tags":["python"],"title":"Pthon读写文件","uri":"https://liangkang233.github.io/2021/03/python%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6/","year":"2021"},{"content":"hello world 测试 老生常谈的hello world，在此之前的原blog帖子会归档本地草稿\n各测试项目文件 draft: true,\ntag: blog test\nrich-content\nemoji-support\nmarkdown-syntax\nplaceholder-text\nvideo test ","id":36,"section":"posts","summary":"hello world 测试 老生常谈的hello world，在此之前的原blog帖子会归档本地草稿 各测试项目文件 draft: true, tag: blog test rich-content emoji-support markdown-syntax placeholder-text video test","tags":["blog test"],"title":"Hello World","uri":"https://liangkang233.github.io/2020/12/hello-world/","year":"2020"}],"tags":[{"title":"blog test","uri":"https://liangkang233.github.io/tags/blog-test/"},{"title":"C/C++","uri":"https://liangkang233.github.io/tags/c/c++/"},{"title":"go","uri":"https://liangkang233.github.io/tags/go/"},{"title":"linux","uri":"https://liangkang233.github.io/tags/linux/"},{"title":"network","uri":"https://liangkang233.github.io/tags/network/"},{"title":"python","uri":"https://liangkang233.github.io/tags/python/"},{"title":"sdn","uri":"https://liangkang233.github.io/tags/sdn/"},{"title":"仿真","uri":"https://liangkang233.github.io/tags/%E4%BB%BF%E7%9C%9F/"},{"title":"容器","uri":"https://liangkang233.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"title":"开发","uri":"https://liangkang233.github.io/tags/%E5%BC%80%E5%8F%91/"},{"title":"数据结构","uri":"https://liangkang233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"算法","uri":"https://liangkang233.github.io/tags/%E7%AE%97%E6%B3%95/"}]}