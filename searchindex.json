{"categories":[{"title":"Core","uri":"https://liangkang233.github.io/categories/core/"},{"title":"学习","uri":"https://liangkang233.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"title":"工具","uri":"https://liangkang233.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"title":"杂谈","uri":"https://liangkang233.github.io/categories/%E6%9D%82%E8%B0%88/"},{"title":"编程","uri":"https://liangkang233.github.io/categories/%E7%BC%96%E7%A8%8B/"},{"title":"记录","uri":"https://liangkang233.github.io/categories/%E8%AE%B0%E5%BD%95/"}],"posts":[{"content":"最近在做一个关于应用上云的测试，于是看到有华为云的免费服务器试用就注册了一个，记录下操作备忘。\n个人用户实名注册即可领取一个低性能的2核4g的服务器，试用15天。领取链接\n初始化操作 领取成功后，按照创建步骤即可。如果没有设定登录密码的，在控制台设置即可。弹性公网即为服务器的公网IP，与其链接通信试用这个ip。 远程登录可以试用 CloudShell VNC Xshell shell 等登录，先使用VNC设置初始密码，网络安全组的入站等规则。 此页面也可查询服务器详细一段时间内运行状态 需要的初步操作：   添加普通用户\nroot 用户权限太大，为了以防误操作和开发需要，需要新建一个有root权限的普通用户。\n# 创建用户 sudo adduser username ## 命令将向你询问一系列的问题。密码是必需的，其他字段都是可选的。 Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully Changing the user information for username Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] # 最后，输入Y确认信息是否正确。 # 如果您希望新创建的用户具有管理权限，请将用户添加到sudo组： sudo usermod -aG sudo username # 您可以使用两个命令行工具来删除用户帐户：userdel和deluser。在Ubuntu上，建议您使用deluser命令，因为它比userdel 更友好。 # 要删除用户而不删除用户文件，请运行： sudo deluser username # 如果要删除并且用户的家目录和邮件使用--remove-home选项： sudo deluser --remove-home username    ssh公钥免密登录\n我更习惯直接使用ssh登录远程服务器，所以设置免密登录很有必要\napt-get install openssh-server openssh-client # 如果没有或者需要一个新公私钥的创建命令 ssh-keygen -t rsa -f ~/.ssh/cloud # 复制公钥，需要登录那个用户就复制到哪 ssh-copy-id -i ~/.ssh/cloud.pub root@弹性公网IP    X11图形界面允许\n如果需要符合传输X11协议的图形界面需要确保ssh登录后：\n环境说明： A主机ssh连接B主机，A使用X11服务显示使用B主机的code等界面 a. 首先确保A可以连接上B主机 b. 设置主机A运行其他服务器的 X11 界面： xhost + c. 设置主机A sudo vim /etc/ssh/ssh_config ForwardAgent yes ForwardX11 yes ForwardX11Trusted yes d. 设置主机B的 daemon 配置X11转发 sudo vim /etc/ssh/sshd_config #补充下面这行,我这台服务器是已经配置好的。 X11Forwarding yes #确保正确后重启ssh daemon sudo systemctl restart sshd 最后连接B主机即可 ssh -X username@B主机(IP)    更改主机名\n如果你在一个云实例上运行 Ubuntu，并且安装了cloud-init软件包，你也可以编辑/etc/cloud/cloud.cfg文件。这个软件包由云服务器厂商提供，通常默认被安装，并且它可以被用来处理云服务器实例的初始化。如果文件存在于你的系统上，打开它：sudo nano /etc/cloud/cloud.cfg搜索\u0026quot;preserve_hostname”,并且将值从false修改到true。\n#This will cause the set+update hostname module to not operate (if true) preserve_hostname: true # 保存文件，并且关闭编辑器运行命令 hostnamectl sethostname YOUR_define_name    远程Vscode 虽然服务器自带vim等编辑器，但是还是vscode用的顺手，下面是配置远端登录vscode的记录。（用x11打开的vscode太卡，不推荐如此使用）\n打开本地主机的vscode扩展商店，搜索安装 Remote - SSH: Editing Configuration Files ms-vscode-remote.remote-ssh-edit 之后打开此扩展设定远程登录的IP和用户 可是启动远程登录时ssh Server卡在Setting up SSH Host XX: Downloading VS Code Server\n重新连接后有detail选项，打开显示的部分日志如下：\n[14:30:07.314] Log Level: 2 [14:30:07.317] remote-ssh@0.66.0 [14:30:07.318] linux x64 [14:30:07.321] SSH Resolver called for \u0026quot;ssh-remote+cloud-huawei-root\u0026quot;, attempt 1 [14:30:07.322] \u0026quot;remote.SSH.useLocalServer\u0026quot;: true [14:30:07.322] \u0026quot;remote.SSH.path\u0026quot;: undefined [14:30:07.322] \u0026quot;remote.SSH.configFile\u0026quot;: undefined [14:30:07.322] \u0026quot;remote.SSH.useFlock\u0026quot;: true [14:30:07.323] \u0026quot;remote.SSH.lockfilesInTmp\u0026quot;: false [14:30:07.323] \u0026quot;remote.SSH.localServerDownload\u0026quot;: auto [14:30:07.323] \u0026quot;remote.SSH.remoteServerListenOnSocket\u0026quot;: false [14:30:07.323] \u0026quot;remote.SSH.showLoginTerminal\u0026quot;: false [14:30:07.324] \u0026quot;remote.SSH.defaultExtensions\u0026quot;: [] [14:30:07.324] \u0026quot;remote.SSH.loglevel\u0026quot;: 2 [14:30:07.325] SSH Resolver called for host: cloud-huawei-root [14:30:07.325] Setting up SSH remote \u0026quot;cloud-huawei-root\u0026quot; [14:30:07.331] Acquiring local install lock: /tmp/vscode-remote-ssh-fd33cb2f-install.lock [14:30:07.352] Looking for existing server data file at /home/lk233/.config/Code/User/globalStorage/ms-vscode-remote.remote-ssh/vscode-ssh-host-fd33cb2f-b4c1bd0a9b03c749ea011b06c6d2676c8091a70c-0.66.0/data.json [14:30:07.356] Using commit id \u0026quot;b4c1bd0a9b03c749ea011b06c6d2676c8091a70c\u0026quot; and quality \u0026quot;stable\u0026quot; for server [14:30:07.368] Install and start server if needed [14:30:07.379] PATH: /home/lk233/.local/bin:/home/lk233/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/lk233/.local/bin:/home/lk233/go/bin:/usr/local/go/bin:/home/lk233/.local/bin:/home/lk233/.local/bin [14:30:07.380] Checking ssh with \u0026quot;ssh -V\u0026quot; [14:30:07.418] \u0026gt; OpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n 7 Dec 2017 [14:30:07.429] askpass server listening on /run/user/1000/vscode-ssh-askpass-40f6502d1f6ea56e214539b4c7f7cd72b715cc8b.sock [14:30:07.430] Spawning local server with {\u0026quot;serverId\u0026quot;:1,\u0026quot;ipcHandlePath\u0026quot;:\u0026quot;/run/user/1000/vscode-ssh-askpass-2918dcdc514eef86200f16b5db8a75360fbea57c.sock\u0026quot;,\u0026quot;sshCommand\u0026quot;:\u0026quot;ssh\u0026quot;,\u0026quot;sshArgs\u0026quot;:[\u0026quot;-v\u0026quot;,\u0026quot;-T\u0026quot;,\u0026quot;-D\u0026quot;,\u0026quot;45283\u0026quot;,\u0026quot;-o\u0026quot;,\u0026quot;ConnectTimeout=15\u0026quot;,\u0026quot;cloud-huawei-root\u0026quot;],\u0026quot;dataFilePath\u0026quot;:\u0026quot;/home/lk233/.config/Code/User/globalStorage/ms-vscode-remote.remote-ssh/vscode-ssh-host-fd33cb2f-b4c1bd0a9b03c749ea011b06c6d2676c8091a70c-0.66.0/data.json\u0026quot;} [14:30:07.430] Local server env: {\u0026quot;DISPLAY\u0026quot;:\u0026quot;:0\u0026quot;,\u0026quot;ELECTRON_RUN_AS_NODE\u0026quot;:\u0026quot;1\u0026quot;,\u0026quot;SSH_ASKPASS\u0026quot;:\u0026quot;/home/lk233/.vscode/extensions/ms-vscode-remote.remote-ssh-0.66.0/out/local-server/askpass.sh\u0026quot;,\u0026quot;VSCODE_SSH_ASKPASS_NODE\u0026quot;:\u0026quot;/usr/share/code/code\u0026quot;,\u0026quot;VSCODE_SSH_ASKPASS_MAIN\u0026quot;:\u0026quot;/home/lk233/.vscode/extensions/ms-vscode-remote.remote-ssh-0.66.0/out/askpass-main.js\u0026quot;,\u0026quot;VSCODE_SSH_ASKPASS_HANDLE\u0026quot;:\u0026quot;/run/user/1000/vscode-ssh-askpass-40f6502d1f6ea56e214539b4c7f7cd72b715cc8b.sock\u0026quot;} [14:30:07.447] Spawned 11142 [14:30:07.653] \u0026gt; local-server-1\u0026gt; Spawned ssh, pid=11150 [14:30:07.659] stderr\u0026gt; OpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n 7 Dec 2017 [14:30:07.914] stderr\u0026gt; debug1: Server host key: ecdsa-sha2-nistp256 SHA256:TeikcLf0gyEyeAnlAgObhrs6PKRrfQQeW6zLEFgFiA4 [14:30:08.172] stderr\u0026gt; Authenticated to 123.60.23.165 ([123.60.23.165]:22). [14:30:08.977] \u0026gt; Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-70-generic aarch64) \u0026gt; \u0026gt; * Documentation: https://help.ubuntu.com \u0026gt; * Management: https://landscape.canonical.com \u0026gt; * Support: https://ubuntu.com/advantage \u0026gt; \u0026gt; System information as of Sun Nov 14 14:30:08 CST 2021 \u0026gt; \u0026gt; System load: 0.05 Processes: 99 \u0026gt; Usage of /: 10.2% of 38.63GB Users logged in: 0 \u0026gt; Memory usage: 6% IP address for eth0: 192.168.0.20 \u0026gt; Swap usage: 0% \u0026gt; *****  查了下果然是这个vscode-server包需要科学上网，所以云服务器无法连接上。 只能按照How can I install vscode-server in linux offline类似的安装了。不过里面问题提问的人的是x86架构的包，我使用的是ARM的包。\n上面日志可以看到有一句Using commit id \u0026ldquo;b4c1bd0a9b03c749ea011b06c6d2676c8091a70c\u0026rdquo; and quality \u0026ldquo;stable\u0026rdquo; for server，这个等价替换上面问题的解决方案的commitid即可。其实直接查看主机运行的code 相关进程即可看到：\nroot@cloud:~# ps aux | grep code root 507 0.0 0.1 11488 5940 ? S 14:27 0:00 wget --tries=1 --connect-timeout=7 --dns-timeout=7 -nv -O vscode-server.tar.gz https://update.code.visualstudio.com/commit:b4c1bd0a9b03c749ea011b06c6d2676c8091a70c/server-linux-arm64/stable root 5321 0.0 0.0 5672 664 pts/0 S+ 14:31 0:00 grep --color=auto code  总结下解决方案：\n 本地下好对应包 我的版本的 commit id = b4c1bd0a9b03c749ea011b06c6d2676c8091a70c，使用stable版本（inside预览不推荐） 浏览器或wget下载https://update.code.visualstudio.com/commit:b4c1bd0a9b03c749ea011b06c6d2676c8091a70c/server-linux-arm64/stable scp复制该压缩包上传云服务器 $ scp /home/localuser/vscode-server-linux-arm64.tar.gz user@123.60.23.165:/home/user/ 解压并设定状态 如果之前下载失败了记得把commit对应文件夹清空，或者新建一个。user对应云服务器用户名一般为 /root/.vscode-server-insiders/bin/${commit_id} 或者 /home/user/.vscode-server-insiders/bin/${commit_id} tar zxvf ./vscode-server-linux-x64.tar.gz -C /home/user/.vscode-server-insiders/bin/${commit_id} --strip 1 touch /home/user/.vscode-server-insiders/bin/${commit_id}/0    最后，安装完毕，登录成功如下所示 当然，要记得关闭后台更新。\n","id":0,"section":"posts","summary":"最近在做一个关于应用上云的测试，于是看到有华为云的免费服务器试用就注册了一个，记录下操作备忘。 个人用户实名注册即可领取一个低性能的2核4g的","tags":["linux"],"title":"华为云服务器折腾记录","uri":"https://liangkang233.github.io/2021/11/%E5%8D%8E%E4%B8%BA%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8A%98%E8%85%BE%E8%AE%B0%E5%BD%95/","year":"2021"},{"content":"先简单介绍几个基础概念：   递归 递归是重复调用函数自身实现循环。迭代是函数内某段代码实现循环。 其中，迭代与普通循环的区别是：迭代时，循环代码中参与运算的变量同时是保存结果的变量，当前保存的结果作为下一次循环计算的初始值。典型的应用有深度搜索dfs\n  迭代 递归循环中，遇到满足终止条件的情况时逐层返回来结束。迭代则使用计数器结束循环。 当然很多情况都是多种循环混合采用，这要根据具体需求.在循环的次数较大的时候，迭代的效率明显高于递归,但是不易于理解。典型应用有bfs中遍历队列。\n对于斐波那契数列\n// 递归方法 int fibonacci_sequence_recursion(int n) { return (n \u0026amp;lt; 2) ? n : fibonacci_sequence_recursion(n - 1) + fibonacci_sequence_recursion(n - 2); } // 迭代方法 int fibonacci_sequence_loop(int n) { if (n \u0026amp;lt; 2) return n; int before = 0; int last = 1; while (1 \u0026amp;lt; n--) { last = before + last; before = last - before; } return last; }    五大基本算法： 穷举 enumerate 枚举的思想是不断地猜测，从可能的集合中一一尝试，然后再判断题目的条件是否成立。 枚举的时候要想清楚：可能的情况是什么？要枚举哪些要素？ 枚举的范围是什么？是所有的内容都需要枚举吗？\n在用枚举法解决问题的时候，一定要想清楚这两件事，否则会带来不必要的时间开销。\n贪心 greedy 在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望导致结果是最好或最优的算法。比如在旅行推销员问题中，如果旅行员每次都选择最近的城市，那这就是一种贪心算法。\n贪心算法与动态规划的不同在于它对每个子问题的解决方案都做出选择，不能回退。动态规划则会保存以前的运算结果，并根据以前的结果对当前进行选择，有回退功能。\n分治 divide-and-conquer 把问题分解成规模小的问题，再去递归(或迭代)解决。\n 注意二分搜索(binary-search)每次都要舍弃一半，从留下的一半中寻找目标；而分治法把一个大问题分成两个或多个小问题\n  归并排序  void merge_sort_recursive(int arr[], int reg[], int start, int end) { if (start \u0026gt;= end) return; int len = end - start, mid = (len \u0026gt;\u0026gt; 1) + start; int start1 = start, end1 = mid; int start2 = mid + 1, end2 = end; merge_sort_recursive(arr, reg, start1, end1); merge_sort_recursive(arr, reg, start2, end2); int k = start; while (start1 \u0026lt;= end1 \u0026amp;\u0026amp; start2 \u0026lt;= end2) reg[k++] = arr[start1] \u0026lt; arr[start2] ? arr[start1++] : arr[start2++]; while (start1 \u0026lt;= end1) reg[k++] = arr[start1++]; while (start2 \u0026lt;= end2) reg[k++] = arr[start2++]; for (k = start; k \u0026lt;= end; k++) arr[k] = reg[k]; } void merge_sort(int arr[], const int len) { int reg[len]; merge_sort_recursive(arr, reg, 0, len - 1); }   汉诺塔问题  #!/usr/bin/env python3 # -*- coding: utf-8 -*- def move(n, a, b, c): if n == 1: print(a, '--\u0026gt;', c) return move(n-1, a, c, b) print(a, '--\u0026gt;', c) move(n-1, b, a, c) a = input(\u0026quot;请输入汉尼塔A的个数: \u0026quot;) move(int(a), 'A', 'B', 'C') \u0026quot;\u0026quot;\u0026quot; 总次数一定为 2^n - 1 可以把盘子看成两部分，最下面的第n个和上面的n-1个，完成所有盘子的从a到c可以分解为3步: 1.把上面n-1个盘子从a移动到b 2.把最下面的第n个盘子从a移动到c 3.把在b上的n-1个盘子移动到c 这样从最后一步往前n-1个分解，只不过步骤1和3中的移动前n-1个不是借助b从a移动到c，而分别是，借助c从a到b和借助a从b到c。 这样就分解成了n-1个盘子的汉诺塔问题，一直用这三步迭代分解一直到n等于1。 \u0026quot;\u0026quot;\u0026quot;  回溯 backtracking 回溯法简单来说就是按照深度优先的顺序，穷举所有可能性的算法，但是回溯算法比暴力穷举法更高明的地方就是回溯算法可以随时判断当前状态是否符合问题的条件。一旦不符合条件，那么就退回到上一个状态，省去了继续往下探索的时间。所以根据这类问题，一般会有优化剪枝策略以及启发式搜索策略。\n多说无益，给出几个具体例子：\n  经典八皇后问题\n八皇后问题是一个以国际象棋为背景的问题：如何能够在8×8的国际象棋棋盘上放置八个皇后， 使得任何一个皇后都无法直接吃掉其他的皇后？为了达到此目的，任两个皇后都不能处于同一条横行、纵行或斜线上。八皇后问题可以推广为更一般的n皇后摆放问题：这时棋盘的大小变为n×n，而皇后个数也变成n。当且仅当n = 1或n ≥ 4时问题有解[1]。*/\n#include \u0026lt;iostream\u0026gt; using namespace std; const int N = 8; int arr[10], total_cnt; // arr记录每一行(X)皇后的Y坐标 bool isPlaceOK(int *a, int n, int c) { for (int i = 1; i \u0026lt;= n - 1; ++i) { if (a[i] == c || a[i] - i == c - n || a[i] + i == c + n) return false; //检查位置是否可以放 (n行c列)是将要放置的位置 //a[i] == c如果放在同一列，false //a[i] -+ i = c -+ n 如果在对角线上，（处在同一左(右)对角,行列值只差(和)相同） false } return true; } void printSol(int *a) { for (int i = 1; i \u0026lt;= N; ++i) { //遍历每一行 for (int j = 1; j \u0026lt;= N; ++j) { //遍历每一列 cout \u0026lt;\u0026lt; (a[i] == j ? \u0026quot;X\u0026quot; : \u0026quot;-\u0026quot;) \u0026lt;\u0026lt; \u0026quot; \u0026quot;;; } //如果标记数组中这一行的皇后放在j位置，则输出X，否则输出-， //用空格分隔 cout \u0026lt;\u0026lt; endl; //每一行输出一个换行 } cout \u0026lt;\u0026lt; endl; //每一组数据一个换行分隔 } void addQueen(int *a, int n) { if (n \u0026gt; N) { //n代表从第一行开始放置 printSol(a); total_cnt++; return ; } for (int i = 1; i \u0026lt;= N; ++i) { //i从第1列到第N列遍历 if (isPlaceOK(a, n, i)) { a[n] = i; //如果可以放置，就把皇后放在第n行第i列 addQueen(a, n + 1); } } } int main() { addQueen(arr, 1); cout \u0026lt;\u0026lt; \u0026quot;total: \u0026quot; \u0026lt;\u0026lt; total_cnt \u0026lt;\u0026lt; \u0026quot; solutions.\\n\u0026quot;; return 0; }   分割回文串  class Solution { public: vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; ans; bool isHui(string a) { int size = a.size(); for (int i = 0; i \u0026lt; size / 2; i++) { if (a[i] != a[size - i - 1]) return false; } return true; } void find(string s, int index, vector\u0026lt;string\u0026gt; temp) { if (index == s.size()) ans.push_back(temp); for (int i = 1; index + i \u0026lt;= s.size(); i++) { if (isHui(s.substr(index, i))) { vector\u0026lt;string\u0026gt; temp1(temp); temp1.push_back(s.substr(index, i)); find(s, index + i, temp1); } } } vector\u0026lt;vector\u0026lt;string\u0026gt;\u0026gt; partition(string s) { vector\u0026lt;string\u0026gt; temp; find(s, 0, temp); return ans; } };    动态规划 dynamic-programming 动态规划在刷题中经常遇到，有很多种变形题但是基本都是这么个思路，自顶向下 拆分问题 找出状态转移方程。 动态规划就是一种聪明的穷举，记录其中部分过程的状态。非常重要，多做多思考。\n 经典背包问题  #include\u0026lt;stdio.h\u0026gt; int V[200][200];//前i个物品装入容量为j的背包中获得的最大价值 int max(int a,int b) { if(a\u0026gt;=b) return a; else return b; } int KnapSack(int n,int w[],int v[],int x[],int C) { int i,j; //填表,其中第一行和第一列全为0 for(i=0;i\u0026lt;=n;i++) V[i][0]=0; for(j=0;j\u0026lt;=C;j++) V[0][j]=0; for(i=1;i\u0026lt;=n;i++) { printf(\u0026quot;物品编号%d 重量%d 价值%d \u0026quot;,i,w[i-1],v[i-1]); for(j=1;j\u0026lt;=C;j++) { if(j\u0026lt;w[i-1]) //当前编号物品比整个背包容量还大 { V[i][j]=V[i-1][j]; printf(\u0026quot;[%d][%d]=%2d \u0026quot;,i,j,V[i][j]); } else // 用max比较要不要放下当前物品 { V[i][j]=max(V[i-1][j],V[i-1][j-w[i-1]]+v[i-1]); printf(\u0026quot;[%d][%d]=%2d \u0026quot;,i,j,V[i][j]); } } printf(\u0026quot;\\n\u0026quot;); } //判断哪些物品被选中 j=C; for(i=n;i\u0026gt;=1;i--) { if(V[i][j]\u0026gt;V[i-1][j]) { x[i]=1; j=j-w[i-1]; } else x[i]=0; } printf(\u0026quot;选中的物品是:\\n\u0026quot;); for(i=1;i\u0026lt;=n;i++) printf(\u0026quot;%d \u0026quot;,x[i]); printf(\u0026quot;\\n\u0026quot;); return V[n][C]; } void main() { int s;//获得的最大价值 int w[15];//物品的重量 int v[15];//物品的价值 int x[15];//物品的选取状态 int n,i; int C;//背包最大容量 n=5; printf(\u0026quot;请输入背包的最大容量:\\n\u0026quot;); scanf(\u0026quot;%d\u0026quot;,\u0026amp;C); printf(\u0026quot;输入物品数:\\n\u0026quot;); scanf(\u0026quot;%d\u0026quot;,\u0026amp;n); printf(\u0026quot;请分别输入物品的重量:\\n\u0026quot;); for(i=0;i\u0026lt;n;i++) scanf(\u0026quot;%d\u0026quot;,\u0026amp;w[i]); printf(\u0026quot;请分别输入物品的价值:\\n\u0026quot;); for(i=0;i\u0026lt;n;i++) scanf(\u0026quot;%d\u0026quot;,\u0026amp;v[i]); s=KnapSack(n,w,v,x,C); printf(\u0026quot;最大物品价值为:\\n\u0026quot;); printf(\u0026quot;%d\\n\u0026quot;,s); }   KMP算法 在计算机科学中，Knuth-Morris-Pratt字符串查找算法（简称为KMP算法）可在一个字符串S内查找一个词W的出现位置。一个词在不匹配时本身就包含足够的信息来确定下一个匹配可能的开始位置，此算法利用这一特性以避免重新检查先前配对的字符。  阮一峰的博客分析的很好，这里将具体实现分享下。\n 注意size() 返回的是无符号数，其与负数比较大小时一定要转为有符号的，否则负数会先转变为无符号数之后比较大小结果错误。\n #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; const int Maxn = 1024; class Solution { public: int next[Maxn] = { 0 }; //维护p等价前缀长度的记录数组,p匹配失败就跳转到该位置 即匹配了p的个数-1 // 关键在于计算next数组 这里基于最大长度表(字符串的前缀后缀的公共元素的最大长度)来做 // next数组是除当前字符外的最长相同前缀后缀。所以为最大长度表向右移一位，初值赋为-1的数组 void GetNextval(string p) { next[0] = -1; int i = -1, j = 0; //p[i]表示前缀 while (j \u0026lt; (p.size()) - 1) { if (i == -1 || p[i] == p[j]) { ++i; ++j; // next[j] = i; //优化如下所示, 当p[i] == p[j] 时，KmpSearch里不匹配调用next会重复调用，所以这里直接处理 if(p[i] != p[j]) next[j] = i; else next[j] = next[i]; } else i = next[i]; } } int KmpSearch(string s, string p) { int i = 0, j = 0; GetNextval(p); // 注意！ size() 返回的是无符号数，一定要转为有符号的 否则j为-1时会先转变为无符号数比较大小会错误 while ( i \u0026lt; int(s.size()) \u0026amp;\u0026amp; j \u0026lt; int(p.size()) ) { // j为-1 或 匹配成功 s、p的下标都向后走 if (j == -1 || s[i] == p[j]) { i++; j++; } // 否则字符匹配失败，i不变 j转为next记录值，再用原来的s[i] 与 新的p[j]匹配 // 当j==-1即该字符前不可能有相同前后缀时 还不匹配 说明 i 需要+1 而j=0 else j = next[j]; } if (j == p.size()) return i - j; return -1; } }; int main() { Solution sol; string s1, s2; while (1) { cin \u0026gt;\u0026gt; s1 \u0026gt;\u0026gt; s2; cout \u0026lt;\u0026lt; sol.KmpSearch(s1, s2) \u0026lt;\u0026lt; endl; } }   关于字符匹配的动态规划题  10.正则表达式匹配\nclass Solution { public: bool isMatch(string s, string p) { int sl = s.size(), pl = p.size(); vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; f_map; f_map.assign(sl + 1, vector\u0026lt;int\u0026gt;(pl + 1, 0)); f_map[0][0] = 1; // p为正则表达式字符串 // 匿名函数用法 这样做可减少内存的拷贝 auto matches = [\u0026amp;](int i, int j) -\u0026gt; bool{ if(i == 0) return false; else if(p[j - 1] == '.') return true; else return s[i - 1] == p[j - 1]; }; for (int i = 0; i \u0026lt;= sl; i++) { // i j代表第几个字符，若为0 表示字符为空 for (int j = 1; j \u0026lt;= pl; j++) { // j为0时除非i=0否则必定匹配失败,初始化时已经给所有除f_map[0][0]外赋0 if(p[j-1] == '*') { if( matches(i, j-1) ) // f_map[i][j] = f_map[i-1][j]; i-1表示*复制一份前字符，j-2表示*和之前字符代表空 f_map[i][j] = f_map[i-1][j] || f_map[i][j-2]; //加上或，防止当前s头不能减少的情况 else f_map[i][j] = f_map[i][j-2]; // } else{ if( matches(i, j) ) f_map[i][j] = f_map[i-1][j-1]; } } } return f_map[sl][pl]; } };  44.通配符匹配\nclass Solution { public: // s为输入测试值,测试是否与p匹配 p,包含a-z ? * // 此题与 10.正则表达式匹配.cpp 类似。不过此处通配符是匹配任意一段字符串，且*前可无字符 // 正则表达式是 *匹配前一个字符N次 bool isMatch(string s, string p) { int sl = s.size(), pl = p.size(); // dp[i][j] 表示 s的i长度 与 p的j长度 是否匹配 i、j为0表示长度为0的空的字符串 auto match = [\u0026amp;](int i, int j) -\u0026gt; bool { if (i == 0) return false; //进入match判断时必定不为* 所以可以直接return false else if (p[j-1] == '?') return true; return s[i-1] == p[j-1]; }; vector\u0026lt;vector\u0026lt;bool\u0026gt;\u0026gt; dp(sl + 1, vector\u0026lt;bool\u0026gt;(pl + 1, false)); dp[0][0] = true; for (int i = 0; i \u0026lt;= sl; i++) { for (int j = 1; j \u0026lt;= pl; j++) { if (p[j-1] == '*') dp[i][j] = dp[i][j-1] || (i\u0026gt;0 \u0026amp;\u0026amp; dp[i-1][j]); //等价 *不存在 或者 *前面匹配成功 else dp[i][j] = match(i, j) \u0026amp;\u0026amp; dp[i-1][j-1]; } } return dp[sl][pl]; } };  ","id":1,"section":"posts","summary":"先简单介绍几个基础概念： 递归 递归是重复调用函数自身实现循环。迭代是函数内某段代码实现循环。 其中，迭代与普通循环的区别是：迭代时，循环代码中参","tags":["C/C++","算法"],"title":"五大基本算法","uri":"https://liangkang233.github.io/2021/11/%E4%BA%94%E5%A4%A7%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95/","year":"2021"},{"content":"内存模型 对于C/C++ 等语言来说，内存空间大致使用在\n  栈区（stack）：又编译器自动分配释放，存放函数的参数值，局部变量的值等，其操作方式类似于数据结构的栈。\n  堆区（heap）：一般是由程序员分配释放，若程序员不释放的话，程序结束时可能由OS回收，值得注意的是他与数据结构的堆是两回事.\n  全局区（static）：也叫静态数据内存空间，存储全局变量和静态变量，全局变量和静态变量的存储是放一块的，初始化的全局变量和静态变量放一块区域，没有初始化的在相邻的另一块区域，程序结束后由系统释放。\n  文字常量区(const)：常量字符串就是放在这里，程序结束后由系统释放。\n  程序代码区：存放函数体的二进制代码。\n  堆中的对象对于Go 以及 Java 等编程语言来说由工程师和编译器共同管理，堆内存对象由内存分配器分配并由垃圾收集器 gc *(garbage collection)*回收。\n在多线程编程下，追求更高内存管理效率：更快的分配是主要目的。\n 引入虚拟内存后，让内存的并发访问问题的粒度从多进程级别，降低到多线程级别。 为线程预分配缓存需要进行1次系统调用，后续线程申请小内存时，从缓存分配，都是在用户态执行，没有系统调用，缩短了内存总体的分配和释放时间， 多个线程同时申请小内存时，从各自的缓存分配，访问的是不同的地址空间，无需加锁，把内存并发访问的粒度进一步降低  接下来介绍go的具体内存模型：\n内存分配方法   线性分配器（Sequential Allocator，Bump Allocator）\n实现简单，直接在内存中维护一个指向可用地址的指针。其GC需要与具有拷贝特性的回收方法:标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法,所以像C、C++这样暴漏内存地址指针的无法使用。\n  空闲链表分配器（Free-List Allocator）\n大致分为以下四种策略：go使用的是第四种\n 首次适应（First-Fit）— 从链表头开始遍历，选择第一个大小大于申请内存的内存块； 循环首次适应（Next-Fit）— 从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块； 最优适应（Best-Fit）— 从链表头遍历整个链表，选择最合适的内存块； 隔离适应（Segregated-Fit）— 将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块；举例：将内存分割成由 4、8、16、32 字节的内存块组成的链表，当我们向内存分配器申请 8 字节的内存时，它会在8字节链表中找到满足条件的空闲内存块并返回。隔离适应的分配策略减少了需要遍历的内存块数量，提高了内存分配的效率。    除此之外，go的内存分配器还借鉴了TCMalloc(毕竟都是google做的)的设计理念——使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略\n   类别 大小     微对象 (0, 16B)   小对象 [16B, 32KB]   大对象 (32KB, +∞)     Page：操作系统对内存管理以页为单位，TCMalloc也是这样，只不过TCMalloc里的Page大小与操作系统里的大小并不一定相等，而是倍数关系。《TCMalloc解密》里称x64下Page大小是8KB。 Span：一组连续的Page被称为Span，比如可以有2个页大小的Span，也可以有16页大小的Span，Span比Page高一个层级，是为了方便管理一定大小的内存区域，Span是TCMalloc中内存管理的基本单位。 ThreadCache：每个线程各自的Cache，一个Cache包含多个空闲内存块链表，每个链表连接的都是内存块，同一个链表上内存块的大小是相同的，也可以说按内存块大小，给内存块分了个类，这样可以根据申请的内存大小，快速从合适的链表选择空闲内存块。由于每个线程有自己的ThreadCache，所以ThreadCache访问是无锁的。 CentralCache：是所有线程共享的缓存，也是保存的空闲内存块链表，链表的数量与ThreadCache中链表数量相同，当ThreadCache内存块不足时，可以从CentralCache取，当ThreadCache内存块多时，可以放回CentralCache。由于CentralCache是共享的，所以它的访问是要加锁的。 PageHeap：PageHeap是堆内存的抽象，PageHeap存的也是若干链表，链表保存的是Span，当CentralCache没有内存的时，会从PageHeap取，把1个Span拆成若干内存块，添加到对应大小的链表中，当CentralCache内存多的时候，会放回PageHeap。如上图，分别是1页Page的Span链表，2页Page的Span链表等，最后是large span set，这个是用来保存中大对象的。毫无疑问，PageHeap也是要加锁的。  垃圾回收 gc(garbage collection)在几乎所有的现代编程语言中，垃圾收集器都是一个复杂的系统，为了在不影响用户程序的情况下回收废弃的内存需要付出非常多的努力，Java 的垃圾收集机制是一个很好的例子，Java 8 中包含线性、并发、并行标记清除和 G1 四个垃圾收集器，想要理解它们的工作原理和实现细节需要花费很多的精力。\n垃圾收集器将存储器视为一张有向可达图。图中的节点可以分为两组：一组称为根节点，对应于不在堆中的位置，这些位置可以是寄存器、栈中的变量，或者是虚拟存储器中读写数据区域的全局变量；另外一组称为堆节点，对应于堆中一个分配块，如下图：\n当堆节点不可达时即可视为垃圾，因为已经访问不到了。\n介绍几种基础的GC算法：\n  引用计数：\nObjective-C 选择了自动引用计数（智能指针），即创建的堆空间维护一个计数器，每当有新的引用指向它就计数器加一。反之指向其的引用置空或指向其他对象计数器减一，减少至0则释放，实现动态回收内存空间。\n而其缺点是若存在对象的循环引用，无法释放这些对象。并且多个线程同时对引用计数进行增减时，引用计数的值可能会产生不一致的问题，必须使用并发控制机制解决这一问题，也是一个不小的开销。\n  标记清除\n这个算法也称为Mark \u0026amp; Sweep算法，为McCarthy独创。它也是目前公认的最有效的GC方案。Mark\u0026amp;Sweep垃圾收集器由标记阶段和回收阶段组成，标记阶段标记出根节点所有可达的对节点，清除阶段释放每个未被标记的已分配块，其执行过程可以分成标记（Mark）和清除（Sweep）两个阶段：\n 标记阶段 — 从根对象出发查找并标记堆中所有存活的对象； 清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表；  一般的地，块头部中空闲的低位中的一位用来表示这个块是否已经被标记了。通过Mark\u0026amp;Sweep算法动态申请内存时，先按需分配内存，当内存不足以分配时，从寄存器或者程序栈上的引用出发，遍历上述的有向可达图并作标记（标记阶段），然后再遍历一次内存空间，把所有没有标记的对象释放（清除阶段）。因此在收集垃圾时需要中断正常程序STW*(Stop the world)*，在程序涉及内存大、对象多的时候中断过程可能有点长。当然，收集器也可以作为一个独立线程不断地定时更新可达图和回收垃圾。\n该算法不像引用计数可对内存进行即时回收，但是它解决了引用计数的循环引用问题，因此有的语言把引用计数算法搭配Mark \u0026amp; Sweep 算法构成GC机制。\n  节点复制\nMark \u0026amp; Sweep算法的缺点是在分配大量对象时，且对象大都需要回收时，回收中断过程可能消耗很大。而节点复制算法则刚好相反，当需要回收的对象越多时，它的开销很小，而当大部分对象都不需要回收时，其开销反而很大。算法的基本思路是这样的：从根节点开始，被引用的对象都会被复制到一个新的存储区域中，而剩下的对象则是不再被引用的，即为垃圾，留在原来的存储区域。释放内存时，直接把原来的存储区域释放掉，继续维护新的存储区域即可。\n  分代回收\n以上三种基本算法各有各的优缺点，也各自有许多改进的方案。通过对这三种方式的融合，出现了一些更加高级的方式。而高级GC技术中最重要的一种为分代回收。它的基本思路是这样的：程序中存在大量的这样的对象，它们被分配出来之后很快就会被释放，但如果一个对象分配后相当长的一段时间内都没有被回收，那么极有可能它的生命周期很长，尝试收集它是无用功。为了让GC变得更高效，我们应该对刚诞生不久的对象进行重点扫描，这样就可以回收大部分的垃圾。为了达到这个目的，我们需要依据对象的”年龄“进行分代，刚刚生成不久的对象划分为新生代，而存在时间长的对象划分为老生代，根据实现方式的不同，可以划分为多个代。\n一种回收的实现策略可以是：首先从根开始进行一次常规扫描，扫描过程中如果遇到老生代对象则不进行递归扫描，这样可大大减少扫描次数。这个过程可使用标记清除算法或者复制收集算法。然后，把扫描后残留下来的对象划分到老生代，若是采用标记清除算法，则应该在对象上设置某个标志位标志其年龄；若是采用复制收集，则只需要把新的存储区域内对象设置为老生代就可以了。而实际的实现上，分代回收算法的方案五花八门，常常会融合几种基本算法。\n  go的垃圾回收 为了高效的标记对象缩短stw时间，go使用三色标记法（标记清除的一种改良）来做；\n三色对象定义：\n  白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收；\n  黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象；\n  灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；\n  在垃圾收集器开始工作时，垃圾收集的根对象会被标记成灰色，其他对象标记为白色，垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。\n三色标记垃圾收集器的工作原理很简单，我们可以将其归纳成以下几个步骤：\n 从灰色对象的集合队列中选择一个灰色对象并将其标记成黑色并进行步骤2； 将黑色对象指向的所有对象都标记成灰色，保证该对象和被该对象引用的对象都不会被回收； 重复上述两个步骤直到对象图中不存在灰色对象；  垃圾收集器一旦开始执行就会浪费大量的计算资源，为了减少应用程序暂停的最长时间和垃圾收集的总暂停时间，我们会使用下面的策略优化现代的垃圾收集器：\n  增量垃圾收集 — 增量地标记和清除垃圾，降低应用程序暂停的最长时间；\n增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间：\n  并发垃圾收集 — 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾；\n并发（Concurrent）的垃圾收集不仅能够减少程序的最长暂停时间，还能减少整个垃圾收集阶段的时间，通过开启读写屏障、利用多核优势与用户程序并行执行，并发垃圾收集器确实能够减少垃圾收集对应用程序的影响：\n  因为增量和并发两种方式都可以与用户程序交替运行，使用并发或增量执行，有可能会生成悬挂指针——即不该被回收的对象被回收了。所以我们需要使用屏障技术保证垃圾收集的正确性；与此同时，应用程序也不能等到内存溢出时触发垃圾收集，因为当内存不足时，应用程序已经无法分配内存，这与直接暂停程序没有什么区别，增量和并发的垃圾收集需要提前触发并在内存不足前完成整个循环，避免程序的长时间暂停。\n内存屏障技术是一种屏障指令，它可以让 CPU 或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，但是该技术能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存屏障后执行的操作。\n想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的一种：\n 强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象； 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径  垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。\n","id":2,"section":"posts","summary":"内存模型 对于C/C++ 等语言来说，内存空间大致使用在 栈区（stack）：又编译器自动分配释放，存放函数的参数值，局部变量的值等，其操作方式类","tags":["go"],"title":"Go内存模型","uri":"https://liangkang233.github.io/2021/10/go%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","year":"2021"},{"content":"树状数组 树状数组简单来说就是一个维护了一段数据和的数组，其记录值规律如下所示。\n关键在于lowbit函数  a \u0026amp; -a，即：取出a的二进制表达中的最后一位1的值（负数在计算机中以补码表示）\n原数组为a[i]，c[i]树状数组。\n所以，对于一个树状数组，添加新元素、计算前n项和的时间复杂度都是O(log n)。\n 其进阶操作为线段树，以后遇到合适案例再补充记录。\n 实现  .aspect-ratio { position: relative; width: 100%; height: 0; padding-bottom: 75%; } .aspect-ratio iframe { position: absolute; width: 100%; height: 100%; left: 0; top: 0; }    添加值就是递归的加lowbit添加，相反查询的话就是递归的减lowbit累加和即为区间和。\n实际使用时不用推导，直接拿来用。\n视频源码：\nint t[maxn]; // t数组为维护的树状数组 void add(int x, int k) { for(; x \u0026lt;= n; x += (x\u0026amp;-x) ) { t[x] += k; } } int ask(int x) { int ans; for (; i \u0026gt; 0; x -= (x\u0026amp;-x)) { ans += t[x]; } return ans; } // 单点修改、单点查询 add(x, k); ask(x) - ask(x-1); // 单点修改，区间查询 add(x, k); ask(r) - ask(l-1); // 区间[l,r]内  // 区间查询修改 需要两个树状数组维护 // t1[]维护b[i]前缀和,t2[]维护i*b[i]前缀和 int t1[maxn], t2[maxn]]; void add1(int x, int k) { for(; x \u0026lt;= n; x += (x\u0026amp;-x) ) { t1[x] += k; } } int ask1(int x) { int ans; for (; i \u0026gt; 0; x -= (x\u0026amp;-x)) { ans += t1[x]; } return ans; } void add2(int x, int k) { for(; x \u0026lt;= n; x += (x\u0026amp;-x) ) { t2[x] += k; } } int ask2(int x) { int ans; for (; i \u0026gt; 0; x -= (x\u0026amp;-x)) { ans += t2[x]; } return ans; } // 区间修改，区间查询 // 在区间[l, r]修改 add1(l, d); add1(r+1, -d); add2(l, l*d); add2(r+1, -(r+1)*d); sum[r] - sum[l-1]; //即为下式 (r+1)*ask1[r] - ask2[r] + (l-1+1)*ask1[l-1] - ask2[l-1];  应用 蓝桥杯题目：蓝桥杯-历届试题 小朋友排队 （树状数组） (lagou.com)\n/* 问题描述 n 个小朋友站成一排。现在要把他们按身高从低到高的顺序排列，但是每次只能交换位置相邻的两个小朋友。 每个小朋友都有一个不高兴的程度。开始的时候，所有小朋友的不高兴程度都是0。 如果某个小朋友第一次被要求交换，则他的不高兴程度增加1，如果第二次要求他交换，则他的不高兴程度增加2（即不高兴程度为3）， 依次类推。当要求某个小朋友第k次交换时，他的不高兴程度增加k。 请问，要让所有小朋友按从低到高排队，他们的不高兴程度之和最小是多少。 如果有两个小朋友身高一样，则他们谁站在谁前面是没有关系的。 输入格式 输入的第一行包含一个整数n，表示小朋友的个数。 第二行包含 n 个整数 H1 H2 … Hn，分别表示每个小朋友的身高。 输出格式 输出一行，包含一个整数，表示小朋友的不高兴程度和的最小值。 样例输入 3 3 2 1 样例输出 9 样例说明 首先交换身高为3和2的小朋友，再交换身高为3和1的小朋友，再交换身高为2和1的小朋友，每个小朋友的不高兴程度都是3，总和为9。 数据规模和约定 对于10%的数据， 1\u0026lt;=n\u0026lt;=10； 对于30%的数据， 1\u0026lt;=n\u0026lt;=1000； 对于50%的数据， 1\u0026lt;=n\u0026lt;=10000； 对于100%的数据，1\u0026lt;=n\u0026lt;=100000，0\u0026lt;=Hi\u0026lt;=1000000。 */ // 用求逆序数的思想去做，定义前面的数大于当前数的个数为逆序数，后面的数小于当前数的个数为逆序数2号， // 逆序数定义可知，一个数的逆序数是往前挪几次，相应的逆序数2号就是被后面的数挪动的次数， // 如果是求交换次数，只需要求逆序数1或2之后累加即可 // 其实逆序数1n个和与逆序数2的n个和一定是相同的，只不过这里要累计的是每个项的等差数列和所以只能分开来求 // 小朋友的不高兴值 = 逆序数 + 逆序数2号 使用树状数组来做 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;cstring\u0026gt; using namespace std; // 小朋友身高居然可以为0!! // 由于树状数组结构设计无法向tree[0]存储值所以存树状值下标为身高值加1 // 堆空间申请返回的是单个元素的指针，切不可使用memset(tree, 0, sizeof(tree)); // 而是 memset(tree, 0, maxn * sizeof(int)); 同理传参也是如此 #define maxn 1000002 using namespace std; void add(int i, int k, int* tree) { for (; i \u0026lt; maxn; i += (i \u0026amp; -i)) { tree[i] += k; } } int sum (int i, int *tree) { int sum = 0; for (; i \u0026gt; 0; i -= (i \u0026amp; -i)) { sum += tree[i]; } return sum; } int main() { int N; long long count = 0; int* tree = new int[maxn]; int* temp = new int[maxn]; long long* num = new long long[maxn]; memset(temp, 0, maxn * sizeof(int)); memset(num, 0, maxn * sizeof(long long)); cin \u0026gt;\u0026gt; N; for (int i = 0; i \u0026lt; N; i++) cin \u0026gt;\u0026gt; temp[i]; // 从左往右 记录左边比它高的 memset(tree, 0, maxn * sizeof(int)); for (int j = 0; j \u0026lt; N; j++) { add(temp[j]+1 , 1, tree); num[j] = j+1 - sum(temp[j]+1, tree); // cout \u0026lt;\u0026lt; \u0026quot;test1 \u0026quot; \u0026lt;\u0026lt; num[j] \u0026lt;\u0026lt; endl; } // 从右往左 记录右边比他矮的 memset(tree, 0, maxn * sizeof(int)); for (int j = N-1; j \u0026gt;= 0; j--) { add(temp[j]+1, 1, tree); num[j] += sum(temp[j], tree); // cout \u0026lt;\u0026lt; \u0026quot;test2 \u0026quot; \u0026lt;\u0026lt; sum(temp[j], tree) \u0026lt;\u0026lt; endl; } for (int i = 0; i \u0026lt; N; i++) { // cout \u0026lt;\u0026lt; \u0026quot;test \u0026quot; \u0026lt;\u0026lt; num[i] \u0026lt;\u0026lt; endl; count += num[i] * (num[i]+1) / 2; } cout \u0026lt;\u0026lt; count; delete[] tree; delete[] temp; delete[] num; return 0; }  ","id":3,"section":"posts","summary":"树状数组 树状数组简单来说就是一个维护了一段数据和的数组，其记录值规律如下所示。 关键在于lowbit函数 a \u0026amp; -a，即：取出a的二进制表达中的最","tags":["C/C++","数据结构"],"title":"数据结构-树状数组","uri":"https://liangkang233.github.io/2021/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/","year":"2021"},{"content":"并查集 并查集是一种树形的数据结构，用于处理不交集（Disjoint sets）的合并和查询问题。\n案例：初始状态n个元素，每个元素位于独立的集合，之后进行合并操作将集合合并。合并过程中判断集合中是否有重复元素。\n所以并查集主要的两个操作：\n 查询: find 确定某个元素处于哪个子集 合并: union 将两个子集合合并成一个集合  并查集的实现 思路:使用数组等结构记录每一个节点的父节点，查询操作就是递归的查询该节点的父节点找寻其root，合并操作就是把两个节点的中一个作为另一个节点的父节点这样就完成了合并。\n一开始每个节点就是一个集合，随着所有节点迭代下去的合并，合并两个节点就相当于合并包含该节点的两个集合。每两个节点合并时查询两个节点的的root节点。如果相同说明两个这两个集合有相同的子节点，合并后必定会产生环。\n优化：\n 路径压缩：查找root节点的时候就直接把他的父节点改为root，省的下次重复查找 按秩合并：维护一个秩数组，记录该节点下的子树深度。这样合并两个节点时，让秩大的做父节点避免子树过长。  视频的解析很清楚，做个提纲防止忘记\n .aspect-ratio { position: relative; width: 100%; height: 0; padding-bottom: 75%; } .aspect-ratio iframe { position: absolute; width: 100%; height: 100%; left: 0; top: 0; }    视频的源码：\n#include\u0026lt;stdio.h\u0026gt; #include\u0026lt;stdlib.h\u0026gt; #include\u0026lt;string.h\u0026gt; #define VERTICES 6 #define _CRT_SECURE_NO_WARNINGS int find_root(int x, int parent[]) // 找到根节点 { if (parent[x] != x) { //当父节点是自己说明已经是根节点 parent[x] = find_root(parent[x], parent); //路径压缩,找父节点的同时更新自己的父节点为root节点 } return parent[x]; } int union_vertices(int x, int y, int parent[],int rank[]) // 让两个集合合并 { int x_root = find_root(x, parent); int y_root = find_root(y, parent); if (x_root == y_root) return 0; else { if (rank[x_root] \u0026gt; rank[y_root]) // 让 少的指向多 的 parent[y_root] = x_root; else if (rank[x_root] \u0026lt; rank[y_root]) parent[x_root] = y_root; else { parent[x_root] = y_root; // 这个随便可以 rank[y_root]++; } return 1; } } int main(void) { int parent[VERTICES] = { 0 }; int rank[VERTICES] = { 0 }; memset(rank, 0, sizeof(rank)); // memset(parent, -1, sizeof(parent)); for (int i = 0; i \u0026lt; VERTICES; i++) //初始父节点就是自己 parent[i] = i; int edges[6][2] = { {0,1},{1,2},{1,3},{2,4},{3,4},{2,5} }; for (int i = 0; i \u0026lt; 6; i++) { int x = edges[i][0]; int y = edges[i][1]; if (union_vertices(x, y, parent,rank) == 0) { printf(\u0026quot;Cycle detected!\\n\u0026quot;); system(\u0026quot;pause\u0026quot;); exit(0); } } printf(\u0026quot;No cycle found.\\n\u0026quot;); system(\u0026quot;pause\u0026quot;); return 0; }  并查集的应用 leetcode 547题目\nclass Solution { public: int find(int i) { if (parent[i] != i) //递归寻找root节点并把root赋值 parent[i] = find(parent[i]); return parent[i]; } void merge(int i, int j) { int root1 = find(i), root2 = find(j); if(root1 == root2) // 若相等则两个集合有交集，相当于在同一个省份内的两个城市相连（成环） return; // 这里不做任何处理 ans省份树不会减少 ans--; // 接下来进行合并 if(rank[root1] \u0026gt;= rank[root2]) parent[root2] = root1; else parent[root1] = root2; if (rank[root1] == rank[root2]) rank[root1]++; } int ans; vector\u0026lt;int\u0026gt; parent, rank; int findCircleNum(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; isConnected) { ans = isConnected.size(); //初始视作每个城市都是一个省份 rank.resize(ans, 0); for (int i = 0; i \u0026lt; isConnected.size(); i++) parent.push_back(i); for (int i = 0; i \u0026lt; isConnected.size(); i++) { for (int j = 0; j \u0026lt; isConnected.size(); j++) { if (isConnected[i][j] == 0 || i == j) continue; merge(i, j); } } return ans; } };   题外话：双指针判断链表是否有环，看起来类似也是找环，但是用的双指针找的。141. 环形链表\n 堆  这里说的堆指的时数据结构堆，不是程序申请的堆空间。\n 堆（heap）是计算机科学中一类特殊的数据结构的统称。堆通常是一个可以被看做一棵树的数组对象。\n堆总是满足下列性质：\n  小根堆Min-heap: 父节点的值小于或等于子节点的值； 大根堆Max-heap: 父节点的值大于或等于子节点的值；\n  堆中某个结点的值总是不大于或不小于其父结点的值；\n  堆总是一棵完全二叉树1\n其插入添加元素的时间复杂度都为O(log n)。查询最大、小值的时间复杂度为O(1)\n  堆的实现 由于堆是一颗完全二叉树，所以完全可以用一个数组准确并唯一的表示该二叉树。\n用数组表示该完全二叉树由上到下、由做到右的记录时，有以下性质：\n 父节点 = (i - 1) / 2 左子节点 = 2 * i + 1 右子节点 = 2 * i + 2  C++ STL库优先队列的使用方式 头文件: #include \u0026lt;queue\u0026gt;\npriority_queue\u0026lt;point, vector\u0026lt;point\u0026gt;, greater\u0026lt;point\u0026gt;\u0026gt; que; // 第一个参数是存储对象的类型，第二个参数是存储元素的底层容器，第三个参数是函数对象，第二第三参数可以不填入 // 与sort刚好相优先队列反队列默认采用的是less生成的是大根堆，sort 默认是 less 从小到大升序排序  堆的应用 用于堆排序 时间复杂度O(nlog n)，额外空间复杂度O(1)\n// 对一个节点做heapify的时候，必须保证它的所有子树都已经是堆。 void swap(int *a, int *b) { int temp = *b; *b = *a; *a = temp; } void max_heapify(int arr[], int start, int end) { int dad = start; int son = dad * 2 + 1; while (son \u0026lt;= end) { if (son + 1 \u0026lt;= end \u0026amp;\u0026amp; arr[son] \u0026lt; arr[son + 1]) // 判断右子节点是否存在，并比较大小 son++; if (arr[dad] \u0026gt; arr[son]) //如果父节点大于子节点代表调整完毕，直接跳出函數 return; else { // 否则交换父子节点 swap(\u0026amp;arr[dad], \u0026amp;arr[son]); dad = son; son = dad * 2 + 1; } } } void heap_sort(int arr[], int len) { int i; // 初始化，从最后一个父节点开始调整 for (i = (len-2) / 2; i \u0026gt;= 0; i--) max_heapify(arr, i, len - 1); // 取出最大值(堆头)，然后重新heapify 这里优化为将堆头换到最后一位，然后最后一个节点不参加heapify // 迭代全部堆头后，就是排序后的列表 for (i = len - 1; i \u0026gt; 0; i--) { swap(\u0026amp;arr[0], \u0026amp;arr[i]); max_heapify(arr, 0, i - 1); } }  用优先队列解决的案例：23. 合并K个升序链表 - 力扣（LeetCode） (leetcode-cn.com)\nclass Solution { public: //题目23 \u0026quot;重载结构体的\u0026lt;\u0026quot;，用默认的less（所以省略了该参数） struct Status { int val; ListNode *ptr; bool operator \u0026lt; (const Status \u0026amp;rhs) const { return val \u0026gt; rhs.val; } }; priority_queue \u0026lt;Status\u0026gt; q; ListNode* mergeKLists(vector\u0026lt;ListNode*\u0026gt;\u0026amp; lists) { for (auto node: lists) { if (node) q.push({node-\u0026gt;val, node}); } ListNode head, *tail = \u0026amp;head; while (!q.empty()) { auto f = q.top(); q.pop(); tail-\u0026gt;next = f.ptr; tail = tail-\u0026gt;next; if (f.ptr-\u0026gt;next) q.push({f.ptr-\u0026gt;next-\u0026gt;val, f.ptr-\u0026gt;next}); } return head.next; } }; // \u0026quot;也可以重载()\u0026quot; 其实 greater 和 less 就是一个模板调用的模板类，里面重载了元素的() 返回\u0026gt; 或\u0026lt;的bool // STRUCT TEMPLATE greater template \u0026lt;class _Ty = void\u0026gt; struct greater { _CXX17_DEPRECATE_ADAPTOR_TYPEDEFS typedef _Ty _FIRST_ARGUMENT_TYPE_NAME; _CXX17_DEPRECATE_ADAPTOR_TYPEDEFS typedef _Ty _SECOND_ARGUMENT_TYPE_NAME; _CXX17_DEPRECATE_ADAPTOR_TYPEDEFS typedef bool _RESULT_TYPE_NAME; _NODISCARD constexpr bool operator()(const _Ty\u0026amp; _Left, const _Ty\u0026amp; _Right) const { return _Left \u0026gt; _Right; } }; // 重载()如下所示 struct com{ bool operator()(pair\u0026lt;int,int\u0026gt;\u0026amp;a,pair\u0026lt;int,int\u0026gt;\u0026amp;b){ return a.second\u0026gt;b.second; } }; priority_queue\u0026lt;pair\u0026lt;int,int\u0026gt;,vector\u0026lt;pair\u0026lt;int,int\u0026gt;\u0026gt;,com\u0026gt; q;    一棵深度为k的有n个结点的二叉树，对树中的结点按从上至下、从左到右的顺序进行编号，如果编号为i（1≤i≤n）的结点与满二叉树中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","id":4,"section":"posts","summary":"并查集 并查集是一种树形的数据结构，用于处理不交集（Disjoint sets）的合并和查询问题。 案例：初始状态n个元素，每个元素位于独立的集合","tags":["C/C++","数据结构"],"title":"并查集、堆(优先队列)","uri":"https://liangkang233.github.io/2021/10/%E5%B9%B6%E6%9F%A5%E9%9B%86%E5%A0%86%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/","year":"2021"},{"content":"介绍 最近在做一个关于无线移动自组织网络相关的内容，移动自组织网络是由彼此已经发现和互相接近的且有通信需求的移动设备构成的。由于网内节点的移动拓扑是不可知的，所以各自组网结构是动态变化的。要根据其各个实时动态形成的自组网开发新的内容，这就需要一个可以探测网内节点数量的工具来设定当前自组网内状态。在网上找寻相关工具资料的时候想到OSPF的hello组播包，觉得这个实现很不错，于是尝试用go写了个udp组播实现的探测网内节点的工具，分享下。\n其实现原理就是使用定时器定时触发helllo组播包给组播域，如果节点接收到其他节点发送的组播包就记录下。每一个总检测周期内查询接收的节点，根据接收到的节点名就可以知道该节点的自组网下节点有哪些。例如场景中有1-10个节点，1节点能够收到2-7节点的组播包说明1-7节点在同一自组网内属于该自组网的存活节点。（非存活节点并不是表示该节点down，仅仅是代表该节点例如节点8不在这个自组网内）\n实现过程 go中对udp等套接字的官方包实现类似unix，基本的套接字知识就不在这回顾了，总之要了解下udp也是可以使用connect函数做有连接的请求，并不是说如tcp那般握手提供可靠连接，仅仅是单方面的确定源目标地址的连接。\n组播定义：组播是指在IP网络中将数据包以尽力传送的形式发送到某个确定的节点集合（即组播组），其基本思想是：源主机（即组播源）只发送一份数据，其目的地址为组播组地址；组播组中的所有接收者都可收到同样的数据拷贝，并且只有组播组内的主机可以接收该数据，而其它主机则不能收到。\n基础的用go的套接字示例实现看看深入Go UDP编程这篇博客即可，简单易用。组播部分代码也是使用在这篇文章的通用多播编程代码1改写的\n// 组播服务器代码 func main() { //如果第二参数为nil,它会使用系统指定多播接口，但是不推荐这样使用 addr, err := net.ResolveUDPAddr(\u0026quot;udp\u0026quot;, \u0026quot;224.0.0.250:9981\u0026quot;) if err != nil { fmt.Println(err) } listener, err := net.ListenMulticastUDP(\u0026quot;udp\u0026quot;, nil, addr) if err != nil { fmt.Println(err) return } fmt.Printf(\u0026quot;Local: \u0026lt;%s\u0026gt; \\n\u0026quot;, listener.LocalAddr().String()) data := make([]byte, 1024) for { n, remoteAddr, err := listener.ReadFromUDP(data) if err != nil { fmt.Printf(\u0026quot;error during read: %s\u0026quot;, err) } fmt.Printf(\u0026quot;\u0026lt;%s\u0026gt; %s\\n\u0026quot;, remoteAddr, data[:n]) } } // 组播客户端代码 func main() { ip := net.ParseIP(\u0026quot;224.0.0.250\u0026quot;) srcAddr := \u0026amp;net.UDPAddr{IP: net.IPv4zero, Port: 0} dstAddr := \u0026amp;net.UDPAddr{IP: ip, Port: 9981} conn, err := net.DialUDP(\u0026quot;udp\u0026quot;, srcAddr, dstAddr) if err != nil { fmt.Println(err) } defer conn.Close() conn.Write([]byte(\u0026quot;hello\u0026quot;)) fmt.Printf(\u0026quot;\u0026lt;%s\u0026gt;\\n\u0026quot;, conn.RemoteAddr())}  build代码后运行发现客户端运行报错:dial udp 0.0.0.0:0-\u0026gt;224.0.0.250:9981: connect: network is unreachable.\n客户端的错误应该路由不可达没配路由所以无法到达224网段。可以设置路由解决问题，例如ip route add 224.0.0.0/8 dev ens33但这在用户层面操作太蠢了，而且会干扰原有的路由表。应该在代码处指定发送方网卡用该网卡ip发送组播包。所以修改了下客户端的代码，其中客户端传参需要发送组播ip的网卡。\n其中获取网卡ip的函数gain_ip是参考这篇文章2改的。我这里的功能修改为读出输入网卡的任意一个有效的ipv4地址。\n//DialUDP的srcAddr设置0.0.0.0:0 或nil会自己找匹配路由 端口号为0表示系统分配端口 func main() { //选择使用那张网卡发送组播包(取出其ip作源地址), 不输入参数网卡设定为空 eg. eth0 var ethAddr net.IP = nil if len(os.Args) \u0026gt; 1 { ethAddr = gain_ip(os.Args[1]) } if ethAddr == nil { fmt.Printf(\u0026quot;Failed to retrieve valid ipv4 address as source address,\\nsearch for matching route to send\\n\u0026quot;) ethAddr = net.IPv4zero } srcAddr := \u0026amp;net.UDPAddr{IP: ethAddr, Port: 0} dstAddr, _ := net.ResolveUDPAddr(\u0026quot;udp\u0026quot;, \u0026quot;224.0.0.250:9981\u0026quot;) conn, err := net.DialUDP(\u0026quot;udp\u0026quot;, srcAddr, dstAddr) if err != nil { fmt.Println(err) return } defer conn.Close() conn.Write([]byte(\u0026quot;hello\u0026quot;)) fmt.Printf(\u0026quot;\u0026lt;%s\u0026gt;\\n\u0026quot;, conn.RemoteAddr()) } // 取得网卡的任意一个有效ipv4地址 func gain_ip(ethname string) net.IP { eth, _ := net.InterfaceByName(ethname) Addrs, err := eth.Addrs() if err != nil { // fmt.Println(err) //网卡无效 return nil } for _, Addr := range Addrs { if ipnet, ok := Addr.(*net.IPNet); ok \u0026amp;\u0026amp; !ipnet.IP.IsLoopback() { //接口转为结构体 if ipnet.IP.To4() != nil { return ipnet.IP.To4() } } } return nil //找不到有效网卡地址 }  运行服务器端发现也有报错：setsockopt:no such device ，查看了ListenMulticastUDP函数的源码，发现上面的例程ListenMulticastUDP没有传入第二个接口参数，会使得程序找寻默认到该组播域的路由所以配路由也能解决该问题。我这里还是传参一个网卡名称解决。\nfunc main() { var ethname string = \u0026quot;\u0026quot; if len(os.Args) \u0026gt; 1 { ethname = os.Args[1] } /* listener, err := net.ListenMulticastUDP(\u0026quot;udp\u0026quot;, nil, Multicast_addr) ListenMulticastUDP监听本地系统的所有可用IP地址，包括组播组IP地址。 如果ifi(第二个参数)为零，ListenMulticastUDP使用系统分配的多播接口，但不建议这样做， 因为分配取决于平台，有时可能需要路由配置。如果gaddr的端口字段为0，则会自动选择一个端口号。 */ eth, _ := net.InterfaceByName(ethname) //选择使用那张网卡加入组播域 Multicast_addr, _ := net.ResolveUDPAddr(\u0026quot;udp\u0026quot;, \u0026quot;224.0.0.250:9981\u0026quot;) listener, err := net.ListenMulticastUDP(\u0026quot;udp\u0026quot;, eth, Multicast_addr) if err != nil { fmt.Println(err) return } defer listener.Close() fmt.Printf(\u0026quot;Listener Multicast addr: \u0026lt;%s\u0026gt; \\n\u0026quot;, Multicast_addr.String()) data := make([]byte, 1024) for { n, remoteAddr, err := listener.ReadFromUDP(data) if err != nil { fmt.Printf(\u0026quot;error during read: %s\u0026quot;, err) } fmt.Printf(\u0026quot;\u0026lt;src ip: %s\u0026gt; %s\\n\u0026quot;, remoteAddr, data[:n]) } }  示例代码 准确的相对时间触发对分布式系统尤为重要，虽然只是简单的调用定时器，但是这位大佬的博客3对go中定时器的有比较好的分析，打日志的参考文章4也标注出来。\n最后整合了下客户端和服务器接收，每个移动设备运行该程序（定时发动组播包，后台协程监听来自组播域其他节点包消息）就能探测各网内存活/在线设备。关于接收数据的处理我这里故意只打日志不做其他处理，关于接收的数据如何处理，处理数据具体干啥就看你自己的用途了。就像我参考的这些文章一样，希望能对读者有所帮助。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net\u0026quot; \u0026quot;os\u0026quot; \u0026quot;time\u0026quot; ) type myconn struct { send *net.UDPConn recv chan int } var ( Info *log.Logger Warning *log.Logger Error *log.Logger ) func init() { logfile, err := os.OpenFile(\u0026quot;Nodes_multicast.log\u0026quot;, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666) if err != nil { log.Fatalln(\u0026quot;打开日志文件失败：\u0026quot;, err) } Info = log.New(logfile, \u0026quot;Info: \u0026quot;, log.Lmicroseconds|log.Lshortfile) Warning = log.New(io.MultiWriter(os.Stdout, logfile), \u0026quot;Warning: \u0026quot;, log.Lmicroseconds|log.Lshortfile) Error = log.New(io.MultiWriter(os.Stderr, logfile), \u0026quot;Error: \u0026quot;, log.Lmicroseconds|log.Lshortfile) } func main() { // 使用参数1的网卡发送和监听组播包(取出其ip作源地址), 不输入参数使用默认路由 // 参数2代表运行客户端nem节点号，默认为1 var ethname, nemid string = \u0026quot;\u0026quot;, \u0026quot;1\u0026quot; if len(os.Args) \u0026gt; 2 { ethname = os.Args[1] nemid = os.Args[2] } else { Warning.Println(\u0026quot;No parameter is entered,now using default route and nemid:\u0026quot;, nemid) } conn, err := multicast_init(ethname) if err != nil { Error.Println(\u0026quot;multicast init error:\u0026quot;, err) return } defer conn.send.Close() Info.Println(\u0026quot;Nodes start multicast :\u0026quot;) send_interval := time.Tick(time.Second * 3) check_interval := time.Tick(time.Second * 15) for { select { case \u0026lt;-send_interval: Info.Println(\u0026quot;\\\u0026quot;send msg\\\u0026quot;\u0026quot;) // s := []byte(fmt.Sprintf(\u0026quot;Hello,I'm %s\u0026quot;, nemid)) s := []byte(\u0026quot;Hello,I'm \u0026quot; + nemid) conn.send.Write(s) case \u0026lt;-check_interval: Info.Println(\u0026quot;\\\u0026quot;check schedul\\\u0026quot;\u0026quot;) case num := \u0026lt;-conn.recv: Info.Println(\u0026quot;\\\u0026quot;recv msg\\\u0026quot; \u0026quot;, num) } } } // 取得网卡的任意一个有效ipv4地址 func gain_ip(ethname string) net.IP { eth, _ := net.InterfaceByName(ethname) Addrs, err := eth.Addrs() if err != nil { // Warning.Println(err) //网卡无效 return nil } for _, Addr := range Addrs { if ipnet, ok := Addr.(*net.IPNet); ok \u0026amp;\u0026amp; !ipnet.IP.IsLoopback() { //接口强转为结构体 if ipnet.IP.To4() != nil { return ipnet.IP.To4() } } } return nil } // udp组播的发送初始化，并开始监听组播域 func multicast_init(ethname string) (myconn, error) { ethAddr := gain_ip(ethname) if ethAddr == nil { Warning.Printf(\u0026quot;Failed to retrieve valid ipv4 address as source address,\\nsearch for matching route to send\\n\u0026quot;) ethAddr = net.IPv4zero } srcAddr := \u0026amp;net.UDPAddr{IP: ethAddr, Port: 0} Multicast_addr, _ := net.ResolveUDPAddr(\u0026quot;udp\u0026quot;, \u0026quot;224.0.0.250:9981\u0026quot;) Info.Println(\u0026quot;send addr is\u0026quot;, srcAddr, \u0026quot;ListenMulticast is\u0026quot;, Multicast_addr) send, err := net.DialUDP(\u0026quot;udp\u0026quot;, srcAddr, Multicast_addr) if err != nil { return myconn{}, err } eth, _ := net.InterfaceByName(ethname) listener, err := net.ListenMulticastUDP(\u0026quot;udp\u0026quot;, eth, Multicast_addr) if err != nil { send.Close() return myconn{}, err } data := make([]byte, 1024) datach := make(chan int, 0) go func() { // go的匿名函数默认捕获上下文变量 defer listener.Close() for { n, remoteAddr, err := listener.ReadFromUDP(data) if err != nil { Warning.Printf(\u0026quot;error during read: %s\u0026quot;, err) continue } s := string(data[:n]) if remoteAddr.IP.Equal(ethAddr) { continue // 排除自身发出的组播包 } // Info.Printf(\u0026quot;receive %s %d bytes: %s\\n\u0026quot;, remoteAddr, n, s) _, err = fmt.Sscanf(s, \u0026quot;Hello,I'm %d\u0026quot;, \u0026amp;n) if err != nil { Warning.Printf(\u0026quot;error during Sscanf: %s\u0026quot;, err) continue } datach \u0026lt;- n } }() return myconn{send: send, recv: datach}, nil }  后续内容 其实我使用这个工具只是做的TDMA动态时隙的统计，大致做法是将各个节点的接收数据做记录存入map中。没到检测时间的管道计时到达后开始处理map数据生成时隙表。注意go中的map并不是并发安全的，需要加sync.Mutex互斥锁或sync.RWMutex读写锁来避免竞争冒险。不过好在我是分开在select中处理不会出现上述问题，go中也有人做了并发安全的set5。\n关于go的文件读写还是要提下，*bufio.Writer *os.File这两个接口都实现可writestring函数，下面的写文件代码为了提升效率新建了bufio,bufio 在一定场景下还是很能提升效率的，不过还是需要注意与直接写入文件的异同，防止缓存数据未同步的状况发生。如下，写完文件后需要调用Flush刷新。\nfunc write_schedule(filepath string, newdata []string) error { file, err := os.Create(filepath) if err != nil { return err } defer file.Close() writer := bufio.NewWriter(file) for _, str := range newdata { _, err = writer.WriteString(str + \u0026quot;\\n\u0026quot;) } //注意，bufio 通过flush操作将缓冲写入真实的文件的，在关闭文件之前先flush，否则会造成数据丢失的情况。 writer.Flush() return err }  之后有可能会分享下后续具体动态时隙内容。\n组播探测程序：\n组播部分： 每个节点都会通过指定网卡向组播域中发送hello包，定时间隔为 'send_interval_time' 通过加入该组播域监听该组播域内消息，做到类似探测网内存活节点数量目的 定时检测时隙(组播域中成员是否有变化),检测时间为 'check_interval_time' 即一次检测时隙周期内接收到对应nemid组播包即认为该节点存活 收发包格式为 \u0026quot;Hello,I'm $nemid\u0026quot; 发送控制网时隙消息： 确定主控制网网桥IP，例如172.16.0.254 接收的组播记录存储至 并发安全set中，我这里的实现采用map(并发不安全) 这是因为我使用select管道传输数据再进行修改map就不会出现竞争冒险，造成并发的读写 各个节点信息综合格式为 I'm 1,recv 2 3 4 5  时隙统计程序：\n首先打开当前场景的时隙分配xml文件，获取基本参数信息 然后定时检测各个节点发送的节点监测消息，根据优先级固定的顺序分配时隙 一定是先排列完全部节点后再继续按照节点优先级顺序排列时隙， 所以优先级高的节点其分配到时隙的可能性越大 当前优先级 简单的处理为 nemid，id越小 优先级越高,具体参考myschedule_create的实现 检测时间间隔与多播程序的时间间隔相同 'check_interval' 注意：这里仅仅是为了处理方便将所有节点时隙数据整合在一起 其实实际各个节点的时隙是单独分派的，例如若两节点n1 n15分别在两个网内（组播域中未互相探测到） 所以他们的时隙很可能是会有重合冲突的部分，但由于组播无法互相探测到可认为是无影响的。 // 根据时隙表规则，设定以节点id为优先级 固定顺序的排列时隙表，举例 时隙为10 // 1收到 2 3：\t顺序：1 2 3 1 2 3 1 2 3 1\t1的时隙：0,3,6,9 // 7收到 8 9 4：\t顺序：4 7 8 9 4 7 8 9 4 7\t7的时隙：1,5,9 // 要推算节点 datas.id 的时隙分布，只要知道时隙个数，优先级排名(id越小，优先级越高)即可推算    鸟窝. 深入Go UDP编程 (colobu.com) 通用多播编程\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n 不二星空. GO实现获取本地IP地址(csdn.net) 获取网卡ip\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Draveness. Go 语言设计与实现(draveness.me) 并发编程与计时器\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n 飞雪无情. Go语言实战笔记(flysnow.org) 定制go日志\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n 波罗学. Go 中如何使用 set - 掘金 (juejin.cn)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","id":5,"section":"posts","summary":"介绍 最近在做一个关于无线移动自组织网络相关的内容，移动自组织网络是由彼此已经发现和互相接近的且有通信需求的移动设备构成的。由于网内节点的移动","tags":["go","network"],"title":"网内存活节点测试工具","uri":"https://liangkang233.github.io/2021/09/%E7%BD%91%E5%86%85%E5%AD%98%E6%B4%BB%E8%8A%82%E7%82%B9%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/","year":"2021"},{"content":" 其实网上有很多关于扩容的文章，但是没有解决我的问题所以当扩容后成功后还是决定做个记录方便解决类似问题。不论是虚拟机还是物理机的扩容都可以试试下面的方法。\n 问题分析 Ubuntu的图形界面非常直观，上手难度也不大，所以使用VM虚拟机装了个Ubuntu系统，搭建专门跑实验室的一些linux软件环境，用到后面 / 挂载的磁盘仅剩500M不到，根本不够用就很难受。但是重配环境又很麻烦所以还是决定扩容分区。\n扩容首先得有空间，虚拟机就直接如下图般添加空间即可（需要删除所有快照），如果有未分配的空间直接拿来用不用此步。\n物理机的话就准备新的硬盘挂载分区。实在不行也可以从其他分区挤出些空间。\n 注意除非是windows的动态磁盘，否则分区物理分配逻辑是从左到右的顺序，不可以跨分区分配给其他空间。\n Ubuntu有图形分区工具 gparted ,我这里添加了20g的空间（固态空间剩的不多了，所以也没扩多少）\n所以搞过windows分区的话看起来很快就能搞定，图形界面点两下就完事了。\n 上锁的分区需要卸载后操作完毕再挂载。\n # 查看挂载分区空间命令 df -Th # 安装 分区工具 sudo apt-get install gparted  文件系统 类型 容量 已用 可用 已用% 挂载点 udev devtmpfs 1.9G 0 1.9G 0% /dev tmpfs tmpfs 391M 2.2M 389M 1% /run /dev/sda6 ext4 9.4G 8.4G 475M 95% / tmpfs tmpfs 2.0G 111M 1.9G 6% /dev/shm tmpfs tmpfs 5.0M 4.0K 5.0M 1% /run/lock tmpfs tmpfs 2.0G 0 2.0G 0% /sys/fs/cgroup /dev/loop1 squashfs 2.5M 2.5M 0 100% /snap/gnome-system-monitor/163 /dev/loop2 squashfs 219M 219M 0 100% /snap/gnome-3-34-1804/66 /dev/loop3 squashfs 219M 219M 0 100% /snap/gnome-3-34-1804/72 /dev/loop4 squashfs 640K 640K 0 100% /snap/gnome-logs/103 /dev/loop5 squashfs 2.5M 2.5M 0 100% /snap/gnome-calculator/884 /dev/loop6 squashfs 242M 242M 0 100% /snap/gnome-3-38-2004/70 /dev/loop7 squashfs 2.5M 2.5M 0 100% /snap/gnome-system-monitor/160 /dev/loop0 squashfs 640K 640K 0 100% /snap/gnome-logs/106 /dev/loop10 squashfs 66M 66M 0 100% /snap/gtk-common-themes/1515 /dev/loop9 squashfs 56M 56M 0 100% /snap/core18/2128 /dev/loop11 squashfs 768K 768K 0 100% /snap/gnome-characters/726 /dev/loop12 squashfs 768K 768K 0 100% /snap/gnome-characters/723 /dev/loop13 squashfs 62M 62M 0 100% /snap/core20/1081 /dev/loop14 squashfs 56M 56M 0 100% /snap/core18/2074 /dev/loop15 squashfs 33M 33M 0 100% /snap/snapd/12883 /dev/sda1 ext4 268M 118M 132M 48% /boot /dev/loop16 squashfs 33M 33M 0 100% /snap/snapd/12704 /dev/sda3 ext4 15G 5.2G 8.2G 39% /home /dev/loop17 squashfs 62M 62M 0 100% /snap/core20/1026 /dev/loop18 squashfs 65M 65M 0 100% /snap/gtk-common-themes/1514 /dev/sda4 ext4 3.9G 63M 3.6G 2% /tmp /dev/loop19 squashfs 2.5M 2.5M 0 100% /snap/gnome-calculator/748 tmpfs tmpfs 391M 40K 391M 1% /run/user/1000 /dev/loop20 squashfs 243M 243M 0 100% /snap/gnome-3-38-2004/76  一开始我是想直接把home分区（看上面的记录 home分区基本没用多少）复制挂载到扩容硬盘新建立分区。然后把home分区删除分给 /。 但是也不知道当时为啥这么憨😓 装系统时 home 交换空间 tmp boot都拿来做主分区，拿一个10g的逻辑分区挂载 / 。而且系统分区表选的是mbr导致一个磁盘置多四个主分区。所以这个计划根本不可行，不能在当前系统下操作加新主分区。（我在当前系统下肯定是不太好操作当前系统的磁盘的）\n回想起windows有pe工具，说不定Ubuntu也有类似的工具。网上一查ubuntu启动盘自身就是一个linux系统，可以直接使用这些linux软件包，说干就干准备启动盘。\n解决步骤   如果是虚拟机：\n找到安装该系统对应的iso镜像，并在虚拟机硬件设置中选项cd/dvd中选中该镜像并勾选启动时连接时。然后如下图直接进bios设置启动项即可。\n  如果是物理机，就跟装系统一样做一个你当前主板bios能识别的启动盘即可，镜像要与当前系统一样，这里就不赘述启动盘的制作了。之后进入bios设置启动盘。\n  成功进入启动盘后，选择试用Ubuntu就进入到启动盘中的linux系统了，由于与主硬盘分离所以可以操作挂载的路径分区等。\n同样的进入 gparted中，没有就联网安装一个。\n接下来就可以随心改变分区了不过有几个注意点，重要数据一定要先备份，数据无价。（虚拟机的话直接加个快照，有问题就还原回来）\n  有些仍挂载的分区上锁状态要先禁用或卸载，之后再启用或是挂载 例如我的swap交换空间。\n  逻辑分区的大小扩容要先扩容其主分区大小，再操作逻辑分区 例如我这挂载 / 的sda6扇区就是逻辑分区。\n  移动分区时，如果改变了扇区头要注意该扇区内是否挂载了 boot uefi等启动分区可能回造成启动项无法识别。\n​\t您可以在GParted FAQ中学习如何修复启动配置。http://gparted.org/faq.php。我使用的mbr分区表没有uefi启动分区，bios是单独的扇区挂载上去的所以可以放心操作。\n  最后扩容就完成了，图形界面的操作没啥说的。只能感叹linux的强大，windows to go要是也能如此功能强大、配置方便就好了。\n","id":6,"section":"posts","summary":"其实网上有很多关于扩容的文章，但是没有解决我的问题所以当扩容后成功后还是决定做个记录方便解决类似问题。不论是虚拟机还是物理机的扩容都可以试试","tags":["linux"],"title":"Ubuntu分区扩容","uri":"https://liangkang233.github.io/2021/09/ubuntu%E5%88%86%E5%8C%BA%E6%89%A9%E5%AE%B9/","year":"2021"},{"content":"对go的基础学习中，也了解了些相关热点问题。\n发现篇非常好的文章详细介绍了go中的并发设计原理、内存模型。写些读后感。\n并发编程 上下文 上下文简单的理解为代码运行的环境，上下文 context.Context 在 Go 语言中用来设置截止日期、同步信号，传递请求相关值的结构体。context.Context是 Go 语言在 1.7 版本中引入标准库的接口，该接口定义了四个需要实现的方法，其中包括：\n   方法 概述     Deadline 返回 context.Context 被取消的时间，也就是完成工作的截止日期；   Done 返回一个 Channel，这个 Channel 会在当前工作完成或者上下文被取消后关闭，多次调用 Done 方法会返回同一个 Channel；   Err 返回 context.Context 结束的原因，它只会在 Done 方法对应的 Channel 关闭时返回非空的值；如果 context.Context 被取消，会返回 Canceled 错误；如果 context.Context 超时，会返回 DeadlineExceeded 错误；   Value 如果 context.Context 超时，会返回 DeadlineExceeded 错误；从 context.Context 中获取键对应的值，对于同一个上下文来说，多次调用 Value 并传入相同的 Key 会返回相同的结果，该方法可以用来传递请求特定的数据；    Go 语言中的 context.Context 的主要作用还是在多个 Goroutine 组成的树中同步取消信号以减少对资源的消耗和占用，例如使用context.WithCancel 函数能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数。一旦我们执行返回的取消函数，当前上下文以及它的子上下文都会被取消，所有的 Goroutine 都会同步收到这一取消信号，父上下文取消时子上下文也会被取消。虽然它也有传值的功能，但是这个功能我们还是很少用到。\n在真正使用传值的功能时我们也应该非常谨慎，使用 context.Context 传递请求的所有参数一种非常差的设计，比较常见的使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。\nchannel channel常用来做协程间的信息同步，是个建立时设定缓冲区（默认是0）用于共享消息先入先出的队列。\ntype hchan struct { qcount uint\t// Channel 中的元素个数； dataqsiz uint\t// Channel 中的循环队列的长度； buf unsafe.Pointer // Channel 的缓冲区数据指针； elemsize uint16 closed uint32 elemtype *_type sendx uint\t// Channel 的发送操作处理到的位置 recvx uint\t// Channel 的发送操作处理到的位置 recvq waitq sendq waitq lock mutex }  具体细节网上资料很详细，这里记录几个易错点：\n  当一个channel被关闭后，再向该channel发送数据将导致panic异常。当一个被关闭的channel中已经发送的数据都被成功接收后，后续的接收操作将不再阻塞，它们会立即返回一个零值。关闭上面例子中的naturals变量对应的channel并不能终止循环，它依然会收到一个永无休止的零值序列，然后将它们发送给打印者goroutine。\n没有办法直接测试一个channel是否被关闭，但是接收操作有一个变体形式：它多接收一个结果，多接收的第二个结果是一个布尔值ok，ture表示成功从channels接收到值，false表示channels已经被关闭并且里面没有值可接收。使用这个特性，我们可以修改squarer函数中的循环代码，当naturals对应的channel被关闭并没有值可接收时跳出循环，并且也关闭squares对应的channel.\ngo func() { for { x, ok := \u0026lt;-naturals if !ok { break // channel was closed and drained } squares \u0026lt;- x * x } close(squares) }()  因为上面的语法是笨拙的，而且这种处理模式很常见，因此Go语言的range循环可直接在channels上面迭代。使用range循环是上面处理模式的简洁语法，它依次从channel接收数据，当channel被关闭并且没有值可接收时跳出循环。（channel不关闭 将一直堵塞在range处）\ngo func() { for x := range naturals { squares \u0026lt;- x * x } close(squares) }()    chan要用make生成，对空值的ch调用会造成堵塞\n例如var tick \u0026lt;-chan time.Time tick就是一个空值的channel（nil）对其写入或读取操作都会造成堵塞\n  函数形参的单向channel 就是普通 channel 由编辑器检查传输方向来确保单向而实现的，传参会进行隐式转换 双向变为单向 单向不可变为双向\nnaturals := make(chan int) 无缓存 缓存为0\nnaturals := make(chan int, 3) 缓存为3 cap(naturals)=3 len(naturals)=0\n举例： out in 为形参名\n   参数：只发送 ch func count (out chan \u0026lt;- int) {}     参数：只接收 ch func counter (in \u0026lt;- chan int) {}   参数：普通双向 func counter (chan int) {}      共享变量 Go 语言也有类似unix中实现的那些共享变量的内容。在 sync 包中提供了用于同步的一些基本原语，包括常见的 sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Once 和 sync.Cond。\n只要在go build，go run或者go test命令后面加上-race的flag，就会使编译器创建一个你的应用的“修改”版或者一个附带了能够记录所有运行期对共享变量访问工具的test，并且会记录下每一个读或者写共享变量的goroutine的身份信息。另外，修改版的程序会记录下所有的同步事件，比如go语句，channel操作，以及对(*sync.Mutex).Lock，(*sync.WaitGroup).Wait等等的调用。\n这些互斥锁与c中的一样，且都不支持重入锁，再次上锁会死锁。这些锁主要是应对竞争条件下对变量的读写，介绍几个常见的锁用法：\n  sync.Mutex互斥锁\nvar mu sync.Mutex mu.Lock() mu.Unlock() // 锁记得要释放    sync.RWMutex读写锁\n// 其允许多个只读操作并行执行，但写操作会完全互斥。 var mu sync.RWMutex mu.RLock() // readers lock mu.RUnlock() // 调用了RLock和RUnlock方法来获取和释放一个读取或者共享锁。(上锁时，RLock不堵塞) mu.Lock() mu.Unlock() // 调用mu.Lock和mu.Unlock方法来获取和释放一个写或互斥锁。（上锁时其他任何锁堵塞）    sync.Once单次锁\n// 一般用于初始化，只上锁一次 var loadIconsOnce sync.Once var icons map[string]image.Image // Concurrency-safe. func Icon(name string) image.Image { loadIconsOnce.Do(loadIcons)\t//loadIcons为调用的其他函数 return icons[name] }    sync.WaitGroup 等待开锁组\n// 递增的计数器，这个计数器需要在多个goroutine操作时做到安全并且提供在其完成之前一直等待。 var wg sync.WaitGroup // number of working goroutines wg.Add(1) wg.Done() wg.Wait() //堵塞等待上锁组内全部done    gorutine与线程 协程英文名Coroutine。但在 Go 语言中，协程的英文名是：gorutine。它常常被用于进行多任务，即并发作业。\n协程的特点：\n 多个协程可由一个或多个线程管理，协程的调度发生在其所在的线程中。 可以被调度，调度策略由应用层代码定义，即可被高度自定义实现。 执行效率高。 占用内存少。      线程 协程     数据存储 内核态的内存空间 一般是线程提供的用户态内存空间   切换操作 操作最终在内核层完成，应用层需要调用内核层提供的 syscall 底层函数 应用层使用代码进行简单的现场保存和恢复即可   任务调度 由内核实现，抢占方式，依赖各种锁 由用户态的实现的具体调度器进行。例如 go 协程的调度器   语音支持程度 绝大部分编程语言 部分语言：Lua，Go，Python \u0026hellip;   实现规范 按照现代操作系统规范实现 无统一规范。在应用层由开发者实现，高度自定义，比如只支持单线程的线程。不同的调度策略，等等    OS线程会被操作系统内核调度。每几毫秒，一个硬件计时器会中断处理器，这会调用一个叫作scheduler的内核函数。这个函数会挂起当前执行的线程并将它的寄存器内容保存到内存中，检查线程列表并决定下一次哪个线程可以被运行，并从内存中恢复该线程的寄存器信息，然后恢复执行该线程的现场并开始执行线程。因为操作系统线程是被内核所调度，所以从一个线程向另一个“移动”需要完整的上下文切换，也就是说，保存一个用户线程的状态到内存，恢复另一个线程的到寄存器，然后更新调度器的数据结构。这几步操作很慢，因为其局部性很差需要几次内存访问，并且会增加运行的cpu周期。\nGo的运行时包含了其自己的调度器，这个调度器使用了一些技术手段，比如m:n调度，因为其会在n个操作系统线程上多工（调度）m个goroutine。Go调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的Go程序中的goroutine（译注：按程序独立）。\n和操作系统的线程调度不同的是，Go调度器并不是用一个硬件定时器，而是被Go语言“建筑”本身进行调度的。例如当一个goroutine调用了time.Sleep，或者被channel调用或者mutex操作阻塞时，调度器会使其进入休眠并开始执行另一个goroutine，直到时机到了再去唤醒第一个goroutine。因为这种调度方式不需要进入内核的上下文，所以重新调度一个goroutine比调度一个线程代价要低得多。\ngo拥有其协程调度器，调度器的三个基本对象：\n  G (Goroutine)，代表协程，也就是每次代码中使用 go 关键词时候会创建的一个对象\n  M (Work Thread)，工作线程\n  P (Processor)，代表一个处理器，又称上下文\n  每一个运行的 M 都必须绑定一个 P，线程M 创建后会去检查并执行G (goroutine)对象。每一个 P 保存着一个协程G 的队列。除了每个 P 自身保存的 G 的队列外，调度器还拥有一个全局的 G 队列。M 从队列中提取 G，并执行P 的个数就是GOMAXPROCS（最大256），启动时固定的，一般不修改。（ go 1.5 版本之前的 GOMAXPROCS 默认是 1，go 1.5 版本之后的 GOMAXPROCS 默认是 Num of cpu）M 的个数和 P 的个数不一定一样多（会有休眠的M 或 P不绑定M ）（最大10000）。P 是用一个全局数组（255）来保存的，并且维护着一个全局的 P 空闲链表\nGOMAXPROCS 就是 go 中 runtime 包的一个函数。它设置了 P 的最多的个数。这也就直接导致了 M 最多的个数是多少，而 M 的个数就决定了各个 G 队列能同时被多少个 M 线程来进行调取执行！如下演示\nfor{ gofmt.Print(0) fmt.Print(1) } // $ GOMAXPROCS=1gorun hacker-cliché.go111111111111111111110000000000000000000011111... // $ GOMAXPROCS=2gorun hacker-cliché.go010101010101010101011001100101011010010100110...  在第一次执行时，最多同时只能有一个goroutine被执行。初始情况下只有main goroutine被执行，所以会打印很多1。过了一段时间后，GO调度器会将其置为休眠，并唤醒另一个goroutine，这时候就开始打印很多0了，在打印的时候，goroutine是被调度到操作系统线程上的。在第二次执行时，我们使用了两个操作系统线程，所以两个goroutine可以一起被执行，以同样的频率交替打印0和1。我们必须强调的是goroutine的调度是受很多因子影响的，而runtime也是在不断地发展演进的，所以这里的你实际得到的结果可能会因为版本的不同而与我们运行的结果有所不同。\n","id":7,"section":"posts","summary":"对go的基础学习中，也了解了些相关热点问题。 发现篇非常好的文章详细介绍了go中的并发设计原理、内存模型。写些读后感。 并发编程 上下文 上下文简单","tags":["go"],"title":"Go并发解析","uri":"https://liangkang233.github.io/2021/09/go%E5%B9%B6%E5%8F%91%E8%A7%A3%E6%9E%90/","year":"2021"},{"content":"常用小技巧 leetcode刷题遇到的一些问题，关于算法的结构文字描述的有限，记录些常用的单元的代码，备忘。\n最小公倍数 最大公约数 利用最大公约数求最小公倍数\n已知a,b最大公约数为X，最小公倍数为Y，则有公式为a*b=最大公约数X * 最小公倍数Y\n证明：由已知得a=Xc b=Xd 且c与d互为素数（否则X就不是c与d的最大公因数）所以Y=Xcd, 即a*b = c * X * X * d = X * Y\n求最大公约数：辗转相除法 用较大数除以较小数，再用出现的余数（第一余数）去除除数，再用出现的余数（第二余数）去除第一余数，如此反复，直到最后余数是0为止。 如果是求两个数的最大公约数，那么最后的除数就是这两个数的最大公约数 定理：两个整数的最大公约数等于其中较小的那个数和两数相除余数的最大公约数。最大公约数（Greatest Common Divisor）缩写为GCD。 gcd(a,b) = gcd(b,a mod b) (不妨设a\u0026gt;b 且r=a mod b ,r不为0)\n证明： a可以表示成a = kb + r（a，b，k，r皆为正整数，且r\u0026lt;b），则r = a mod b 假设d是a,b的一个公约数，记作d|a,d|b，即a和b都可以被d整除。 而r = a - kb，两边同时除以d，r/d=a/d-kb/d=m，由等式右边可知m为整数，因此d|r 因此d也是b,a mod b的公约数。 因(a,b)和(b,a mod b)的公约数相等，则其最大公约数也相等，得证。\nint MinBei(int a, int b) {\tint tmp, count = a * b; // 求最大公约数 while (b) { tmp = b; b = a % b; a = tmp; } // cout \u0026lt;\u0026lt; \u0026quot;yue: \u0026quot; \u0026lt;\u0026lt; a; return count / a ; //两数相乘等于 最大公约数乘最小公倍数 } int main() {\tint a, b, c, temp; cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b \u0026gt;\u0026gt; c; temp = MinBei(a, b); // cout \u0026lt;\u0026lt; temp \u0026lt;\u0026lt; endl; temp = MinBei(c, temp); // cout \u0026lt;\u0026lt; temp \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; temp; return 0; }  质(因)数  哥德巴赫猜想：任一大于2的偶数，都可表示成两个素数之和。\n 合数性质：\n 所有大于2的偶数都是合数，也就是在正整数中除了2以外，其余数的个位数为0、2、4、6、8者均为合数。4为最小的合数。 每一合数都可以以唯一形式被写成质数的乘积。（算术基本定理） 所有合数都有至少3个正因数，例如4有正因数1、2、4，6有正因数1、2、3、6。 对任一大于5的合数n，(n-1)!==0（威尔逊定理） 对于任意的正整数n，都可以找到一个正整数x，使得x、x+1、x+2、…、x+n 都是合数。  快速计算是否为质数方法：\n根据性质2，任何一个合数都能能分解成质数相乘，那么可以表示为N＝a1*a2*...*ak，（ak均为质数） 上述质因数拆分中 k \u0026gt;= 2,所以最小质因数为a1，容易知道a1小于 sqrt(N) 即合数一定存在一个小于sqrt(N)的质因数 6x 6x-2 6x-3 6x-4肯定不是质数。 所以如果 n 是6 倍数两侧的数，那么n才有可能是质数。 即结论 质数(大于3时)一定是6x-1 或6x-5（x\u0026gt;=1）  #include \u0026lt;iostream\u0026gt; #include \u0026lt;cmath\u0026gt; // 最原始 bool isPrime(int n){ if (n \u0026lt;= 3) { return n \u0026gt; 1; } for(int i = 2; i \u0026lt; n; i++){ if (n % i == 0) { return false; } } return true; } // 初步优化 // 若不是质数 其一定存在因数p1\u0026lt;=sqrt(n)，p2\u0026gt;=sqrt(n) bool isPrime1(int n) { if (n \u0026lt;= 3) { return n \u0026gt; 1; } int s = (int)sqrt(n); for (int i = 2; i \u0026lt;= s; i++) { if(n % i == 0) { return false; } } return true; } // 质数还有一个特点，就是它总是等于 6x-1 或者 6x-5，其中 x 是大于等于1的自然数。 bool isPrime2(int num) { if (num \u0026lt;= 3) { return num \u0026gt; 1; } // 不在6的倍数两侧的一定不是质数 if (num % 6 != 1 \u0026amp;\u0026amp; num % 6 != 5) { return false; } int s = (int)sqrt(num); // 若这个数是合数，则有质因数i,i \u0026lt;= sqrt(num) // 且i为质数一定为6倍数两侧，以6为步长寻找 for (int i = 6; i \u0026lt;= s; i += 6) { if (num % (i-1) == 0 || num % (i+1) == 0) { return false; } } return true; }  平方根函数 用牛顿法实现平方根函数。\n计算机通常使用循环来计算 x 的平方根。从某个猜测的值 z 开始，我们可以根据 z² 与 x 的近似度来调整 z，产生一个更好的猜测：\n z -= (z * z - x) / (2*z)\n 上面的 z² − x 是 z² 到它所要到达的值（即 x）的距离， 除以的 2z 为 z² 的导数，我们通过 z² 的变化速度来改变 z 的调整量。X在上式中为固定值。\n这种通用方法叫做牛顿法。 它对很多函数，特别是平方根而言非常有效。 int main() { double x1, x2; float a; scanf(\u0026quot;%f\u0026quot;, \u0026amp;a); x2 = 1.0; do { x1 = x2; x2 = (x1 + a / x1) / 2; } while (fabs(x1-x2)\u0026gt;pow(10,-5)); printf(\u0026quot;value:%lf\u0026quot;, x2); system(\u0026quot;pause\u0026quot;); return 0; }  扩展，雷神之锤源码平方根调用方法，只看最后一部分即可。将 f(x)=y 转为 f(y)=x 来简化运算\n .aspect-ratio { position: relative; width: 100%; height: 0; padding-bottom: 75%; } .aspect-ratio iframe { position: absolute; width: 100%; height: 100%; left: 0; top: 0; }    回文数 求回文时，若是字符串就法1比较，若是数字利用迭代乘、余来做\n// 法1 while (start \u0026lt; end) { if (nums[start++] != nums[end--]) return false; } return true; //法2 bool isPalindrome(int x) { if (x \u0026lt; 0 || (x % 10 == 0 \u0026amp;\u0026amp; x != 0)) return false; int revertedNumber = 0; while (x \u0026gt; revertedNumber) { revertedNumber = revertedNumber * 10 + x % 10; x /= 10; } // 当数字长度为奇数时，我们可以通过 revertedNumber/10 去除处于中位的数字。 // 例如，当输入为 12321 时，在 while 循环的末尾我们可以得到 x = 12，revertedNumber = 123， // 由于处于中位的数字不影响回文（它总是与自己相等），所以我们可以简单地将其去除。 return x == revertedNumber || x == revertedNumber / 10; }  位运算 注意：左移运算用零填充右边空缺的bit位，无符号数的右移运算也是用0填充左边空缺的bit位，但是有符号数的右移运算会用符号位的值填充左边空缺的bit位。\n因为这个原因，最好用无符号运算，这样你可以将整数完全当作一个bit位模式处理。\n   ! 逻辑非     ~ 位非   ^ 异或   | 或   \u0026amp; 与       功能 使用方法 参考链接     树状数组中的求 一个数二进制的1的最低位置 直接 return = x\u0026amp;(-x) lowbit 树状数组关键函数   求某个数据出现次数 使用 \u0026amp;操作，复杂的添加状态表 https://leetcode-cn.com/problems/single-number/   将x的最低的一个非零的bit位清零 使用 x\u0026amp;(x-1)    查询一个64位数据的二进制1个数 建表查，省的每次都循环64次 右边main文件内含建表代码   移位查数据，除了直接 \u0026raquo; 也可如右边 x\u0026amp;(1\u0026laquo;i)     标准二分查找及其衍生 //二分法查找/折半查找 int binarySearch(Element array[], int len, int key){ int low = 0, high = len - 1, middle; while(low \u0026lt;= high){ middle = (low + high) / 2; if(array[middle] == key){ //找到,返回下标索引值 return middle; }else if(array[middle] \u0026gt; key){ //查找值在低半区 high = middle - 1; }else{ //查找值在高半区 low = middle + 1; } } return -1; //找不到 } // 衍生：寻找两个正序数组的中位数 // 其实无论size为奇数偶数，它的值都为 (num(size-1) + num(size)) / 2 // https://leetcode-cn.com/problems/median-of-two-sorted-arrays/solution/xun-zhao-liang-ge-you-xu-shu-zu-de-zhong-wei-s-114/ class Solution1 { public: //使用二分法找到第k个的元素(排序从1开始) int findKth(vector\u0026lt;int\u0026gt; nums1, vector\u0026lt;int\u0026gt; nums2, int k) { int n1 = 0, n2 = 0; int size1 = nums1.size(); int size2 = nums2.size(); for ( ; ;) { if(n1 == size1) return nums2[n2 + k - 1]; else if(n2 == size2) return nums1[n1 + k - 1]; else if(k == 1) return min(nums1[n1], nums2[n2]); else { // key 无论如何排列 k都不会在两个数组中k/2中较小的那个位置 int new_n1 = n1 + k/2 - 1 \u0026lt; size1 ? nums1[n1 + k/2 - 1] : 0X7FFFFFFF; int new_n2 = n2 + k/2 - 1 \u0026lt; size2 ? nums2[n2 + k/2 - 1] : 0X7FFFFFFF; if(new_n1 \u0026lt; new_n2) n1 += k/2; else n2 += k/2; k -= k/2; } } } double findMedianSortedArrays(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2) { int size = nums1.size() + nums2.size(); // 中位数无论奇数还是偶数，其中位数都是第size/2 + 1 和 (size+1)/2)个元素的平均数 return (findKth(nums1, nums2, size/2 + 1) + findKth(nums1, nums2, (size + 1)/2) ) / 2.0; } };  ","id":8,"section":"posts","summary":"常用小技巧 leetcode刷题遇到的一些问题，关于算法的结构文字描述的有限，记录些常用的单元的代码，备忘。 最小公倍数 最大公约数 利用最大公约数","tags":["C/C++","算法"],"title":"编程题中常见技巧","uri":"https://liangkang233.github.io/2021/08/%E5%B8%B8%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/","year":"2021"},{"content":"shell脚本在linux使用用的十分广泛，写篇总结学习性的文章做记录。\n这个运维手册写的比较详细，可以做参考。\n另一个比较全的参考\n基本语法  if else： # then 与 if 同一行时要加 ; if [ `whoami` != \u0026quot;root\u0026quot; ];then echo \u0026quot;Please run it as a superuser\u0026quot; exit 0 elif $something -gt 2 ; then echo \u0026quot;else if\u0026quot; else echo \u0026quot;else\u0026quot; fi   switch： read -p $'Please input a number... \\n1 means icmp,2 means udp ,3 means tcp ' case $n in 1) echo \u0026quot;you will accept icmp data\u0026quot; tcpdump icmp -c 5 -i ens33 -l -w./aaa.cap \u0026amp; ;; 2) echo \u0026quot;you will accept udp data\u0026quot; tcpdump udp -c 5 -i ens33 ;; 3) echo \u0026quot;you will accept tcp data\u0026quot; tcpdump tcp -c 5 -i ens33 ;; *) echo \u0026quot;invail command\u0026quot; ;; esac   for：  datetime=`date +%F-%H:%M:%S` i=1 while [ $i -lt 5 ];do echo \u0026quot;start NO.$i capture data\u0026quot; # sudo tcpdump icmp -i ens33 -w ./$datetime.cap \u0026amp; # sudo tcpdump icmp -i ens33 -w ./`date +%F-%H:%M:%S` \u0026amp; tdid=`pgrep tcpdump` sleep 10s echo \u0026quot;$tdid\u0026quot; kill -9 $tdid ((i++)) done for i in ${!IdArry[@]} do echo ${IdArry[i]:1} # echo ${IdArry[i]:i:j} 表示打印第i位到第j位数据，j省略表示第i位到最后一位 done  关系运算符，如下：  注意： 使用 [] 就可以使用c中常用的关系符, # [ ]符号旁必须有空格，否则会被shell认为是命令执行\n  -gt：大于，greater than。 -eq：等于，equal。 -lt：小于，less than。 -ge：大于等于，greater than or equal。 -le：小于等于，less than or equal。 -ne：不等于，not equal。  连接符，如下：\n -a：且，and。 -o：或，or。  条件判断，逻辑运算符，如下：\n \u0026amp;\u0026amp;：用来执行条件成立后执行的命令。 ||：用来执行条件不成立后的执行命令。  函数、传参、返回值 给定的参数以$1，$2，$3,...$n的形式访问，对应于函数名后参数的位置。$0变量的值是函数的名称。 $? 表示上次运行的结果，非0表示异常 $# 变量用于保存赋予函数的位置自变量/参数的数量。其中 $* 和 $@ 变量用于保存赋予函数的所有参数。 传参时，若$cmd中带空格需要加\u0026quot;\u0026quot; , 不加双引号会自动以空格为分割符号传参 数组传参数使用 ${Mymap[*]} 或 ${Mymap[@]}，区别为${Mymap[*]} 是传入一个参数， 例如“1 2 3”${Mymap[@]} 是传入多个参数，例如\u0026quot;1\u0026quot;,\u0026quot;2\u0026quot;,\u0026quot;3\u0026quot;  # 声明函数的语法有两种格式定义： # 第一种方法：以函数名称开头，后跟括号。这是最优选且最常用的方法，语法如下： function_name () { commands } # 单行语法如下： function_name () { commands; } # 第二种方法：以函数保留字开头，后跟函数名称： function function_name { commands } # 单行语法如下： function_name () { commands; }  数组、关联数组（字典）变量  索引-1是最后一个元素的参考\n declare -a ARRAY_NA 声明数组 declare -A ARRAY_NAME 声明关联数组 local temp 声明局部变量\n 注意脚本中哪怕函数内定义变量默认是全局的，在函数内定义的local变量会结束作用域后销毁。\n 关联数组用法示例:\n# 访问元素类似数组 Mymap[${NameArry}] # 添加元素 Mymap[${NameArry}] = 12 # 删除元素 unset Mymap[$findkey] 删除操作 # 遍历元素 for i in ${IdArry[@]} do echo i done # ${!Mymap[@]}为数组或字典全部index ${Mymap[@]}为全部value #  \u0026amp;() 与 ｀｀区别 在操作上，这两者都是达到相应的效果。在bash中，$( )与｀｀（反引号,博客格式有问题，这里打中文的代替）都是用来作命令替换的。命令替换与变量替换差不多，都是用来重组命令行的，先完成引号里的命令行，然后将其结果替换出来，再重组成新的命令行。\n$ echo today is $(date \u0026quot;+%Y-%m-%d\u0026quot;) today is 2021-08-01  在多层次的复合替换中，｀｀必须要额外的跳脱处理（反斜线），而$( )比较直观。 最后，$( )的弊端是，并不是所有的类unix系统都支持这种方式，但反引号是肯定支持的。\n# 将cmd1执行结果作为cmd2参数，再将cmd2结果作为cmd3的参数 cmd3 $(cmd2 $(cmd1)) # 如果是用反引号，直接引用是不行的，还需要作跳脱处理 cmd3 `cmd2 \\`cmd1\\``  trap 详细trap介绍\n在shell中，使用内置命令trap(中文就翻译为陷阱、圈套)也可以布置所谓的陷阱，这个陷阱当然不是捕老鼠的，而是捕捉信号。\n通常trap都在脚本中使用，主要有2种功能：\n(1).忽略信号。当运行中的脚本进程接收到某信号时(例如误按了CTRL+C)，可以将其忽略，免得脚本执行到一半就被终止 (2).捕捉到信号后做相应处理。主要是清理一些脚本创建的临时文件，然后退出\n进程结束临时文件销毁示例\n# XXX会被随即字符代替保证唯一，-d生成目录，-t表示生成在/temp中， # 脚本临时文件全部存在此处，程序捕获到EXIT后执行finish删除临时文件夹 scratch=$(mktemp -d -t coretmp.XXX) function finish { rm -rf \u0026quot;$scratch\u0026quot; } trap finish EXIT  调用core api示例 awk grep sed 是处理文本的三大利器，后面示例用到了用到了awk，直接将其返回一个变量会传输到数组中。\n#!/bin/bash scratch=$(mktemp -d -t coretmp.XXX) function finish { rm -rf \u0026quot;$scratch\u0026quot; } trap finish EXIT function ApiCall { local nodeId=$1; local cmd=$2; # tee一边重定向到文件一边打印，防止等待response卡死，也方便打印报错信息 coresendmsg execute flags=tty node=$nodeId number=1001 command=\u0026quot;$cmd\u0026quot; -l | tee $scratch/core_msg res=$(awk -F ': ' '{if($1 ~ /RESULT/) print $2}' $scratch/core_msg) if [ \u0026quot;$res\u0026quot; == \u0026quot;\u0026quot; ]; then exit 0 else echo -e \u0026quot;excute core api command: \\n$res\\n\u0026quot; fi eval $res } function SetMap { file=$1 Mymap=$2 local IdArry=(`awk '$1==\u0026quot;node\u0026quot; {print $2}' $file`) local NameArry=(`awk '$1==\u0026quot;hostname\u0026quot; {print $2}' $file`) for i in ${!IdArry[@]} do Mymap[${NameArry[i]}]=${IdArry[i]:1} done # echo ${!Mymap[@]} ${Mymap[@]} } # 默认命令、场景文件参数 nodeId='1' protocol='icmp' interface='eth0' imnPwd=$(echo $HOME/.core/configs/) scene='sample1' declare -A Mymap # 读取参数 if [ $# == 0 ]; then echo -e \u0026quot;The required parameters are imn scenario name and node name\\n\\ When \\$3 is CMD, \\$4 is the command to execute... Otherwise, \\$3 indicates the NIC ID and \\$4 indicates the packet capture protocol (optional).\\n\\ !! default: nodename=n1, interface=$interface, protocol=$protocol(options) !! sense file: echo $imnPwd$scene.imn\u0026quot; else scene=$1 file=$(echo $imnPwd$scene.imn) echo -e \u0026quot;sense file: $file\u0026quot; SetMap $file ${Mymap[*]} # echo \u0026quot;场景节点名: ${!Mymap[@]} \\n 场景节点id: ${Mymap[@]}\u0026quot; nodeId=${Mymap[$2]} interface=$3 protocol=$4 if [ ! -n \u0026quot;$nodeId\u0026quot; ]; then echo \u0026quot;node name error!\u0026quot; exit 0 fi fi if [ \u0026quot;$3\u0026quot; == \u0026quot;cmd\u0026quot; ] ; then ApiCall $nodeId \u0026quot;$4\u0026quot; elif [ $# -ge 3 ] || [ $# == 0 ]; then cmd=$(echo tcpdump $protocol -i $interface -l) ApiCall $nodeId \u0026quot;$cmd\u0026quot; else echo \u0026quot;Invalid input parameter\u0026quot; exit 0 fi  ","id":9,"section":"posts","summary":"shell脚本在linux使用用的十分广泛，写篇总结学习性的文章做记录。 这个运维手册写的比较详细，可以做参考。 另一个比较全的参考 基本语法 if e","tags":["linux"],"title":"SHELL脚本语法示例","uri":"https://liangkang233.github.io/2021/08/shell%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B/","year":"2021"},{"content":"基础太薄弱，最近做一个关于主机路由转发的东西折腾了挺久。做个记录 😕\n默认网关、路由 区别 两者其实是一类功能，在不同应用的产生的不同叫法。\n内网主机向公网发送数据包时，由于目的主机跟源主机不在同一网段，所以数据包暂时发往内网默认网关处理，而本网段的主机对此数据包不做任何回应。\n由于源主机ip是私有的，禁止在公网使用，所以必须将数据包的源发送地址修改成公网上的可用ip，这就是网关收到数据包之后首先要做的工作\u0026ndash;ip转换。\n然后网关再把数据包发往目的主机。目的主机收到数据包之后，只认为这是网关发送的请求，并不知道内网主机的存在，也没必要知道，目的主机处理完请求，把回应信息发还给网关。网关收到后，将目的主机发还的数据包的目的ip地址修改为发出请求的内网主机的ip地址，并将其发给内网主机。\n这就是网关的第二个工作\u0026ndash;数据包的路由转发。内网的主机只要查看数据包的目的ip与发送请求的源主机ip地址相同，就会回应，这就完成了一次请求。 出于安全考虑，Linux系统默认是禁止数据包转发的。所谓转发即当主机拥有多于一块的网卡时，其中一块收到数据包，根据数据包的目的ip地址将包发往本机另一网卡，该网卡根据路由表继续发送数据包。这通常就是路由器所要实现的功能。\n场景介绍 以下图为例\n一共有三个场景：\n  场景一：右上角为路由器做转发无需任何配置的局域网，\n  场景二：其下为三台主机分别桥接的局域网，其中n10左右桥接的两个网卡对应两个网段，n10做路由转发\n  场景三： 左边的场景为上方桥接局域网与下方桥接局域网通过中间两台机器的无线互相转发路由\n  配置主机路由转发 Linux系统缺省并没有打开IP转发功能，要确认IP转发功能的状态，可以查看/proc文件系统， 使用下面命令： cat /proc/sys/net/ipv4/ip_forward 查看是否开启\n在测试中是n10 n1 n4 都开启了IP forward\n这里采用core仿真的配置来设定转发\n# auto-generated by IPForward service (utility.py) sysctl -w net.ipv4.conf.all.forwarding=1 sysctl -w net.ipv4.conf.default.forwarding=1 sysctl -w net.ipv6.conf.all.forwarding=1 sysctl -w net.ipv6.conf.default.forwarding=1 sysctl -w net.ipv4.conf.all.send_redirects=0 sysctl -w net.ipv4.conf.default.send_redirects=0 sysctl -w net.ipv4.conf.all.rp_filter=0 sysctl -w net.ipv4.conf.default.rp_filter=0 sysctl -w net.ipv4.conf.eth0.forwarding=1 sysctl -w net.ipv4.conf.eth0.send_redirects=0 sysctl -w net.ipv4.conf.eth0.rp_filter=0 sysctl -w net.ipv4.conf.eth1.forwarding=1 sysctl -w net.ipv4.conf.eth1.send_redirects=0 sysctl -w net.ipv4.conf.eth1.rp_filter=0  配置后主机就开启了上面路由器默认开启的路由转发服务（ip_forward）\n配置转发网关路由 经过多次测试，发现一直钻了死胡同，只配中转的路由而不是网关路由所以没有将路由转发出去。抓n10包只有一端有数据，还以为是网卡转发未开启成功。\n错误复盘： 场景二节点 n6 n7配默认路由都是指向自己的网卡，以为只要配n10的路由转发就能正确传输。 即在n10设定右边网卡收到的10.0.0.0/24网段全由左网卡出去，左网卡收到的10.0.2.0/24由右边网卡发出。 这样是无法通过测试的。 对于节点n6，只配默认路由到本地网卡10.0.2.20是无法让主机n10转发该数据的，应该配n6路由为下一跳网关。 n10无需配置路由只要开ip转发即可。 其实仔细想想，本地路由只是针对当前网段局域网内的转发，跨网段会找不到路直接丢弃包的  路由配置方法，统一使用 ip route，route命令当然也可配置，不推荐。\n  在场景2中\n# (网关ip要为下一跳地址) # 配置到网段的静态路由 ip route add 10.0.2.20/24 via 10.0.0.20 # 配置特定到特定主机的网关/路由 ip route add ip 目标主机 via 网关 # 配置默认网关/路由 ip route add default via 10.0.2.21    在场景3中，类比场景2\n分别配置 n2 -\u0026gt; n4 n4 -\u0026gt; n1 n1 -\u0026gt; n4 n11 -\u0026gt;n1 这四条默认网关即可    ","id":10,"section":"posts","summary":"基础太薄弱，最近做一个关于主机路由转发的东西折腾了挺久。做个记录 😕 默认网关、路由 区别 两者其实是一类功能，在不同应用的产生的不同叫法。 内网主机","tags":["Linux","network"],"title":"linux配置主机路由转发","uri":"https://liangkang233.github.io/2021/07/linux%E4%B8%BB%E6%9C%BA%E8%B7%AF%E7%94%B1%E8%BD%AC%E5%8F%91/","year":"2021"},{"content":" 笔记实时更新中。。\n Core、Emane 介绍 官方文档\n一句话概括: CORE侧重于模拟如网络层传输层、会话层和应用层，提供了用户构建虚拟网络的图形用户界面；在一台或多台计符机上进行网络模拟的工具，实时运行的模拟。这些模拟的网络可以实时连接到物理网络和路由器，可以在使用相对廉价的硬件的前提下，保证在模拟网络上运行实时的应用程序的真实性。\nEMANE主要针对物理层和数据链路层工作，为模拟链路层和物理层的无线网络提供了必需的可插拔框架。关于网络层路由协议可以选用适用移动自组网的 OSPF MDR 协议。\nCore Core源码\n通用开放式研究仿真器（Common Open Research Emulator）是一种构建虚拟网络的工具。作为模拟器，CORE 构建了实时运行的真实计算机网络的表示，而不是使用抽象模型的模拟。实时运行的仿真可以连接到物理网络和路由器。它提供了运行真实应用程序和协议的环境，利用了 Linux 操作系统提供的工具。\nCORE 通常用于网络和协议研究、演示、应用程序和平台测试、评估网络场景、安全研究以及增加物理测试网络的规模。\n   主题 描述 总结或翻译     Architecture 体系结构概述，介绍如何使用Python、gRPC直接控制Core 架构   Installation CORE的安装方法及要求 环境搭建   GUI 如何使用GUI 界面教程   Node Types CORE支持的节点类型概述 节点类型   (BETA) Python GUI 如何使用基于BETA Python的GUI    Python API 介绍如何使用Python直接控制Core (自己实现core-daemon) Python API   gRPC API 介绍如何使用gRPC控制Core (连接core-daemon 调用其api) gRPC API   Distributed 在多个服务器上运行CORE的分布式细节 分布式   CTRLNET 如何控制网络从主机与节点通信 控制网络   Services 概述所提供的服务并创建自定义服务 服务配置   Core Emane CORE中运行和使用EMANE的高级主题和示例 Emane   Performance 使用CORE时的性能说明 Core 性能分析   Developers Guide 概述如何对CORE开发做出贡献 Core 开发相关    绑定SDT-3D到core仿真中，源码 SDT 3D安装     Core 常见问题    基础内容学习   TLV编码格式详解\n  了解 gRPC协议\n  什么是GRE隧道\n  OSPF MDR OSPF即开放最短路径优先(Open Shortest Path First)是为有线网络设计的标准路由协议。\n每个自治系统AS（Autonomous System）内部的路由选路协议，位于网络层。\nOSPF MDR即OSPF指定路由器移动自组网协议（OSPF MANET Designated Routers）也是美国海军研究实验室(NRL)开发，其源码在这可以找到。Quagga 中OSPFv3的OSPF MDR是依照移动自组织网络(MANETs: Mobile Ad Hoc Networks)中有效路由的 RFC 5614 (OSPF MDR), RFC 5243 (OSPF Database Exchange Optimization), 和 RFC 5838 (OSPFv3 Address Families)来实现的。\n该软件基于开源的Quagga路由套件，最初由Richard Ogier和波音幻影工程公司开发，现在由NRL的移动路由项目维护。\n  Linux基础网络设备详解：Core的链路实现就是依赖这些虚拟网络设备，利用Linux命名空间特性创建各个独立的虚拟节点。\n  Core 开发相关 源码概述 由于历史原因，CORE源代码由几种不同的编程语言组成。目前的开发重点是Python模块和守护进程。下面是源目录的简要描述。(netns = network nodes)\n   目录 描述     daemon 处理接收API调用和创建容器的Python CORE daemon（守护进程）代码   docs 托管在GitHub上的使用文档   gui Tcl/Tk GUI   man 为各种CORE命令行实用程序创建手册页的模板文件   netns 用于创建CORE容器的C程序    其切换开发版本分支\ngit clone https://github.com/coreemu/core.git cd core git checkout develop  安装开发环境 此命令将自动安装系统依赖项、克隆和构建 OSPF-MDR, 搭建CORE, 设置CORE poetry 环境, 然后安装 pre-commit hooks.您可以参考install docs来了解不同发行版的相关问题。\n./install -d  其中pre-commit帮助自动运行工具检查修改的代码。每次提交时，都会运行python实用程序来检查代码的有效性，可能会失败并退出提交。这些更改目前是作为当前CI的一部分强制执行的，因此添加更改并再次提交。\n运行core 您现在可以像平常一样运行core，或者利用一些调用任务来方便地运行测试等。\n# run core-daemon sudo core-daemon # run python gui core-pygui # run tcl gui core-gui # run mocked 单元测试 cd \u0026lt;CORE_REPO\u0026gt; inv test-mock  容器命令 Linux namespace containers通常使用Linux容器工具或lxc-tools包进行管理。lxc-tools网站可在这里http://lxc.sourceforge.net/获得更多信息。CORE不使用这些管理core实用工具(utilities)，core自己实现了一组用于实例化和配置网络名称空间容器的工具。这些工具大体分为：\n  vnoded (Virtual nodes daemon )\nvnoded daemon是用于创建新名称空间的程序，并在控制通道上侦听可能实例化其他进程的命令。这个守护进程在容器中作为PID 1运行。它由CORE守护进程自动启动。控制通道是UNIX域套接字，通常命名为/tmp/pycore。对于运行在CORE会话23098上的节点3，例如:23098/n3。创建一个新的命名空间需要Root特权。\n  vcmd (Virtual cmd )\nvcmd程序用于连接Linux网络命名空间中的vnoded，用于运行命名空间容器中的命令。CORE守护进程使用相同的通道设置节点并在其中运行进程。这个程序有两个必需的参数，控制通道名和要在命名空间中运行的命令行。该命令不需要以root权限运行。\n当你在运行模拟中双击一个节点时，CORE会使用如下命令打开该节点的shell窗口:\ngnome-terminal -e vcmd -c /tmp/pycore.50160/n1 -- bash  类似地，IPv4路由观察者小部件将运行一个命令来显示路由表，使用如下命令:\nvcmd -c /tmp/pycore.50160/n1 -- /sbin/ip -4 ro    core-cleanup 脚本\n提供了一个名为 core-cleanup 的脚本来清理任何正在运行的CORE仿真。它将试图杀死任何剩余的vnoded进程，杀死任何EMANE进程，删除 :file:/tmp/pycore.* 会话目录。删除任何bridge或ebtables规则。使用*-d*选项，它也将杀死任何正在运行的CORE守护进程。\n  netns 命令\nCORE不直接使用netns命令。此实用程序可用于在新的网络名称空间中运行命令，以进行测试。它不会打开一个控制通道来接收进一步的命令。\n  其他常用命令\n# 查看Linux网桥配置 ip link show type bridge # 查看某网桥被attach设备 brctl show bridge_name # 查看用于应用链接效果的netem规则 tc qdisc show # 查看使无线局域网工作的规则 ebtables -L    Core 性能分析 关于CORE性能的首要问题通常是它能处理多少个节点?答案取决于几个因素:\n   因素 性能影响     硬件 计算机中处理器的数量和速度、可用的处理器缓存、RAM内存和前端总线速度可能会极大地影响整体性能。   系统版本 Linux的发行和所使用的特定内核版本将影响整体性能。   活动进程 所有节点共享相同的CPU资源，因此如果一个或多个节点执行CPU密集型任务，整体性能将受到影响。   网络流量 在虚拟网络中发送的数据包越多，CPU使用率就越高。   GUI使用 定期运行的小部件、移动场景和其他GUI交互通常会消耗模拟所需的CPU周期。    在典型的单cpu 3.0GHz Xeon服务器上，2GB RAM运行Linux，我们发现运行30-75个节点运行OSPFv2和OSPFv3路由是合理的。在这个硬件上，CORE可以实例化100个或更多的节点，但是在这一点上，每个节点在做什么就变得至关重要了。\n因为这个软件主要是一个网络模拟器，所以更合适的问题是它能处理多少网络流量?在上面描述的3.0GHz服务器上，运行Linux，大约每秒可以通过系统推送30万个包。跳数和报文大小不那么重要。限制因素是操作系统需要处理数据包的次数。300,000pps表示系统作为一个整体需要处理一个数据包的次数。随着更多的网络跳数的增加，上下文切换的数量会增加，并且会降低整个网络路径上的吞吐量。\n注意: 问题关键在于是能跑多少流量? 而不是多少节点\n有关CORE性能的更详细研究，请参阅以下出版物:\n J. Ahrenholz, T. Goff, and B. Adamson, Integration of the CORE and EMANE Network Emulators, Proceedings of the IEEE Military Communications Conference 2011, November 2011. Ahrenholz, J., Comparison of CORE Network Emulation Platforms, Proceedings of the IEEE Military Communications Conference 2010, pp. 864-869, November 2010. J. Ahrenholz, C. Danilov, T. Henderson, and J.H. Kim, CORE: A real-time network emulator, Proceedings of IEEE MILCOM Conference, 2008.  节点类型 CORE中可以配置不同的节点类型，每个节点类型都表示节点在运行时将如何表示的机器类型。不同的机器类型允许不同的选择。\nNetns 节点 netns(net nodes) 类型是默认的节点类型， 这是用于由 Linux 网络命名空间支持的节点。这种机器类型很少使用系统资源来模拟网络。这被指定为默认机器类型的另一个原因是，此技术通常不需要更改内核，它可从最新的主流Linux发行版中开箱即用。\n物理 节点 physical 机器类型用于表示真正的基于linux的机器的节点，这些机器将参与模拟的网络场景。该节点通常用于合并来自模拟测试平台的服务器机组。物理节点是运行CORE守护进程(CORE-daemon)的节点，它不会被进一步分区到容器中。在物理节点上运行的服务不是在一个隔离的环境中运行，而是直接在操作系统上运行。\n必须给物理节点分配服务器，与使用分布式仿真（Distributed Emulation）将节点分配仿真服务器的方式相同。可用物理节点列表当前与仿真服务器共享同一个对话框和列表，可以使用Session菜单中的emulation servers…条目进行访问。\n对物理节点的支持正在开发中，并可能在未来的版本中得到改进。目前，当任何节点连接到一个物理节点时，会画一条虚线来表示网络隧道。将在物理节点上创建一个GRE隧道接口，用于隧道通信流进出模拟世界。\n在运行时双击物理节点将打开一个终端，该终端带有指向该节点的SSH shell。用户应该像使用仿真服务器那样配置公钥SSH登录。\nSDT 3D安装 首先安装对应Java环境，推荐java8，根据源码手册下面为Ubuntu的安装教程\nsudo apt-get install openjdk-8-jdk # 添加环境变量 在文件中 $HOME/.bash.profile export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ source $HOME/.bash.profile update-alternatives --display java update-alternatives --display javac update-alternatives --display jar sudo apt-get install libvecmath-java sudo apt-get install libpcap-dev sudo apt-get install libnetfilter-queue-dev cd sdt/makefiles make -f Makefile.linux_\u0026lt;arm64\u0026gt; sdt3d sdtcmd make -f Makefile.linux_\u0026lt;arm64\u0026gt; distclean #卸载包，有问题需要清理时运行 #绑定脚本至core中 sudo make -f Makefile.linux_amd64 install /usr/local/bin/ #修改 /usr/local/bin/sdt3d.sh 内容： THISDIR=/home/$USER/sdt/makefiles/build/sdt3d  Core 常见问题：   core安装、卸载重装等报错问题\n 不能使用sudo 运行install.sh 否则后面装依赖包及生成虚拟环境目录权限为root用户，肯定会报错。\n  似乎 ARM 架构的 ubuntu 无法安装该软件的虚拟环境，真实环境下也是各种不包的依赖环境不对。\n 自动化安装脚本依赖invoke，其执行流程由core源码根目录的task.py脚本定义。其写法是一旦遇到装过pipx等就直接退出安装脚本，所以可以修改其执行语句（添加 \u0026ndash;force）来强制安装已经装过的包。或者简单的做法就是把装的虚拟环境删除即可，删pipx的venv文件夹(~/.local/pipx/venvs/*) 和poetry生成的虚拟环境文件夹(~/.cache/pypoetry/virtualenvs/core-3XChpotV-py3.6)或使用命令\ncd ~/core/daemon poetry env list # 查看安装位置 poetry remove venv1 pipx uninstall poetry pipx uninstall invoke pip3 uninstall pipx    poetry或pip安装满导致的超时错误\npython换源\n/home/lk233/core/daemon/pyproject.toml [[tool.poetry.source]] name = \u0026quot;tsinghua\u0026quot; default = true url = \u0026quot;https://pypi.tuna.tsinghua.edu.cn/simple\u0026quot; # 更新 poetry 锁文件 poetry lock --no-update # 如果是安装本地直接如下 pip config set global.index-url http://pypi.tuna.tsinghua.edu.cn/simple pip config set global.trusted-host pypi.tuna.tsinghua.edu.cn    安装 pyymal 报错\n将pip降级可以解决pip install --upgrade --force-reinstall pip==9.0.3\n  poetry 安装 cffi 报错\nBuilding wheel for cffi (setup.py) error XXX.. Package libffi was not found in the pkg-config search path.  安装缺少的包sudo apt-get install libffi6 libffi-devsudo \n  local 安装 lxml 时报错\n安装缺少的包\nsudo apt-get install libxml2 sudo snap install libxslt      无法使用子节点终端的图形界面：\n# 报错提示 No protocol specified Error: Can't open display: :0  解决：Xserver默认情况下，不允许别的用户的图形程序的图形显示在当前屏幕上。在图形正常的用户终端中输入 xhost +\nxhost + # access control enabled, only authorized clients can connect xhost - # access control disabled, only authorized clients can connect    Xterm下的Tcpdump 抓包不刷新问题：\n使用 -l 选项，设置stdout行缓冲， 这样也可以有效搭配如下命令\ntcpdump -l | tee dat tcpdump -l \u0026gt; dat \u0026amp; tail -f dat\t#终止时tcpdump未终止 记得kill pid    iperf3等流量测试工具在走分布式场景时会发生数据无法传输问题：\n由于分布式之间的数据通过隧道链接，而建立的隧道默认MTU为1458字节。所以当分布式服务器的路由包的MTU过大时，不会转发数据。\n以iperf3为例，设定传输流量包mss为1024就能解决无法传输跨分布式服务器的包的数据\niperf -c 192.168.131.161 -M 1024 #注意，这里的-M设定的是MSS为TCP、STCP传输层概念，MTU为传输层传递的最大IP包    容器隔离问题\n注意虽然容器节点与外部物理机系统隔离有独立的网络、进程堆栈，但是部分文件系统是与外界共享的。例如家目录都是设置为外界用户的家目录，其他系统文件例如配置路由的转发的文件/proc/sys/net/ipv4/ip_forward却又是独立的（在终端使用sysctl不影响外面运行仿真的系统）\n  emanesh脚本无导入库问题\n由于是安装在虚拟环境的python，所以执行得用core-python执行。有些脚本例如emanesh还是使用外部物理环境的python执行，将第一行的 执行文件修改成对应core-python路径。或者执行时加上core-python即可。\n#!/usr/bin/python3 =\u0026gt; 修改为类似的下面的执行路径 #!/home/user/.cache/pypoetry/virtualenvs/core-3XChpotV-py3.6/bin/python    core后台运行batch问题\n有一条issue提到了该问题： 程序自带的batch选项后续没有维护，运行带有移动拓扑及emane无线模型直接报错或是不加载。解决该问题需要使用前台gui启动或者带有虚拟帧缓冲区的启动，使用Xvfb可以正常运行，Xvfb 在虚拟内存中执行所有图形操作，而不显示任何屏幕输出，运行时部分ui报错可忽略。\n使用方法：xvfb-run core-gui -s ~/.core/configs/sample1.imn，提示没有这个包就apt-get安装即可。\n如果是生成一个场景并后台执行，个人推荐使用 gRPC API Python API 直接构建场景实例化运行，并且也能调用savexml保存。\n  分布式场景初始化问题\n​\t由于 boot_nodes 和 boot service 默认是调用线程池大小为10的非堵塞任务，所以瞬时业务的并发量特别大造成ssh通道饱和连接失败。具体问题示例如此处[SSH BUG] · Issue #622 · coreemu/core (github.com)。需要修改coreservices.py下的 boot_services 和 session.py下的 boot_nodes 的调用线程数量。当然也可以重构分布式通信部分，将多个连接命令合并之后解析ssh。\n  ","id":11,"section":"posts","summary":"笔记实时更新中。。 Core、Emane 介绍 官方文档 一句话概括: CORE侧重于模拟如网络层传输层、会话层和应用层，提供了用户构建虚拟网络的图形","tags":["仿真"],"title":"Core 学习笔记","uri":"https://liangkang233.github.io/2021/07/core%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","year":"2021"},{"content":"CORE/EMANE 无线仿真基本内容学习：   衰落模型\n emane只能使用事件或nakagami模型\n core设定的默认值是有问题的，m值越大信道越理想\n  路径损耗\n emane可设定为2-RAY、freespace\n 注意：针对大尺度场景下的路径损耗需要使用freespace，例如高度变化差异大的场景，否则效果不明显。\n当propagationmodel设置为precomputed 预定义模型，其路径损耗通过pathloss事件触发。\n上述概念切勿混淆，其本质为信道衰落反映的是接收机观察到的信道强弱变化。\n它通常是大尺度衰落（路径损耗、阴影）和小尺度衰落（多径效应）的综合。\n  emane无线干扰\n根据下面的式子无线物理层处理是否接受该数据包（rxPower \u0026gt; rxSensitivity 即接收）\nrxPower = txPower + txAntennaGain + rxAntennaGain − pathloss` rxSensitivity = −174 + noiseFigure + 10log(bandWidth)  对于frequencyofinterest监视的频率接收到后，根据设定不同的subid然后区分为带内外信号。\n节点设定noisemod会设定物理层能够根据噪声模式配置参数记录所有信号能量、带外信号能量或无信号能量(即该节点是否接受带内外信号影响造成干扰)。当在给定的请求间隔内没有记录信号能量或没有发生信号能量时，接收机灵敏度被用作底噪。802.11abg 具体例子\n最后计算信噪比SINR在mac层对应具体模型（例如rfpipe模型）再得到丢包率，采集有效包向core传输。\n  emane相关注意点：  场景配置中的云并不是类似有线场景的路由器，仅仅是配置链接上的节点的ip、无线模型、等phy mac的默认配置。关于节点是否可通信除了上面信号强度要达到rxSensitivity外，还要监听频率符合。所以发射频率和接收频率（phy层的frequency和frequencyofinterest）不同会组成上行下行信道，这样就不产生带内干扰。  Emane 介绍 EMANE 源码\nEmane 架构\nEMANE 教程测试\n可扩展移动自组织网络仿真器 (The Extendable Mobile Ad-hoc Network Emulator) 允许使用可插拔 MAC 和 PHY 层架构进行异构网络仿真。EMANE是由美国海军研究实验室(NRL)代号5522和 Adjacent Link 有限责任公司开发的。EMANE 框架提供了一种实现架构，用于以网络仿真模块 (NEM: Network Emulation Modules) 的形式对不同的无线电接口类型进行建模，并将这些模块合并到在分布式环境中运行的实时仿真中。\n http://www.adjacentlink.com/  可以使用 EMANE 绑定到虚拟设备的 EMANE 来模拟高保真无线网络，而不是使用 CORE 构建 Linux 以太网网桥。CORE 仿效第 3 层及以上（网络、会话、应用程序）及其虚拟网络堆栈和处理空间，用于协议和应用程序，而 EMANE 则使用其可插入的 PHY 和 MAC 模型模拟物理层和数据链路层。它为无线网络实验人员提供了一个高度灵活的模块化环境，用于设计、开发和测试简单和复杂的网络架构。EMANE采用物理层模型来考虑信号传播、天线轮廓效应和干扰源，以便为无线实验提供一个真实的环境。单个无线电模型插件用于模拟波形的最低层，并可以与现有的软件定义无线电(SDR)相结合。\nCore和 EMANE 之间的接口是 TAP 设备。CORE 使用 Linux 网络名称空间构建虚拟节点，将 TAP 设备安装到名称空间中，并在名称空间中即时化一个 EMANE 过程。EMANE 过程将用户空间Socket与 TAP 设备绑定，以便从 CORE 发送和接收数据。\nEMANE 实例通过控制端口（例如ctrl0 ，ctrl1）发送和接收 OTA（空中）流量来往于其他 EMANE 实例。它还使用相同或不同的控制端口发送和接收事件来回事件服务。通过 CORE 的WLAN配置对话配置 EMANE 模型。每个支持的 EMANE 模型都有相相应的Emane Python 子类，以提供配置项目及其对 XML 文件的映射。这样，新配置就可以很容易地得到支持。当 CORE 开始模拟时，它会生成指定 EMANE NEM 配置的相应 XML 文件，并启动 EMANE daemon\n某些 EMANE 模型支持位置信息，以确定何时应丢弃数据包。EMANE 具有一个事件系统，其中位置事件广播给所有 NEM。当节点在画布上移动时，CORE 可以生成这些位置事件。画布大小和比例对话具有将 X，Y 坐标系统映射到 EMANE 使用的纬度、经度地理系统的控件。还可以在core.conf配置文件设定CORE订阅 EMANE 位置事件，这样core gui画布上的节点与EMANE 仿真中时节点的会同步移动。例如，当模拟脚本生成器运行移动脚本时，就会发生这种情况。\n 下面的每个主题都假设已经安装了CORE、EMANE和OSPF MDR。演示文件将在 core-pygui 中找到\n   主题 模型 描述 总结     XML Files RF Pipe 概述生成的用于驱动EMANE的XML文件 XML Files   GPSD RF Pipe 概述gpsd与EMANE的运行和集成 gpsd   Precomputed RF Pipe 概述如何使用预计算传播模型 预计算传播模型   EEL RF Pipe 概述如何使用仿真事件日志(EEL)生成器 EEL生成器   Antenna Profiles RF Pipe 概述如何在EMANE中使用天线配置文件 天线配置     EMANE Configuration CORE 配置文件 /etc/core/core.conf 包含EMANE特有选项，如下所示：\n# EMANE 配置 emane_platform_port = 8101 emane_transform_port = 8201 emane_event_monitor = False # emane_models_dir = /home/username/.core/myemane # EMANE log 范围[0,4] 默认: 2 emane_log_level = 2 emane_realtime = True # emane安装地址前缀 # emane_prefix = /usr  如果你有一个EMANE事件生成器(例如移动或路径损耗脚本)，并且想让CORE订阅EMANE位置事件，在 CORE.conf 配置文件中设置以下行。\n 我这边测试可以不改此项，例如ns-2移动脚本gui与后端gps数据的同步，但是发送的emane事件无法触发gui的变化。\n # 如果要手动拖动画布上的节点来更新它们在EMANE中的位置，设置为 False emane_event_monitor = True   经过测试发现，此项设置为false，daemon打印log依旧显示core监听了emane event。 如果改了后会发生下面的报错，暂时未解决此问题，决定emane_event_monitor保持默认的false\n ERROR - emanemanager:starteventmonitor - Warning: EMANE events will not be generated because the emaneeventservice binding was unable to load (install the python-emaneeventservice bindings)  另一个常见的问题是，如果从源代码安装EMANE，默认配置前缀将把DTD文件放在 /usr/local/share/emane/dtd\n而core.com希望他们在 /usr/share/emane/dtd\n更新EMANE前缀配置可以解决此问题。\nemane_prefix = /usr/local  自定义EMANE模型 CORE通过动态加载用户创建的表示模型的python文件来支持自定义开发的EMANE模型。\n自定义的EMANE模型应该放在CORE配置文件中 emane_models_dir 所定义的路径中。这个路径不能以 /emane 结尾。\n下面是一个用文档描述功能的示例模型:\n\u0026quot;\u0026quot;\u0026quot; Example custom emane model. \u0026quot;\u0026quot;\u0026quot; from typing import Dict, List, Optional, Set from core.config import Configuration from core.emane import emanemanifest, emanemodel class ExampleModel(emanemodel.EmaneModel): \u0026quot;\u0026quot;\u0026quot; 自定义 emane 模型. :cvar name: 定义将在GUI中显示的emane模型名称 Mac Definition: :cvar mac_library: 定义模型将引用的MAC库 :cvar mac_xml: 定义MAC清单文件，它将被解析以获得配置选项，这将在GUI中显示 :cvar mac_defaults: 允许您重写上面清单文件中维护的选项 :cvar mac_config: 解析清单文件并将配置转换为core支持的格式 Phy Definition: 注意: Phy配置将默认为通用模型如下所示，下面的部分非必须包括在内 :cvar phy_library: 定义模型将引用的phy库，在需要提供自定义phy时使用 :cvar phy_xml: 定义phy清单文件，该文件将被解析以获得配置选项，将在GUI中显示 :cvar phy_defaults: 允许您重写上面清单文件中维护的选项或默认通用模型的选项 :cvar phy_config: 解析清单文件并将配置转换为Core心支持的格式 Custom Override Options: 注意: 这些选项默认为下面所见的内容，不需要包括在内 :cvar config_ignore: 允许您忽略phy/mac中的选项，通常在您需要添加一个自定义选项以在GUI中显示时使用 \u0026quot;\u0026quot;\u0026quot; name: str = \u0026quot;emane_example\u0026quot; mac_library: str = \u0026quot;rfpipemaclayer\u0026quot; mac_xml: str = \u0026quot;/usr/share/emane/manifest/rfpipemaclayer.xml\u0026quot; mac_defaults: Dict[str, str] = { \u0026quot;pcrcurveuri\u0026quot;: \u0026quot;/usr/share/emane/xml/models/mac/rfpipe/rfpipepcr.xml\u0026quot; } mac_config: List[Configuration] = emanemanifest.parse(mac_xml, mac_defaults) phy_library: Optional[str] = None phy_xml: str = \u0026quot;/usr/share/emane/manifest/emanephy.xml\u0026quot; phy_defaults: Dict[str, str] = { \u0026quot;subid\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;propagationmodel\u0026quot;: \u0026quot;2ray\u0026quot;, \u0026quot;noisemode\u0026quot;: \u0026quot;none\u0026quot; } phy_config: List[Configuration] = emanemanifest.parse(phy_xml, phy_defaults) config_ignore: Set[str] = set()  单主机EMANE 本节描述在单个机器上运行CORE和EMANE。这是使用CORE构建EMANE网络时的默认操作模式。\nOTA管理器和Event服务接口被设置为使用ctrl0，虚拟节点使用主控制通道进行相互通信。\n当涉及到EMANE的场景时，主控制通道会自动激活。使用主控制通道可以防止模拟会话在本地\n网络上发送多播流量，并干扰其他EMANE用户。\nEMANE是通过一个WLAN节点配置的，因为它完全是关于模拟无线无线电网络的。\n一旦节点连接到使用EMANE模型配置的WLAN云，该节点上的无线电接口也可以单独配置(除了云之外)。\n双击WLAN节点以调用WLAN配置对话框。单击EMANE选项卡;正确安装EMANE后，EMANE无线模块应列在\nEMANE型号列表中。(如果在安装EMANE Python绑定之前运行CORE守护进程，则可能需要重新启动它)\n单击一个模型名称来启用它。\n当在 EMANE Models 列表中选择一个EMANE模型时，单击 model options 按钮导致GUI查询\nCORE daemon 以获取配置项。每个模型都会有不同的参数，请参考每个项目的解释的EMANE文档。\n默认值显示在对话框中。单击 Apply 将存储EMANE模型选择。\nEMANE options 按钮允许指定一些Emane 全局参数，其中一些是分布式操作所必需的。\nRF-PIPE 和 IEEE 802.11abg 模型使用支持地理位置信息的通用PHY来确定节点之间的路径损耗。\n一个默认的经纬度位置由CORE提供，这个基于位置的路径损耗默认启用;这是通用PHY的路径损耗模式设置。\n在模拟运行时移动画布上的节点将为EMANE生成位置事件。\n要查看或更改画布的地理位置或比例，请使用画布菜单中的“画布大小和比例”对话框。\n注意，地理坐标系和笛卡尔坐标系之间的转换是使用通用墨卡托投影(UTM: Universal Transverse Mercator)完成的，\n其中定义了6层不同的经度带区域。对于跨越多个UTM区域的非常大的场景，CORE生成的位置事件在区域边界附近可能变得不准确。\n在这种情况下，建议使用EMANE位置脚本来实现地理位置的准确性。\n单击绿色的 Start 按钮将启动模拟，并导致在连接到EMANE WLAN的虚拟节点中创建TAP设备。\n这些设备显示为接口名称，如eth0、eth1等。EMANE进程现在应该在每个名称空间中运行。如下为四个节点的场景:\nps -aef | grep emane root 1063 969 0 11:46 ? 00:00:00 emane -d --logl 3 -r -f /tmp/pycore.59992/emane4.log /tmp/pycore.59992/platform4.xml root 1117 959 0 11:46 ? 00:00:00 emane -d --logl 3 -r -f /tmp/pycore.59992/emane2.log /tmp/pycore.59992/platform2.xml root 1179 942 0 11:46 ? 00:00:00 emane -d --logl 3 -r -f /tmp/pycore.59992/emane1.log /tmp/pycore.59992/platform1.xml root 1239 979 0 11:46 ? 00:00:00 emane -d --logl 3 -r -f /tmp/pycore.59992/emane5.log /tmp/pycore.59992/platform5.xml  上面的示例显示了CORE启动的EMANE进程。要查看CORE生成的配置，请查看/tmp/pycore。\n这是一个用于存放 platform.xml 文件和其他 XML文件的 session目录。\n查看这些信息的一种简单方法是双击其中一个虚拟节点，然后键入cd ..在shell中转到会话目录。\n分布式 EMANE 在两个或多个模拟服务器中运行CORE和EMANE与在单个机器上运行类似。 为了仿真能够运行，需要设置一些关键的配置项，这里概述了这些配置项。\n维护 数据(OTA流量)和控制流量为独立的网络是一个好主意。例如，控制网络可能是一个共享的实验室网络， core不希望数据网络上的多播通信干扰其他EMANE用户。此外，控制流量可能会干扰OTA延迟和吞吐量， 并可能影响仿真的保真度。这里描述的示例将使用eth0作为控制接口，使用eth1作为数据接口， 尽管并不严格要求使用单独的接口。注意，这些接口名称指的是物理主机上的接口，而不是节点内的虚拟接口。\n重要事项:如果使用了辅助控制网络，则需要将主机上的一个接口分配给该网络\n作为模拟服务器的每台机器都需要安装CORE和EMANE。\n可用服务器的IP地址从核心仿真服务器对话框中配置(选择 Session 然后 Emulation servers\u0026hellip; )。 这个服务器列表存储在*~/.core/servers.conf*文件中。对话框显示了可用的服务器， 其中的一部分或全部可以分配给画布上的节点。\n需要将节点分配给仿真服务器。选择几个节点，右键单击它们，选择Assign to和所需服务器的名称。 当未将节点分配给任何仿真服务器时，将在本地对其进行仿真。GUI连接的本地机器被认为是“主”机器， 而主机器又连接到其他模拟服务器的“从属”。应该配置从主服务器到从服务器的公钥SSH登录 具体请看分布式\n 注意 下面是使用EMANE进行分布式模拟的快速检查表。\n  遵循常规CORE的步骤。 在EMANE WLAN的 EMANE 标签下，单击 EMANE options 。 打开 OTA Manager channel ，设置 OTA Manager device 。同时设置 Event Service device 。 选择节点组，右键单击它们，并使用 assign to 菜单将它们分配给主或从服务器。 在开始模拟之前，使用 ntp 或 ptp 同步机器的时钟。一些EMANE模型对时间很敏感。 按 Start 按钮启动分布式仿真。  现在，当使用Start按钮实例化模拟时，本地CORE Python守护进程将连接到已分配给节点的其他模拟服务器。 每个服务器都有自己的会话目录，其中生成platform.xml文件和其他EMANE XML文件。NEM id在服务器之间自动协调， 因此没有重叠。每个服务器还获得自己的平台ID。\n以太网设备用于传播组播EMANE事件，如 configure EMANE 对话框中所指定的。EMANE的事件服务可以通过移动性 或路径损耗脚本运行，如单主机Emane所述。 如果CORE没有订阅位置事件，它将在画布上移动节点时生成这些事件。\n在运行时双击节点将导致GUI尝试SSH到该节点的仿真服务器，并运行交互式shell。在启动模拟之前， 应该使用所有模拟服务器对公钥SSH配置进行测试。\nEmane架构 Emane架构主要由三部分组成：\nEmulation Processing(仿真服务过程) Emulation Processing 由 物理层模型 实例与一个或多个 无线电（波形）模型 实例配对。仿真器处理XML 配置文件以确定要实例化的无线电模型插件类型、应如何配置模型和物理层实例以及应用什么通用业务设置。\nEMANE 分布包括三种无线电模型：\n RF Pipe Model IE 802.11abg Model TDMA Model  和一个实用新型：\n Comm Effect Model  当模拟器即时化模型插件时，它将每个插件放置在 网络模拟模块（NEM） 以及模拟器物理层的专用实例中。物理层实例使用 Over-The-Air （OTA）多广播通道相互连接。所有 OTA 消息均由每个模拟器实例使用相同的 OTA 多广播通道进行处理。这就是模拟器物理层如何负责异构无线电模型的信号传播、天线效应和干扰源。\n每个无线电模型的运行方式不同，但一般的想法是，模型从应用空间接收消息，进行空中传输，并将消息发送到其物理层实例，以便通过 OTA 多播通道传输（可能在无线电模型执行通道访问功能之后）。使用同一 OTA 多播通道的所有模拟器实例都会接收消息并执行接收功率测试。根据消息接收功率的物理层实例是否大于接收器灵敏度，可将消息归类为噪声或有效的带内波形信号。有效的波形信号被发送到接收无线电模型进行额外的处理。大多数无线电模型使用基于消息 Signal to Noise and Interference Ratio（SINR） 的 Bit Error Rate （BER） 曲线，作为决定是否将消息传递到相应的应用空间过程的决定的一部分。\n术语 application space process (应用空间过程)不应与内核和应用/用户空间的概念混淆。所有 EMANE 进程都在用户空间中运行。我们使用术语应用程序空间（通常作为 application/emulation boundary 主题的一部分）表示任何进程，该过程不是作为模拟器中的插件运行，而是以某种方式连接到（使用）模拟器。\n我们使用 下游 术语来表示所有指向 OTA 多播通道的消息，以及所有向应用空间过程交付的消息的 上游 术语。这并不意味着 OTA 多播通道或应用空间过程必须是最终消息目的地。当无线电模型向其相应的物理层实例发送控制消息时，我们称之为下游控制消息，当物理层实例向无线电模型发送数据包消息时，我们称之为 上游数据包消息 。一旦你开始分析无线电模型性能统计，你会理解其中的区别。\nApplication/Emulation Transport Boundary Processing (传输边界过程) 应用/模拟传输边界是负责在模拟器实例和一个或多个应用空间过程之间传递消息的仿真组件。我们称这个组件为 运输 工具。为模拟器和应用空间消息提供出入口点。\n运输插件可以作为模拟器过程的一部分在内部即时化，也可以作为其他应用的一部分在外部即时化。Transport DaemonEMANE 应用程序处理配置 XML，以确定要即时的外部传输插件类型、应如何配置插件以及应用什么一般应用级别设置。\nEMANE 包含两种传输数据的方式：\n Raw Transport Virtual Transport  EMANE 支持 IP 和非 IP 无线仿真，因此个人传输支持的应用空间消息类型差异很大。但是，一旦传输有消息要传递，它们通常都必须做同样的事情。在下游方向，传输必须确定下一跳消息的 NEM ID（这可能是 NEM 广播地址），并将消息与源和目的地 NEM ID 一起发送到已连接的 NEM。在上游方向，传输必须确定应用空间过程才能接收并发送消息。\n当应用程序空间消息通过Transport传输时，它们将失去其形式，并作为指定大小的不透明有效负载通过仿真器发送。Transport是模拟器中唯一可以读写应用程序空间消息细节的组件。\n例如，Virtual Transport使用TUN/TAP接口创建 虚拟接口 （vif） 作为应用程序/模拟边界入口/出口点。在下游方向上，由内核路由到 vif 的以太网框架被打包成消息并发送到适当的 NEM 进行处理。在上游方向，NEM 消息被拆包并作为以太网帧写入到 TUN/TAP 界面。\n应用/模拟边界不限于由仿真器内部加载的插件或由运输守护进程从外部加载的插件。当将 软件定义无线电（SDR）波形连接到 EMANE 时，应开发自定义传输并嵌入*Modem Hardware Abstraction Layer *（MHAL） 的 SDR 中。EMANE 提供应用级别的 API，使开发自定义传输非常容易。\nEvent Processing (仿真事件过程) 为了有趣，运行模拟需要一个场景。场景是发送到一个或多个 NEM 以更改环境特征的一组事件。事件不透明地传递给注册的无线电模型实例，因此单个无线电模型可能需要自己的专业活动。只要有可能，我们主张重复使用 EMANE 标准事件，而不是创建做同样的事情的新事件。\nEMANE 分布包括以下事件：\n Antenna Profile Event Comm Effect Event Location Event Pathloss Event TDMA Schedule Event Fading Selection Event  事件由事件生成器创建。Event ServiceEMANE 应用程序处理XML配置文件以确定要即时处理的事件生成器插件的类型、应如何配置插件以及应用什么业务。\nEMANE 分布包含一个事件生成器，将创建所有标准事件：\n EEL Generator  并提供python modules，让您创建自己的事件生成器应用程序：\n emane.events.EventService emane.events.AntennaProfileEvent emane.events.CommEffectEvent emane.events.LocationEvent emane.events.PathlossEvent emane.events.TDMAScheduleEvent emane.events.FadingSelectionEvent  Emane教程及测试  EMANE 教程 测试实例 Emane shell用法  本教程中的每个演示都旨在突出显示模拟器的特定功能。本教程提供了一个使用LXC Containers 创建一组测试节点的简单测试流，这些测试节点运行模拟器实例以及MANET(移动自组网)世界中通常使用的应用程序和服务。\n其中关于环境和测试用例的配置方法为了方便省事，直接用官方给的虚拟机来做测试。\n教程虚拟机 (Tutorial VM) 是一个CentOS 7 VirtualBox镜像，带有EMANE 1.2.1。教程演示的保真度将根据主机系统配置的不同而变化。\n 用户名：emane 密码: emanedemo 虚拟机sha1sum: 9fb689eff14b43f700935e8514abb62aebc13761  # 首先进行编译安装 cd ~/emane-tutorial make  教程中有9个demo测试：\n   Demo 容器数 模型 传输 描述     0 2 Bypass Virtual 介绍仿真器子系统和应用程序   1 10 RF Pipe Virtual 介绍事件生成、EMANE Shell和一般物理层的概念   2 7 RF Pipe Virtual 介绍射频管无线电模型(RF Pipe radio)   3 10 IEEE 802.11abg Virtual 介绍IEEE 802.11abg无线模型   5 4 IEEE 802.11abg, RF Pipe Virtual 了解仿真器频谱监测和噪声处理   6 4 RF Pipe Virtual 如何使用物理层天线配置文件   7 10 Comm Effect Raw 介绍了Comm Effect实用模型和黑盒测试   8 10 TDMA Virtual 介绍TDMA事件调度器无线电模型      注意：\n此教程仅仅展示Emane工作流程无需专门学习其配置流程，在core中配置节点Emane等操作有专门的控制流程。并且Emane的实现并不一定需要LXC容器，但是这里展示和core的节点实现是采用lxc容器做的。\n   注意：之后的几章节测试使用corepygui打开图片路径不会报错，这几个emane测试场景路径为 ~/.coregui/xmls 注意：emane 的几个python程序默认用的是主机python，安装在虚拟环境的core需要将python运行路径替换为core-python，或者使用core-python运行。其使用说明在emane介绍中可以看到。\n XML Files 在配置好emane的场景或直接运行 emane-demo-files.xml 后，在会话的临时目录(例如/tmp/pycore.44151/n8.conf) 中就会生成对应emane配置的xml文件。就像 emane-demo 中配置的xml文件那样。（emane demo0）\n用于节点运行EMANE的根配置文件是 platform.xml 文件。其作用为：\n 列出为Emane设定的所有总配置值 为节点创建的每个接口给定的唯一的 nem id 用于定义使用的 nem.xml 路径  nem.xml文件定义将包含对给定nem所使用的 transport mac phy xml文件的的定义及引用。\n   文件名 描述     -platform.xml emane仿真实例化的配置文件   -nem.xml 创造NEM的配置文件 (NEM: Network Emulation Modules)   -mac.xml 用于定义NEMs MAC层的配置   -phy.xml 用于定义NEMs PHY层的配置   -trans-virtual.xml 使用 virtual 传输时的配置   -trans.xml 使用 raw 传输时的配置    Gpsd GPSD是一个计算机软件程序，从全球定位系统（GPS）接收器收集数据，并通过互联网协议（IP）网络向服务器-客户端应用程序架构中潜在的多个客户端应用程序提供数据。Gpsd 可以作为一个daemon运行，以透明的方式运行为服务器的后台任务。网络界面为多个并发客户端应用程序（如Kismet或 GPS导航软件）提供了标准化的数据格式。Emane的位置数据就是如此获取的（EMANE仿真中运行gpsd位置代理，该代理将把位置输出到伪终端文件gps.pty。gpsd服务器可以读入该文件，使gpsd客户机可以使用EMANE位置事件。）\n物理机上安装gpsd软件：\nsudo apt-get install gpsd sudo apt-get install gpsd-clients  gpsd客户端及daemon的官方介绍\n运行示例 emane-demo-gpsd.xml（emane demo0）\nEMANE GPSD Event Daemon 具体流程:\n 首先在会话目录对应的n1节点文件夹下创建emane 的事件守护进程配置文件 eventdaemon.xml。  \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventdaemon SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventdaemon.dtd\u0026quot;\u0026gt; \u0026lt;eventdaemon nemid=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;param name=\u0026quot;eventservicegroup\u0026quot; value=\u0026quot;224.1.2.8:45703\u0026quot;/\u0026gt; \u0026lt;param name=\u0026quot;eventservicedevice\u0026quot; value=\u0026quot;ctrl0\u0026quot;/\u0026gt; \u0026lt;agent definition=\u0026quot;gpsdlocationagent.xml\u0026quot;/\u0026gt; \u0026lt;/eventdaemon\u0026gt;  上面的配置会生成如下的 gpsdlocationagent.xml 文件。  \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventagent SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventagent.dtd\u0026quot;\u0026gt; \u0026lt;eventagent library=\u0026quot;gpsdlocationagent\u0026quot;\u0026gt; \u0026lt;param name=\u0026quot;pseudoterminalfile\u0026quot; value=\u0026quot;gps.pty\u0026quot;/\u0026gt; \u0026lt;/eventagent\u0026gt;  启动EMANE事件代理。这将有助于将位置事件输出到上面定义的伪终端文件。  emaneeventd eventdaemon.xml -r -d -l 3 -f emaneeventd.log  启动gpsd，读取伪终端文件。  gpsd -G -n -b $(cat gps.pty)  EMANE EEL Event Daemon 具体流程:\nEEL 事件将通过指定的控制网络接口从实际主机运行。在主机上的同一目录中创建以下文件，在主机终端打开对应文件夹\n 注意：确保以下 eventservicedevice 与主机上用于 EMANE 的控制网络设备匹配\n  创建 eventservice.xml 文件  \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventservice SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventservice.dtd\u0026quot;\u0026gt; \u0026lt;eventservice\u0026gt; \u0026lt;param name=\u0026quot;eventservicegroup\u0026quot; value=\u0026quot;224.1.2.8:45703\u0026quot;/\u0026gt; \u0026lt;param name=\u0026quot;eventservicedevice\u0026quot; value=\u0026quot;b.9001.1\u0026quot;/\u0026gt; \u0026lt;generator definition=\u0026quot;eelgenerator.xml\u0026quot;/\u0026gt; \u0026lt;/eventservice\u0026gt;  创建 eelgenerator.xml 文件  \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventgenerator SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventgenerator.dtd\u0026quot;\u0026gt; \u0026lt;eventgenerator library=\u0026quot;eelgenerator\u0026quot;\u0026gt; \u0026lt;param name=\u0026quot;inputfile\u0026quot; value=\u0026quot;scenario.eel\u0026quot; /\u0026gt; \u0026lt;paramlist name=\u0026quot;loader\u0026quot;\u0026gt; \u0026lt;item value=\u0026quot;commeffect:eelloadercommeffect:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;location,velocity,orientation:eelloaderlocation:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;pathloss:eelloaderpathloss:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;antennaprofile:eelloaderantennaprofile:delta\u0026quot;/\u0026gt; \u0026lt;/paramlist\u0026gt; \u0026lt;/eventgenerator\u0026gt;  创建 scenario.eel 文件  0.0 nem:1 location gps 40.031075,-74.523518,3.000000 0.0 nem:2 location gps 40.031165,-74.523412,3.000000  启动 EEL 事件服务，它将通过控制网络将上述文件中定义的事件发送到所有 EMANE 节点。这些位置事件将被接收并提供给 gpsd。这允许 gpsd 客户端连接并获取 gps 位置。  emaneeventservice eventservice.xml -l 3  传播模型 物理层模型中的路径损耗基于位置或路径损耗事件。当传播模型配置参数设置为2ray或freespace时，路径损耗是基于位置事件动态计算的，这将分别在2-ray flat earth或freespace传播模型之间进行选择。也可以使用外部传播的路径损耗事件计算实时的路径损耗，需要将propagationmodel参数设置为预先计算模型precomputed,以处理接收的路径损耗pathloss事件。\n介绍预先计算模型（EMANE Demo 1），运行 emane-demo-precomputed.xml 场景，（相对于上面的场景即改变rf-pipe选项-\u0026gt;PHY Parameters-\u0026gt;propagationmodel-\u0026gt;precomputed）\n打开n1中终端,由于使用了预计算的路径损耗事件，并且还没有发送任何路径损耗事件，节点之间还不能ping通。\n您可以利用 EMANE Shell 来调查数据包被丢弃的原因。\nroot@n1:/tmp/pycore.46777/n1.conf# emanesh localhost get table nems phy BroadcastPacketDropTable0 UnicastPacketDropTable0 nem 1 phy BroadcastPacketDropTable0 | NEM | Out-of-Band | Rx Sensitivity | Propagation Model | Gain Location | Gain Horizon | Gain Profile | Not FOI | Spectrum Clamp | Fade Location | Fade Algorithm | Fade Select | | 2 | 0 | 0 | 169 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | nem 1 phy UnicastPacketDropTable0 | NEM | Out-of-Band | Rx Sensitivity | Propagation Model | Gain Location | Gain Horizon | Gain Profile | Not FOI | Spectrum Clamp | Fade Location | Fade Algorithm | Fade Select |  在上面的例子中，我们可以看到数据包被丢弃的原因是由于传播模型，这是因为我们没有发出任何路径损耗事件。您可以运行另一个命令来验证您是否收到了任何路径损耗事件。\nroot@n1:/tmp/pycore.46777/n1.conf# emanesh localhost get table nems phy PathlossEventInfoTable nem 1 phy PathlossEventInfoTable | NEM | Forward Pathloss | Reverse Pathloss |  Pathloss Events 在主机上，我们将从所有nem向所有其他nem发送路径损耗事件。\n 注意:确保正确指定控制网络设备\n emaneevent-pathloss 1:2 90 -i \u0026lt;controlnet device\u0026gt;  现在，如果我们检查n2上的路径损耗事件，我们将看到刚才发送的内容。\nroot@n1:/tmp/pycore.46777/n1.conf# emanesh localhost get table nems phy PathlossEventInfoTable nem 1 phy PathlossEventInfoTable | NEM | Forward Pathloss | Reverse Pathloss | | 2 | 90.0 | 90.0  这之后就可以 ping 通n1 n2。（需要两边都添加默认网关路由 ip link default add 10.0.0.2[1]）\n其实直接看gui上有无绿线就知是否联通，有绿线ping不通大概率是路由问题。\nEEL生成器（Emulation Event Log） 介绍如何使用EMANE事件服务和eel文件提供事件。先加载场景 emane-demo-eel.xml（EMANE Demo 1）\n在n1上，我们将使用 EMANE event dump utility 监听事件。\nroot@n1:/tmp/pycore.46777/n1.conf# emaneevent-dump -i ctrl0  发送事件 使用以下内容创建eventservice.xml。（在外部主机创建运行）\n 此法需要core开启监听emane事件。 测试发现发送改变节点gps位置事件，节点GPS的确改变，但是对应UI未改变。\n \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventservice SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventservice.dtd\u0026quot;\u0026gt; \u0026lt;eventservice\u0026gt; \u0026lt;param name=\u0026quot;eventservicegroup\u0026quot; value=\u0026quot;224.1.2.8:45703\u0026quot;/\u0026gt; \u0026lt;param name=\u0026quot;eventservicedevice\u0026quot; value=\u0026quot;b.9001.f\u0026quot;/\u0026gt; \u0026lt;generator definition=\u0026quot;eelgenerator.xml\u0026quot;/\u0026gt; \u0026lt;/eventservice\u0026gt;  接下来，我们将创建eelgenerator.xml文件。\nEEL Generator实际上是一个sentence加载并解析的插件。 解析插件知道如何将某些指令(commeffect、location、velocity、orientation、pathloss和antennaprofile )转换成相应的emane事件。\n commeffect : eelloadercommeffect : delta location, velocity, orientation : eelloaderlocation:delta pathloss : eelloaderpathloss : delta antennaprofile : eelloaderantennaprofile : delta  这些配置项告诉EEL Generator 哪些 sentences 要映射到哪个插件，以及是发布增量更新还是完整更新。\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE eventgenerator SYSTEM \u0026quot;file:///usr/share/emane/dtd/eventgenerator.dtd\u0026quot;\u0026gt; \u0026lt;eventgenerator library=\u0026quot;eelgenerator\u0026quot;\u0026gt; \u0026lt;param name=\u0026quot;inputfile\u0026quot; value=\u0026quot;scenario.eel\u0026quot; /\u0026gt; \u0026lt;paramlist name=\u0026quot;loader\u0026quot;\u0026gt; \u0026lt;item value=\u0026quot;commeffect:eelloadercommeffect:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;location,velocity,orientation:eelloaderlocation:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;pathloss:eelloaderpathloss:delta\u0026quot;/\u0026gt; \u0026lt;item value=\u0026quot;antennaprofile:eelloaderantennaprofile:delta\u0026quot;/\u0026gt; \u0026lt;/paramlist\u0026gt; \u0026lt;/eventgenerator\u0026gt;  最后,创建 scenario.eel\n0.0 nem:1 pathloss nem:2,90.0 0.0 nem:2 pathloss nem:1,90.0 0.0 nem:1 location gps 40.031075,-74.523518,3.000000 0.0 nem:2 location gps 40.031165,-74.523412,3.000000  emaneeventservice eventservice.xml -l 3  如果我们返回查看原始终端，我们将看到事件注销到终端。\nroot@n1:/tmp/pycore.46777/n1.conf# emaneevent-dump -i ctrl0 [1601858142.917224] nem: 0 event: 100 len: 66 seq: 1 [Location] UUID: 0af267be-17d3-4103-9f76-6f697e13bcec (1, {'latitude': 40.031075, 'altitude': 3.0, 'longitude': -74.823518}) (2, {'latitude': 40.031165, 'altitude': 3.0, 'longitude': -74.523412}) [1601858142.917466] nem: 1 event: 101 len: 14 seq: 2 [Pathloss] UUID: 0af267be-17d3-4103-9f76-6f697e13bcec (2, {'forward': 90.0, 'reverse': 90.0}) [1601858142.917889] nem: 2 event: 101 len: 14 seq: 3 [Pathloss] UUID: 0af267be-17d3-4103-9f76-6f697e13bcec (1, {'forward': 90.0, 'reverse': 90.0})  天线配置 介绍在CORE中使用EMANE天线剖面，基于下面链接的EMANE演示示例。（EMANE Demo 6）\n在开始这个会话之前，我们需要创建一些文件。创建目录放置天线配置文件。\nmkdir /tmp/emane  创建 /tmp/emane/antennaprofile.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE profiles SYSTEM \u0026quot;file:///usr/share/emane/dtd/antennaprofile.dtd\u0026quot;\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;profile id=\u0026quot;1\u0026quot; antennapatternuri=\u0026quot;/tmp/emane/antenna30dsector.xml\u0026quot; blockagepatternuri=\u0026quot;/tmp/emane/blockageaft.xml\u0026quot;\u0026gt; \u0026lt;placement north=\u0026quot;0\u0026quot; east=\u0026quot;0\u0026quot; up=\u0026quot;0\u0026quot;/\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile id=\u0026quot;2\u0026quot; antennapatternuri=\u0026quot;/tmp/emane/antenna30dsector.xml\u0026quot;\u0026gt; \u0026lt;placement north=\u0026quot;0\u0026quot; east=\u0026quot;0\u0026quot; up=\u0026quot;0\u0026quot;/\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt;  创建 /tmp/emane/antenna30dsector.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE antennaprofile SYSTEM \u0026quot;file:///usr/share/emane/dtd/antennaprofile.dtd\u0026quot;\u0026gt; \u0026lt;!-- 30degree sector antenna pattern with main beam at +6dB and gain decreasing by 3dB every 5 degrees in elevation or bearing.--\u0026gt; \u0026lt;antennaprofile\u0026gt; \u0026lt;antennapattern\u0026gt; \u0026lt;elevation min='-90' max='-16'\u0026gt; \u0026lt;bearing min='0' max='359'\u0026gt; \u0026lt;gain value='-200'/\u0026gt; \u0026lt;/bearing\u0026gt; \u0026lt;/elevation\u0026gt; /* 略 */ \u0026lt;elevation min='16' max='90'\u0026gt; \u0026lt;bearing min='0' max='359'\u0026gt; \u0026lt;gain value='-200'/\u0026gt; \u0026lt;/bearing\u0026gt; \u0026lt;/elevation\u0026gt; \u0026lt;/antennapattern\u0026gt; \u0026lt;/antennaprofile\u0026gt;  创建 /tmp/emane/blockageaft.xml\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE antennaprofile SYSTEM \u0026quot;file:///usr/share/emane/dtd/antennaprofile.dtd\u0026quot;\u0026gt; \u0026lt;!-- blockage pattern: 1) entire aft in bearing (90 to 270) blocked 2) elevation below -10 blocked, 3) elevation from -10 to -1 is at -10dB to -1 dB 3) elevation from 0 to 90 no blockage--\u0026gt; \u0026lt;antennaprofile\u0026gt; \u0026lt;blockagepattern\u0026gt; \u0026lt;elevation min='-90' max='-11'\u0026gt; \u0026lt;bearing min='0' max='359'\u0026gt; \u0026lt;gain value='-200'/\u0026gt; \u0026lt;/bearing\u0026gt; \u0026lt;/elevation\u0026gt; /* 略 */ \u0026lt;/bearing\u0026gt; \u0026lt;/elevation\u0026gt; \u0026lt;/blockagepattern\u0026gt; \u0026lt;/antennaprofile\u0026gt;  加载场景 emane-demo-antenna.xml，双击 n1终端\n本演示将介绍如何运行EMANE事件服务来提供天线、位置和路径损耗事件，以演示如何使用天线剖面。\n与之前类似的配置文件 eventservice.xml eelgenerator.xml (外部主机运行emaneeventservice -l 3 eventservice.xml)\nscenario.eel 内容为\n0.0 nem:1 antennaprofile 1,0.0,0.0 0.0 nem:4 antennaprofile 2,0.0,0.0 # 0.0 nem:1 pathloss nem:2,60 nem:3,60 nem:4,60 0.0 nem:2 pathloss nem:3,60 nem:4,60 0.0 nem:3 pathloss nem:4,60 # 0.0 nem:1 location gps 40.025495,-74.315441,3.0 0.0 nem:2 location gps 40.025495,-74.312501,3.0 0.0 nem:3 location gps 40.023235,-74.315441,3.0 0.0 nem:4 location gps 40.023235,-74.312501,3.0 0.0 nem:4 velocity 180.0,0.0,10.0 # 30.0 nem:1 velocity 20.0,0.0,10.0 30.0 nem:1 orientation 0.0,0.0,10.0 30.0 nem:1 antennaprofile 1,60.0,0.0 30.0 nem:4 velocity 270.0,0.0,10.0 # 60.0 nem:1 antennaprofile 1,105.0,0.0 60.0 nem:4 antennaprofile 2,45.0,0.0 # 90.0 nem:1 velocity 90.0,0.0,10.0 90.0 nem:1 orientation 0.0,0.0,0.0 90.0 nem:1 antennaprofile 1,45.0,0.0  发送的事件将触发4种不同的状态。\n 状态1  N2和N3相互看到 N4和N3指向外   状态2  N2和N3相互看到 N1和N2相互看到 N4和N3相互看到   状态3  N2和N3相互看到 N4和N3正对着对方，但是被阻塞了   状态4  N2和N3相互看到 N4和N3相互看到    ","id":12,"section":"posts","summary":"CORE/EMANE 无线仿真基本内容学习： 衰落模型 emane只能使用事件或nakagami模型 core设定的默认值是有问题的，m值越大信道越理想 路径损耗 ema","tags":["仿真"],"title":"Emane学习记录","uri":"https://liangkang233.github.io/2021/07/emane/","year":"2021"},{"content":"服务 CORE 使用服务的概念来指定节点启动时运行哪些进程或脚本。路由器和PC等第三层节点是由他们所运行的服务来定义的。\n可以为每个节点定制服务，也可以创造新的自定义服务。可以创建具有不同名称、图标和默认服务集的新节点类型。 每个服务定义每个节点的路径、配置文件、启动索引、启动命令、验证命令、关闭命令和与节点关联的元数据。\n 注意: 使用 init, upstart, 或 systemd 框架时，网络名称节点空间不会经历正常的Linux引导过程 ，这些轻量节点使用已经配置好的CORE服务。\n 提供的服务    服务组 服务 总结     BIRD BGP, OSPF, RADV, RIP, Static    EMANE Transport Service    FRR BABEL, BGP, OSPFv2, OSPFv3, PIMD, RIP, RIPNG, Zebra    NRL arouted, MGEN Sink, MGEN Actor, NHDP, OLSR, OLSRORG, OLSRv2, SMF    Quagga BABEL, BGP, OSPFv2, OSPFv3, OSPFv3 MDR, RIP, RIPNG, XPIMD, Zebra    SDN OVS, RYU    Security Firewall, IPsec, NAT, VPN Client, VPN Server    Utility ATD, Routing Utils, DHCP, FTP, IP Forward, PCAP, RADVD, SSF, UCARP    XORP BGP, OLSR, OSPFv2, OSPFv3, PIMSM4, PIMSM6, RIP, RIPNG, Router Manager     节点类型和默认服务 以下是默认节点类型和他们的服务:\n   节点类型 服务     router 针对IGP链路状态路由的 zebra, OSFPv2, OSPFv3, and IPForward 服务。   host 默认路由和SSH服务, 其表示直接连接到路由器时，SSH具有默认路由。   PC 为拥有默认路由且直接连接到路由器的节点提供默认路由服务.   mdr 针对无线优化的 MANET 指定路由的 zebra、 OSPFv3MDR 和 IPForward 服务。   prouter 和 路由器 节点类型具有相同默认服务的物理路由器; 用于将Linux测试平台设备合并到仿真中。    配置文件可以由每个服务自动生成。例如，CORE 会自动为路由器节点生成路由协议配置，来简化虚拟网络的创建。\n更改与节点相关联的服务，可以双击节点来调用配置对话框, 然后单击 服务\u0026hellip; 按钮，或者右键单击某个节点，从右键菜单中选择 服务\u0026hellip; 选项。通过单击服务的名称可以启用或禁止该服务。每个服务名称旁边的按钮允许您为该节点自定义此服务的所有方面。例如，可以将特殊的路由重分发命令插入到与 zebra 服务关联的 Quagga 路由配置中。\n若要更改与节点类型相关的默认服务, 请使用第三层节点工具栏末端的 编辑 按钮中的 节点类型\u0026hellip; 对话框，或是从 会话 菜单中选择 节点类型\u0026hellip;。 注意，如果已经定制了节点，那么所选择的任何新服务都不会应用于现有节点。\n节点类型被保存在 ~/.core/nodes.conf 文件中，而不是 .imn 文件。在更改现有节点的默认服务时请记住这一点; 最好只创建一个新的节点类型。并且建议不要更改默认的内置节点类型。可以在 CORE 设备之间复制nodes.conf 文件来保存你的自定义类型。\n定制服务 可以为特定节点完全定制服务。 从节点的配置对话框中，单击服务名称旁边的按钮，来调用该服务的服务定制对话框。该对话框有三个选项卡用于配置服务的不同方面：Files， Directories和tartup/shutdown。\n服务旁边的 黄色 自定义图标表示服务需要自定义（例如 Firewall 服务）。绿色 的自定义图标表示存在自定义配置。在自定义服务时单击 default 按钮会移除所有自定义选项。\nFiles选项卡用于显示或编辑用于该服务的配置文件或脚本。文件可以从下拉列表中选择，它们的内容将显示在下面的文本框中。文件的内容由 CORE daemon根据自定义对话框调用时存在的网络拓扑进程生成。\nDirectories选项卡显示该服务的每个节点的路径。对于默认类型，CORE节点共享相同的文件系统树，但被服务定义的每个节点除外。例如，对于每个运行 Zebra 服务的节点，其 /var/run/quagga 路径必须是唯一的，因为在每个节点运行的 Quagga 需要向该路径写入单独的 PID 文件。\n默认情况下， /var/log 和 /var/run 路径按照每个节点唯一挂载。每个节点的挂载目标可以在 /tmp/pycore.nnnnn/nN.conf/ （其中 nnnnn 是会话编号，N是节点编号）中找到。\nStartup/shutdown 选项卡列出用于启动和停止该服务的命令。 startup index允许在该服务启动时对为该节点启用的其他相关服务进行配置；Startup较低的服务先于Startup较高的服务. 由于Files选项卡生成的shell脚本没有执行权限设置，因此启动命令应包含shell名称，类似于 sh script.sh。\n 注意! 其中的 start time 及index 选项我简单浏览了 core/daemon/core/services/coreservices.py 的 CoreService类，似乎作者移除了这两项的实现。在后续的 ServiceShim 的 tovaluelist 方法中直接填入写死的index = 0以及time = 0。可能是原有的bug导致作者放弃了实现这个功能。\n Shutdown 命令可选择终止与此服务关联的进程。通常，它们使用 kill 或 killall 命令向正在运行的进程发送kill 信号。如果服务没有使用 Shutdown 命令终止正在运行的进程，那么当终止 vnoded 守护进程(使用 kill -9命令)并摧毁命名空间时，进程将被杀死。指定 shutdown 命令是一个很好的实践，这将允许适当的进程终止，以及停止和重启服务的运行控制。\nValidate 命令按照启动命令执行。 Validate 命令可以执行应返回0值的流程或者脚本，对于启动出现问题的服务返回非0值。例如，pidof 命令将检查某个进程是否正在运行，是则返回0值。当 Validate 命令生成了一个非零返回值，这将产生一个异常而导致在 Check Emulation Light 中显示一个错误。\n在运行时启动、停止和重启服务，需要右键单击节点并使用 服务\u0026hellip; 菜单。\n新的服务 服务可以节省配置节点所需的时间，特别是当大量节点都需要类似的配置程序时。此时可以引入新的服务来使任务自动化。\n如果使用tlv等界面api配置如下所示：\n其中File name和startup为必选项，其作用为节点容器初始化后复制一份脚本名为File name的脚本至于temp中的节点文件夹，startup等命令除了初始化仿真会调用也可通过界面选项来使用，具体参考其他server选项做法。\n利用用户自定义 将新流程的配置捕获到服务中的最简单方法是使用 UserDefined 服务。这是一个空白服务，可以自定义其中的任何方面。 UserDefined 服务便于在添加新的服务类型之前测试服务。\n创建新的服务   修改如下所示的实例服务，以便做您想做的事情。它可以生成配置/脚本文件、每个节点的挂载路径、启动进程/脚本等。sample.py 是一个 Python 文件，它定义了一个或更多需要导入的类。您可以创建多个将被导入的Python文件。将任何新文件名添加到 init.py 文件中。\n  把这些文件放在诸如 /home/username/.core/myservices 这样的路径中。但应注意路径最后的名称 myservices 不应该命名为类似于与现有的Python名称冲突的 服务（使用的语法是 from myservices import *'）\n  添加命令 custom_services_dir = /home/username/.core/myservices 到 /etc/core/core.conf 文件中。\n注意: 在 custom_services_dir 使用的路径名应该是唯一的，并且不应该对应于任何现有的Python模块名。例如，不要使用 subprocess 或是 services 名称。\n  重启 CORE 守护进程 (core-daemon). 任何导入错误 (Python 语法)都应显示在 /var/log/core-daemon.log 日志文件上（或显示在屏幕上）。\n  开始在节点上使用自定义服务吧。您可以创建使用您的服务的新节点类型，或者更改现有节点的默认服务，又或者更 改单个节点。\n  如果您已经创建了一个可能对他人有用的新服务类型，请考虑将其贡献给 CORE 项目。\n自定义服务示例 下面是带有一些说明文档的自定义服务框架。大多数人可能只会设置所需的类变量 (name/group)。然后定义 configs （他们想要生成的文件），并实现 generate_config 函数来动态创建所需的文件。最后，被提供的 startup 命令通常倾向于运行生成的shell文件。\n\u0026quot;\u0026quot;\u0026quot; Simple example custom service, used to drive shell commands on a node. \u0026quot;\u0026quot;\u0026quot; from typing import Tuple from core.nodes.base import CoreNode from core.services.coreservices import CoreService, ServiceMode class ExampleService(CoreService): \u0026quot;\u0026quot;\u0026quot; Example Custom CORE Service :cvar name: name used as a unique ID for this service and is required, no spaces :cvar group: allows you to group services within the GUI under a common name :cvar executables: executables this service depends on to function, if executable is not on the path, service will not be loaded :cvar dependencies: services that this service depends on for startup, tuple of service names :cvar dirs: directories that this service will create within a node :cvar configs: files that this service will generate, without a full path this file goes in the node's directory e.g. /tmp/pycore.12345/n1.conf/myfile :cvar startup: commands used to start this service, any non-zero exit code will cause a failure :cvar validate: commands used to validate that a service was started, any non-zero exit code will cause a failure :cvar validation_mode: validation mode, used to determine startup success. NON_BLOCKING - runs startup commands, and validates success with validation commands BLOCKING - runs startup commands, and validates success with the startup commands themselves TIMER - runs startup commands, and validates success by waiting for \u0026quot;validation_timer\u0026quot; alone :cvar validation_timer: time in seconds for a service to wait for validation, before determining success in TIMER/NON_BLOCKING modes. :cvar validation_period: period in seconds to wait before retrying validation, only used in NON_BLOCKING mode :cvar shutdown: shutdown commands to stop this service \u0026quot;\u0026quot;\u0026quot; name: str = \u0026quot;ExampleService\u0026quot; group: str = \u0026quot;Utility\u0026quot; executables: Tuple[str, ...] = () dependencies: Tuple[str, ...] = () dirs: Tuple[str, ...] = () configs: Tuple[str, ...] = (\u0026quot;myservice1.sh\u0026quot;, \u0026quot;myservice2.sh\u0026quot;) startup: Tuple[str, ...] = tuple(f\u0026quot;sh {x}\u0026quot; for x in configs) validate: Tuple[str, ...] = () validation_mode: ServiceMode = ServiceMode.NON_BLOCKING validation_timer: int = 5 validation_period: float = 0.5 shutdown: Tuple[str, ...] = () @classmethod def on_load(cls) -\u0026gt; None: \u0026quot;\u0026quot;\u0026quot; Provides a way to run some arbitrary logic when the service is loaded, possibly to help facilitate dynamic settings for the environment. :return: nothing \u0026quot;\u0026quot;\u0026quot; pass @classmethod def get_configs(cls, node: CoreNode) -\u0026gt; Tuple[str, ...]: \u0026quot;\u0026quot;\u0026quot; Provides a way to dynamically generate the config files from the node a service will run. Defaults to the class definition and can be left out entirely if not needed. :param node: core node that the service is being ran on :return: tuple of config files to create \u0026quot;\u0026quot;\u0026quot; return cls.configs @classmethod def generate_config(cls, node: CoreNode, filename: str) -\u0026gt; str: \u0026quot;\u0026quot;\u0026quot; Returns a string representation for a file, given the node the service is starting on the config filename that this information will be used for. This must be defined, if \u0026quot;configs\u0026quot; are defined. :param node: core node that the service is being ran on :param filename: configuration file to generate :return: configuration file content \u0026quot;\u0026quot;\u0026quot; cfg = \u0026quot;#!/bin/sh\\n\u0026quot; if filename == cls.configs[0]: cfg += \u0026quot;# auto-generated by MyService (sample.py)\\n\u0026quot; for iface in node.get_ifaces(): cfg += f'echo \u0026quot;Node {node.name} has interface {iface.name}\u0026quot;\\n' elif filename == cls.configs[1]: cfg += \u0026quot;echo hello\u0026quot; return cfg @classmethod def get_startup(cls, node: CoreNode) -\u0026gt; Tuple[str, ...]: \u0026quot;\u0026quot;\u0026quot; Provides a way to dynamically generate the startup commands from the node a service will run. Defaults to the class definition and can be left out entirely if not needed. :param node: core node that the service is being ran on :return: tuple of startup commands to run \u0026quot;\u0026quot;\u0026quot; return cls.startup @classmethod def get_validate(cls, node: CoreNode) -\u0026gt; Tuple[str, ...]: \u0026quot;\u0026quot;\u0026quot; Provides a way to dynamically generate the validate commands from the node a service will run. Defaults to the class definition and can be left out entirely if not needed. :param node: core node that the service is being ran on :return: tuple of commands to validate service startup with \u0026quot;\u0026quot;\u0026quot; return cls.validate  ","id":13,"section":"posts","summary":"服务 CORE 使用服务的概念来指定节点启动时运行哪些进程或脚本。路由器和PC等第三层节点是由他们所运行的服务来定义的。 可以为每个节点定制服务，也可以","tags":["仿真"],"title":"Core services","uri":"https://liangkang233.github.io/2021/07/services/","year":"2021"},{"content":"CORE 分布式仿真 概述 大型模拟场景可以部署在多个模拟服务器上由单个Core-GUI控制。表示整个拓扑的GUI可以是 其中一台模拟服务器或单独的只运行GUI的机器。\n作为模拟的每台机器都需要安装一个分布式CORE包和一些允许root用户使用ssh的配置。\nCORE 配置 使用分布式功能所需的核心配置设置：\n最好先了解CORE的控制网络章节内容\ncore运行的配置文件默认为 /etc/core/core.conf 可以修改该文件来配置core的相关参数，或者运行core-daemon时指定自定义的配置文件(-f 选项)\n# 取消注释并将其设置为远程服务器的地址 # 此地址用于主控网络返回至主机，即为主服务器真实IP地址 distributed_address = 129.168.0.101 # 不配置Emance默认所有分布式服务器和主控制服务器使用同一主控制网段 # 仿真中所有节点都会分配一个该网段内IP并将节点attach每台服务器对应的主控网桥上 # 各分布式主网桥数据会直接汇总到主服务器的控制网桥，服务器的主控制网络会自动建立一个隧道联通物理网卡eth0和主控网桥 controlnet = 172.16.0.0/24  若是单独跑分布式数据，这里主控网不配置也是能走通的，可不开启。\n分布式 EMANE 特定配置 EMANE 需要在 core.conf 中配置 controlnet 才能正确启动。 地址前的名称需要与配置的分布式服务器的名称相匹配。\n# 与上面所有分布式服务器的主控制网桥使用同一网段（在同一局域网内）不同 # 分布式Emance要求每一台分布服务器的主控制网桥工作在不同网段 # 最后各分布式服务器主控网桥的数据会通过隧道汇总到主控网络 controlnet = 172.16.0.0/24 controlnet1 = 172.16.1.0/24 emane_event_generate = True  配置 SSH 分布式CORE使用python fabric库在远程服务器上通过SSH运行命令。\n远程 GUI 终端 您需要确保每个服务器上的用户名相同，因为运行CORE GUI的用户会登录相同用户的远程bash（ssh）\nEdit -\u0026gt; Preferences\u0026hellip; -\u0026gt; Terminal program: 目前建议将此设置为xterm -e作为默认值，gnome-terminal无法工作。 如果没有安装，可能需要安装xterm\nsudo apt install xterm  分布式服务器SSH配置 首先，必须将分布式服务器配置为允许通过SSH进行无密码的root用户登录，或者分布式服务器插入主服务器的公钥免密登录。\n在分布式服务器上如此配置：\n# 安装 openssh-server sudo apt install openssh-server # 打开 sshd 配置 vi /etc/ssh/sshd_config # 验证这些配置是否启用 PermitRootLogin yes PasswordAuthentication yes # 如果需要，添加/修改以下行以允许SSH # 接受所有env变量 AcceptEnv * # 重启 sshd sudo systemctl restart sshd  在主服务器上：\n# 安装环境所需包 sudo apt install openssh-client  法1：公钥登录（推荐）\n# 在主服务器上生成SSH公、密钥 # 要确保生成的公钥密钥文件的绝对路径是 ~/.ssh，如下所示密钥文件为core，公钥文件为core.pub ssh-keygen -o -t rsa -b 4096 -f ~/.ssh/core  如果遇到类似 not a valid RSA private key file 的错误时使用此条命令。\nssh-keygen -o -m PEM -t rsa -b 4096 -f ~/.ssh/core  这是因为现在通过 ssh-keygen -o 使用新的OpenSSH格式而不是更兼容的PEM格式保存私钥。新格式增加了对暴力破解密码的抵抗力，但OpenSSH 6.5之前的版本不支持所以该模块无法识别。Ed25519密钥总是使用新的私钥格式。-m 支持格式有 “RFC4716”(RFC4716/SSH2)、“PKCS8”(PEM PKCS8)或“PEM”\n# 将公钥复制到从服务器地址server的authorized_keys文件中（需输入密码登录） ssh-copy-id -i ~/.ssh/core root@server # 当然运行core-gui的user用户也需要如上配置，否则无法使用远程终端界面 ssh-copy-id -i ~/.ssh/core user@server # 配置fabric使用Core SSH密钥 sudo vi /etc/fabric.yml # 添加/修改配置文件，其中路径中的user改为对应用户名 connect_kwargs: {\u0026quot;key_filename\u0026quot;: \u0026quot;/home/user/.ssh/core\u0026quot;}  法2：设置无需密码登录\n# 在分布式服务器上，打开 sshd 配置 vi /etc/ssh/sshd_config # 将root登录的配置更改为不需要密码 PermitRootLogin without-password # 重启 sshd sudo systemctl restart sshd  在 GUI 中添加仿真服务器 在 core-gui 的导航菜单中： Session -\u0026gt; Emulation servers\u0026hellip; 在出现的对话框中，添加或修改现有服务器（如果存在）以使用您计划使用的服务器的名称、地址和端口（真实环境下参数）\n服务器配置默认加载到下面的GUI 的配置文件 ~/.core/servers.conf\n# 名字 地址 端口 server2 192.168.0.2 4038  分配节点 用户需要为场景中的仿真服务器分配节点。不分配意味着节点将在主服务器上模拟。在每个节点的配置窗口中，位于Node name和Image按钮之间的下拉框将选择模拟服务器的名称。默认情况下，此菜单显示 (none)，表示该节点将在 master 上本地模拟。进入执行模式时，CORE GUI 将在其分配的仿真服务器上部署节点。\n分配仿真服务器的另一种方法是使用选择工具选择一个或多个节点（按住 Ctrl 键单击以选择多个），然后右键单击其中一个节点并选择 Assign to\u0026hellip;.\nCORE emulation servers对话框也可以用于为服务器分配节点。分配的服务器名称显示在节点名称旁边的括号中。要将所有节点分配给其中一台服务器，请单击服务器名称，然后单击all nodes按钮. 已分配节点的服务器在服务器列表中显示为蓝色. 另一种选择是先选择一个节点子集, 然后打开CORE emulation servers 选项并使用 selected nodes 按钮.\n注意: 如果要在主服务器上运行这些节点，则不要分配它们。无需显式地将节点分配给主服务器\nGUI 可视化 如果位于不同服务器上的两个节点之间存在链接，GUI将用虚线绘制链接。\n问题和局限性   无线模型\n只有当 EMANE 模型用于 WLAN 时，无线节点，即连接到 WLAN 节点的那些节点，才能被分配到不同的仿真服务器并参与相同的无线网络。由于使用了 Linux 网桥和 ebtables 规则，basic无线模型不能跨多个服务器工作\n  主从服务器流量\n自己测试发现，所有仿真中节点跨从服务器数据都是先发送到主服务器上再转发至从服务器，而且主控制网络路由也是需要主服务器转发。从服务器数量增多后势必导致主服务器转发路由负荷过大。正在测试能否使用控制网间的隧道或其他方法使从服务器间有直接联通的链路，而非主服务器转发。\n  注意: basic无线模型不支持分布式仿真，但EMANE支持\n当节点跨服务器链接时， core-daemons将在执行时自动在节点之间创建必要的隧道。应注意安排拓扑以使隧道的数量最小化。隧道在服务器之间传送数据以连接拓扑中指定的节点。这些隧道是使用 GRE 隧道创建的，类似于隧道工具\n分布式配置清单  在主服务器上安装 CORE 在所有需要的服务器上安装分布式 CORE 包 在所有服务器上安装和配置公钥 SSH 访问（如果想要使用双击打开终端或是窗口部件）为 GUI 用户（用于终端）和 root 运行 CORE 命令 根据需要更新 CORE 配置 选择参与分布式仿真的服务器 将节点分配给所需的服务器，若是节点在主服务器仿真则不分配（NONE）。 主服务器按start按钮启动分布式仿真，分服务器无须开启gui和daemon  ","id":14,"section":"posts","summary":"CORE 分布式仿真 概述 大型模拟场景可以部署在多个模拟服务器上由单个Core-GUI控制。表示整个拓扑的GUI可以是 其中一台模拟服务器或单独的只运行","tags":[""],"title":"Core 分布式","uri":"https://liangkang233.github.io/2021/07/distributed/","year":"2021"},{"content":"CORE 控制网络（CTRL NET） 概述 CORE 控制网络允许虚拟节点与其宿主环境进行通信。有两种类型：主控制网络和辅助控制网络。主控制网络主要用于与主机的虚拟节点通信以及多服务器分布式环境中的主从通信。辅助控制网络的功能为将由命名空间托管的仿真软件流量路由至测试网络场景。\n激活主控制网络 在 Session Menu有一个选项来设置 control network prefix.\n这可以设置为网络前缀（网段），例如 172.16.0.0/24。将在网段范围内的最后一个地址（例如 172.16.0.254）的主机上创建一个网桥，并且每个节点将有一个额外的 ctrl0 控制接口，并配置一个与其节点号相对应的ip地址（例如172.16.0.3 表示 n3)\n还可以通过在 /etc/core/core.conf 配置文件中设置 controlnet 行来指定主控制网络的默认值，新会话将默认使用该行。要同时使用控制网络运行多个会话，应使用 session 选项而不是 core.conf 默认值\n 注意: 如果您有超过 253 个节点的大型场景，请使用 /23 或更大的网段。\n  注意: 如果前一个会话已设置控制网络并且其网桥仍在运行，则继续使用控制网络运行会话可能会失败。首先关闭上一个会话或等待它完成。如果不能，则可能需要重新启动核心守护程序并手动删除延迟的桥接器\n # 重启 CORE Daemon sudo /etc/init.d core-daemon restart # 移除残留的控制网桥 ctrlbridges=`brctl show | grep b.ctrl | awk '{print $1}'` for cb in $ctrlbridges; do sudo ifconfig $cb down sudo brctl delbr $cb done   **注意:**如果在 /etc/core/core.conf 中对主控制网络配置所做的调整似乎没有生效，请检查Session Menu, the *Options\u0026hellip;*对话框中是否有任何设置，它们可能需要清除。这些会话的设置会覆盖 /etc/core/core.conf 中的默认值。\n 分布式会话中的控制网络 当主控制网络做为分布式会话激活时，将在每个从服务器上创建一个控制网桥，并通过GRE隧道返回到主服务器的网桥。从控制网桥没有分配地址，可以从主机访问任何节点(本地或远程)，就像单个服务器的情况一样。\n在某些情况下，远程模拟节点需要与运行它们的主机而不是主服务器进行通信。可以在会话选项或 /etc/core/core.conf 中指定多个控制网络前缀，以空格分隔并以主服务器开头。每个条目的格式为 server:prefix 。如下所示，更改 /etc/core/core.conf 默认配置，为服务器 core1、core2 和 core3 分配了控制网络网段。也可在会话session选项中设定。\ncontrolnet=core1:172.16.1.0/24 core2:172.16.2.0/24 core3:172.16.1.0/24  然后，控制网桥将被分配如下\n* core1 = 172.16.1.254 （假设它是主服务器） * core2 = 172.16.2.254 * core3 = 172.16.3.254  仍将构建从服务器导向主服务器的隧道，但如果需要在控制网络前缀之间建立网络，则需要用户添加适当的路由。控制网络脚本可能对此有所帮助。\n控制网络脚本 可以使用 /etc/core/core.conf 文件中的 controlnet_updown_script 选项指定控制网络脚本。该脚本将在网桥建成（并分配地址）后运行，命令的第一个参数是网桥的名称，第二个参数是关键字 “startup”。该脚本将在移除桥时会再次被调用，命令的第一个参数是网桥的名称，命令的第二个参数是关键字 “shutdown”。该脚本默认位置在~/core/daemon/examples/controlnet_updown中。\n辅助控制网络 从 EMANE 0.9.2 开始，CORE 将在命名空间内运行 EMANE 实例。由于建议将 OTA 流量与其他流量分开，因此我们将需要多个从命名空间导出的通道。最多可以定义三个辅助控制网络。 /etc/core/core.conf 文件中设置了多个控制网络。线路 controlnet1、controlnet2 和 controlnet3 定义辅助网络。\n例如 /etc/core/core.conf 中配置如下\ncontrolnet = core1:172.17.1.0/24 core2:172.17.2.0/24 core3:172.17.3.0/24 controlnet1 = core1:172.18.1.0/24 core2:172.18.2.0/24 core3:172.18.3.0/24 controlnet2 = core1:172.19.1.0/24 core2:172.19.2.0/24 core3:172.19.3.0/24 # 经过测试发现，源码已经改变读取配置方式，辅助控制网只会接入第一个网段。如下配置即可 controlnet0 = 172.17.1.0/24 controlnet1 = 172.18.1.0/24 controlnet2 = 172.19.1.0/24 # controlnet配置且controlnet0未配置时，controlnet就是主控网，否则主控网网段为controlnet0 # 辅助控制网接口只在配置了emane的节点容器上生成，主控网间通信都是gre通向主服务器转发。 # 而辅助控制网接口attach节点外物理主机的网桥，并且各分布式辅助网在同一局域网配置路由后无视仿真拓扑可直接通信。  这将激活主控制网络controlnet和两个辅助控制网络，并向每个节点添加接口 ctrl0、ctrl1、ctrl2。例如在 EMANE 选项对话框中将 ctrl1 分配给 OTA 管理器设备，将 ctrl2 分配给事件服务设备，并将 ctrl0 留给 CORE 控制流量（主控网络）\n NOTE: controlnet0 可以用来代替 controlnet 来配置主控制网络\n 与主控制网络不同，辅助控制网络不会使用隧道，因为它们的主要目的是有效地传输多播 EMANE OTA 和事件流量。\n请注意，辅助控制网络没有针对每个会话的配置\n为了在分布式测试环境中扩展辅助控制网络，需要向其中添加主机网络接口。 /etc/core/core.conf 中的以下几行将主机设备的 eth1、eth2 添加到 controlnet1、controlnet2：\ncontrolnetif1 = eth1 controlnetif2 = eth2   NOTE: 无需为主控制网络分配接口，因为使用servers.conf 中提供的IP 地址在主设备和从设备之间形成隧道\n 下图是上述配置的示意图：\n","id":15,"section":"posts","summary":"CORE 控制网络（CTRL NET） 概述 CORE 控制网络允许虚拟节点与其宿主环境进行通信。有两种类型：主控制网络和辅助控制网络。主控制网络主要用于与主机的","tags":[""],"title":"Core 控制网络","uri":"https://liangkang233.github.io/2021/07/ctrlnet/","year":"2021"},{"content":"Core 环境搭建 推荐使用Vscode编辑代码，可以安装对应python扩展跳转定义声明等。\n# 更新软件包索引，并且安装依赖软件： sudo apt update # 启用 Visual Studio Code 源仓库，输入： sudo apt install software-properties-common apt-transport-https wget # 使用 wget 命令插入 Microsoft GPG key ： wget -q https://packages.microsoft.com/keys/microsoft.asc -O- | sudo apt-key add - # 启用 Visual Studio Code 源仓库: sudo add-apt-repository \u0026quot;deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main\u0026quot; sudo apt install code  安装抓包工具和ssh等组件\nsudo apt-get install openssh-client openssh-server isc-dhcp-server isc-dhcp-client \\ tcpdump openvpn traceroute wireshark iperf3 sudo setcap 'CAP_NET_RAW+eip CAP_NET_ADMIN+eip' /usr/bin/dumpcap sudo adduser $USER wireshark  安装Core 依照手册教程即可：列出遇到的问题。推荐安装core在虚拟环境中（默认选项）\n# 更新python和pip python3 -m pip install -U pip # 或者直接apt-get sudo apt install python3 python3-pip # clone CORE repo git clone https://github.com/coreemu/core.git cd core # 脚本用法: install.sh [-v] [-d] [-l] [-p \u0026lt;prefix\u0026gt;] # -v enable verbose install # -d enable developer install # -l enable local install, not compatible with developer install # -p install prefix, defaults to /usr/local # install core to virtual environment ./install.sh -p \u0026lt;prefix\u0026gt; # install core locally ./install.sh -p \u0026lt;prefix\u0026gt; -l    自动安装脚本install.sh将会执行以下工作\n 安装安装所需的基础工具python3, pip, pipx, invoke, poetry 为构建Core安装系统依赖 clone/build/install OPSF MDR 的工作版本 通过传入参数标志，设定将Core安装到poetry管理的虚拟环境中或真实环境中 根据安装类型来安装适当的Python位置的指向脚本 根据安装类型来安装适当的Python位置的systemd服务    运行软件安装脚本install.sh报错或无效时会直接停止导致后续命令不执行。\n如果是因为模块已经安装过，打开脚本进行查看对应安装命令，卸载需要删掉的环境模块即可。\n  Invok命令的使用：\n其实install脚本就是运行invoke对应选项的安装，使用如下教程来进行core的安装卸载\ninv --list #list 指令选项: daemon #运行 core-daemon install #安装 core, poetry, scripts, service, ospf mdr install-emane #安装 emane and the python bindings install-scripts #安装 core 脚本执行文件, 修改以利用虚拟环境 install-service #安装 systemd core 服务 test #运行 core tests test-emane #运行 core emane tests test-mock #运行 core tests 使用 mock 来避免以管理员(sudo)来执行 uninstall #卸载 core, scripts, service, virtual environment, 清理 build 目录 #安装的详细帮助信息 inv -h install Usage: inv[oke] [--core-opts] install [--options] [other tasks here ...] Docstring: install core, poetry, scripts, service, and ospf mdr Options: -d, --dev 安装开发模式 -p STRING, --prefix=STRING 设置脚本安装路径，默认是/usr/local -v, --verbose 启用 verbose    关于汉化gui界面的重装\n# 先卸载 sudo make uninstall make clean ./bootstrap.sh clean #安装 ./bootstrap.sh ./configure make sudo make install # 上述代码就是早期版本的生成和卸载  # 新版本直接使用invoke卸载重装整个即可,当然有需要可以在invole脚本对应的task.py中添加instal-core，如下所示 @task() def reinstall_core( c, dev=False, verbose=False, local=False, prefix=DEFAULT_PREFIX, install_type=None ): \u0026quot;\u0026quot;\u0026quot; reinstall core by LK233 \u0026quot;\u0026quot;\u0026quot; hide = not verbose p = Progress(verbose) c.run(\u0026quot;sudo -v\u0026quot;, hide=True) print(f\u0026quot;uninstalling core with prefix: {prefix}\u0026quot;) with p.start(\u0026quot;uninstalling core\u0026quot;): c.run(\u0026quot;sudo make uninstall\u0026quot;, hide=hide) with p.start(\u0026quot;cleaning build directory\u0026quot;): c.run(\u0026quot;make clean\u0026quot;, hide=hide) c.run(\u0026quot;./bootstrap.sh clean\u0026quot;, hide=hide) print(f\u0026quot;installing core with prefix: {prefix}\u0026quot;) with p.start(\u0026quot;building core\u0026quot;): build_core(c, hide, prefix) with p.start(\u0026quot;installing vcmd/gui\u0026quot;): install_core(c, hide)    整个core套件卸载重装时遇到的问题\n由于卸载脚本运行时没有卸载虚拟环境中的poetry，导致之后运行安装脚本invoke报错停止。可以通过在安装脚本添加\u0026ndash;force强制安装或卸载脚本添加卸载poetry代码解决，最快的解决办法（core安装在虚拟环境的情况）卸载后在core的根目录执行\npipx uninstall poetry\n  安装Emane 自动安装脚本安装的Emane版本为1.25，Core虚拟环境安装仅支持Emane1.21以上版本\ninvoke脚本任务能自动安装Emane，它从源代码来构建安装Emane，但在较老的Protobuf编译器上的系统存在问题。\n# 安装Emane到core虚拟环境中 inv install-emane # 安装到真实python环境 inv install-emane -l  另外，EMANE可以从deb或RPM包或从源代码安装。详见EMANE GitHub。需要注意的是，如果不是本地python环境安装，python需要绑定到CORE的virtualenv中。(Emane安装教程)需要将EMANE python绑定安装到CORE虚拟环境virtualenv中。如下所示：（安装过程与invok脚本安装emane类似）\n# 克隆和构建Emane python绑定 git clone https://github.com/adjacentlink/emane.git cd emane ./autogen.sh PYTHON=python3 ./configure --prefix=/usr cd src/python make # 安装到core虚拟环境 cd \u0026lt;CORE_REPO\u0026gt;/daemon poetry run pip install \u0026lt;EMANE_REPO\u0026gt;/src/python  运行core   要测试CORE Network Emulator是否工作，请启动CORE守护进程和GUI。 首先，启动CORE守护进程:\nsudo service core-daemon start #直接开新终端运行，方便看日志 sudo core-daemon #守护进程帮助手册 -h -f CONFIGFILE, --configfile CONFIGFILE 读取配置文件CONFIGFILE，默认是/etc/core/core.conf -p PORT, --port PORT 设定port为守护进程监听端口，默认4038 --ovs 启用实验ovs模式，默认为false --grpc-port GRPCPORT 设定GRPCPORT为GRPC监听端口，默认50051 --grpc-address GRPCADDRESS 设定GRPCADDRESS为监听grpc地址;默认本地主机 -l LOGFILE, --logfile LOGFILE 设置LOGFILE为守护进程日志选项，默认为/etc/core/logging.conf，错误日志为core-daemon.log  如果在安装CORE后没有重新启动，此时可能会遇到错误。如果您看到告诉您文件core守护进程的错误。 服务不存在，请重新启动系统。重新启动后，再次尝试启动core守护进程服务。 然后，运行CORE GUI\ncore-gui    如果你创建自己的python脚本来直接运行CORE或者使用gRPC/TLV api，你需要确保你是在安装的虚拟环境的上下文中运行它们。为了帮助支持这个CORE提供了CORE-python可执行文件。这个可执行文件将允许你进入CORE的python虚拟环境解释器或在其中运行脚本。\ncore-python \u0026lt;script\u0026gt;  若是安装在真实环境中直接执行\npython3 \u0026lt;script\u0026gt;    Core文件介绍 下面是运行自动安装后将安装的文件列表。\n **注:**默认的安装前缀是/usr/local，但可以更改如下所示\n  执行文件  \u0026lt;prefix\u0026gt;/bin/{core-daemon, core-gui, vcmd, vnoded, etc}   tcl/tk gui 文件  \u0026lt;prefix\u0026gt;/lib/core \u0026lt;prefix\u0026gt;/share/core/icons   示例场景 imn 文件  \u0026lt;prefix\u0026gt;/share/core/examples   python 文件  poetry 虚拟环境  cd \u0026lt;repo\u0026gt;/daemon \u0026amp;\u0026amp; poetry env info ~/.cache/pypoetry/virtualenvs/   本地python安装  default install path for python3 installation of a wheel python3 -c \u0026quot;import core; print(core.__file__)\u0026quot;     配置文件  /etc/core/{core.conf, logging.conf}   ospf mdr 仓库文件  \u0026lt;repo\u0026gt;/../ospf-mdr   emane 仓库文件  \u0026lt;repo\u0026gt;/../emane    执行文件 安装完成后，它将安装以下脚本。\n   名称 描述     core-cleanup 删除工具，帮助删除Core创建的容器，网桥，目录   core-cli 运行支持的Core服务器，提供TLV和gRPC api   core-daemon runs the backed core server providing TLV and gRPC APIs   core-gui 运行传统的基于tcl/tk的GUI   core-imn-to-xml 帮助自动将.imn文件转换为.xml格式的工具   core-manage 用于添加、移除或检查|中的服务、模型和节点类型的工具   core-pygui 运行新的的基于Python的GUI   core-python 运行core虚拟环境内的python   core-route-monitor 帮助监控节点间的流量并将其提供给SDT的工具   core-service-update 更新修改遗留服务以匹配当前命名的工具   coresendmsg 从命令行发送TLV API命令的工具    ","id":16,"section":"posts","summary":"Core 环境搭建 推荐使用Vscode编辑代码，可以安装对应python扩展跳转定义声明等。 # 更新软件包索引，并且安装依赖软件： sudo apt update # 启用 Visual Studio Code 源","tags":[""],"title":"Core Emane环境搭建","uri":"https://liangkang233.github.io/2021/07/installation/","year":"2021"},{"content":" Core 架构 Python API gRPC API  Core架构 主要组件   Core守护(服务)进程 (core-daemon)\n 该程序是利用小型C二进制文件来创建节点的Python仿真程序 管理网络节点、链路的仿真会话 使用Linux命名空间创建节点 链路是由Linux网桥和虚拟以太网设备TAP等创建的 链路数据包是通过流量控制来操纵的 仿真过程可以由CORE GUI控制 提供自定义TLV API和gRPC API    Core-gui\n GUI和守护进程通过自定义TLV API进行通信 拖放节点和链接的创建 可以在运行的会话中启动仿真节点的终端 可以保存/打开场景文件重新创建以前的会话 TCL/TK 程序    Coresendmsg\n 用于将TLV API消息发送到核心守护进程的命令行实用程序    虚拟命令终端 (vcmd)\n 用于向节点发送shell命令的命令行实用程序    会话Sessions CORE可以同时创建和运行多个模拟会话，下面表格从左向右概述了典型GUI交互期间会话将转换的状态。\n   定义初始化 配置参数 安装模拟节点 运行仿真 数据采集 停止仿真     XML/IMN 会话Gui绘制脚本 配置hooks、配置服务、配置移动性和WLAN、配置Emance 创建节点、接口桥接链路、启动服务 移动性仿真、交互shell、状态设定脚本  关闭服务销毁接口、桥接链路、节点    工作原理 CORE框架运行在Linux上，并使用Linux命名空间创建节点容器。这些节点使用Linux网桥和虚拟接口连接在一起。CORE会话是一组节点和链接，它们出于特定目的一起工作。Linux网络名称空间(也称为netns: Linux network namespaces )是CORE使用的主要技术。大多数最新的Linux发行版都具有开箱即用的支持名称空间的内核。每个命名空间都有自己的进程环境和私有的网络堆栈。网络名称空间在CORE中共享相同的文件系统。CORE将这些名称空间与Linux以太网桥接结合起来，形成网络。使用Linux Netem排队规则应用链接特性。Ebtables是Linux桥上的以太网帧过滤方法，通过使用ebtables规则控制哪些接口可以发送和接收来模拟无线网络。\n之前的工作 Tcl/Tk CORE GUI最初起源于萨格勒布大学的开源IMUNES项目，作为波音研究与技术网络技术研究小组2004年的一个定制项目。从那时起，他们开发了使用Linux命名空间的CORE框架，开发了一个Python框架，并进行了大量的用户和内核空间开发，例如支持无线网络、IPsec、分布式仿真、仿真集成等等。IMUNES项目还包括用户空间和内核组件。\n开源项目和资源 CORE已经由波音在BSD许可下发布给开源社区。如果您发现CORE对您的工作有用，请返回到项目中。贡献可以像报告bug、向邮件列表提供鼓励或技术建议一样简单，也可以包括提交补丁或维护工具的各个方面。\nPython API  关键要理解上面的架构图，就能明白下面这些api的具体实现\n 使用Python API可以完全控制仿真的所有方面，这些python脚本需要以 root 权限运行，因为它们会创建新的网络命名空间。\n一般情况下 使用这些python api 的CORE Python 程序不会连接到 CORE daemon（可以理解为它自己就是一个core-daemon），实际上，core-daemon 只是另一个使用 CORE Python api 模块并与 GUI 交换消息的 Python 脚本。相关api文件查看该路径 core/daemon/core/emulator/data.py 的 InterfaceData类。\n具体例子就不分析了，直接看使用gRPC协议的 api 如何使用。\ngRPC API core-pygui 与 coredaemon 的界面交互就是通过 gRPC api 来驱动core的所有功能，所以调用这些api需要启动 core-daemon。可以从包含在 CORE 中的原始生成的 grpc 文件创建一个 python client，或者可以利用 core 源码中 提供的 gRPC api 来帮助封装一些功能做进一步的开发。\n gRPC api是指使用了gRPC框架通信协议的api，其代码实现可以是python c++等语言(这里使用的还是python语言)与上述的Python api并非同种api。\n CoreGrpcClient 提供了一个 python 客户端包装器其封装了一些常用的api调用，下面的示例就是调用的它。由于 gRPC 基于 HTTP2，代理配置可能会导致问题。默认情况下，gRPC 客户端禁用代理支持以避免启用代理时出现问题。Proto 文件用于定义用于与此 API 接口的 API 和 protobuf 消息。 可以在此处找到它们以查看正在发生的事情的细节以及将返回的响应消息值。\n具体例子和python api的例子在同一目录中，可以看到其api的调用与功能与python api非常相似，个人猜测是原有的 coresendmsg core-gui 等程序调用的 tlv 协议作者想一步步弃用，所以为了兼容降低学习成本根据原来tlv格式的api使用方法 来设计封装 gRPC api。该上级目录其中还包含了docker、lxd映射到core仿真中的某个节点的示例，后续有可能会进行相关的开发。\n","id":17,"section":"posts","summary":"Core 架构 Python API gRPC API Core架构 主要组件 Core守护(服务)进程 (core-daemon) 该程序是利用小型C二进制文件来创建节点的Python仿真程序 管理网络节点、链路的","tags":[""],"title":"Core 仿真架构","uri":"https://liangkang233.github.io/2021/07/architecture/","year":"2021"},{"content":"使用 CORE GUI 下图显示 CORE GUI:\n概述 GUI 用于在画布上绘制节点和网络设备，将它们连接在一起，以创建模拟的网络会话。\n按下启动按钮后，CORE 将通过这些阶段进行，保持在运行时阶段。会话停止后，CORE 将进入数据收集阶段，然后卸载模拟状态。\nCORE 可自定义以在每个状态执行任何操作。有关何时达到这些会话状态，请参阅会话菜单上的Hooks\u0026hellip;\n必要条件 除了安装CORE之外，还必须运行CORE守护进程。\n在命令行中使用systemd或sysv。\n# systemd sudo systemctl daemon-reload sudo systemctl start core-daemon # sysv sudo service core-daemon start  还可以直接从命令行调用守护进程，如果您想直接查看日志输出，这很有用。\n# direct invocation sudo core-daemon  操作模式 核心GUI有两种主要操作模式，编辑和执行模式。运行GUI，通过键入没有选项Core-gui，从编辑模式开始。节点使用左侧的工具栏绘制在空白画布上，并从右键单击菜单或双击菜单进行配置。GUI 不需要作为root运行。\n编辑完成后，按下绿色开始按钮（或从会话菜单中选择执行）会因 Linux 内核中的拓扑，然后进入执行模式。在执行模式下，用户可以通过双击或右键单击运行模拟的计算机进行交互。编辑工具栏消失，由执行工具栏替换，该工具栏在运行仿真时提供工具。按下红色停止按钮（或从会话菜单中选择终止）将破坏运行模拟并将 CORE 返回到编辑模式。\nCORE可以通过指定 start 命令行直接在执行模式下启动场景：\ncore-gui --start ~/.core/configs/myfile.imn  一旦模拟开始运行，就可以关闭GUI，并出现提示询问是否应该终止仿真。之后运行时，GUI会提示重新连接到现有的会话。\nGUI可以在Linux上以普通用户的身份运行。GUI可以连接到不同的地址或TCP端口使用**\u0026ndash;address和/或\u0026ndash;port**选项。默认值如下所示。\ncore-gui --address 127.0.0.1 --port 4038  工具栏 工具栏是一排按钮，沿Core gui窗口的左侧垂直运行。工具栏会根据操作模式而变化。\n编辑工具栏 当 CORE 处于编辑模式（默认值）时，垂直编辑工具栏位于核心窗口的左侧。\n以下是从顶部开始的每个工具栏项的简要说明。大多数工具被分组到相关的子菜单中，当您单击其组图标时会出现这些子菜单。\n   图标 名字 描述      选择工具 用于选择、移动、配置节点的工具。    启动按钮 开始执行模式，实例化模拟节点。    链接 允许通过单击和拖动鼠标在两个节点之间绘制网络链接。    核心节点 这些节点将创建一个新的节点容器并运行相关服务。\n   图标 名字 描述      路由器 运行Quagga OSPFv2和OSPFv3路由转发数据包。    主机 模拟服务器机具有默认路线，运行SSH服务器。    个人电脑 具有默认路线的基本模拟机器，默认情况下不运行任何进程。    指定路由器移动自组网协议（ MANET Designated Routers） 运行 Quagga OSPFv3 MDR 路由，用于管理优化路由。（MANETs: Mobile Ad Hoc Networks 移动自组网）    物理路由器（PRouter） 物理路由器代表了一个真实的试验机器。    编辑 生成自定义节点对话。    网络节点 这些节点主要用于创建一个 Linux 网桥，用于以下目的。\n   图标 名字 描述      集线器hub 以太网集线器将传入的数据包转发到每个连接的节点。    交换机Switch 以太网交换机使用以太网地址哈希表智能地将传入的数据包转发给附加主机。    Wireless LAN 当路由器连接到此 WLAN 节点时，它们会加入无线网络，并绘制天线而不是连接线：WLAN节点通常根据连接的距离控制连接无线节点之间的连接。    RJ45 RJ45物理接口工具，仿真节点可链接到真正的物理接口：使用此工具，真正的网络和设备可以物理连接到实时运行模拟。    Tunnel Tool allows connecting together more than one CORE emulation using GRE tunnels.    注释工具    图标 名字 描述      Marker 用于在画布上绘制标记。    Oval 用于在背景中显示的画布上绘制圆圈。    Rectangle 用于在背景中显示的画布上绘制矩形。    Text 用于在画布上放置文本字幕。    执行工具栏 按下\u0026quot;开始\u0026quot;按钮后，CORE 切换到\u0026quot;执行\u0026quot;模式，核心窗口左侧的编辑工具栏替换为执行工具栏，下面是此工具栏上的项，从顶部开始。\n   图标 名字 描述      Selection Tool 在执行模式下，选择工具可用于在画布周围移动节点，在节点上双击将打开该节点的外壳窗口：右键单击节点会调用该节点的运行时间选项的弹出菜单。    Stop Button 停止执行模式，终止仿真，将 CORE 返回到编辑模式。    Observer Widgets Tool 单击此放大镜图标可调用菜单以轻松选择\u0026quot;观察者小部件\u0026quot;。当\u0026quot;观察者小部件\u0026quot;处于活动状态时，图标具有较深的灰色背景，在此期间，将鼠标移到节点上会弹出该节点的信息显示。    Marker 用于在画布上画手线，在演示期间有用：标记未保存。    Two-node Tool 单击以选择开始和结束节点，并在这些节点之间运行一次性跟踪路由或节点之间连续*ping-R。*输出实时显示在结果框中，而 IP 地址则解析，并在 CORE 显示屏上突出显示完整的网络路径。    Run Tool 此工具允许轻松地在所有节点的全部或子集上运行命令。列表框允许选择任何节点。文本输入框允许输入任何命令。命令应立即返回，否则显示屏将阻止等待响应。例如，没有参数的ping命令不是个好主意。每个命令的结果都显示在结果框中。特殊文本\u0026quot;NODE\u0026quot;的第一次出现将替换为节点名称。命令不会尝试在不是路由器、PC 或主机的节点上运行，即使它们被选中。    菜单 菜单栏沿 CORE GUI 窗口的顶部运行，并提供对各种功能的访问。某些菜单可以通过单击顶部的虚线来分离，例如小部件菜单。\n查看菜单 \u0026ldquo;视图\u0026quot;菜单包含用于控制绘图画布上显示的内容的项目。\n   Option Description     Show Opens a submenu of items that can be displayed or hidden, such as interface names, addresses, and labels. Use these options to help declutter the display. These options are generally saved in the topology files, so scenarios have a more consistent look when copied from one computer to another.   Show hidden nodes Reveal nodes that have been hidden. Nodes are hidden by selecting one or more nodes, right-clicking one and choosing hide.   Locked Toggles locked view; when the view is locked, nodes cannot be moved around on the canvas with the mouse. This could be useful when sharing the topology with someone and you do not expect them to change things.   3D GUI\u0026hellip; 运行Preferences， 3D GUI command下定义的命令启动3D GUI。这通常是一个运行SDT3D显示的脚本。SDT是NRL的脚本显示工具，它基于美国宇航局基于java的WorldWind虚拟地球软件。   Zoom In Magnifies the display. You can also zoom in by clicking zoom 100% label in the status bar, or by pressing the + (plus) key.   Zoom Out Reduces the size of the display. You can also zoom out by right-clicking zoom 100% label in the status bar or by pressing the - (minus) key.    工具菜单 工具菜单列出了不同的实用功能。\n   选择 描述     Autorearrange all 自动排列画布上的所有节点。具有更多链接的节点移动到中心。此模式可以在放置节点时继续运行。要关闭此自动重新排列模式，请单击带有选定工具的画布空白区域，或再次选择此菜单选项。   Autorearrange selected 自动排列画布上选定的节点。   Align to grid 将节点移动到网格形成中，从画布左上角的最小编号节点开始，在垂直柱中排列节点。   Traffic\u0026hellip; 调用 CORE 流量流对话框，允许为模拟配置、启动和停止 MGEN 流量流。   IP addresses\u0026hellip; 调用 IP 地址对话框来配置自动处理新接口时使用的 IPv4/IPv6 前缀。   MAC addresses\u0026hellip; 调用 MAC 地址对话框来配置生成每个接口 MAC 地址时用作最低分节的起始编号。在进行 CORE 模拟之间的隧道时，应更改此值，以防止 MAC 解决冲突。   Build hosts file\u0026hellip; 调用\u0026quot;构建主机文件\u0026quot;对话框，根据仿真中使用的 IP 地址生成 /etc/host 文件条目。   Renumber nodes\u0026hellip; 调用\u0026quot;重新编号节点\u0026quot;对话框，允许在点击数时将一个节点编号与另一个节点编号交换。   Experimental\u0026hellip; 实验选项的菜单，如转换ns-2脚本到IMUNES imn拓扑，只支持基本的ns-2功能，以及一个自动划分拓扑到分区的工具。   Topology generator 打开要生成的拓扑的子菜单。您可以首先选择拓扑应该包含的节点类型，否则将默认选择路由器。节点可以随机放置、在网格中对齐或各种其他拓扑模式。下表列出了所有受支持的模式。   Debugger\u0026hellip; 打开Core Debugger执行任意 Tcl/Tk 命令。    拓扑发生器    模式 描述     随机 节点随机放置在画布上，但未链接在一起。这可以与 WLAN 节点一起快速创建无线网络。   网格 节点位于水平行中，从左上角开始，均匀地向右间隔：节点之间不链接。   已连接的网格 节点位于 N x M（宽度和高度）矩形网格中，每个节点都连接到上面、下面、左侧和右侧的节点。   链 节点在链条中一个接一个地连接在一起。   星 一个节点放置在中心，N 节点以圆形模式环绕，每个节点都链接到中心节点。   周期 节点以圆形模式排列，每个节点都连接到其邻居，形成封闭的圆形路径。   轮子 车轮模式将节点连接在星形和循环模式的组合中。   立方体 生成节点的立方体图。   全连接 创建一个结点的分队图，每个节点都连接到所有其他节点。   二分图 创建两个节点的双分方图，具有两组脱节的顶点。    部件菜单 小部件是 GUI 元素，允许与运行模拟进行交互。小部件通常自动在模拟节点上运行命令，以报告某种类型的状态信息并在屏幕上显示这些信息。\n周期性部件 这些小部件是主小部件菜单中可用的。其中多个小部件可以同时运行。事件循环每秒发射一次，模拟正在运行。如果启用了其中一个小部件，则此时将调用其周期性例程。每个小部件可能有一个配置对话框，也可以从小部件菜单访问。\n下面是一些标准部件：\n Adjacency- 显示Quagga’s OSPFv2和OSPFv3路由协议的路由器对接状态。从每个路由器中抽取一条线，中途到相邻路由器的路由器 ID。线的颜色基于 OSPF 的对会状态，如Two-way 或 Full。要了解不同的颜色，请参阅Configure Adjacency…菜单项，vtysh命令用于转储 OSPF 邻居信息。只绘制了一半的线，因为每个路由器可能处于与另一个路由器不同的对等状态。 Throughput- 使用ng_pipe Netgraph节点收集的统计数据来实现显示每个链接上方的每秒千位吞吐量。如果吞吐量超过一定阈值，链接将变得突出显示。对于向范围内的所有节点广播数据的无线节点，吞吐率显示在节点旁边，如果阈值超出，节点将变得圆圈化。  观察部件 这些小部件可从小部件菜单的\u0026quot;观察者小部件\u0026quot;子菜单以及工具栏上的\u0026quot;小部件工具\u0026quot;中获取。一次只能使用一个观察者小部件。在会话运行时，鼠标在节点上弹出有关该节点的信息显示。\n可用的观察者小部件包括 IPv4 和 IPv6 路由表、socket信息、运行过程列表和 OSPFv2/v3 邻居信息。\n观察者小部件可以由用户编辑并重新排列。从\u0026quot;观察者小部件\u0026quot;菜单中选择编辑将调用\u0026quot;观察者小部件\u0026quot;对话。显示观察者小部件列表以及用于重新排列列表的上下箭头。控件可用于重命名每个小部件、更改鼠标运行期间运行的命令以及从列表中添加和删除项目。请注意，指定命令应立即返回，以避免 GUI 显示屏出现延迟。更改将保存到 CORE 配置目录中的widgets.conf文件。\n会话菜单 除了节点类型、注释、钩子、服务器和选项等全局选项外，会话菜单还有启动、停止和管理会话的条目。\n   Option Description     Start or Stop 启动或停止仿真，执行与绿色启动或红色停止按钮相同的功能。   Change sessions\u0026hellip; 调用包含守护进程的活动CORE会话列表的CORE Sessions对话框。显示会话的名称、节点数、起始时间和缩略图等基本信息。这个对话框允许连接到不同的会话，关闭会话，或启动一个新的会话等功能。   Node types\u0026hellip; 调用核心节点类型对话框，执行与网络层节点工具栏上的编辑按钮相同的功能。   Comments\u0026hellip; 调用CORE Session Comments窗口，其中可以指定可选的文本注释。这些注释保存在配置文件的顶部，对于描述拓扑或如何使用网络非常有用。   Hooks\u0026hellip; 调用CORE Session Hooks窗口，其中脚本可以配置为特定的会话状态。会话状态定义在下面的表格中。窗口的顶部有一个已配置的钩子列表，左下方的按钮允许添加、编辑和删除钩子脚本。新建或编辑按钮将打开一个钩子脚本编辑窗口。hook脚本是在主机上(不是在虚拟节点内)调用的shell脚本。   Reset node positions 如果您已经使用鼠标或通过移动模块移动了节点，选择该项目将重置所有节点到它们在画布上的原始位置。当您第一次按下Start按钮时，就已经记录节点位置。   Emulation servers\u0026hellip; 调用CORE仿真服务器对话框进行配置。   Options\u0026hellip; 提供每个会话的选项，如是否使用的IPv4前缀，控制网络保存会话目录的能力，SDT3D支持的开/关等。    会话状态    状态 描述     定义 GUI 用来告诉后端清除任何状态。   配置 当用户按下开始按钮时，节点、链接和其他配置数据将发送到后端。当用户自定义服务时，也会达到此状态。   实例 在发送配置数据后，就在创建节点之前创建实例。   运行 所有节点和网络都已构建并正在运行。(这与前面命名的全局实验脚本运行时的状态相同。)   数据收集 用户已按下停止按钮，但在服务停止和节点被关闭之前。这是从节点收集日志文件和其他数据的好时机。   关闭 所有节点和网络都已被关闭和销毁。    连接物理网络 CORE 的模拟网络可实时运行，因此可以连接到实时物理网络。RJ45 工具和隧道工具有助于连接到现实世界。这些工具可从链接层节点菜单中获取。\n当两个或多个CORE仿真连接在一起时，应该避免MAC地址冲突。开始仿真时，CORE自动为各接口分配MAC地址，起始地址为00:00:00:aa:00:00，从底字节开始递增。第二台机器上的CORE的MAC起始地址应该改变以避免冲突，使用Tool菜单的 MAC地址… 选项来设定。\nRJ45 工具 CORE中的RJ45节点代表真实CORE机器上的一个物理接口。 任何真实世界的网络设备都可以连接到该接口并进行通信实时使用CORE节点。\n其主要缺点是每个连接都需要一个物理接口。当物理接口被分配给CORE时，它可能无法用于其他任何事情。另一个需要考虑的问题是，您所连接的计算机或网络必须与运行CORE仿真的机器位于同一局域网。\n单击“链路层节点”工具栏上，在子菜单中选择“RJ45”。单击要连接到的节点附近的画布，例如路由器、集线器、交换机或WLAN。现在点击链接工具，在RJ-45和另一个节点之间做一条链接。该RJ45节点将显示“UNASSIGNED”。双击RJ45节点，分配物理接口。将显示可用接口列表，可以双击列表中的接口名称进行选择，也可以在文本框中输入接口名称。\n 注意:当你按下Start按钮实例化你的拓扑时，分配给RJ45的接口将连接到CORE拓扑。系统无法再使用该接口。\n 如果使用802.1x VLAN，可以在CORE内部使用多个RJ45节点，并将其分配到同一个物理接口。这允许RJ45节点比物理网口更多。 但(例如交换机)硬件连接到物理端口必须支持VLAN标签，可用的带宽将被共享。\n您需要在Linux主机上创建单独的VLAN虚拟设备，然后将这些设备分配给CORE内部的RJ45节点。 VLANning实际上是在CORE外部执行的，所以当CORE模拟节点收到传输给Vlan的数据包时，会自动将VLAN tag移除。VLAN基本知识\n以下是在Linux下创建VLAN设备的命令示例:\nip link add link PHYS_DEV name.1 type vlan id 1 ip link add link PHYS_DEV name.2 type vlan id 2 ip link add link PHYS_DEV name.3 type vlan id 3  隧道工具 隧道工具在CORE仿真或其他主机之间构建GRE隧道。 当物理接口的数量有限或对等体位于不同的网络时，隧道技术会很有帮助。 物理接口也不需要像RJ45工具那样专用于CORE。\n对端GRE隧道端点可能是另一台支持GRE隧道的CORE机器或另一台主机。 当放置一个Tunnel隧道节点时，该节点最初将显示“UNASSIGNED”。 此处需要替换为隧道对接处的IP地址。这是另一个CORE机器或物理机器的IP地址，而不是另一个虚拟节点的IP地址。\n 注意 GRE设备可能存在的MTU(最大传输单元)问题。gre tap设备接口MTU为1458字节,当连接到Linux网桥时，网桥的MTU也变成1458字节。如果其他网桥端口具有更高的MTU(比如1500字节)，那个Linux网桥将不会对该大数据包执行分片。\n GRE密钥用于识别使用GRE隧道的流。这使得多个GRE隧道存在于同一对隧道对等体之间。 当多个隧道与同一个对等体使用时，应使用一个唯一的编号。 当配置隧道对端时，确保匹配的密钥为使用。\n下面是在Linux上构建隧道另一端的示例命令。 在这个例子中，CORE中的路由器拥有虚拟地址 10.0.0.20/24 ，Core主机（设为user1）的真实地址为192.168.163.130/24。 将与CORE机器连接的Linux机器（设为user2）可以通过真实的网络在192.168.163.133/24处访问。\n仿真路由器与Tunnel节点相连。在隧道节点配置对话框中，输入地址192.168.163.133，密钥为1。\n# 这些命令在匹配tunnel的用户user2上执行 sudo ip link add gt0 type gretap remote 192.168.163.130 local 192.168.163.133 key 1 # Linux机器上的gretap接口将从虚拟路由器节点的子网中分配一个地址10.0.0.22/24。 sudo ip addr add 10.0.0.22/24 dev gt0 sudo ip link set dev gt0 up  现在虚拟路由器应该可以ping通Linux机器User2了:\n# from the CORE router node ping 10.0.0.22 # 如果想要直接ping物理地址加条路由即可 ip route add 192.168.163.133 via 10.0.0.22  User2应该能够ping通内核仿真内部:\n# from the tunnel peer ping 10.0.0.20  要调试此配置，tcpdump可以在gretap设备上运行，也可以在CORE或Linux机器的物理接口上运行。 确保防火墙没有阻断GRE流量。\n与主机通信 节点不一定要可以访问到运行core-gui或core-daemon的主机。例如，在一个节点上运行一个X11应用程序可以使用特定的通信方式让应用程序连接到X服务器以进行图形化显示。有几种不同的方式可以从节点连接到主机，反之亦然。\n控制网络 通过控制网络是与主机连接的最快方式。 通过控制网络，主机可以在节点上启动X11应用程序。首先要在该节点上启用SSH服务，并且使用SSH来进行从主机到该节点的X11服务转发。\nSSH原理与运用（一）：远程登录 \nSSH原理与运用（二）：远程操作与端口转发\n# 节点n5使用ssh来转发主机运行x协议标准的时钟xclock程序界面 ssh -X 172.16.0.5 xclock  注意，可以使用coresendmsg将消息发送到主机上运行的CORE守护进程与运行的仿真交互 (需要 /etc/core/core.conf 的配置文件中设定监听地址为广播即 listenaddr = 0.0.0.0 ) 例如，一个节点可以通过上述方法移动自己或其他节点，或者根据某个节点的状态更改其图标。\n其他方法 还有其他方法可以将主机与节点连接起来。RJ-45工具可以配合虚拟接口访问节点:\n# 或者使用modprobe命令创建dummy设备 sudo modprobe dummy numdummies=1 # 但是使用ip link show无法查看到，不知是否失效， # 推荐使用ip命令创建 sudo ip link add dummy0 type dummy # 使用方法 ip link del dev \u0026lt;dummy-interface\u0026gt; ip link add dev \u0026lt;dummy-interface\u0026gt; type dummy ip addr add \u0026lt;IPv4\u0026gt;/32 dev \u0026lt;dummy-interface\u0026gt; ip link set \u0026lt;dummy-interface\u0026gt; up  主机上应该出现一个 dummy0 接口。使用RJ45工具分配给dummy0，并将其链接到您的场景中的一个节点。(相当于core仿真后会建立一个网桥，上述dummy0设备会attach到该网桥)会话启动后，需要在主机上配置地址。\nip link show type bridge # 根据上述命令确定core仿真的网桥名称 # 在与链接节点相同的网络上分配一个IP地址 sudo ip addr add 10.0.1.2/24 dev 该设备名  在上面的例子中，主机将有地址10.0.1.2，而连接到RJ45的节点可能有地址10.0.1.1。\n构建样本网络 有线网络 有线网络是使用链接工具创建的，以绘制两个节点之间的链接。这将自动绘制一条代表以太网链路的红线，并在网络层节点上创建新的接口。\n双击链接以调用链接配置对话框。在这里您可以更改该链路的带宽、延迟、丢失和重复速率参数。您还可以修改链接的颜色和宽度，从而影响其显示。\n链路层节点用于对有线网络进行建模。这些不会产生 一个单独的网络堆栈，而是使用Linux网桥实现。 这些是集线器、交换机和无线局域网节点。集线器从 每个连接的链路的传入链路，而交换机的行为更像是 以太网交换机，并跟踪连接的对等体的以太网地址， 只转发单播流量到适当的端口。\n无线网络 WLAN节点允许您构建无线网络，移动节点会影响它们之间的连接。一对节点之间越紧密，连接越强;节点之间越远连接越弱。无线局域网(WLAN)节点以小云的形式出现。根据您的建模需求，WLAN提供了多个级别的无线仿真保真度。\nWLAN工具可以通过插件进行扩展，以实现不同级别的无线保真度。基本的开/关范围是所有平台上可用的默认设置。其他插件以更高的复杂性和CPU使用量为代价提供更高的保真度。某些插件的可用性因平台而异。关于无线模型类型的简要概述，请参见下表。\n   模型 类型 支持平台 保真度 描述     basic on/off Linux Low 使用ebtables的以太网桥接   EMANE Plug-in Linux High TAP设备连接到EMANE模拟器的可插拔的MAC和PHY无线射频模型    要快速构建无线网络，您可以首先将多个路由器节点放置在画布上。如果您安装了 Quagga MDR 软件，建议您使用mdr节点类型来减少开销路由。接下来从链接层节点子菜单选择无线局域网。首先通过双击云图标设置所需的 WLAN 参数。然后，您可以通过右键单击 WLAN 并选择链接到所有路由器来链接所有路由器。\n将路由器连接到 WLAN 会导致出现小天线，但不会绘制红色链接线。路由器可以具有多个无线链接以及无线和有线链接（但是您需要重新手动设置路由。mdr 节点类型将生成路由配置，使 OSPFv3 具有 MANET 扩展。这是波音公司开发的对QuaggaOSPFv3的扩展，可减少洪泛费用，并优化移动临时（MANET）移动自组网络的洪泛过程。\nWLAN 的默认配置设置为使用基本basic模型，使用 WLAN 配置对话框中的基本选项卡。选择此模型会导致core-daemon基于屏幕像素位置来计算节点之间的距离。使用 范围滑块（Range slider） 为无线网络设置屏幕像素的数字范围。当两个无线节点在它们之间画了一条绿线，它们是相连的。两个距离超过像素距离的无线节点不被连接。在执行模式中，用户可以通过单击和移动无线节点拖动它们，无线链接就会被动态创建或断开。\nEMANE 选项卡列出了可用于无线网络的可用 EMANE 模型。有关使用 EMANE 的详细信息，请参阅Emane。\n移动性脚本 CORE下述方法来设置脚本移动性。\n   选项 描述     ns-2 script 该脚本指定了绝对位置或具有速度的路径点。位置用笛卡尔坐标给出。   CORE API 外部实体可以通过发送带有更新的X,Y坐标的CORE API Node消息来移动节点;coresendmsg实用程序允许shell脚本生成这些消息。   EMANE events 有关使用EMANE脚本移动节点的详细信息，请参见[EMANE .md]。位置信息通常以纬度、经度和高度给出。    对于第一种方法，可以使用文本编辑器或BonnMotion之类的工具创建移动脚本，并将脚本与使用WLAN配置对话框中的一个无线连接起来，点击 ns-2 mobility script\u0026hellip; 按钮, 并在 ns2script 中的配置对话框设置 mobility script file 字段\nBonnMotion安装教程：官网下载 BonnMotion 安装包，解压，进入目录运行./install即可(需要事先安装jdk，sudo apt-get install default-jdk)。官方使用指南点这里进行下载。\n下面是一个为10个节点创建BonnMotion脚本的示例:\nbm -f sample RandomWaypoint -n 10 -d 60 -x 1000 -y 750 bm NSFile -f sample # 第二行是将sample.movements转为sample.ns_movements ns脚本移动数据 # 自己测试发现 /usr/bin/中并没有 bm，执行文件在安装包文件夹下 ./bin/bm # 创建个软链接 sudo ln -s ~/桌面/bonnmotion-3.0.1/bin/bm /usr/bin  在启动Execute模式并且其中一个WLAN节点具有移动性时 脚本时，将出现一个移动脚本窗口。此窗口包含控件 启动、停止和重置移动性脚本的运行时间，loop 复选框设置脚本连续重复调用。分辨率resolution 文本框包含每个计时器事件之间的毫秒数;较低的值使移动性看起来更流畅，但消耗更多的CPU时间。\nns-2移动脚本的格式如下:\n# nodes: 3, max time: 35.000000, max x: 600.00, max y: 600.00 $node_(2) set X_ 144.0 $node_(2) set Y_ 240.0 $node_(2) set Z_ 0.00 $ns_ at 1.00 \u0026quot;$node_(2) setdest 130.0 280.0 15.0\u0026quot;  前三行设置节点2的初始位置。上面例子中的最后一行导致节点2以速度 15 向目的地 (130,280) 移动。所有单位都是屏幕坐标，速度以每秒为单位。总脚本时间是在所有节点到达它们的路径点之后得到的。 最初，移动脚本对话框中的时间滑块并不准确。\n示例移动脚本(及其相关的拓扑文件)可以在 configs/ 目录中找到。\n多画布 CORE 支持多个画布，用于组织模拟节点。在不同的画布上运行的节点可以链接在一起。要创建一个新的画布，从 canvas 菜单中选择 new 。一个新的画布标签出现在左下角。点击一个画布标签切换到它画布。双击其中一个选项卡来调用 Manage Canvases 对话框盒子。在这里，画布可以重命名和重新排序，你可以很容易地切换到并选择其中一幅画布。\n每个画布维护自己的一组节点和注释。画布之间要构建联系首先选择一个节点，右键单击它，选择 Create link to ，选择列表中的目标画布，以及该子菜单中的所需节点。之后将绘制一个伪链接，表示上两个节点之间的链接到不同的画布。双击箭头末端的标签即可跳转到它所链接的画布。\n检查仿真灯（CEL） CEL（Check Emulation Light）位于GUI的右下角，这是一个黄色图标，指示运行模拟中的一个或多个问题。单击CEL将调用CEL 对话框。Check Emulation Light对话框包含从CORE守护进程接收到的异常列表。异常列表包含有时间、严重级别、可选节点号和来源这些信息。当CEL闪烁时，这表示一个或多个致命异常。\n具有致命严重级别的异常表明无法创建模拟的一个或多个基本部分，例如无法创建桥或名称空间，或者无法为基于eman1的网络启动eman1进程。单击异常将显示该异常的详细信息。如果指定了节点号，当选中异常时，该节点将在画布上高亮显示。异常源是一个文本字符串，用于帮助跟踪异常发生的位置;例如，UserDefined服务的验证命令失败时，会出现 \u0026ldquo;service:UserDefined\u0026rdquo; 。\n对话框底部有一些按钮，用于清除异常列表和查看CORE守护进程和节点日志文件。\n 注意: 在批处理模式下，从CORE守护进程接收到的异常将显示在控制台上。\n 场景配置文件 场景配置拓扑文件保存为 .xml 或 .imn 。你可以轻松地编辑这些文件与文本编辑器。当您编辑拓扑时文件，您将需要停止模拟(如果它正在运行)并重新加载文件。\n.imn 文件格式来自IMUNES，主要成分是 节点、链接、etc的Tcl链表。 拓扑文件中的制表符Tab和空格有严格规范。该文件首先列出每个节点，然后列出链接、注释、画布和选项。每个实体都有一个包含在花括号中的块。第一个块缩进四个空格。 在 network-config 块(以及任何 custom\u0026ndash;config 块)中，缩进是一个制表符。\n 注意: 有几个拓扑示例包括在CORE中的：~/.core/configs, 如果Core安装到文件系统中则在 /usr[/local]/share/examples/configs.\n  注意: 当使用 Imn 文件格式，特定文件路径： CORE_DATA_DIR = /usr/share/core, CONFDIR = ~/.core/configs\n  注意: 您可以使用最喜欢的文本编辑器直接编辑文件。\n 定制您的拓扑外观 提供多个注释工具来改变您的拓扑呈现方式。文字工具可以添加字幕。椭圆形和矩形可能绘制在后台，有助于在视觉上将节点分组在一起。\n在实时演示期间，标记工具可能有助于在画布上绘制可能很快被擦除的临时注释。选择标记工具时，工具栏底部会出现大小和调色板。标记只是暂时的，不会保存在拓扑文件中。\n基本节点图标可以替换为您选择的自定义图像。图标在使用具有透明背景的 GIF 或 PNG 格式时显示得最好。要更改节点的图标，请双击节点以调用其配置对话框，然后单击显示节点当前图标的节点名称右侧的按钮。\n画布的背景图像可以使用 canvas 菜单中的 Wallpaper… 设置。图像可以居中、平铺或以中心做缩放来适应画布大小。例如，可以使用现有的地形、地图或网络图可以用作背景，并将CORE节点绘制在顶部。。\n偏好 Preferences 对话框可以从 Edit_Menu 访问。此对话可以设置许多默认值，这些默认值存储在 ~/.core/prefs.conf 首选项文件中。\n","id":18,"section":"posts","summary":"使用 CORE GUI 下图显示 CORE GUI: 概述 GUI 用于在画布上绘制节点和网络设备，将它们连接在一起，以创建模拟的网络会话。 按下启动按钮后，CORE 将通过这些阶段进行","tags":[""],"title":"Core Gui","uri":"https://liangkang233.github.io/2021/07/gui/","year":"2021"},{"content":"go指南练习 新手初学Go语言，看到这个go指南网站在线测试很方便做了几道练习后就在上面学习。 其中最后一页的测试： go指南练习:web爬虫 学了go的并发基本使用方法后，觉得比c的多线程好写多了，所以最后的模拟web爬虫练习的代码贴出来，希望指教下怎么写更安全、高效。\n题目要求 /* 练习：Web 爬虫 在这个练习中，我们将会使用 Go 的并发特性来并行化一个 Web 爬虫。 修改 Crawl 函数来并行地抓取 URL，并且保证不重复。 提示：你可以用一个 map 来缓存已经获取的 URL， 但是要注意 map 本身并不是并发安全的！ */ // TODO: 并行的抓取 URL。 // TODO: 不重复抓取页面。 // Crawl 并没有实现上面两种情况：  修改部分 该代码其实是对伪造的fakeFetcher进行抓取，每个伪造结果map内的元素是一个结构体fakeResult。 该结构体元素由body字段（真正要展示的内容）和归属的urls。 Crawl函数调用Fetcher接口的fetcher方法对fakeResult的body字段匹配，并打印匹配到的body出来，没找到就打印报错。 若是匹配成功，Crawl深度减一递归的调用Crawl，url使用匹配body对应的fakeResult下的urls切片每一个url值。\n 要求使用并发的实现 所以为了不改变原函数模板采用sync.WaitGroup来进行主进程等待子进程结束。  // sync.WaitGroup 用法 var wg sync.WaitGroup wg.Add(i int) //添加i个worker协程 wg.Done()\t//该子进程结束，做记录 wg.Wait() //当worker协程未全部执行结束，会一直堵塞  要求使用map记录已经爬取的页面避免重复抓取 由于map非并发安全（多个goroutine同时写入map会报错），添加互斥锁解决。  // 带互斥锁的map，防止并行的写入 type SafeUrlMap struct { set map[string]int mux sync.Mutex } func (myset SafeUrlMap) add(url string) { myset.mux.Lock() // elem, ok = set[url] myset.set[url]++ myset.mux.Unlock() } func (myset SafeUrlMap) have(url string) bool { myset.mux.Lock() if myset.set[url] != 0 { defer myset.mux.Unlock() return true } return false }\t 完整代码 package main import ( \u0026quot;fmt\u0026quot; \u0026quot;sync\u0026quot; ) type Fetcher interface { // Fetch 返回 URL 的 body 内容，并且将在这个页面上找到的 URL 放到一个 slice 中。 Fetch(url string) (body string, urls []string, err error) } // Crawl 使用 fetcher 从某个 URL 开始递归的爬取页面，直到达到最大深度。 func Crawl(url string, depth int, fetcher Fetcher) { if depth \u0026lt;= 0 { wg.Done() return } if myset.have(url) { wg.Done() return } body, urls, err := fetcher.Fetch(url) myset.add(url) // 无论该网页是否找到，都做一次记录防止下次重复抓取 if err != nil { fmt.Println(err) wg.Done() return } fmt.Printf(\u0026quot;found: %s %q\\n\u0026quot;, url, body) for _, u := range urls { wg.Add(1) go Crawl(u, depth-1, fetcher) } wg.Done() return } func main() { myset = SafeUrlMap{set: make(map[string]int)} wg.Add(1) Crawl(\u0026quot;https://golang.org/\u0026quot;, 4, fetcher) wg.Wait() } // 带互斥锁的map，防止并行的写入 type SafeUrlMap struct { set map[string]int mux sync.Mutex } // url记录的查询方法 func (myset SafeUrlMap) add(url string) { myset.mux.Lock() // elem, ok = set[url] myset.set[url]++ myset.mux.Unlock() } // url记录的添加方法 func (myset SafeUrlMap) have(url string) bool { myset.mux.Lock() if myset.set[url] != 0 { defer myset.mux.Unlock() return true } return false } // fakeFetcher 是返回若干结果的 Fetcher。 type fakeFetcher map[string]*fakeResult type fakeResult struct { body string urls []string } func (f fakeFetcher) Fetch(url string) (string, []string, error) { if res, ok := f[url]; ok { return res.body, res.urls, nil } return \u0026quot;\u0026quot;, nil, fmt.Errorf(\u0026quot;not found: %s\u0026quot;, url) } // 已采集的Url清单,采集进程组 var ( myset SafeUrlMap wg sync.WaitGroup ) // fetcher 是填充后的 fakeFetcher。 var fetcher = fakeFetcher{ \u0026quot;https://golang.org/\u0026quot;: \u0026amp;fakeResult{ \u0026quot;The Go Programming Language\u0026quot;, []string{ \u0026quot;https://golang.org/pkg/\u0026quot;, \u0026quot;https://golang.org/cmd/\u0026quot;, }, }, \u0026quot;https://golang.org/pkg/\u0026quot;: \u0026amp;fakeResult{ \u0026quot;Packages\u0026quot;, []string{ \u0026quot;https://golang.org/\u0026quot;, \u0026quot;https://golang.org/cmd/\u0026quot;, \u0026quot;https://golang.org/pkg/fmt/\u0026quot;, \u0026quot;https://golang.org/pkg/os/\u0026quot;, }, }, \u0026quot;https://golang.org/pkg/fmt/\u0026quot;: \u0026amp;fakeResult{ \u0026quot;Package fmt\u0026quot;, []string{ \u0026quot;https://golang.org/\u0026quot;, \u0026quot;https://golang.org/pkg/\u0026quot;, }, }, \u0026quot;https://golang.org/pkg/os/\u0026quot;: \u0026amp;fakeResult{ \u0026quot;Package os\u0026quot;, []string{ \u0026quot;https://golang.org/\u0026quot;, \u0026quot;https://golang.org/pkg/\u0026quot;, }, }, }  ","id":19,"section":"posts","summary":"go指南练习 新手初学Go语言，看到这个go指南网站在线测试很方便做了几道练习后就在上面学习。 其中最后一页的测试： go指南练习:web爬虫 学了","tags":["go"],"title":"Go指南练习","uri":"https://liangkang233.github.io/2021/06/go%E6%8C%87%E5%8D%97%E7%BB%83%E4%B9%A0-web%E7%88%AC%E8%99%AB/","year":"2021"},{"content":"VScode是一款非常好用的代码编辑器，还拥有强大的在线扩展插件。甚至可以进行代码的debug，整理了下配置过程遇到的问题分享出来。 我使用的windows平台vscode版本为V1.56。\n通用配置 VS Code内置了对Node.js运行时的调试支持，可以调试JavaScript、TypeScript或JavaScript语言。\n要调试其他语言(包括PHP, Ruby, Go, c#， Python, C++， PowerShell等)时，在VS Code扩展中寻找调试器扩展，或者在顶级运行菜单中选择安装额外的调试器。\n确定安装可以编译调试的扩展或软件再进行以下步骤：\n右击工程文件夹使用VScode打开。 打开需要编译、运行的文件，点击顶部菜单-\u0026gt;运行-\u0026gt;添加配置\u0026hellip;选择需要debug的类型，之后根据语言及即可在 .vscode文件夹下生成launch.json文件。生成的json文件对整个文件夹和子文件夹生效。\n举例如何debug go 以go语言为例，路径切换至当前工程文件夹。首先安装调试软件推荐使用dlv，终端中输入\ngo get -u github.com/go-delve/delve/cmd/dlv # 未生成mod还得添加mod才能调试\tgo mod init yourProjectName  一切准备就绪后，点击上述步骤生成launch.json文件，此处会让你选择调试包还是附着到本地进程或远程服务器调试。 选择默认的调试package，这里打开生成的默认json\n{ // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;, \u0026quot;configurations\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;Launch Package\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;go\u0026quot;, \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;, \u0026quot;mode\u0026quot;: \u0026quot;auto\u0026quot;, \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}\u0026quot; } ] }  需要添加新的配置直接点击右下角即可，\u0026ldquo;name\u0026quot;的值为左标签页调试器的名字用于区分用。\n“type”语言类型设置为go，vs code 用于设定调试代码扩展类型。”mode“可以设置为 auto, debug, remote, test, exec 中的一个。\n”program“调试程序的路径（绝对路径），这里使用workspaceFolder说明对整个工作区目录文件进行调试。\n各配置变量的含义 其中有许多vscode定义的变量，这里列出常用的：\n ${workspaceFolder} - 在VS Code中打开的文件夹路径 ${workspaceFolderBasename} - 在VS Code中打开的文件夹的名称没有任何斜杠(/) ${file} - 当前打开的文件名 ${fileWorkspaceFolder} - 当前打开的文件的工作区文件夹 ${relativeFile} - 当前打开的文件名相对于workspaceFolder ${relativeFileDirname} - 当前打开的文件的目录名相对于workspaceFolder ${fileBasename} - 当前打开的文件的基名 ${fileBasenameNoExtension} - 当前打开的文件的基名没有文件扩展名 ${fileDirname} - 当前打开文件的目录名 ${fileExtname} - 当前打开的文件的扩展名 ${cwd} - 任务运行器启动时的当前工作目录 ${lineNumber} - 当前选中的行号在活动文件中 ${selectedText} - 活动文件中当前选定的文本 ${execPath} - 运行VS Code可执行文件的路径 ${defaultBuildTask} - 默认构建任务的名称 ${pathSeparator} - 操作系统用于分隔文件路径中的组件的字符 ${pathSeparator} - 在macOS或linux系统为/, 在Windows上为\\  关于debug C/C++ 该文件设置debug的各项配置根据语言的不同，设置也不尽相同。这里介绍c/c++的具体配置流程。  总结各文件作用 与其他语言类似的，debug的配置文件也是生成在.vscode文件夹中。 c/c++程序配置一般有三个文件：\n tasks.json（如何编译生成可执行程序） launch.json（调试设置） c_cpp_properties.json（编译器路径和vscode感知设置） 其中c_cpp_properties非常坑，由于我使用了自己写的头文件在c_cpp_properties.json的includePath项目配置各种路径类型都不生效，后面才看懂这个只是让vscode识别头文件该跳转的路径而已，真正要添加外部库或头文件的话要么放在系统默认库、头文件路径，要么在task.json中配置生成。  具体流程 c/c++代码需要先编译链接生成可执行程序（tasks.json），再使用gdb调试（launch.json），c_cpp_properties.json设置c/c++使用语言标准例如c++11等。注意：调试前确保系统环境已配置g++、gdb。验证方法：\n要检查您的 Mingw-w64 工具是否正确安装和可用，请打开新的命令提示并键入： g++ \u0026ndash;version gdb \u0026ndash;version 以此工程文件夹为例，main函数调用了lib文件夹下的stu_rw.h文件\n打开main.cpp文件，点击顶部菜单-\u0026gt;终端-\u0026gt;配置默认生成任务，选择使用g++生成活动文件。打开生成的task.json文件\n{ \u0026quot;version\u0026quot;: \u0026quot;2.0.0\u0026quot;, \u0026quot;tasks\u0026quot;: [ { \u0026quot;type\u0026quot;: \u0026quot;cppbuild\u0026quot;, \u0026quot;label\u0026quot;: \u0026quot;C/C++: g++.exe 生成活动文件\u0026quot;, \u0026quot;command\u0026quot;: \u0026quot;C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin\\\\g++.exe\u0026quot;, \u0026quot;args\u0026quot;: [ \u0026quot;-g\u0026quot;, \u0026quot;-Wall\u0026quot;, //显示全部详细警告 \u0026quot;-std=c++11\u0026quot;, //支持C11 \u0026quot;${file}\u0026quot;,\t\u0026quot;-I\u0026quot;, \u0026quot;${workspaceFolder}\\\\lib\u0026quot;, \u0026quot;-o\u0026quot;, \u0026quot;${fileDirname}\\\\${fileBasenameNoExtension}.exe\u0026quot; ], \u0026quot;options\u0026quot;: { \u0026quot;cwd\u0026quot;: \u0026quot;${fileDirname}\u0026quot; }, \u0026quot;problemMatcher\u0026quot;: [ \u0026quot;$gcc\u0026quot; ], \u0026quot;group\u0026quot;: { \u0026quot;kind\u0026quot;: \u0026quot;build\u0026quot;, \u0026quot;isDefault\u0026quot;: true }, \u0026quot;detail\u0026quot;: \u0026quot;编译器: \\\u0026quot;C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin\\\\g++.exe\\\u0026quot;\u0026quot; } ] }  其中args选项即为g++编译链接选项，如上所示我已经添加了\u0026rdquo;-I\u0026quot;相关参数添加头文件路径，c11标准。静态库链接等就放-o选项后，除最后一行配置文件每行都得加逗号。\n之后打开main.cpp点击顶部菜单-\u0026gt;终端-\u0026gt;运行生成任务，看是否生成成功。\n之后设定debug选项，点击顶部菜单-\u0026gt;运行-\u0026gt;添加配置，选择gdb、之后选g++生成默认配置。 下面展示配置的说明：\n{ // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;, \u0026quot;configurations\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;g++.exe - 生成和调试活动文件\u0026quot;,\t// 配置名称，将会在启动配置的下拉菜单中显示 \u0026quot;type\u0026quot;: \u0026quot;cppdbg\u0026quot;, \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\t// 请求配置类型，可以为launch（启动）或attach（附加） \u0026quot;program\u0026quot;: \u0026quot;${fileDirname}\\\\${fileBasenameNoExtension}.exe\u0026quot;,\t// 将要进行调试的程序的路径 \u0026quot;args\u0026quot;: [],\t// 程序调试时传递给程序的命令行参数，一般设为空即可 \u0026quot;stopAtEntry\u0026quot;: false, \u0026quot;cwd\u0026quot;: \u0026quot;${fileDirname}\u0026quot;, \u0026quot;environment\u0026quot;: [], \u0026quot;externalConsole\u0026quot;: false, \u0026quot;MIMode\u0026quot;: \u0026quot;gdb\u0026quot;, \u0026quot;miDebuggerPath\u0026quot;: \u0026quot;C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin\\\\gdb.exe\u0026quot;, \u0026quot;setupCommands\u0026quot;: [ { \u0026quot;description\u0026quot;: \u0026quot;为 gdb 启用整齐打印\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;-enable-pretty-printing\u0026quot;, \u0026quot;ignoreFailures\u0026quot;: true } ], \u0026quot;preLaunchTask\u0026quot;: \u0026quot;C/C++: g++.exe 生成活动文件\u0026quot; } ] }  如果您想要对 C/C++扩展进行更多控制，c_cpp_properties.json将配置如编译器的路径，include路径、C++标准（默认值为 C++17）等等。\n通过命令终端（Ctrl+Shift+P）输入\u0026gt;c/c++，有两个选项一个是直接配置json一个是通过UI界面配置。\n这里的C/C++ 配置UI页面，基本保持默认即可。注意这里的配置编辑器是给vscode和扩展使用的，不影响task.json来配置真正生成可执行程序的过程。\n","id":20,"section":"posts","summary":"VScode是一款非常好用的代码编辑器，还拥有强大的在线扩展插件。甚至可以进行代码的debug，整理了下配置过程遇到的问题分享出来。 我使用的","tags":[""],"title":"Vscode配置debug","uri":"https://liangkang233.github.io/2021/06/vsode%E9%85%8D%E7%BD%AEdebug/","year":"2021"},{"content":"背景 我目前需要解决一个需求，将一个c工程中的特定数据转发到VUE前端框架上做界面展示，且该框架已经有后端为flask框架。\n所以得考虑如何将c工程中的数据发送到python中。容易知道，进程间通信的方式有管道、信号量、消息队列、共享内存、套接字等。为了简易实现上述功能和尽量不影响他们两边原先进程的功能，使用套接字发送封装的数据做http请求给flask后端，这样来实现数据转发。\nHTTP（超文本传输协议）是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP请求的资源由统一资源标识符（Uniform Resource Identifiers，URI）来标识。具体区别这篇博客讲的很详细。总而言之http连接=以http协议为通信协议的tcp连接，http协议可以由tcp协议封装报文而来，现在要解决的就是c的套接字如何封装成符合http协议的get/post请求。\n参考案例 最开始找了网上很多案例，tcp套接字细节此处不赘述。http请求就是其tcp传输附上对应http请求的报文，但是实际测试不对，没有相应返回。猜想到可能测试环境不同封装格式也要改变，所以使用wireshark抓包软件抓了个具体的数据包来分析。 使用的get、post请求的html页面\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;GET and POST\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action = \u0026quot;http://localhost:5000\u0026quot; method = \u0026quot;get\u0026quot;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Name\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type =\u0026quot;text\u0026quot; name =\u0026quot;username\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Password\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type =\u0026quot;password\u0026quot; name =\u0026quot;password\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type = \u0026quot;get submit\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;form action = \u0026quot;http://localhost:5000\u0026quot; method = \u0026quot;post\u0026quot;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Name\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type =\u0026quot;text\u0026quot; name =\u0026quot;username\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;Password\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type =\u0026quot;password\u0026quot; name =\u0026quot;password\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;input type = \u0026quot;post submit\u0026quot;\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  后端flask接收代码\nfrom flask import Flask, request app = Flask(__name__) @app.route('/', methods=['GET']) def index(): username = request.args.get('username') password = request.args.get('password') if username == \u0026quot;xugaoxiang\u0026quot; and password == \u0026quot;xugaoxiang\u0026quot;: return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;Welcome {username}\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; else: return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;Welcome!\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; @app.route('/', methods=['POST']) def index(): username = request.form['username'] password = request.form['password'] if username == \u0026quot;xugaoxiang\u0026quot; and password == \u0026quot;xugaoxiang\u0026quot;: return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;Welcome {username}\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; else: return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;Welcome!\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; if __name__ == '__main__': app.run(debug=True)  测试案例取自此教程，贴出教程源码链接：https://github.com/xugaoxiang/FlaskTutorial 其抓包结果如下所示： 只需要关注http数据包中的tcp报文内容即可。 具体实现 注：为了解决大小端和数据位数不统一的问题，我是将所有数据转为字符串来发送。如果想要发送json等数据格式同样用抓包看下具体如何封装即可，此处简易的实现先不考虑那些功能。 有了上面的数据样本，进行下面c代码的封装转发。使用环境不同，部分函数可能有所变化。这里只展示基础模板。 真正通用的是下面这段补齐信令的函数\nvoid addget(const char* str1) //补齐get信令数据 { strcat(str1, \u0026quot;Host: 127.0.0.1\\r\\n\u0026quot;);//cname记录不影响连接，此处不做修改 strcat(str1, \u0026quot;Content-Type: text/html\\r\\n\\r\\n\u0026quot;); } void addpost(char* str1, const char* data) //补齐post信令数据 { char postlength[128]; sprintf(postlength, \u0026quot;%d\\r\\n\u0026quot;, strlen(data + 1)); strcat(str1, \u0026quot;Host: 127.0.0.1\\r\\n\u0026quot;);//cname记录不影响连接，此处不做修改 strcat(str1, \u0026quot;Content-Type: application/x-www-form-urlencoded\\r\\n\u0026quot;); strcat(str1, \u0026quot;Content-Length: \u0026quot;); strcat(str1, postlength); strcat(str1, \u0026quot;\\r\\n\\r\\n\u0026quot;); strcat(str1, data + 1);\t} /* 调用方式 //data即为传输而来的数据 case get_test:{\t// 封装成http的get请求 strcpy(str1, \u0026quot;GET /getsometing?\u0026quot;); strcat(str1, data + 1); strcat(str1, \u0026quot; HTTP/1.1\\r\\n\u0026quot;); addget(str1); break; } case post_test:{\t// 封装成http的post请求 strcpy(str1, \u0026quot;POST /postsometing HTTP/1.1\\r\\n\u0026quot;); addpost(str1, data); break;\t} */  请求代码模板 只讨论http请求方面内容，展示基础的tcp套接字绑定及封装http请求流程\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;winsock2.h\u0026gt; #include \u0026lt;windows.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #define PORT 5000\t// 设定发送端口 #define BUFSIZE 1024 #define DATASIZE 2000 enum send_flask_type { start=1, accomplish, get_test, post_test }; // 实现函数，flaskip为http请求的ip地址 此处为环回地址127.0.0.1 data为传输数据(例如type=start) send_type设定传输方式 int HandleFlask(const char* flaskip, const char* data, int send_type) { int i, sockfd_flask; fd_set t_set1; struct timeval timeset; struct sockaddr_in flaskaddr; char str1[2 * DATASIZE], buf[BUFSIZE]; //* 创建flask连接套接字 *// if ((sockfd_flask = socket(AF_INET, SOCK_STREAM, 0)) \u0026lt; 0 ) { printf(\u0026quot;创建网络连接失败,本线程即将终止!\\n\u0026quot;); return -1; } flaskaddr.sin_family = AF_INET; flaskaddr.sin_addr.s_addr = inet_addr(flaskip); flaskaddr.sin_port = htons(PORT); memset(\u0026amp;flaskaddr.sin_zero, 0, 8); if (connect(sockfd_flask, (struct sockaddr *)\u0026amp;flaskaddr, sizeof(flaskaddr)) \u0026lt; 0){ printf(\u0026quot;连接到flask服务器失败!\\n\u0026quot;); return -1; } // printf(\u0026quot;连接Flask服务器成功\\n\u0026quot;); switch(send_type) { case get_test:{\t/* 封装成http的get请求 */ strcpy(str1, \u0026quot;GET /getsometing?\u0026quot;); // if(SplitStr(data + 1, str1) \u0026lt; 0) { //将data中的tpye数字类型转成字符串并添加至str1 // printf(\u0026quot;需要转发的报文格式有误\\n\u0026quot;); // return -1; // } strcat(str1, data + 1); strcat(str1, \u0026quot; HTTP/1.1\\r\\n\u0026quot;); addget(str1); break; } case post_test:{\t/* 封装成http的post请求 */ strcpy(str1, \u0026quot;POST /postsometing HTTP/1.1\\r\\n\u0026quot;); addpost(str1, data); break;\t} default:{ printf(\u0026quot;接收到无效格式，舍弃\\n\u0026quot;); return 0; } } i = send(sockfd_flask, str1, strlen(str1), 0); if (i \u0026lt; 0) { // printf(\u0026quot;发送失败！错误代码是%d，错误信息是'%s'\\n\u0026quot;,errno, strerror(errno)); printf(\u0026quot;发送数据给flask失败！错误代码是%d\\n\u0026quot;, WSAGetLastError());//windows获取erron closesocket(sockfd_flask); return -1; } else { // printf(\u0026quot;消息发送至flask成功，共发送了%d个字节！send_type=%d \\n\u0026quot;, i, send_type); } // python安装插件eventlet后，外部http访问后flask不会立即关闭套接字 // (即falsk return后不会发送空的tcp报文)， // 所以此修改为不考虑复杂场景只接收一次flask的http返回数据后就关闭套接字 FD_ZERO(\u0026amp;t_set1); FD_SET(sockfd_flask, \u0026amp;t_set1); timeset.tv_sec= 0; timeset.tv_usec= 100000; //扫描堵塞时间100ms i= select(sockfd_flask +1, \u0026amp;t_set1, NULL, NULL, \u0026amp;timeset); if (i == 0) { // printf(\u0026quot;长时间未接收到flask http响应，跳过\\n\u0026quot;); // continue; // break; } else if (i \u0026lt; 0) { printf(\u0026quot;在读取flask数据报文时SELECT检测到异常，该异常导致线程终止！\\n\u0026quot;); closesocket(sockfd_flask); return -1; } else { memset(buf, 0, sizeof(buf) ); i = recv(sockfd_flask, buf, sizeof(buf), 0); if (i \u0026lt;= 0) { closesocket(sockfd_flask); if (i == 0) { // printf(\u0026quot;与flask通信的http套接字关闭\\n\u0026quot;); return 0; } else { printf(\u0026quot;接收flask数据报出现错误！错误代码是%d\\n\u0026quot;, WSAGetLastError()); //windows获取erron return -1; } } else { //对http返回值进行处理 // printf(\u0026quot;flask返回值%s\\n\u0026quot;, buf); // continue; // break; } } closesocket(sockfd_flask); return 0; }  flask接收示例 # flask后端测试用 @app.route('/getsometing', methods=['GET']) def gettest(): type = request.args.get('type') src = request.args.get('src') dst = request.args.get('dst') print(f\u0026quot;get data: type={type},src={src},dst={dst}\u0026quot;) return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;get return: type={type},src={src},dst={dst}\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; @app.route('/postsometing', methods=['POST']) def posttest(): type = request.form['type'] src = request.form['src'] dst = request.form['dst'] print(f\u0026quot;post data: type={type},src={src},dst={dst}\u0026quot;) return f\u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;post return: type={type},src={src},dst={dst}\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot;  如果数据量比较大可以这样写\n@app.route('/getsometing', methods=['GET']) def gettest(): get_data=request.args.to_dict() type = get_data['type'] cur_time=time.strftime(\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot;, time.localtime()) if type == 'Start' : #自己定义的发送数据的type pass elif type == 'Accomplish' : pass elif type == 'change' : pass else : print (\u0026quot;接收到无效数据，将其丢弃\u0026quot;) with open(\u0026quot;log.txt\u0026quot;, \u0026quot;a+\u0026quot;) as f: f.write('\\n# ' + cur_time + ' ---------- get error：\\n' + json.dumps(get_data)) return \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; Flask access invalid data \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; return \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; data access \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; @app.route('/postsometing', methods=['POST']) def posttest(): post_data = request.form.to_dict() print (post_data) type = post_data['type'] cur_time=time.strftime(\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot;, time.localtime()) if type == \u0026quot;change\u0026quot;: pass else : print (\u0026quot;接收到无效数据，将其丢弃\u0026quot;) with open(\u0026quot;log.txt\u0026quot;, \u0026quot;a+\u0026quot;) as f: f.write('\\n# ' + cur_time + ' ---------- post error：\\n' + json.dumps(post_data)) return \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; Flask access invalid data \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; return \u0026quot;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; data access \u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot;  ","id":21,"section":"posts","summary":"背景 我目前需要解决一个需求，将一个c工程中的特定数据转发到VUE前端框架上做界面展示，且该框架已经有后端为flask框架。 所以得考虑如何将c","tags":["C/C++"],"title":"C语言实现的http请求","uri":"https://liangkang233.github.io/2021/06/c%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0http%E8%AF%B7%E6%B1%82/","year":"2021"},{"content":"思路 python的特性支持快速开发实用小程序的能力，能让你做事效率大幅度提高。特别是在c++数据测试中，检验一个程序的可靠性需要大量数据进行测试可靠性。虽然c++也有随机函数等方法但是不方便移植更改，用Python编写数据生成器是再合适不过的了。接下来进行举例说明：下面的代码直接在python3终端中运行，生成一个长度在4 ~9之间， 恰好包含一个大写字母， 其他字符为小写字母的特殊串。\n\u0026gt;\u0026gt;\u0026gt; from random import* \u0026gt;\u0026gt;\u0026gt; from string import* \u0026gt;\u0026gt;\u0026gt; L = randint(4, 9) \u0026gt;\u0026gt;\u0026gt; s =''.join([choice(ascii_lowercase) for i in range(L)]) \u0026gt;\u0026gt;\u0026gt; p = randint(0, len(s)) \u0026gt;\u0026gt;\u0026gt; s[:p] + choice(ascii_uppercase) + s[p:] ' bdsqVgke'  列表解析Clist comprehension) 是一种构造列表的简单方法。range(5) 生成列表[0,1,2,3,4]。这条语句就是 “对于列表[0,1,2,3,4]中的每个数i调用一次 choice(lowercase)，把结果拼成一个列表” 。接下来用join函数把列表里的字符串连接起来。 .join(L)的作用是把字符串列表L中的各个字符串拼接起来。 最后随机出小写字符出现的位置p, 然后插入到大写字母串中。s[a:b]代表列表或者字符串的第a个元素到第b-1 个元素。a和b都可以省略，a默认为0, b默认为列表长度。L2 = L[:］的作用是创建一个和L 一样的数组。 由于Python 的所有值都是引用类型的， 因此L2=L只是把L中保存的引用拷贝（浅拷贝）到了L2，这点需要小心。例如下面的代码，求其地址id可以分析出来。\n\u0026gt;\u0026gt;\u0026gt; a,b=1,2 \u0026gt;\u0026gt;\u0026gt; a= [1,3,7] \u0026gt;\u0026gt;\u0026gt; b=[1,3,7] \u0026gt;\u0026gt;\u0026gt; c,d=a,a[:] \u0026gt;\u0026gt;\u0026gt; id (a), id (b), id (c), id (d) (12598008, 12517288, 12598008, 12517208)  计算 30!可以采用如下写法:\n\u0026gt;\u0026gt;\u0026gt; from functools import* \u0026gt;\u0026gt;\u0026gt; reduce(lambda x,y: x*y, range(1,31)) 265252859812191058636308480000000L  简单实现 类似的东西还有很多。 使用Python后， 能大大缩短编写数据生成器、对拍器、 “猜想验证器” 等小程序的时间，这里我打算把python生成的数据全部转为字符数据存入文本中(转字符数据就不用考虑int位数 浮点数精度等问题)。c++再读数据存入容器进行原本函数的测试。\npython生成数据代码 接下来的代码为进行测试写入文件的代码，作为参考：\n# !/usr/bin/env python3 # coding: utf-8 from random import * from string import * def create_element0(lines, a = 4, b = 7): elements = [] for i in range(lines): # ascii_lowercase在string中定义，为所有小写字符的列表 # choice(seq): 返回列表、元组或字符串seq的随机项str。（可重复） L = randint(a, b) s =''.join([choice(ascii_lowercase) for i in range(L)]) p = randint(0, len(s)) element = s[:p] + choice(ascii_uppercase) + s[p:] + '\\n' elements.append(element) return elements def create_element1(lines): elements = [] for i in range(lines): # sample: 不重复的取列表中i个元素，并返回这些元素组成的列表 # 不可像choice中列表添加for in，因为其返回的是列表 # 要生成m个不重复i元素列表得在外面加循环 username = ''.join(sample(ascii_letters + digits, 5)) password = randint(10000,99999) element= str(username) + \u0026quot;,\u0026quot; + str(password) + '\\n' elements.append(element) return elements def create_element2(lines): elements = [] allNum = list(range(-10000, 10000)) NumLen = len(allNum) #在allNum中抽取Len个不重复数字,最后依照题意排序，旋转。共lines组 for i in range(lines): s = [] num = randint(1, 256) for j in range(num) : index = randint(j, NumLen - 1) s.append(allNum[index]) # 把用过的元素到前面,以防再次选中 allNum[index], allNum[i] = allNum[i], allNum[index] # 模拟target是否存在，有1/36的几率必定不存在 suiji = randint(0,35) if suiji == 35: target = 10001 else : target = s[randint(0, num-1)] #排序取出的不重复数组并旋转 s.sort() k = randint(0, num-1) if k != 0 : s = list(reversed(s[0:k])) + list(reversed(s[k:num])) s.reverse() element = ' '.join([str(s[i]) for i in range(num)]) + '\\n' elements.append(element) elements.append(str(target) + '\\n') print(f\u0026quot;i = {i},\\t k = {k}, \\ttarget = {target}\u0026quot;) return elements  C++读取文件代码 C++中各种流头文件说明 iostream处理控制台IO； fstream处理命名文件IO； stringstream完成内存string的IO。 类fstream和stringstream都是继承在类iostream的。 输入类都继承自istream，输出类都继承自ostream。 string流：sstream头文件定义了三个类型来支持内存IO， 这些类型可以向string写入数据，从string读取数据，就像string是一个IO流一样。 将所有行数据打印出： 该代码仅为读取数据并载入容器中作为模板使用，若要加入判断正确等功能可以根据实际情况添加\n// 导入文本至容器，将每一行的数据以空格为间隔输入一个字符容器，将所有行的数据输入 int main() { string temp; ifstream myfile(\u0026quot;./date.txt\u0026quot;); if( !myfile ) { cout \u0026lt;\u0026lt; \u0026quot;open file fail!\u0026quot; \u0026lt;\u0026lt; endl; return -1; } vector\u0026lt;string\u0026gt; res; while (getline(myfile, temp)) {\t//默认停止符\\n stringstream slices(temp); string slice; while (slices \u0026gt;\u0026gt; slice) {\t// 类似cin输入，将每行排除不可显字符 空格等字符输入容器，直到接收回车为止 res.push_back(slice); // stoi(int), stol(long), stof(float), stod(double) } // for( auto r : res) //\tcout \u0026lt;\u0026lt; r \u0026lt;\u0026lt; endl; res.clear(); } myfile.close(); return 0; }  实际测试案例 上述测试确定无问题后，开始实际做python数据导入c++中做测试： 其中c++代码为leetcode题目搜索旋转排序数组 python生成数据函数即为上述代码的create_element2用于测试判断c++代码是否正确 接下来是c++的读取文件并进行调用。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;fstream\u0026gt; using namespace std; // 自己写的跟官方的思路差不多，官方答案不用先找到最大临界值再二分 直接进行判断二分 // 下面为官方答案，注意 边界 等于 问题 class Solution { public: int search(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { int n = (int)nums.size(); if (!n) return -1; else if (n == 1) return nums[0] == target ? 0 : -1; int l = 0, r = n - 1; while (l \u0026lt;= r) { int mid = (l + r) / 2; if (nums[mid] == target) return mid; // target判断是否为mid if (nums[0] \u0026lt;= nums[mid]) { // 说明0到mid是升序 if (nums[0] \u0026lt;= target \u0026amp;\u0026amp; target \u0026lt; nums[mid]) // target在该升序中 r = mid - 1; else l = mid + 1; } else { // 说明mid到n-1是升序 if (nums[mid] \u0026lt; target \u0026amp;\u0026amp; target \u0026lt;= nums[n - 1]) // target在该升序中 l = mid + 1; else r = mid - 1; } } return -1; } }; // 导入文本至容器测试，将每一行的数据以空格为间隔输入一个字符容器，将所有行的数据输入 int main() { string temp; ifstream myfile(\u0026quot;./date.txt\u0026quot;); if( !myfile ) { cout \u0026lt;\u0026lt; \u0026quot;open file fail!\u0026quot; \u0026lt;\u0026lt; endl; return -1; } vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; ress; vector\u0026lt;int\u0026gt; res; vector\u0026lt;int\u0026gt; targets; while (getline(myfile, temp)) {\t//默认停止符\\n stringstream slices(temp); string slice; while (slices \u0026gt;\u0026gt; slice) {\t// 类似cin输入，将每行排除不可显字符 空格等字符输入容器，直到接收回车为止 res.push_back(stoi(slice)); // stoi(int), stol(long), stof(float), stod(double) } getline(myfile, temp); targets.push_back(stoi(temp)); // for( auto rio : res) // cout \u0026lt;\u0026lt; rio \u0026lt;\u0026lt; endl; ress.push_back(res); res.clear(); } myfile.close(); Solution su; for (int i = 0; i \u0026lt; ress.size(); i++) { int ans = su.search(ress[i], targets[i]); cout \u0026lt;\u0026lt; targets[i] \u0026lt;\u0026lt; ' ' \u0026lt;\u0026lt; ans \u0026lt;\u0026lt;endl; } return 0; }  ","id":22,"section":"posts","summary":"思路 python的特性支持快速开发实用小程序的能力，能让你做事效率大幅度提高。特别是在c++数据测试中，检验一个程序的可靠性需要大量数据进行","tags":["python","C/C++"],"title":"Python随机数据生成","uri":"https://liangkang233.github.io/2021/05/python%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/","year":"2021"},{"content":"本人习惯使用onenote记录一些问题和做记录，最近发现开启本地http代理服务器后onenote无法同步，但是我代理配置是无误的。经过查询发现这个是uwp应用的特性：\nUWP 是微软在 Windows 10 中引入的新概念，由于所有 UWP 应用均运行在被称为 App Container 的虚拟沙箱环境中，其安全性及纯净度远胜于传统的 EXE 应用。但 App Container 机制同时也阻止了网络流量发送到本机（即 loopback）， 使大部分网络抓包调试工具无法对 UWP 应用进行流量分析。同样的，该机制也阻止了 UWP 应用访问 localhost，即使你在系统设置中启用了代理，也无法令 UWP 应用访问本地代理服务器。\n所以只要设置uwp应用可以访问本地代理服务器就能解决问题了。\n解决方法： 参考官方给的解决方案 要解决此问题，您需要使用PowerShell命令将有关应用添加到 Windows 10 回路豁免列表。 将带有\u0026quot;Microsoft.MinecraftUWP_8wekyb3d8bbwe\u0026quot;的包名的应用程序添加到循环回路豁免列表中。 要查找包名，您可以使用以下powershell命令：\nGet-AppxPackage #列出所有uwp应用程序。 Get-AppxPackage | Select-String -Pattern \u0026quot;Minecraft\u0026quot; #列出所有名字中含有“Minecraft”的应用程序。 CheckNetIsolation LoopbackExempt -d -n=\u0026quot;Microsoft.MinecraftUWP_8wekyb3d8bbwe\u0026quot; # 使用程序名字从豁免列表中剔除该程序 CheckNetIsolation LoopbackExempt -d -p=\u0026quot;sid编号\u0026quot; # 使用程序sid从豁免列表中剔除该程序 CheckNetIsolation LoopbackExempt -s #展示豁免列表 CheckNetIsolation LoopbackExempt -c #清除豁免列表  法1 查询注册表sid 举例：\nGet-AppxPackage | Select-String -Pattern \u0026quot;onenote\u0026quot;\t#查找onenote包名称 #查询到onenote 包名为 Microsoft.Office.OneNote_16001.13801.20202.0_x64__8wekyb3d8bbwe CheckNetIsolation LoopbackExempt -a -n=\u0026quot;Microsoft.Office.OneNote_16001.13801.20202.0_x64__8wekyb3d8bbwe\u0026quot; #添加至豁免列表 CheckNetIsolation LoopbackExempt -d -n=\u0026quot;Microsoft.Office.OneNote_16001.13801.20202.0_x64__8wekyb3d8bbwe\u0026quot; #从豁免列表中移除  法2 注册表查询程序包名 win+r 输入regedit，打开注册表编辑器，地址栏粘贴 HKEY_CURRENT_USER\\Software\\Classes\\Local Settings\\Software\\Microsoft\\Windows\\CurrentVersion\\AppContainer\\Mappings，里面的DisplayName值就是应用名称，查询对应程序的sid类似S-1-15-2-3445883232-1224167743-206467785-1580939083-2750001491-3097792036-3019341970形式\nCheckNetIsolation.exe loopbackexempt -a -p=UWP的SID CheckNetIsolation.exe loopbackexempt -d -p=UWP的SID #举例：豁免onenote走代理 CheckNetIsolation.exe loopbackexempt -a -p=S-1-15-2-3445883232-1224167743-206467785-1580939083-2750001491-3097792036-3019341970  onenote问题 可惜的是，法1对MinecraftUWP有效，对onenote失效。可能是其包名不对，该包名指向的是office套件中的onenote。打印如下的豁免表可知，法二生成的豁免表是生效的 法2生成\n列出环回免除的 AppContainer [1] ----------------------------------------------------------------- 名称: microsoft.office.onenote_8wekyb3d8bbwe SID: S-1-15-2-3445883232-1224167743-206467785-1580939083-2750001491-3097792036-3019341970 [2] ----------------------------------------------------------------- 名称: AppContainer NOT FOUND SID: S-1-15-2-3624051433-2125758914-1423191267-1740899205-1073925389-3782572162-737981194-4043415302-551583165-304772019-4009825106 [3] ----------------------------------------------------------------- 名称: 001 SID: S-1-15-2-3624051433-2125758914-1423191267-1740899205-1073925389-3782572162-737981194-4256926629-1688279915-2739229046-3928706915  法1生成\n列出环回免除的 AppContainer [1] ----------------------------------------------------------------- 名称: AppContainer NOT FOUND SID: S-1-15-2-883788003-1897955942-3642183005-638760255-2249287259-3707616651-3249579104 [2] ----------------------------------------------------------------- 名称: AppContainer NOT FOUND SID: S-1-15-2-3624051433-2125758914-1423191267-1740899205-1073925389-3782572162-737981194-4043415302-551583165-304772019-4009825106 [3] ----------------------------------------------------------------- 名称: 001 SID: S-1-15-2-3624051433-2125758914-1423191267-1740899205-1073925389-3782572162-737981194-4256926629-1688279915-2739229046-3928706915  ","id":23,"section":"posts","summary":"本人习惯使用onenote记录一些问题和做记录，最近发现开启本地http代理服务器后onenote无法同步，但是我代理配置是无误的。经过查询","tags":[],"title":"uwp应用代理","uri":"https://liangkang233.github.io/2021/04/uwp%E5%BA%94%E7%94%A8%E4%BB%A3%E7%90%86/","year":"2021"},{"content":"功能 之前想获得一段机器配音时，总是一句一句粘贴在翻译软件上读取，非常麻烦。 后来知道百度AI提供了免费的语音合成api，所以简单分享下使用方法。\n使用说明 百度智能云语音识别\n  首先打开上述网址点击立即开始注册或登录账号\n  创建一个应用并按照你的需求注册，当然不只是语音识别还有其他类似人脸识别图像处理等接口，但是大部分是要收费的。具体其他业务可以看看官方指南  这些我们可以不管，只需要注册语音识别应用，文本转语音业务包含在其中。注册好可以如下图领取免费额度。   最后配置完成后，下载python的sdk来安装,使用python setup.py install\n  其他组件 所有组件github地址: 百度AI python sdk地址. 其它功能也可类似调用接口实现，这里只是简单使用语音识别的文本语音转换功能。\n文本转语音测试 参考了官方的测试案例编写了下面的代码，有兴趣的可以试试其他api的调用，此代码python2 3皆可使用。\n# coding: utf-8 # 逐行读入source/test.txt文件，并创建audio1.mp3 audio2.mp3 audio3.mp3存入source文件夹中 ...... import sys import json IS_PY3 = sys.version_info.major == 3 if IS_PY3: from urllib.request import urlopen from urllib.request import Request from urllib.error import URLError from urllib.parse import urlencode from urllib.parse import quote_plus else: import urllib2 from urllib import quote_plus from urllib2 import urlopen from urllib2 import Request from urllib2 import URLError from urllib import urlencode API_KEY = '此处替换为你应用的API_KEY ' SECRET_KEY = '此处替换为你应用的SECRET_KEY' TEXT = \u0026quot;欢迎使用百度语音合成。\u0026quot; # 发音人选择，默认为度小美 # 基础音库：0为度小美，1为度小宇，3为度逍遥，4为度丫丫， # 精品音库：5为度小娇，103为度米朵，106为度博文，110为度小童，111为度小萌 PER = 3 # 语速，取值0-15，默认为5中语速 SPD = 6 # 音调，取值0-15，默认为5中语调 PIT = 5 # 音量，取值0-9，默认为5中音量 VOL = 7 # 下载的文件格式, 3：mp3(default) 4： pcm-16k 5： pcm-8k 6. wav AUE = 3 FORMATS = {3: \u0026quot;.mp3\u0026quot;, 4: \u0026quot;.pcm\u0026quot;, 5: \u0026quot;.pcm\u0026quot;, 6: \u0026quot;.wav\u0026quot;} FORMAT = FORMATS[AUE] CUID = \u0026quot;123456PYTHON\u0026quot; TTS_URL = 'http://tsn.baidu.com/text2audio' class DemoError(Exception): pass \u0026quot;\u0026quot;\u0026quot; TOKEN start \u0026quot;\u0026quot;\u0026quot; TOKEN_URL = 'http://openapi.baidu.com/oauth/2.0/token' SCOPE = 'audio_tts_post' # 有此scope表示有tts能力，没有请在网页里勾选 def fetch_token(): print(\u0026quot;fetch token begin\u0026quot;) params = {'grant_type': 'client_credentials', 'client_id': API_KEY, 'client_secret': SECRET_KEY} post_data = urlencode(params) if (IS_PY3): post_data = post_data.encode('utf-8') req = Request(TOKEN_URL, post_data) try: f = urlopen(req, timeout=5) result_str = f.read() except URLError as err: print('token http response http code : ' + str(err.code)) result_str = err.read() if (IS_PY3): result_str = result_str.decode() print(result_str) result = json.loads(result_str) print(result) if ('access_token' in result.keys() and 'scope' in result.keys()): if not SCOPE in result['scope'].split(' '): raise DemoError('scope is not correct') print('SUCCESS WITH TOKEN: %s ; EXPIRES IN SECONDS: %s' % (result['access_token'], result['expires_in'])) return result['access_token'] else: raise DemoError('MAYBE API_KEY or SECRET_KEY not correct: access_token or scope not found in token response') \u0026quot;\u0026quot;\u0026quot; TOKEN end \u0026quot;\u0026quot;\u0026quot; def tts(str, id): # tex = quote_plus(TEXT) tex = quote_plus(text[i]) # 此处TEXT需要两次urlencode print(tex) params = {'tok': token, 'tex': tex, 'per': PER, 'spd': SPD, 'pit': PIT, 'vol': VOL, 'aue': AUE, 'cuid': CUID, 'lan': 'zh', 'ctp': 1} # lan ctp 固定参数 data = urlencode(params) print('test on Web Browser' + TTS_URL + '?' + data) req = Request(TTS_URL, data.encode('utf-8')) has_error = False try: f = urlopen(req) result_str = f.read() headers = dict((name.lower(), value) for name, value in f.headers.items()) has_error = ('content-type' not in headers.keys() or headers['content-type'].find('audio/') \u0026lt; 0) except URLError as err: print('asr http response http code : ' + str(err.code)) result_str = err.read() has_error = True save_file = \u0026quot;error.txt\u0026quot; if has_error else \u0026quot;./source/result\u0026quot; + id + FORMAT #三目运算符 with open(save_file, 'wb') as of: of.write(result_str) if has_error: if (IS_PY3): result_str = str(result_str, 'utf-8') print(\u0026quot;tts api error:\u0026quot; + result_str) print(\u0026quot;result saved as :\u0026quot; + save_file) if __name__ == '__main__': token = fetch_token() text = [] file = open(\u0026quot;./source/test.txt\u0026quot;, 'r', encoding='UTF-8') while True: lines = file.readlines(100000) if not lines: break for line in lines: text.append(line) for i in range(len(text)): tts(text[i], str(i+1))  ","id":24,"section":"posts","summary":"功能 之前想获得一段机器配音时，总是一句一句粘贴在翻译软件上读取，非常麻烦。 后来知道百度AI提供了免费的语音合成api，所以简单分享下使用方法","tags":["python"],"title":"批量语音转文字","uri":"https://liangkang233.github.io/2021/04/%E6%89%B9%E9%87%8F%E8%AF%AD%E9%9F%B3%E8%BD%AC%E5%AD%97%E7%AC%A6/","year":"2021"},{"content":"功能 由于刚好有需求要更改配置文件参数，想到python简单易用的特点，所以边学边做了这个程序帮助修改参数。该程序功能为读取一个二进制文本其中的参数按照指定格式修改。\n参考教程 文件读写教程. 正则表达式教程. python的很多基础都是在廖雪峰老师这学的，写的很详细不错，所以后面的分析就不详细说了。\n源码 #!/usr/bin/python3 # coding: utf-8 speed = int(input(\u0026quot;Please enter the adjustment speed: \u0026quot;)) #修改test.config文件 with open('test.config', 'r', encoding='utf-8') as o_config : lines = o_config.readlines() # readlines返回每行字符串组成的list flen=len(lines) for i in range(flen): if lines[i].startswith(\u0026quot;SIMULATION-TIME\u0026quot;) : config_value = lines[i].split(' ') value = int( config_value[1][0:-2:1] ) # 用切片删去S和回车转成值 value = int(3600 / speed) lines[i] = config_value[0] + ' ' + str(value) + 'S\\n' break else : continue with open('test.config','w', encoding='utf-8') as new_config : new_config.writelines(lines) #修改test.nodes文件 with open('test.nodes', 'r', encoding='utf-8') as o_config : lines = o_config.readlines() # readlines返回每行字符串组成的list flen=len(lines) for i in range(flen): if lines[i] == '\\n' : break node_value = lines[i].split(' ', 2) if node_value[1] == '0' : continue else : value = int( node_value[1][0: -1:1] ) value = int( value / speed ) lines[i] = node_value[0] + ' ' + str(value) + 'S ' + node_value[2] with open('test.nodes','w', encoding='utf-8') as new_nodes : new_nodes.writelines(lines) print(\u0026quot;Modified to complete\u0026quot;)  代码分析  python修改文本暂时没找到直接更改办法，上述代码都是先读取文本复制到内存中的列表，修改后再将列表写入文件。 修改test.config文件代码，使用readlines返回每行字符串组成的list。当然也可以用readline和while读取每一行来进行操作。 使用startswith对每行行首判断寻找关键字符串类型，之后使用split空格分开为字符串列表后用切片提取出值对应的字符串。 例如下图中config文件会读取到lines[8]这行有待寻找关键字，用split生成list[\u0026lsquo;SIMULATION-TIME\u0026rsquo;, \u0026lsquo;3600S\\n\u0026rsquo;], 进行切片操作[1:-2:1]得到字符串'3600' (回车\\n也需要切片去除)，这样转化成int型处理完再转为字符串填充回原来列表中即可。  之后类似的对test.nodes进行操作!\n  此处，由于其配置文件规则简单由空格区分，所以处理起来只需要split和列表切片，若是复杂的字符串数据还是得用上面教程中的正则表达式来处理。 此外，如果需要更改参数精度更好的案例这里也提供一份\n#!/usr/bin/python3 #coding: utf-8 #修改 1.nodes文件 speed = 100 with open('1.nodes', 'r', encoding='utf-8') as o_config : lines = o_config.readlines() # readlines返回每行字符串组成的list flen=len(lines) for i in range(flen): if lines[i] == '\\n' : break node_value = lines[i].split(' ', 5) valuex = round( float( node_value[2][1: -1:1]) / speed,14 ) valuey = round( float( node_value[3][1: -1:1]) / speed,14 ) valuez = round( float( node_value[4][1: -1:1]) / speed,14 ) # lines[i] = node_value[0] + ' ' + node_value[1] + ' (' + \\ # str(valuex) + ', ' + str(valuey) + ', ' + str(valuez) + ') ' + node_value[5] lines[i] = node_value[0] + ' ' + node_value[1] + ' (' + \\ '%.014f'%valuex + ', ' + '%.014f'%valuey + ', ' + '%.014f'%valuez + ') ' + node_value[5] with open('1.nodes','w', encoding='utf-8') as new_nodes : new_nodes.writelines(lines) print(\u0026quot;Modified to complete\u0026quot;)  ","id":25,"section":"posts","summary":"功能 由于刚好有需求要更改配置文件参数，想到python简单易用的特点，所以边学边做了这个程序帮助修改参数。该程序功能为读取一个二进制文本其中","tags":["python"],"title":"Pthon读写文件","uri":"https://liangkang233.github.io/2021/03/python%E8%AF%BB%E5%86%99%E6%96%87%E4%BB%B6/","year":"2021"},{"content":"hello world 测试 老生常谈的hello world，在此之前的原blog帖子会归档本地草稿\n各测试项目文件 draft: true,\ntag: blog test\n  rich-content\n  emoji-support\n  markdown-syntax\n  placeholder-text\n  video test  .aspect-ratio { position: relative; width: 100%; height: 0; padding-bottom: 75%; } .aspect-ratio iframe { position: absolute; width: 100%; height: 100%; left: 0; top: 0; }   \n  ","id":26,"section":"posts","summary":"hello world 测试 老生常谈的hello world，在此之前的原blog帖子会归档本地草稿 各测试项目文件 draft: true, tag: blog test rich-content emoji-support markdown-syntax placeholder-text video test .aspect-ratio { position: relative; width: 100%; height: 0; padding-bottom: 75%; } .aspect-ratio iframe","tags":["blog test"],"title":"Hello World","uri":"https://liangkang233.github.io/2020/12/hello-world/","year":"2020"},{"content":"","id":27,"section":"posts","summary":"","tags":null,"title":"","uri":"https://liangkang233.github.io/1/01/%E8%8F%9C%E9%B8%9F%E5%BB%BA%E6%A8%A1%E5%9B%A7%E4%BA%8B/","year":"0001"}],"tags":[{"title":"blog test","uri":"https://liangkang233.github.io/tags/blog-test/"},{"title":"C/C++","uri":"https://liangkang233.github.io/tags/c/c++/"},{"title":"go","uri":"https://liangkang233.github.io/tags/go/"},{"title":"linux","uri":"https://liangkang233.github.io/tags/linux/"},{"title":"network","uri":"https://liangkang233.github.io/tags/network/"},{"title":"python","uri":"https://liangkang233.github.io/tags/python/"},{"title":"仿真","uri":"https://liangkang233.github.io/tags/%E4%BB%BF%E7%9C%9F/"},{"title":"数据结构","uri":"https://liangkang233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"算法","uri":"https://liangkang233.github.io/tags/%E7%AE%97%E6%B3%95/"}]}